{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Red-Utils","text":"<p>Warning</p> <p>This is my first Python package. I'm experimenting with CI/CD and Pypi. This library is most likely not useful to anyone else, may be broken at times, may undergo refactors with little to no notice/documentation, and all that other awful stuff that comes with being an amateur developer doing this in their free time \ud83d\ude43</p> <p>My personal collection of Python utilities (modules, functions, etc)</p>"},{"location":"#description","title":"Description","text":"<ul> <li>\ud83d\udd17 Project Home - Github Repository</li> <li>\ud83d\udc0d Red Utils on Pypi</li> <li>\ud83d\udcd6 Red Utils Docs</li> </ul> <p>A collection of utility scripts/functions that I use frequently. Includes helper functions/default variables for libraries like <code>loguru</code>, <code>diskcache</code>, and <code>msgpack</code>.</p> <p>The utilities are broken down into 2 modules:</p> <ul> <li><code>std</code>: Utilities with no external dependencies, only the Python <code>stdlib</code>.</li> <li><code>ext</code>: Utilities for dependencies like <code>loguru</code> and <code>msgpack</code></li> <li>Note: It is generally a good practice to import <code>ext</code> modules as a whole, instead of importing functions/variables from the module.</li> <li>This is because some of the function names I chose may be common (like <code>get_ts()</code> in the <code>ext.time_utils</code> module).</li> <li>Example:</li> </ul> Example: Import time_utils<pre><code>from red_utils.ext import time_utils\n\nnow = time_utils.get_ts()\n</code></pre> <p>or, with <code>pendulum</code>: <pre><code>from red_utils.ext.time_utils import pendulum_utils\n\nnow = pendulum_utils.get_ts()\n</code></pre></p> <p>Common code shared by the <code>std</code> and <code>ext</code> modules can be imported from <code>red_utils.core</code> and <code>red_utils.domain</code>. Any code in these modules should be clean of any external dependency. This is because the <code>std</code> module imports from <code>core</code>, and adding non-stdlib functionality in <code>red_utils.core</code> breaks the philosophy of the <code>stdlib</code> module. I may introduce a <code>red_utils.ext.core</code> at some point.</p> <p>Some domain objects (<code>dataclass</code> or regular Python classes) may be stored in <code>red_utils.domain</code>. As of release <code>v0.2.12</code>, this module is empty, but future releases may bring some utilities in the form of a class.</p> <p>Custom/common exceptions are stored in <code>red_utils.exc</code>.</p>"},{"location":"#dynamic-imports","title":"Dynamic imports","text":"<p>The <code>red-utils</code> package makes use of the Python stdlib <code>pkgutil</code> module to control imports. Packages in the <code>ext</code> module are only imported and available in <code>red_utils</code> if the corresponding dependency exists.</p> <p>For instance, <code>red_utils.ext.msgpack_utils</code> will only be available if this check in src/red_utils/ext passes: <pre><code>import pkgutil\n\n...\n\nif pkgutil.find_loader(\"msgpack\"):\n  from . import msgpack_utils\n</code></pre></p> <p><code>pkgutil.find_loader()</code> is used throughout the app to control imports and ensure <code>red_utils</code> is stable, by keeping uninstalled module's utilities out of the namespace.</p>"},{"location":"git_prune_script/","title":"Git prune script","text":"<p>This repository includes a prototype of a script I'm working on to keep my local repositories in check. I get tired of running the command to check for and remove branches in my local repository that I've deleted on the remote, so this script automates that takes.</p> <p>Script execution is configurable with CLI args, parsed with Python's <code>argparser</code>. To see a full list of arguments and their help text, run <code>python -m git_prune.py -h</code>.</p> <p>By default this script will not make any changes on the following branches:</p> <ul> <li>main</li> <li>master</li> <li>dev</li> <li>rc</li> <li>gh-pages</li> </ul> <p>To add more protected branches, run the script with <code>-p</code> and a branch name, i.e. <code>-p staging</code> <code>-p build</code> <code>-p release</code>.</p>"},{"location":"git_prune_script/#requirements","title":"Requirements","text":"<p>This script requires the <code>GitPython</code> package. Install the package with <code>pip install GitPython</code>, or your preferred package manager.</p>"},{"location":"git_prune_script/#usage","title":"Usage","text":"<p>Run this script as a module.</p> <p>Example</p> <p>Run the script with one or more args</p> <pre><code>python -m git_prune &lt;args&gt;\n</code></pre> <p>See available args, arg descriptions, and usage examples</p> <pre><code>python -m git_prune -h\n</code></pre>"},{"location":"git_prune_script/#prevent-accidental-deletions-with-dry-run","title":"Prevent accidental deletions with <code>--dry-run</code>","text":"<p>Run the script with <code>--dry-run</code> to prevent modifications on local branches, instead printing a message describing the action that would have been taken.</p> <p>Example</p> <pre><code>python -m git_python --dry-run\n</code></pre>"},{"location":"git_prune_script/#pass-protected-branches-with-nargs","title":"Pass protected branches with <code>nargs</code>","text":"<p>To add more branches that should be ignored in the local repository, you can either modify the <code>PROTECTED_BRANCHES</code> list below (not recommended), or you can pass additional protected branches with <code>-p</code>.</p> <p>Example</p> <p>Protect the branches <code>ci</code> and <code>stage</code>:</p> <pre><code>python -m git_prune -r &lt;repo_path&gt; -p \"ci\" -p \"stage\"\n</code></pre>"},{"location":"git_prune_script/#attempt-to-force-deletion","title":"Attempt to force deletion","text":"<p><code>git_prune</code> will first attempt to delete a branch with <code>git branch -d &lt;branch&gt;</code>. If this fails and you passed the <code>-f/--force</code> flag, a retry attempt will be made using <code>git branch -D &lt;branch&gt;</code>. If this also fails, a third and final attempt will be made using the host's git by running the command <code>git branch -D &lt;branch&gt;</code> through the <code>subprocess.run()</code> command.</p> <p>Example</p> <p>Run the cleanup script, attempt to force delete any branches that fail on the first pass</p> <pre><code>python -m git_prune -r &lt;repo_path&gt; -f\n</code></pre>"},{"location":"git_prune_script/#script-description-and-code","title":"Script: Description and code","text":"<p>After installing the <code>GitPython</code> package, copy this script into a file called <code>git_python.py</code>. Run the script in the same environment you installed <code>GitPython</code> in.</p> <p>Examples:</p> <p>Using a Python `virtualenv</p> <p>Venv</p> <p>Create virtualenv. You only need to do this once, when you first initialize a project. <pre><code>virtualenv .venv\n</code></pre></p> <p>Activate the <code>.venv</code>.  Do this every time you run this script, before you run it.</p> <ul> <li> <p>Windows <pre><code>. .\\.venv\\Scripts\\activate  # Windows\n</code></pre></p> </li> <li> <p>Linux/Mac <pre><code>. .venv/bin/activate  # Linux/Mac\n</code></pre></p> </li> </ul> <p>Install GitPython in the environment. You only need to do this when you first create your .venv <pre><code>pip install GitPython\n</code></pre></p> <p>Using the <code>pdm</code> project manager</p> <p>Pdm</p> <p>Initialize a pdm project. You only need to do this if no pyproject.toml file exists yet. <pre><code>pdm init\n</code></pre></p> <p>Add the GitPython dependency <pre><code>pdm add GitPython\n</code></pre></p> <p>Run the script without activating the <code>.venv</code> <pre><code>pdm run python -m git_prune.py -r &lt;path/to/repo&gt; -p \"protected_branch_name1\" -p \"protected_branch_name2\" --dry-run\n</code></pre></p> <p>Activate the <code>.venv</code> and run directly <pre><code># . .venv\\Scripts\\Activate on Windows\n. .venv/bin/activate\n\npython -m git_prune.py -r &lt;path/to/repo&gt; -p \"protected_branch_name1\" -p \"protected_branch_name2\" --dry-run\n</code></pre></p>"},{"location":"git_prune_script/#run-the-script","title":"Run the script","text":"<pre><code>python -m git_prune.py -r &lt;path/to/repo&gt; -p \"protected_branch_name1\" -p \"protected_branch_name2\" --dry-run\n</code></pre>"},{"location":"git_prune_script/#git_prunepy","title":"git_prune.py","text":"git_prune.py<pre><code>\"\"\"Cleanup your local git environment.\n\nDescription:\n    This script compares git branches in a specified repository path,\n    defaulting to the directory this script is run from i.e. \".\",\n    with branches on the remote, deleting any local branches not found on the remote.\n\n    This helps by cleaning up branches that have been deleted from the remote, for example a merged feature or fix.\n\n    By default, the script will not touch the following branches if they are found, regardless of their presence on the remote:\n        - main\n        - master\n        - dev\n        - rc\n        - gh-pages\n\n    See the `Usage` section for instructions on passing CLI args, adding more protected branch names, etc.\n\nUsage:\n    Run this script as a module, i.e. `python -m git_prune &lt;args&gt;`. To see available args and their description, run `python -m git_prune -h`.\n\n    ## Prevent accidental deletions with `--dry-run`\n\n    Run the script with `--dry-run` to prevent modifications on local branches,\n    instead printing a message describing the action that would have been taken.\n\n    ## Pass protected branches with `nargs`\n\n    To add more branches that should be ignored in the local repository,\n    you can either modify the `PROTECTED_BRANCHES` list below (not recommended),\n    or you can pass additional protected branches with `-p`.\n\n    For example, to protect the branches `ci` and `stage`, you would run `python -m git_prune -r &lt;repo_path&gt; -p \"ci\" -p \"stage\".\n\n    ## Attempt to force deletion\n\n    `git_prune` will first attempt to delete a branch with `git branch -d &lt;branch&gt;`. If this fails and you passed the `-f/--force` flag,\n    a retry attempt will be made using `git branch -D &lt;branch&gt;`. If this also fails, a third and final attempt will be made using the host's\n    git by running the command `git branch -D &lt;branch&gt;` through the `subprocess.run()` command.\n\n\"\"\"\n\nfrom __future__ import annotations\n\nimport argparse\nimport logging\nimport platform\nimport subprocess\nimport typing as t\n\nlog: logging.Logger = logging.getLogger(\"git_prune\")\nlogging.getLogger(\"git\").setLevel(\"WARNING\")\n\nimport git\n\nDEFAULT_REPO_PATH: str = \".\"\nPROTECTED_BRANCHES: list[str] = [\"main\", \"master\", \"dev\", \"rc\", \"gh-pages\"]\n\n\ndef get_default_python() -&gt; str:\n    \"\"\"Detect Python version from environment.\n\n    Returns:\n        (str): The detected Python version, in format 'major.minor' i.e. '3.11'.\n\n    \"\"\"\n    pyver_tuple: tuple[str, str, str] = platform.python_version_tuple()\n    pyver: str = f\"{pyver_tuple[0]}.{pyver_tuple[1]}\"\n\n    return pyver\n\n\ndef is_git_installed() -&gt; bool:\n    \"\"\"Detect GitPython package.\n\n    Returns:\n        (True): If `GitPython` package is detected in environment.\n        (False): If `GitPython` package is not detected in environment.\n\n    \"\"\"\n    try:\n        import git\n\n        return True\n    except ImportError:\n        return False\n\n\ndef append_protected_branch(\n    protected_branches: list[str] = PROTECTED_BRANCHES, append_branch: str = None\n) -&gt; list[str]:\n    \"\"\"Add a branch to the existing list of protected branch names.\n\n    Params:\n        protected_branches (list[str]): Existing list of protected branch names.\n        append_branch (str): Name of branch to append to list of protected branch names.\n\n    Returns:\n        (list[str]): A list of strings representing git branch names that should not be altered.\n\n    \"\"\"\n    if protected_branches is None:\n        ## Initialize empty list\n        protected_branches: list[str] = []\n\n    if append_branch is None:\n        ## No branch names to append, return protected_branches\n        return protected_branches\n\n    else:\n        ## Append branch and return\n        protected_branches.append(append_branch)\n        return protected_branches\n\n\nPYTHON_VERSION: str = get_default_python()\nGIT_INSTALLED: bool = is_git_installed()\n\n\ndef get_local_branches(repo: git.Repo = None) -&gt; list[str]:\n    \"\"\"Get list of branch names detected in local repository.\n\n    Params:\n        repo (git.Repo): An initialized `git.Repo` instance.\n\n    Returns:\n        (list[str]): List of local git branches.\n\n    \"\"\"\n    ## Get a list of local branches\n    local_branches: list[str] = [head.name for head in repo.heads]\n\n    return local_branches\n\n\ndef get_remote_branches(repo: git.Repo = None) -&gt; list[str]:\n    \"\"\"Get list of branch names detected in remote repository.\n\n    Params:\n        repo (git.Repo): An initialized `git.Repo` instance.\n\n    Returns:\n        (list[str]): List of remote git branches.\n\n    \"\"\"\n    ## Get a list of remote branches\n    remote_branches: list[str] = [\n        ref.name.replace(\"origin/\", \"\") for ref in repo.remotes.origin.refs\n    ]\n\n    return remote_branches\n\n\ndef get_delete_branches(\n    repo: git.Repo = None,\n    local_branches: list[str] = None,\n    remote_branches: list[str] = None,\n    protected_branches: list[str] = PROTECTED_BRANCHES,\n) -&gt; list[str]:\n    \"\"\"Compare local &amp; remote git branches, return list of branch names to delete.\n\n    Params:\n        repo (git.Repo): An initialized `git.Repo` instance. Needed for instances where\n            local_branches or remote_branches are empty/None.\n        local_branches (list[str]): List of branch names found in local repository.\n        remote_branches (list[str]): List of branch names found in remote repository.\n        protected_branches (list[str]): List of branch names that will not be altered.\n\n    Returns:\n        (list[str]): List of git branches to delete from local repository.\n\n    \"\"\"\n    if local_branches is None or remote_branches is None:\n        if repo is None:\n            raise ValueError(\n                \"Missing list of local and/or remote branch names, and no git.Repo object detected. Cannot determine list of branches.\"\n            )\n\n    if local_branches is None:\n        ## Get list of local branch names\n        local_branches = get_local_branches(repo=repo)\n\n    if remote_branches is None:\n        ## Get list of remote branch names\n        remote_branches = get_remote_branches(repo=repo)\n\n    ## Find local branches that are not present in remote branches\n    branches_to_delete: list[str] = [\n        branch\n        for branch in local_branches\n        if (branch not in remote_branches) and (branch not in protected_branches)\n    ]\n\n    return branches_to_delete\n\n\ndef delete_branches(\n    repo: git.Repo = None,\n    branches_to_delete: list[str] = None,\n    force: bool = False,\n    protected_branches: list[str] = PROTECTED_BRANCHES,\n) -&gt; list[str]:\n    \"\"\"Run git branch delete operation on list of branches.\n\n    Params:\n        repo (git.Repo): An initialized `git.Repo` instance.\n        branches_to_delete (list[str]): List of branches to delete from local repository.\n        force (bool): If `True`, delete operations will be retried if they fail. The first attempt will retry using\n            the `-d` flag, and if that fails the function will attempt to use the host's `git` via `subprocess`.\n        protected_branches (list[str]): List of branch names that will not be altered.\n\n    Returns:\n        (list[str]): The list of branches deleted from the local repository.\n\n    \"\"\"\n    deleted_branches: list[str] = []\n\n    ## Iterate over list of branches to delete\n    for branch in branches_to_delete:\n        ## Avoid deleting specified branches\n        if branch not in protected_branches:\n            try:\n                repo.git.branch(\"-d\", branch)\n                log.info(f\"Deleted branch '{branch}'\")\n\n                deleted_branches.append(branch)\n\n            except git.GitError as git_err:\n                msg = Exception(\n                    f\"Git error while deleting branch '{branch}'. Details: {git_err}\"\n                )\n\n                ## Retry with -D if force=True\n                if force:\n                    log.warning(\n                        \"First attempt failed, but force=True. Attempting to delete with -D\"\n                    )\n                    try:\n                        repo.git.branch(\"-D\", branch)\n                        log.info(f\"Force-deleted branch '{branch}'\")\n\n                        deleted_branches.append(branch)\n\n                    except git.GitError as git_err2:\n                        msg2 = Exception(\n                            f\"Git error while force deleting branch '{branch}'. Details: {git_err2}\"\n                        )\n                        log.warning(\n                            f\"Branch '{branch}' was not deleted. Reason: {msg2}\"\n                        )\n\n                        ## Retry with subprocess\n                        try:\n                            log.info(\"Retrying one more time using subprocess.\")\n                            subprocess.run([\"git\", \"branch\", \"-D\", branch], check=True)\n                            log.info(\n                                f\"Force-deleted branch '{branch}'. Required fallback to subprocess.\"\n                            )\n\n                            deleted_branches.append(branch)\n\n                        except subprocess.CalledProcessError as git_err3:\n                            msg3 = f\"Git error while force deleting branch '{branch}' using subprocess. Details: {git_err3}\"\n                            log.warning(\n                                f\"Branch '{branch}' was not deleted. Reason: {msg3}\"\n                            )\n\n                        except Exception as exc:\n                            msg = f\"Unhandled exception attempting to delete git branch '{branch}' using subprocess.run(). Details: {exc}\"\n                            log.error(msg)\n\n                ## force=false, do not retry with Subprocess\n                else:\n                    log.warning(f\"Branch '{branch}' was not deleted. Reason: {msg}\")\n\n                continue\n\n    return deleted_branches\n\n\ndef clean_branches(\n    repo_path: str = DEFAULT_REPO_PATH,\n    dry_run: bool = False,\n    force: bool = False,\n    protected_branches: list[str] = PROTECTED_BRANCHES,\n) -&gt; list[str] | None:\n    \"\"\"Params:\n        repo_path (str): (Default: \".\") Path to the local git repository.\n        dry_run (bool): If `True`, skip all operations that would alter git branches.\n        force (bool): If `True`, when `git branch -d` fails, function will retry with `-D`.\n            If this fails, a final attempt will be made using the host's `git` via `subprocess`.\n        protected_branches (list[str]): List of branch names that will not be altered.\n\n    Returns:\n        (list[str]): List of branches deleted from local repository.\n\n    \"\"\"\n\n    def init_repo(repo_path: str = repo_path) -&gt; git.Repo:\n        ## Initialize repository\n        try:\n            repo = git.Repo(path=repo_path)\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception initializing git.Repo object for repository path '{repo_path}'. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n        ## Fetch latest changes &amp; prune deleted branches\n        try:\n            repo.git.fetch(\"--prune\")\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception fetching branches from remote. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n        return repo\n\n    log.info(\"Cleaning local branches that have been deleted from the remote.\")\n\n    ## Initialize repository &amp; do a git fetch --prune\n    repo: git.Repo = init_repo()\n\n    ## Get list of branch names in local repository\n    local_branches: list[str] = get_local_branches(repo=repo)\n    log.info(f\"Found [{len(local_branches)}] local branch(es).\")\n\n    if len(local_branches) &lt; 15:\n        ## Print local branches if there are less than 15\n        log.debug(f\"Local branches: {local_branches}\")\n\n    ## Get list of branch names in remote repository\n    remote_branches: list[str] = get_remote_branches(repo=repo)\n    log.info(f\"Found [{len(remote_branches)}] remote branch(es).\")\n\n    if len(remote_branches) &lt; 15:\n        ## Print remote branches if there are less than 15\n        log.debug(f\"Remote branches: {remote_branches}\")\n\n    ## Compare local &amp; remote branches, return list of branches in local that are not in remote\n    branches_to_delete: list[str] = get_delete_branches(\n        local_branches=local_branches,\n        remote_branches=remote_branches,\n        protected_branches=protected_branches,\n    )\n    log.info(f\"Prepared [{len(branches_to_delete)}] branch(es) for deletion.\")\n\n    if len(branches_to_delete) &lt; 15:\n        ## Print branches to delete if there are less than 15\n        log.debug(f\"Deleting branches: {branches_to_delete}\")\n\n    ## Terminate early if dry_run=True\n    if dry_run:\n        log.warning(f\"dry_run=True, terminating early to avoid accidental deletion.\")\n        log.warning(f\"Would have deleted [{len(branches_to_delete)}] branch(es).\")\n        for b in branches_to_delete:\n            log.warning(f\"[DRY RUN] Would delete branch: {b}\")\n\n        return\n\n    else:\n        ## Delete local branches\n        try:\n            deleted_branches: list[str] = delete_branches(\n                repo=repo,\n                branches_to_delete=branches_to_delete,\n                protected_branches=protected_branches,\n                force=force,\n            )\n\n            return deleted_branches\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception deleting git branches. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n\ndef program_args() -&gt; list[tuple[list[str], dict[str, str]]] | None:\n    \"\"\"Define arguments for this script's parser.\n\n    Usage:\n        This method should be rewritten for each new script it's used in.\n            The existing code can be used as a reference, but every script requires\n            different args and the code in this function may not suit your script.\n\n    Returns:\n        (list[tuple[list[str], dict[str, str]]] | None): A tuple to be passed to the `parse_cli_args()` method, containing\n            argument flags/actions/help strings.\n\n    \"\"\"\n    ## Define list of args for script to parse\n    add_args: list[tuple[list[str], dict[str, str]]] = [\n        (\n            [\"--dry-run\"],\n            {\n                \"action\": \"store_true\",\n                \"help\": \"Prevent any git operations from occurring, print messages indicating what would have happened.\",\n            },\n        ),\n        (\n            [\"-v\", \"--verbose\"],\n            {\n                \"action\": \"store_true\",\n                \"help\": \"Set logging level to DEBUG.\",\n            },\n        ),\n        (\n            [\"-f\", \"--force\"],\n            {\n                \"action\": \"store_true\",\n                \"help\": \"If GitPython module fails to delete branch with git branch -d and -D, attempt to delete the branch with the host's git using subprocess.\",\n            },\n        ),\n        (\n            [\"-r\", \"--repo-path\"],\n            {\n                \"type\": str,\n                \"help\": 'Specify the file path to the git repository. If no option is passed, uses \".\", i.e. the directory where this script was run.',\n            },\n        ),\n        (\n            [\"-p\", \"--protected-branches\"],\n            {\n                \"nargs\": \"+\",\n                \"help\": 'Specify additional protected branches. Can be used multiple times, i.e. -p \"branch1\" -p \"branch2\".',\n                \"metavar\": \"BRANCH\",\n            },\n        ),\n    ]\n\n    return add_args\n\n\ndef parse_cli_args(\n    program_name: str | None = __name__,\n    usage: str | None = None,\n    description: str | None = None,\n    add_args: list[tuple[list[str], dict[str, str]]] | None = None,\n) -&gt; argparse.Namespace:\n    \"\"\"Parse arguments passed when this script runs.\n\n    Usage:\n        Call this function and assign it to a variable, like `args = parse_cli_args()`. Parsed\n            args will be available via dot notation, for example an arg named `--verbose` will be available\n            at `args.verbose`.\n\n        Pass options/args as a list of tuples, see example of args/flags passed to `parse_cli_args(add_args=add_args)`:\n\n        ```python title=\"Example add_args values\" linenums=\"1\"\n            add_args = [\n                (\n                    [\"-v\", \"--verbose\"],\n                    {\n                        \"action\": \"store_true\",\n                        \"help\": \"Set logging level to DEBUG.\",\n                    },\n                ),\n\n\n                (\n                    [\"--name\"],\n                    {\"type\": str, \"help\": \"Specify the name to be used in the operation.\"},\n                ),\n            ]\n        ```\n\n    Params:\n        program_name (str): Name of the script/program for help menu.\n        usage (str):  String describing how to call the app.\n        description (str): Description of the script/program for help menu.\n        add_args (list[tuple[list[str], dict[str, str]]] | None): List of tuples\n            representing args to add to the parser.\n\n    Returns:\n        (argparse.Namespace): An object with parsed arguments. Arguments are accessible by their name, for\n            example an argument `--verbose` is accessible at `args.verbose`. If an argument has a hyphen, like `--dry-run`,\n            the hyphen becomes an underscore, i.e. `args.dry_run`.\n\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        prog=program_name, usage=usage, description=description\n    )\n\n    ## Add arguments from add_args list\n    if add_args:\n        try:\n            for flags, kwargs in add_args:\n\n                parser.add_argument(*flags, **kwargs)\n        except ValueError as parse_err:\n            msg = ValueError(\n                f\"Error adding flag(s) '{flags}' to parser. Details: {parse_err}\"\n            )\n            log.error(msg)\n\n            raise exc\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception adding argument to parser. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    else:\n        ## Uncomment to add default arguments\n        # parser.add_argument(\"--dry-run\", action=\"store_true\")\n        # parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\")\n\n        pass\n\n    args: argparse.Namespace = parser.parse_args()\n\n    return args\n\n\ndef setup(\n    log_msg_fmt: (\n        str | None\n    ) = \"%(asctime)s | %(levelname)s | %(name)s.%(funcName)s():%(lineno)d |&gt; %(message)s\",\n    log_msg_datefmt: str = \"%Y-%M-%d %H:%m:%S\",\n) -&gt; argparse.Namespace:\n    \"\"\"Run program setup.\n\n    Params:\n        log_msg_fmt (str): The format string for logging messages.\n        log_msg_datefmt (str): The format for timestamps on logging messages.\n\n    Returns:\n        (argparse.Namespace): An object with parsed arguments. Arguments are accessible by their name, for\n            example an argument `--verbose` is accessible at `args.verbose`. If an argument has a hyphen, like `--dry-run`,\n            the hyphen becomes an underscore, i.e. `args.dry_run`.\n\n    \"\"\"\n    add_args: list[tuple[list[str], dict[str, str]]] | None = program_args()\n    args: argparse.Namespace = parse_cli_args(\n        program_name=\"python -m git_prune\",\n        add_args=add_args,\n        description=\"Delete local branches that have been removed from the remote. Use --dry-run to prevent any actions on git branches.\",\n    )\n\n    logging.basicConfig(\n        level=\"DEBUG\" if args.verbose else \"INFO\",\n        format=log_msg_fmt,\n        datefmt=log_msg_datefmt,\n    )\n\n    log.debug(\n        f\"Repository path: {args.repo_path}, Dry run: {args.dry_run}, Verbose: {args.verbose}, Force: {args.force}\"\n    )\n\n    return args\n\n\ndef main(\n    repo_path: str = DEFAULT_REPO_PATH,\n    dry_run: bool = False,\n    force: bool = False,\n    protected_branches: list[str] = PROTECTED_BRANCHES,\n) -&gt; list[str]:\n    \"\"\"Method to run when this script is called directly.\n\n    Params:\n        repo_path (str): (Default: \".\") Path to the local git repository.\n        dry_run (bool): If `True`, skip all operations that would alter git branches.\n        force (bool): If `True`, when `git branch -d` fails, function will retry with `-D`.\n            If this fails, a final attempt will be made using the host's `git` via `subprocess`.\n        protected_branches (list[str]): List of branch names that will not be altered.\n\n    Returns:\n        (list[str]): A list of branches deleted from the local repository.\n\n    \"\"\"\n    log.debug(f\"Found git: {GIT_INSTALLED}\")\n    log.debug(f\"Python version: {PYTHON_VERSION}\")\n    log.debug(f\"Protected branches: {protected_branches}\")\n\n    deleted_branches: list[str] = clean_branches(\n        repo_path=repo_path,\n        dry_run=dry_run,\n        force=force,\n        protected_branches=protected_branches,\n    )\n\n    if deleted_branches:\n        ## Re-check local branches\n        _local_branches: list[str] = get_local_branches()\n\n        log.debug(f\"Refreshed local branches: {_local_branches}\")\n\n    return deleted_branches\n\n\nif __name__ == \"__main__\":\n    ## Run argument parser &amp; logging config, get list of args from cli\n    args: argparse.Namespace = setup()\n    ## Initialize list of branch names to add to PROTECTED_BRANCHES.\n    #  Do not modify this list directly. Use extra_protected_branches.append(\"branch_name\") on lines below\n    extra_protected_branches: list[str] = []\n\n    protected_branches: list[str] = PROTECTED_BRANCHES + extra_protected_branches\n    main(\n        repo_path=args.repo_path,\n        dry_run=args.dry_run,\n        force=args.force,\n        protected_branches=protected_branches,\n    )\n</code></pre>"},{"location":"dev/developing/","title":"Setup dev environment","text":"<p>These notes are mostly for me, but I suppose if anyone ever takes an interest in submitting a pull request, the documentation here will help get the local dev environment set up.</p>"},{"location":"dev/developing/#requirements","title":"Requirements","text":"<ul> <li>PDM</li> <li><code>pdm</code> is used to manage this package and its dependencies</li> <li>Take a look at the project's <code>pyproject.toml</code> for available dependency groups. As you develop modules, consider which dependency group they belong in, i.e. most dependencies should not be added to the default dependency group.<ul> <li>If you are working on a FastAPI module, for example, add new dependencies to the <code>fastapi</code> and <code>all</code> groups.</li> <li><code>pdm add -G fastapi &lt;package&gt;</code></li> <li><code>pdm add -G all &lt;package&gt;</code></li> </ul> </li> <li>There are also a number of project scripts configured in the <code>pyproject.toml</code> file, which aid in development<ul> <li>Scripts are declared in sections that look like <code>[tool.pdm.scripts.&lt;script-name&gt;]</code>, and can be called with <code>pdm run &lt;script-name&gt;</code></li> <li>For example, to run the PDM script that calls <code>black</code> and <code>ruff</code> to format code:<ul> <li><code>pdm run lint</code></li> </ul> </li> <li>To run the PDM script that exports a <code>requirements.txt</code> file:<ul> <li><code>pdm run export</code></li> </ul> </li> </ul> </li> <li>(Optional) Pre-commit</li> <li>There are some <code>pre-commit</code> scripts configured, too, for things like linting/formatting the code during commit.<ul> <li>To see configured <code>pre-commit</code> steps, check <code>.pre-commit-config.yaml</code></li> </ul> </li> <li>To use these <code>pre-commit</code> scripts, they need to be installed locally with <code>pdm run pre-commit install</code></li> <li>To disable the pre-commit hooks, run <code>pdm run pre-commit uninstall</code></li> </ul>"},{"location":"dev/developing/#using-the-vscode-workspace","title":"Using the VSCode Workspace","text":"<p>If you use Visual Studio Code as your text editor, you can open the workspace in the <code>.vscode</code> directory to have a more focused view of the code.</p>"},{"location":"dev/developing/#developing-new-modules","title":"Developing new modules","text":"<p>The <code>red-utils</code> package separates modules into <code>std</code> and <code>ext</code>, which are respectively modules that require only the modules in the Python stdlib, or extended modules that require external dependencies.</p> <p>Any modules in the <code>red_utils.std</code> package should rely only on Python stdlib packages. In fact, anything outside of the <code>red_utils.ext</code> module should rely only on the Python stdlib (i.e. <code>red_utils.core</code>, <code>red_utils.domain</code>).</p> <p>If developing a utility for an external dependency (like <code>sqlalchemy</code>, <code>fastapi</code>, <code>pandas</code>/<code>polars</code>, etc), add the module to the <code>red_utils.ext</code> group and keep all code related to that dependency beneath the <code>red_utils.ext</code> module.</p> <p>You can reference other modules in <code>red_utils.ext</code> to learn how to use <code>pkgutils</code> to control import flow. There are many <code>if pkgutil.find_loader(\"&lt;package-name&gt;\")</code> lines throughout the <code>red-utils</code> app; the <code>.find_loader()</code> function searches for a package in the global namespace, and if it is not found, that module is not imported. This helps keep <code>red-utils</code> stable if, for example, a user installs a dependency group instead of the entirety of <code>red-utils</code>.</p> <p>As an example real-world scenario, if a user installs <code>red-utils[http]</code>, they will only have access to the <code>red_utils.ext</code> modules for dependencies in the <code>http</code> dependency group in the project's <code>pyproject.toml</code>. A package like <code>sqlalchemy</code> is not installed with this group, and so <code>red_utils.ext.sqlalchemy_utils</code> will not be imported or available to the user. Type hinting in an IDE will not suggest <code>red_utils.ext.sqlalchemy_utils</code> as an importable module, and <code>red-utils</code> will skip any modules looking for <code>sqlalchemy</code>.</p>"},{"location":"dev/developing/#testing-with-pdm","title":"Testing with PDM","text":"<p>You can test a new build before pushing a release by creating a new PDM project somewhere else on the system and importing the path to the <code>red-utils</code> repository.</p> <p>For example, if creating a module <code>pandas_utils</code> for utility functions related to <code>Pandas DataFrames</code>, and assuming the <code>red-utils</code> repository was cloned to <code>~/git/red-utils</code>, you would follow a process like the following:</p> <ul> <li>In the <code>~/git/red-utils</code> directory, install <code>pandas</code> in the <code>[all]</code> and <code>[data]</code> dependency groups</li> <li><code>pdm add -G all pandas</code></li> <li><code>pdm add -G data pandas</code></li> <li>Create a directory at <code>red_utils.ext.pandas_utils</code></li> <li>In this directory, create a file <code>operations.py</code> and add some utility functions (such as a function to scan a directory and load all CSV files into a DataFrame).</li> <li>Create <code>red_utils/ext/pandas_utils/__init__.py</code>:<ul> <li>Contents of <code>__init__.py</code>: <pre><code>from .operations import load_files_to_df()\n</code></pre></li> </ul> </li> <li>In <code>red_utils/ext/__init__.py</code>, add a <code>pkgutil.find_loader()</code> line to detect if <code>pandas</code> is installed, then load <code>pandas_utils</code><ul> <li>Contents of <code>red_utils/ext/__init__.py</code>: <pre><code>import pkgutil\n\n...\n\nif pkgutil.find_loader(\"pandas\"):\n    from . import pandas_utils\n</code></pre></li> </ul> </li> <li>The new <code>pandas_utils</code> module should be available if <code>pandas</code> is available in the Python path</li> <li>Build the app with <code>pdm build</code></li> <li>Create a new directory somewhere outside the repository, i.e. <code>~/testing/red-utils</code></li> <li>Initialize the project (example uses <code>pdm</code>):<ul> <li><code>pdm init</code></li> <li>Answer the initialization prompts</li> </ul> </li> <li>Add <code>red-utils</code> from its local path<ul> <li><code>pdm add ~/git/red-utils</code></li> </ul> </li> <li>To remove the local dependency, just run <code>pdm remove ~/git/red-utils</code></li> </ul>"},{"location":"dev/extending/","title":"Extending a red-utils module by adding additional utils","text":"<ul> <li>Create a new directory in <code>red_utils</code></li> <li>Initialize with <code>pdm init</code></li> <li>Add dependencies</li> <li>Add a <code>src</code> dir and an <code>__init__.py</code> file at the module's root</li> <li>Import functions &amp; constants from the <code>src</code> dir into <code>src/__init__.py</code></li> <li>Finally, import desired functions &amp; constants from <code>src</code> in the module's root <code>__init__.py</code></li> </ul>"},{"location":"dev/publishing/","title":"Publishing","text":"<ul> <li>Create a file <code>~/.pypirc</code> ~/.pypirc<pre><code>[distutils]\nindex-servers=\n    pypi\n    testpypi\n\n[testpypi]\nusername = __token__ \npassword = &lt;your-testpypi-token&gt;\n\n[pypi]\nrepository = https://upload.pypi.org/legacy/\nusername = __token__\npassword = &lt;your-pypi-token&gt;\n</code></pre></li> <li>Set the file's chmod to <code>600</code></li> </ul>"},{"location":"dev/publishing/#with-pdm-scripts","title":"With PDM scripts:","text":"<ul> <li>Run <code>pdm run create-&lt;major|minor|micro&gt;-release</code><ul> <li>These scripts use <code>pdm bump</code> to bump the version number, build the package, &amp; publish to pypi.</li> <li>To see the script, check the <code>[tool.pdm.scripts.create-&lt;major|minor|micro&gt;-release]</code> script sections in <code>../../pyproject.toml</code></li> </ul> </li> <li>Upload to pypi:     <pre><code>## Test pypi\npdm run upload-test-pypi\n\n## Pypi\npdm run upload-pypi\n</code></pre></li> </ul>"},{"location":"dev/publishing/#without-pdm-scripts","title":"Without PDM scripts:","text":"<ul> <li>Run the following commands:   <pre><code>pdm bump &lt;major|minor|micro&gt;\npdm bump tag\npdm lock\npdm build\ngit push --tags\n</code></pre></li> <li>Upload to pypi:     <pre><code>## Test pypi\npdm run upload-test-pypi\n\n## Pypi\npdm run upload-pypi\n</code></pre></li> </ul>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>red_utils<ul> <li>core<ul> <li>constants</li> <li>dataclass_utils<ul> <li>mixins<ul> <li>mixin_classes</li> </ul> </li> </ul> </li> </ul> </li> <li>domain</li> <li>exc<ul> <li>_generic</li> <li>base</li> <li>import_exc<ul> <li>_import</li> </ul> </li> </ul> </li> <li>ext<ul> <li>context_managers<ul> <li>cli_spinners<ul> <li>handlers</li> </ul> </li> </ul> </li> <li>dataframe_utils<ul> <li>pandas_utils<ul> <li>constants</li> <li>operations</li> </ul> </li> <li>polars_utils</li> <li>validators<ul> <li>pandas_validators<ul> <li>validators</li> </ul> </li> </ul> </li> </ul> </li> <li>diskcache_utils<ul> <li>__defaults</li> <li>__methods</li> <li>classes</li> <li>constants</li> <li>controllers<ul> <li>_controller</li> </ul> </li> <li>validators</li> </ul> </li> <li>fastapi_utils<ul> <li>constants</li> <li>dependencies</li> <li>healthcheck</li> <li>operations</li> <li>tag_definitions</li> <li>uvicorn_override</li> <li>validators</li> </ul> </li> <li>httpx_utils<ul> <li>cache_storages<ul> <li>_storages</li> </ul> </li> <li>classes</li> <li>constants</li> <li>controllers<ul> <li>_controllers</li> </ul> </li> <li>decoders<ul> <li>__response_decoders</li> </ul> </li> <li>encoders<ul> <li>json_encoders<ul> <li>_encoders</li> </ul> </li> </ul> </li> <li>operations</li> <li>transports<ul> <li>_transports</li> </ul> </li> <li>validators</li> </ul> </li> <li>loguru_utils<ul> <li>constants</li> <li>enums</li> <li>operations</li> <li>sinks</li> <li>validators</li> </ul> </li> <li>msgpack_utils<ul> <li>classes</li> <li>constants</li> <li>operations</li> <li>validators</li> </ul> </li> <li>pydantic_utils<ul> <li>parsers</li> </ul> </li> <li>sqlalchemy_utils<ul> <li>_depends</li> <li>base</li> <li>connection_models</li> <li>constants</li> <li>custom_types<ul> <li>columns</li> <li>meta</li> <li>type_classes</li> </ul> </li> <li>db_config</li> <li>mixins<ul> <li>table_mixins</li> </ul> </li> <li>repository<ul> <li>_repository</li> </ul> </li> <li>utils</li> </ul> </li> <li>time_utils<ul> <li>pendulum_utils<ul> <li>constants</li> <li>operations</li> <li>validators</li> </ul> </li> </ul> </li> </ul> </li> <li>std<ul> <li>context_managers<ul> <li>benchmarks<ul> <li>fn_benchmarks</li> </ul> </li> <li>database_managers<ul> <li>sqlite_managers</li> </ul> </li> <li>object_managers<ul> <li>protect</li> </ul> </li> </ul> </li> <li>dict_utils<ul> <li>operations</li> <li>validators</li> </ul> </li> <li>hash_utils<ul> <li>operations</li> </ul> </li> <li>list_utils<ul> <li>operations</li> <li>validators</li> </ul> </li> <li>logging_utils<ul> <li>__base</li> <li>__methods</li> <li>config_classes<ul> <li>base<ul> <li>_base_config</li> <li>_bases</li> </ul> </li> <li>filters<ul> <li>_filters</li> <li>loglevel_filters<ul> <li>_loglevel_filters</li> </ul> </li> </ul> </li> <li>formatters<ul> <li>_formatters</li> </ul> </li> <li>handlers<ul> <li>_handlers</li> </ul> </li> <li>loggers<ul> <li>_factory</li> <li>_loggers</li> </ul> </li> <li>prefab<ul> <li>third_party<ul> <li>red_utils_logging<ul> <li>_configs</li> </ul> </li> </ul> </li> </ul> </li> <li>types</li> </ul> </li> <li>fmts<ul> <li>_formats</li> </ul> </li> <li>helpers<ul> <li>__methods</li> </ul> </li> </ul> </li> <li>path_utils<ul> <li>constants</li> <li>operations</li> </ul> </li> <li>sqlite_utils<ul> <li>operations</li> <li>schemas</li> </ul> </li> <li>time_utils<ul> <li>constants</li> <li>operations</li> </ul> </li> <li>uuid_utils<ul> <li>classes</li> <li>constants</li> <li>operations</li> <li>validators</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/red_utils/__init__/","title":"red_utils","text":"<p>Custom utilities for stdlib &amp; select libraries.</p> <p>Add utilities to your projects to add functionality like context managers for editing files, lists, dicts, &amp; more, SQLAlchemy helpers like a default <code>Base</code> class, functions to get SQLAlchemy <code>Session</code>s and custom connection classes to handle database URIs &amp; configuration, and much more.</p> <p>Warning</p> <p><code>red_utils</code> is a pet project, not meant to be used in any serious capacity. If you really want to use specific features/functions of <code>red_utils</code>, copy the code into your own project and rewrite it enough that it works with your app.</p> <p>A collection of enhancements/utilities for modules &amp; Python packages I use frequently. Modules are broken down into <code>std</code> and <code>ext</code>. Modules in <code>red_utils.std</code> have no external dependencies, requiring only the Python <code>stdlib</code>. Modules in <code>red_utils.ext</code>, on the other hand, are utilities &amp; extensions I've written for packages like <code>Loguru</code>, <code>SQLAlchemy</code>, and <code>Pydantic</code>.</p> <p>The reference documentation is automatically generated from comments in the code. If I have not added docstrings to a file/function/class, it will not show up in the Reference section of this site. I'll get to it \ud83e\udd37\u200d\u2642\ufe0f</p>"},{"location":"reference/red_utils/__init__/#red_utils.CustomException","title":"<code>CustomException</code>  <code>dataclass</code>","text":"<p>               Bases: <code>CustomExceptionBase</code></p> <p>A generic Exception.</p> <p>Description: This object can store arbitrary types in one of 2 extra fields:</p> <ul> <li>errors</li> <li>extra</li> </ul> <p><code>errors</code> is meant to store an error/a list of errors. <code>extra</code> is meant to store any non-message, non-error data with the exception. This could be a class object, a dict, or some other form of arbitrary data.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>A message to display with the exception.</p> <code>'Custom exception called'</code> <code>errors</code> <code>Any</code> <p>Property to store arbitrary data. Meant to be used for errors associated with the exception.</p> <code>None</code> <code>extra</code> <code>Any</code> <p>Property to store arbitrary data. Data stored in this property can be a Python object (i.e. a class instance, dict, str, or other), a list of objects/strings, etc.</p> <code>None</code> Usage <pre><code>try:\n    ...\nexcept CustomException as exc:\n    raise CustomException(msg=\"Custom exception occurred\", errors=exc)\n</code></pre> Source code in <code>src\\red_utils\\exc\\_generic.py</code> <pre><code>@dataclass\nclass CustomException(CustomExceptionBase):\n    \"\"\"A generic Exception.\n\n    Description: This object can store arbitrary types in one of 2 extra fields:\n\n    - errors\n    - extra\n\n    `errors` is meant to store an error/a list of errors.\n    `extra` is meant to store any non-message, non-error data with the exception. This could be a class\n    object, a dict, or some other form of arbitrary data.\n\n    Params:\n        msg (str): A message to display with the exception.\n        errors (Any): Property to store arbitrary data. Meant to be used for errors associated with the exception.\n        extra (Any): Property to store arbitrary data.\n            Data stored in this property can be a Python object (i.e. a class\n            instance, dict, str, or other), a list of objects/strings, etc.\n\n    Usage:\n        ``` py\n        try:\n            ...\n        except CustomException as exc:\n            raise CustomException(msg=\"Custom exception occurred\", errors=exc)\n        ```\n    \"\"\"\n\n    errors: Any | None = field(default=None)\n    extra: Any | None = field(default=None)\n\n    def __repr__(self):\n        repr_str: str = f\"{self.msg!r}\"\n\n        if self.errors is not None:\n            repr_str: str = f\"{repr_str}\\nErrors: {self.errors!r}\"\n        if self.extra is not None:\n            repr_str: str = f\"{repr_str}\\nExtra: {self.extra!r}\"\n\n        return repr_str\n\n    def __str__(self):\n        return repr(self)\n</code></pre>"},{"location":"reference/red_utils/core/__init__/","title":"core","text":"<p>The <code>core</code> module contains constants &amp; utility functions meant for internal use. Other modules in <code>red_utils</code> can access the <code>red_utils.core</code> package to call constants like <code>DATA_DIR</code> (defaults to <code>.data</code>) when setting default params for a function.</p>"},{"location":"reference/red_utils/core/constants/","title":"constants","text":"<p>Constants for use as default values throughout <code>red_utils</code>.</p> <p>Other modules import from <code>red_utils.core</code> to set values like the default <code>DATA_DIR</code> (.data).</p>"},{"location":"reference/red_utils/core/dataclass_utils/__init__/","title":"dataclass_utils","text":"<p>Core utilities for dataclasses.</p> <p>Mostly used in <code>red_utils.std</code>, but can be imported into any Python script that declares <code>dataclasses.dataclass</code> classes.</p>"},{"location":"reference/red_utils/core/dataclass_utils/__init__/#red_utils.core.dataclass_utils.DictMixin","title":"<code>DictMixin</code>  <code>dataclass</code>","text":"<p>Mixin class to add \"as_dict()\" method to classes. Equivalent to .dict.</p> <p>Adds a <code>.as_dict()</code> method to classes that inherit from this mixin. For example, to add <code>.as_dict()</code> method to a parent class, where all children inherit the .as_dict() function, declare parent as:</p> <pre><code>@dataclass\nclass Parent(DictMixin):\n    ...\n</code></pre> <p>and call like:</p> <pre><code>p = Parent()\np_dict = p.as_dict()\n</code></pre> Source code in <code>src\\red_utils\\core\\dataclass_utils\\mixins\\mixin_classes.py</code> <pre><code>@dataclass\nclass DictMixin:\n    \"\"\"Mixin class to add \"as_dict()\" method to classes. Equivalent to .__dict__.\n\n    Adds a `.as_dict()` method to classes that inherit from this mixin. For example,\n    to add `.as_dict()` method to a parent class, where all children inherit the .as_dict()\n    function, declare parent as:\n\n    ``` py linenums=\"1\"\n    @dataclass\n    class Parent(DictMixin):\n        ...\n    ```\n\n    and call like:\n\n    ``` py linenums=\"1\"\n    p = Parent()\n    p_dict = p.as_dict()\n    ```\n    \"\"\"\n\n    def as_dict(self: Generic[T]):\n        \"\"\"Return dict representation of a dataclass instance.\n\n        Description:\n            Any class that inherits from `DictMixin` will automatically have a method `.as_dict()`.\n                There are no extra params.\n\n        Returns:\n            (dict): A Python `dict` representation of a Python `dataclass` class.\n\n        \"\"\"\n        try:\n            return self.__dict__.copy()\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception converting class instance to dict. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/core/dataclass_utils/__init__/#red_utils.core.dataclass_utils.DictMixin.as_dict","title":"<code>as_dict()</code>","text":"<p>Return dict representation of a dataclass instance.</p> Description <p>Any class that inherits from <code>DictMixin</code> will automatically have a method <code>.as_dict()</code>.     There are no extra params.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A Python <code>dict</code> representation of a Python <code>dataclass</code> class.</p> Source code in <code>src\\red_utils\\core\\dataclass_utils\\mixins\\mixin_classes.py</code> <pre><code>def as_dict(self: Generic[T]):\n    \"\"\"Return dict representation of a dataclass instance.\n\n    Description:\n        Any class that inherits from `DictMixin` will automatically have a method `.as_dict()`.\n            There are no extra params.\n\n    Returns:\n        (dict): A Python `dict` representation of a Python `dataclass` class.\n\n    \"\"\"\n    try:\n        return self.__dict__.copy()\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception converting class instance to dict. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/core/dataclass_utils/mixins/__init__/","title":"mixins","text":"<p>Mixin classes for Python dataclasses.</p> <p>Usage:</p> <p>Define a class that inherits from one or more mixins. For example, to inherit from <code>DictMixin</code>:</p> schemas.py<pre><code>from red_utils.core.mixins import DictMixin\nfrom dataclasses import dataclass\n\nclass ExampleClass(DictMixin):\n    name: str = \"human\"\n\nclassobj = ExampleClass()\nclassobj.as_dict()  # classobj now has access to the `.as_dict()` method of `DictMixin`.\n</code></pre>"},{"location":"reference/red_utils/core/dataclass_utils/mixins/__init__/#red_utils.core.dataclass_utils.mixins.DictMixin","title":"<code>DictMixin</code>  <code>dataclass</code>","text":"<p>Mixin class to add \"as_dict()\" method to classes. Equivalent to .dict.</p> <p>Adds a <code>.as_dict()</code> method to classes that inherit from this mixin. For example, to add <code>.as_dict()</code> method to a parent class, where all children inherit the .as_dict() function, declare parent as:</p> <pre><code>@dataclass\nclass Parent(DictMixin):\n    ...\n</code></pre> <p>and call like:</p> <pre><code>p = Parent()\np_dict = p.as_dict()\n</code></pre> Source code in <code>src\\red_utils\\core\\dataclass_utils\\mixins\\mixin_classes.py</code> <pre><code>@dataclass\nclass DictMixin:\n    \"\"\"Mixin class to add \"as_dict()\" method to classes. Equivalent to .__dict__.\n\n    Adds a `.as_dict()` method to classes that inherit from this mixin. For example,\n    to add `.as_dict()` method to a parent class, where all children inherit the .as_dict()\n    function, declare parent as:\n\n    ``` py linenums=\"1\"\n    @dataclass\n    class Parent(DictMixin):\n        ...\n    ```\n\n    and call like:\n\n    ``` py linenums=\"1\"\n    p = Parent()\n    p_dict = p.as_dict()\n    ```\n    \"\"\"\n\n    def as_dict(self: Generic[T]):\n        \"\"\"Return dict representation of a dataclass instance.\n\n        Description:\n            Any class that inherits from `DictMixin` will automatically have a method `.as_dict()`.\n                There are no extra params.\n\n        Returns:\n            (dict): A Python `dict` representation of a Python `dataclass` class.\n\n        \"\"\"\n        try:\n            return self.__dict__.copy()\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception converting class instance to dict. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/core/dataclass_utils/mixins/__init__/#red_utils.core.dataclass_utils.mixins.DictMixin.as_dict","title":"<code>as_dict()</code>","text":"<p>Return dict representation of a dataclass instance.</p> Description <p>Any class that inherits from <code>DictMixin</code> will automatically have a method <code>.as_dict()</code>.     There are no extra params.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A Python <code>dict</code> representation of a Python <code>dataclass</code> class.</p> Source code in <code>src\\red_utils\\core\\dataclass_utils\\mixins\\mixin_classes.py</code> <pre><code>def as_dict(self: Generic[T]):\n    \"\"\"Return dict representation of a dataclass instance.\n\n    Description:\n        Any class that inherits from `DictMixin` will automatically have a method `.as_dict()`.\n            There are no extra params.\n\n    Returns:\n        (dict): A Python `dict` representation of a Python `dataclass` class.\n\n    \"\"\"\n    try:\n        return self.__dict__.copy()\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception converting class instance to dict. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/core/dataclass_utils/mixins/mixin_classes/","title":"mixin_classes","text":""},{"location":"reference/red_utils/core/dataclass_utils/mixins/mixin_classes/#red_utils.core.dataclass_utils.mixins.mixin_classes.DictMixin","title":"<code>DictMixin</code>  <code>dataclass</code>","text":"<p>Mixin class to add \"as_dict()\" method to classes. Equivalent to .dict.</p> <p>Adds a <code>.as_dict()</code> method to classes that inherit from this mixin. For example, to add <code>.as_dict()</code> method to a parent class, where all children inherit the .as_dict() function, declare parent as:</p> <pre><code>@dataclass\nclass Parent(DictMixin):\n    ...\n</code></pre> <p>and call like:</p> <pre><code>p = Parent()\np_dict = p.as_dict()\n</code></pre> Source code in <code>src\\red_utils\\core\\dataclass_utils\\mixins\\mixin_classes.py</code> <pre><code>@dataclass\nclass DictMixin:\n    \"\"\"Mixin class to add \"as_dict()\" method to classes. Equivalent to .__dict__.\n\n    Adds a `.as_dict()` method to classes that inherit from this mixin. For example,\n    to add `.as_dict()` method to a parent class, where all children inherit the .as_dict()\n    function, declare parent as:\n\n    ``` py linenums=\"1\"\n    @dataclass\n    class Parent(DictMixin):\n        ...\n    ```\n\n    and call like:\n\n    ``` py linenums=\"1\"\n    p = Parent()\n    p_dict = p.as_dict()\n    ```\n    \"\"\"\n\n    def as_dict(self: Generic[T]):\n        \"\"\"Return dict representation of a dataclass instance.\n\n        Description:\n            Any class that inherits from `DictMixin` will automatically have a method `.as_dict()`.\n                There are no extra params.\n\n        Returns:\n            (dict): A Python `dict` representation of a Python `dataclass` class.\n\n        \"\"\"\n        try:\n            return self.__dict__.copy()\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception converting class instance to dict. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/core/dataclass_utils/mixins/mixin_classes/#red_utils.core.dataclass_utils.mixins.mixin_classes.DictMixin.as_dict","title":"<code>as_dict()</code>","text":"<p>Return dict representation of a dataclass instance.</p> Description <p>Any class that inherits from <code>DictMixin</code> will automatically have a method <code>.as_dict()</code>.     There are no extra params.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A Python <code>dict</code> representation of a Python <code>dataclass</code> class.</p> Source code in <code>src\\red_utils\\core\\dataclass_utils\\mixins\\mixin_classes.py</code> <pre><code>def as_dict(self: Generic[T]):\n    \"\"\"Return dict representation of a dataclass instance.\n\n    Description:\n        Any class that inherits from `DictMixin` will automatically have a method `.as_dict()`.\n            There are no extra params.\n\n    Returns:\n        (dict): A Python `dict` representation of a Python `dataclass` class.\n\n    \"\"\"\n    try:\n        return self.__dict__.copy()\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception converting class instance to dict. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/domain/__init__/","title":"domain","text":"<p>Shared domain objects for use throughout the app.</p> <p>Consists of Python/Pydantic/Dataclasses classes.</p>"},{"location":"reference/red_utils/exc/__init__/","title":"exc","text":"<p>Custom exceptions used throughout <code>red_utils</code>. These exceptions can be imported &amp; raised in your own code.</p> <p>For example, to use <code>CustomException</code> as a base class for a new exception specific to your app:</p> exceptions.py<pre><code>from red_utils.exc import CustomException\n\nclass MyException(CustomException):\n    ## Class inherits the 'msg' and 'errors' class variables from CustomException.\n    #  Define a new variable just for this exception\n    level: int = 0\n</code></pre>"},{"location":"reference/red_utils/exc/__init__/#red_utils.exc.CustomException","title":"<code>CustomException</code>  <code>dataclass</code>","text":"<p>               Bases: <code>CustomExceptionBase</code></p> <p>A generic Exception.</p> <p>Description: This object can store arbitrary types in one of 2 extra fields:</p> <ul> <li>errors</li> <li>extra</li> </ul> <p><code>errors</code> is meant to store an error/a list of errors. <code>extra</code> is meant to store any non-message, non-error data with the exception. This could be a class object, a dict, or some other form of arbitrary data.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>A message to display with the exception.</p> <code>'Custom exception called'</code> <code>errors</code> <code>Any</code> <p>Property to store arbitrary data. Meant to be used for errors associated with the exception.</p> <code>None</code> <code>extra</code> <code>Any</code> <p>Property to store arbitrary data. Data stored in this property can be a Python object (i.e. a class instance, dict, str, or other), a list of objects/strings, etc.</p> <code>None</code> Usage <pre><code>try:\n    ...\nexcept CustomException as exc:\n    raise CustomException(msg=\"Custom exception occurred\", errors=exc)\n</code></pre> Source code in <code>src\\red_utils\\exc\\_generic.py</code> <pre><code>@dataclass\nclass CustomException(CustomExceptionBase):\n    \"\"\"A generic Exception.\n\n    Description: This object can store arbitrary types in one of 2 extra fields:\n\n    - errors\n    - extra\n\n    `errors` is meant to store an error/a list of errors.\n    `extra` is meant to store any non-message, non-error data with the exception. This could be a class\n    object, a dict, or some other form of arbitrary data.\n\n    Params:\n        msg (str): A message to display with the exception.\n        errors (Any): Property to store arbitrary data. Meant to be used for errors associated with the exception.\n        extra (Any): Property to store arbitrary data.\n            Data stored in this property can be a Python object (i.e. a class\n            instance, dict, str, or other), a list of objects/strings, etc.\n\n    Usage:\n        ``` py\n        try:\n            ...\n        except CustomException as exc:\n            raise CustomException(msg=\"Custom exception occurred\", errors=exc)\n        ```\n    \"\"\"\n\n    errors: Any | None = field(default=None)\n    extra: Any | None = field(default=None)\n\n    def __repr__(self):\n        repr_str: str = f\"{self.msg!r}\"\n\n        if self.errors is not None:\n            repr_str: str = f\"{repr_str}\\nErrors: {self.errors!r}\"\n        if self.extra is not None:\n            repr_str: str = f\"{repr_str}\\nExtra: {self.extra!r}\"\n\n        return repr_str\n\n    def __str__(self):\n        return repr(self)\n</code></pre>"},{"location":"reference/red_utils/exc/__init__/#red_utils.exc.MissingDependencyException","title":"<code>MissingDependencyException</code>  <code>dataclass</code>","text":"<p>               Bases: <code>CustomException</code></p> <p>Exception to raise when an import is called but a dependency is missing.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>A message to display with the exception.</p> <code>'Custom exception called'</code> <code>errors</code> <code>Any</code> <p>Property to store arbitrary data. Meant to be used for errors associated with the exception.</p> <code>None</code> <code>extra</code> <code>Any</code> <p>Property to store arbitrary data. Data stored in this property can be a Python object (i.e. a class instance, dict, str, or other), a list of objects/strings, etc.</p> <code>None</code> Usage <pre><code>try:\n    ...\nexcept CustomException as exc:\n    raise CustomException(msg=\"Custom exception occurred\", errors=exc)\n</code></pre> Source code in <code>src\\red_utils\\exc\\import_exc\\_import.py</code> <pre><code>@dataclass\nclass MissingDependencyException(CustomException):\n    \"\"\"Exception to raise when an import is called but a dependency is missing.\n\n    Params:\n        msg (str): A message to display with the exception.\n        errors (Any): Property to store arbitrary data. Meant to be used for errors associated with the exception.\n        extra (Any): Property to store arbitrary data.\n            Data stored in this property can be a Python object (i.e. a class\n            instance, dict, str, or other), a list of objects/strings, etc.\n\n    Usage:\n        ``` py\n        try:\n            ...\n        except CustomException as exc:\n            raise CustomException(msg=\"Custom exception occurred\", errors=exc)\n        ```\n    \"\"\"\n\n    errors: Any | None = field(default=None)\n    extra: Any | None = field(default=None)\n    missing_dependencies: list[str] | None = field(default_factory=list())\n\n    def __repr__(self):\n        repr_str: str = f\"{self.msg!r}\"\n\n        if self.errors is not None:\n            repr_str: str = f\"{repr_str}\\nErrors: {self.errors!r}\"\n        if self.extra is not None:\n            repr_str: str = f\"{repr_str}\\nExtra: {self.extra!r}\"\n\n        return repr_str\n\n    def __str__(self):\n        return repr(self)\n\n    @property\n    def exc_msg(self):\n        msg = CustomModuleNotFoundError(\n            msg=self.msg, missing_dependencies=self.missing_dependencies\n        )\n\n        return msg\n</code></pre>"},{"location":"reference/red_utils/exc/_generic/","title":"_generic","text":""},{"location":"reference/red_utils/exc/_generic/#red_utils.exc._generic.CustomException","title":"<code>CustomException</code>  <code>dataclass</code>","text":"<p>               Bases: <code>CustomExceptionBase</code></p> <p>A generic Exception.</p> <p>Description: This object can store arbitrary types in one of 2 extra fields:</p> <ul> <li>errors</li> <li>extra</li> </ul> <p><code>errors</code> is meant to store an error/a list of errors. <code>extra</code> is meant to store any non-message, non-error data with the exception. This could be a class object, a dict, or some other form of arbitrary data.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>A message to display with the exception.</p> <code>'Custom exception called'</code> <code>errors</code> <code>Any</code> <p>Property to store arbitrary data. Meant to be used for errors associated with the exception.</p> <code>None</code> <code>extra</code> <code>Any</code> <p>Property to store arbitrary data. Data stored in this property can be a Python object (i.e. a class instance, dict, str, or other), a list of objects/strings, etc.</p> <code>None</code> Usage <pre><code>try:\n    ...\nexcept CustomException as exc:\n    raise CustomException(msg=\"Custom exception occurred\", errors=exc)\n</code></pre> Source code in <code>src\\red_utils\\exc\\_generic.py</code> <pre><code>@dataclass\nclass CustomException(CustomExceptionBase):\n    \"\"\"A generic Exception.\n\n    Description: This object can store arbitrary types in one of 2 extra fields:\n\n    - errors\n    - extra\n\n    `errors` is meant to store an error/a list of errors.\n    `extra` is meant to store any non-message, non-error data with the exception. This could be a class\n    object, a dict, or some other form of arbitrary data.\n\n    Params:\n        msg (str): A message to display with the exception.\n        errors (Any): Property to store arbitrary data. Meant to be used for errors associated with the exception.\n        extra (Any): Property to store arbitrary data.\n            Data stored in this property can be a Python object (i.e. a class\n            instance, dict, str, or other), a list of objects/strings, etc.\n\n    Usage:\n        ``` py\n        try:\n            ...\n        except CustomException as exc:\n            raise CustomException(msg=\"Custom exception occurred\", errors=exc)\n        ```\n    \"\"\"\n\n    errors: Any | None = field(default=None)\n    extra: Any | None = field(default=None)\n\n    def __repr__(self):\n        repr_str: str = f\"{self.msg!r}\"\n\n        if self.errors is not None:\n            repr_str: str = f\"{repr_str}\\nErrors: {self.errors!r}\"\n        if self.extra is not None:\n            repr_str: str = f\"{repr_str}\\nExtra: {self.extra!r}\"\n\n        return repr_str\n\n    def __str__(self):\n        return repr(self)\n</code></pre>"},{"location":"reference/red_utils/exc/_generic/#red_utils.exc._generic.CustomExceptionBase","title":"<code>CustomExceptionBase</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseException</code></p> <p>Base class for custom exceptions to inherit from.</p> <p>This class itself inherits from Python's Exception class.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>A message to display with the exception</p> <code>'Custom exception called'</code> Usage <pre><code>raise CustomExceptionBase(msg=\"This is a custom exception\")\n</code></pre> Source code in <code>src\\red_utils\\exc\\base.py</code> <pre><code>@dataclass\nclass CustomExceptionBase(BaseException):\n    \"\"\"Base class for custom exceptions to inherit from.\n\n    This class itself inherits from Python's Exception class.\n\n    Params:\n        msg (str): A message to display with the exception\n\n    Usage:\n        ``` py linenums=\"1\"\n\n        raise CustomExceptionBase(msg=\"This is a custom exception\")\n        ```\n    \"\"\"\n\n    msg: str = field(default=\"Custom exception called\")\n    # errors: Any | None = field(default=None)\n    # extra: Any | None = field(default=None)\n\n    def __repr__(self):\n        repr_str: str = f\"{self.msg!r}\"\n\n        return repr_str\n\n    def __str__(self):\n        return repr(self)\n</code></pre>"},{"location":"reference/red_utils/exc/base/","title":"base","text":""},{"location":"reference/red_utils/exc/base/#red_utils.exc.base.CustomExceptionBase","title":"<code>CustomExceptionBase</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseException</code></p> <p>Base class for custom exceptions to inherit from.</p> <p>This class itself inherits from Python's Exception class.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>A message to display with the exception</p> <code>'Custom exception called'</code> Usage <pre><code>raise CustomExceptionBase(msg=\"This is a custom exception\")\n</code></pre> Source code in <code>src\\red_utils\\exc\\base.py</code> <pre><code>@dataclass\nclass CustomExceptionBase(BaseException):\n    \"\"\"Base class for custom exceptions to inherit from.\n\n    This class itself inherits from Python's Exception class.\n\n    Params:\n        msg (str): A message to display with the exception\n\n    Usage:\n        ``` py linenums=\"1\"\n\n        raise CustomExceptionBase(msg=\"This is a custom exception\")\n        ```\n    \"\"\"\n\n    msg: str = field(default=\"Custom exception called\")\n    # errors: Any | None = field(default=None)\n    # extra: Any | None = field(default=None)\n\n    def __repr__(self):\n        repr_str: str = f\"{self.msg!r}\"\n\n        return repr_str\n\n    def __str__(self):\n        return repr(self)\n</code></pre>"},{"location":"reference/red_utils/exc/import_exc/__init__/","title":"import_exc","text":""},{"location":"reference/red_utils/exc/import_exc/__init__/#red_utils.exc.import_exc.MissingDependencyException","title":"<code>MissingDependencyException</code>  <code>dataclass</code>","text":"<p>               Bases: <code>CustomException</code></p> <p>Exception to raise when an import is called but a dependency is missing.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>A message to display with the exception.</p> <code>'Custom exception called'</code> <code>errors</code> <code>Any</code> <p>Property to store arbitrary data. Meant to be used for errors associated with the exception.</p> <code>None</code> <code>extra</code> <code>Any</code> <p>Property to store arbitrary data. Data stored in this property can be a Python object (i.e. a class instance, dict, str, or other), a list of objects/strings, etc.</p> <code>None</code> Usage <pre><code>try:\n    ...\nexcept CustomException as exc:\n    raise CustomException(msg=\"Custom exception occurred\", errors=exc)\n</code></pre> Source code in <code>src\\red_utils\\exc\\import_exc\\_import.py</code> <pre><code>@dataclass\nclass MissingDependencyException(CustomException):\n    \"\"\"Exception to raise when an import is called but a dependency is missing.\n\n    Params:\n        msg (str): A message to display with the exception.\n        errors (Any): Property to store arbitrary data. Meant to be used for errors associated with the exception.\n        extra (Any): Property to store arbitrary data.\n            Data stored in this property can be a Python object (i.e. a class\n            instance, dict, str, or other), a list of objects/strings, etc.\n\n    Usage:\n        ``` py\n        try:\n            ...\n        except CustomException as exc:\n            raise CustomException(msg=\"Custom exception occurred\", errors=exc)\n        ```\n    \"\"\"\n\n    errors: Any | None = field(default=None)\n    extra: Any | None = field(default=None)\n    missing_dependencies: list[str] | None = field(default_factory=list())\n\n    def __repr__(self):\n        repr_str: str = f\"{self.msg!r}\"\n\n        if self.errors is not None:\n            repr_str: str = f\"{repr_str}\\nErrors: {self.errors!r}\"\n        if self.extra is not None:\n            repr_str: str = f\"{repr_str}\\nExtra: {self.extra!r}\"\n\n        return repr_str\n\n    def __str__(self):\n        return repr(self)\n\n    @property\n    def exc_msg(self):\n        msg = CustomModuleNotFoundError(\n            msg=self.msg, missing_dependencies=self.missing_dependencies\n        )\n\n        return msg\n</code></pre>"},{"location":"reference/red_utils/exc/import_exc/_import/","title":"_import","text":""},{"location":"reference/red_utils/exc/import_exc/_import/#red_utils.exc.import_exc._import.CustomException","title":"<code>CustomException</code>  <code>dataclass</code>","text":"<p>               Bases: <code>CustomExceptionBase</code></p> <p>A generic Exception.</p> <p>Description: This object can store arbitrary types in one of 2 extra fields:</p> <ul> <li>errors</li> <li>extra</li> </ul> <p><code>errors</code> is meant to store an error/a list of errors. <code>extra</code> is meant to store any non-message, non-error data with the exception. This could be a class object, a dict, or some other form of arbitrary data.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>A message to display with the exception.</p> <code>'Custom exception called'</code> <code>errors</code> <code>Any</code> <p>Property to store arbitrary data. Meant to be used for errors associated with the exception.</p> <code>None</code> <code>extra</code> <code>Any</code> <p>Property to store arbitrary data. Data stored in this property can be a Python object (i.e. a class instance, dict, str, or other), a list of objects/strings, etc.</p> <code>None</code> Usage <pre><code>try:\n    ...\nexcept CustomException as exc:\n    raise CustomException(msg=\"Custom exception occurred\", errors=exc)\n</code></pre> Source code in <code>src\\red_utils\\exc\\_generic.py</code> <pre><code>@dataclass\nclass CustomException(CustomExceptionBase):\n    \"\"\"A generic Exception.\n\n    Description: This object can store arbitrary types in one of 2 extra fields:\n\n    - errors\n    - extra\n\n    `errors` is meant to store an error/a list of errors.\n    `extra` is meant to store any non-message, non-error data with the exception. This could be a class\n    object, a dict, or some other form of arbitrary data.\n\n    Params:\n        msg (str): A message to display with the exception.\n        errors (Any): Property to store arbitrary data. Meant to be used for errors associated with the exception.\n        extra (Any): Property to store arbitrary data.\n            Data stored in this property can be a Python object (i.e. a class\n            instance, dict, str, or other), a list of objects/strings, etc.\n\n    Usage:\n        ``` py\n        try:\n            ...\n        except CustomException as exc:\n            raise CustomException(msg=\"Custom exception occurred\", errors=exc)\n        ```\n    \"\"\"\n\n    errors: Any | None = field(default=None)\n    extra: Any | None = field(default=None)\n\n    def __repr__(self):\n        repr_str: str = f\"{self.msg!r}\"\n\n        if self.errors is not None:\n            repr_str: str = f\"{repr_str}\\nErrors: {self.errors!r}\"\n        if self.extra is not None:\n            repr_str: str = f\"{repr_str}\\nExtra: {self.extra!r}\"\n\n        return repr_str\n\n    def __str__(self):\n        return repr(self)\n</code></pre>"},{"location":"reference/red_utils/exc/import_exc/_import/#red_utils.exc.import_exc._import.MissingDependencyException","title":"<code>MissingDependencyException</code>  <code>dataclass</code>","text":"<p>               Bases: <code>CustomException</code></p> <p>Exception to raise when an import is called but a dependency is missing.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>A message to display with the exception.</p> <code>'Custom exception called'</code> <code>errors</code> <code>Any</code> <p>Property to store arbitrary data. Meant to be used for errors associated with the exception.</p> <code>None</code> <code>extra</code> <code>Any</code> <p>Property to store arbitrary data. Data stored in this property can be a Python object (i.e. a class instance, dict, str, or other), a list of objects/strings, etc.</p> <code>None</code> Usage <pre><code>try:\n    ...\nexcept CustomException as exc:\n    raise CustomException(msg=\"Custom exception occurred\", errors=exc)\n</code></pre> Source code in <code>src\\red_utils\\exc\\import_exc\\_import.py</code> <pre><code>@dataclass\nclass MissingDependencyException(CustomException):\n    \"\"\"Exception to raise when an import is called but a dependency is missing.\n\n    Params:\n        msg (str): A message to display with the exception.\n        errors (Any): Property to store arbitrary data. Meant to be used for errors associated with the exception.\n        extra (Any): Property to store arbitrary data.\n            Data stored in this property can be a Python object (i.e. a class\n            instance, dict, str, or other), a list of objects/strings, etc.\n\n    Usage:\n        ``` py\n        try:\n            ...\n        except CustomException as exc:\n            raise CustomException(msg=\"Custom exception occurred\", errors=exc)\n        ```\n    \"\"\"\n\n    errors: Any | None = field(default=None)\n    extra: Any | None = field(default=None)\n    missing_dependencies: list[str] | None = field(default_factory=list())\n\n    def __repr__(self):\n        repr_str: str = f\"{self.msg!r}\"\n\n        if self.errors is not None:\n            repr_str: str = f\"{repr_str}\\nErrors: {self.errors!r}\"\n        if self.extra is not None:\n            repr_str: str = f\"{repr_str}\\nExtra: {self.extra!r}\"\n\n        return repr_str\n\n    def __str__(self):\n        return repr(self)\n\n    @property\n    def exc_msg(self):\n        msg = CustomModuleNotFoundError(\n            msg=self.msg, missing_dependencies=self.missing_dependencies\n        )\n\n        return msg\n</code></pre>"},{"location":"reference/red_utils/ext/__init__/","title":"ext","text":"<p>Extensions &amp; utilities for third-party libraries I use frequently, like <code>red_utils.ext.sqla_utils</code>.</p> <p>Contains boilerplate code for <code>SQLAlchemy</code>, or <code>red_utils.ext.pydantic</code>, which contains a method (parse_pydantic_schema) that can parse a <code>Pydantic</code> class object into a compatible <code>SQLAlchemy</code> model.</p> <p>This module uses <code>importlib.util.find_spec()</code> to only load modules if dependencies are met, keeping the <code>red_utils</code> package functional by limiting the utilities that are loaded. If a find_spec() check fails, that import is passed over and will be unavailable for type completion &amp; usage.</p> <p>This can lead to some odd behavior! For example, if you try to import <code>from red_utils.ext import time_utils</code>, but you do not have the <code>pendulum</code> dependency, you will get exceptions about a missing module. If you import a 3rd party util library, make sure the dependency is installed! Check the project's <code>pyproject.toml</code>, or <code>requirements/requirements*.txt</code>.</p>"},{"location":"reference/red_utils/ext/context_managers/__init__/","title":"context_managers","text":"<p>Context manager classes/functions.</p> <p>These context managers can be used as <code>with</code> statements to provide a handler for a task. For example, the <code>SimpleSpinner</code> class in <code>red_utils.ext.context_managers.cli_spinners</code> adds a CLI spinner to a function running within  a <code>with SimpleSpinner()</code> statement:</p> SimpleSpinner() context managers<pre><code>with SimpleSpinner(\"Demo spinner... \"):\n    time.sleep(15)\n</code></pre>"},{"location":"reference/red_utils/ext/context_managers/__init__/#red_utils.ext.context_managers.SimpleSpinner","title":"<code>SimpleSpinner(message='Loading...')</code>","text":"<p>Get a simple CLI spinner context manager.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message to display while the spinner is running</p> <code>'Loading...'</code> <p>Usage:</p> <pre><code>with SimpleSpinnner(\"Your message... \"):\n    ...\n</code></pre> Source code in <code>src\\red_utils\\ext\\context_managers\\cli_spinners\\handlers.py</code> <pre><code>@contextmanager\ndef SimpleSpinner(message: str = \"Loading...\"):\n    \"\"\"Get a simple CLI spinner context manager.\n\n    Params:\n        message (str): The message to display while the spinner is running\n\n    Usage:\n\n    ``` py linenums=\"1\"\n    with SimpleSpinnner(\"Your message... \"):\n        ...\n    ```\n    \"\"\"\n    rich_console: Console = Console()\n\n    try:\n        with rich_console.status(message) as status:\n            yield status\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception yielding spinner. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n    finally:\n        # rich_console.clear()\n        rich_console.clear_live()\n</code></pre>"},{"location":"reference/red_utils/ext/context_managers/cli_spinners/__init__/","title":"cli_spinners","text":"<p>CLI spinner context managers add an animated spinner to long-running tasks.</p> <p>Example: SimpleSpinner() CLI<pre><code>with SimpleSpinner(\"Demo spinner... \"):\n    time.sleep(15)\n</code></pre></p>"},{"location":"reference/red_utils/ext/context_managers/cli_spinners/__init__/#red_utils.ext.context_managers.cli_spinners.SimpleSpinner","title":"<code>SimpleSpinner(message='Loading...')</code>","text":"<p>Get a simple CLI spinner context manager.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message to display while the spinner is running</p> <code>'Loading...'</code> <p>Usage:</p> <pre><code>with SimpleSpinnner(\"Your message... \"):\n    ...\n</code></pre> Source code in <code>src\\red_utils\\ext\\context_managers\\cli_spinners\\handlers.py</code> <pre><code>@contextmanager\ndef SimpleSpinner(message: str = \"Loading...\"):\n    \"\"\"Get a simple CLI spinner context manager.\n\n    Params:\n        message (str): The message to display while the spinner is running\n\n    Usage:\n\n    ``` py linenums=\"1\"\n    with SimpleSpinnner(\"Your message... \"):\n        ...\n    ```\n    \"\"\"\n    rich_console: Console = Console()\n\n    try:\n        with rich_console.status(message) as status:\n            yield status\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception yielding spinner. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n    finally:\n        # rich_console.clear()\n        rich_console.clear_live()\n</code></pre>"},{"location":"reference/red_utils/ext/context_managers/cli_spinners/handlers/","title":"handlers","text":"<p>Handlers defined in this file can be imported and used as <code>with</code> context managers.</p>"},{"location":"reference/red_utils/ext/context_managers/cli_spinners/handlers/#red_utils.ext.context_managers.cli_spinners.handlers.SimpleSpinner","title":"<code>SimpleSpinner(message='Loading...')</code>","text":"<p>Get a simple CLI spinner context manager.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message to display while the spinner is running</p> <code>'Loading...'</code> <p>Usage:</p> <pre><code>with SimpleSpinnner(\"Your message... \"):\n    ...\n</code></pre> Source code in <code>src\\red_utils\\ext\\context_managers\\cli_spinners\\handlers.py</code> <pre><code>@contextmanager\ndef SimpleSpinner(message: str = \"Loading...\"):\n    \"\"\"Get a simple CLI spinner context manager.\n\n    Params:\n        message (str): The message to display while the spinner is running\n\n    Usage:\n\n    ``` py linenums=\"1\"\n    with SimpleSpinnner(\"Your message... \"):\n        ...\n    ```\n    \"\"\"\n    rich_console: Console = Console()\n\n    try:\n        with rich_console.status(message) as status:\n            yield status\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception yielding spinner. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n    finally:\n        # rich_console.clear()\n        rich_console.clear_live()\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/__init__/","title":"dataframe_utils","text":"<p>Utilities for DataFrame libraries like <code>pandas</code> and <code>polars</code>.</p>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/__init__/","title":"pandas_utils","text":"<p>Utilities for the <code>pandas</code> DataFrame library.</p>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/__init__/#red_utils.ext.dataframe_utils.pandas_utils.convert_csv_to_pq","title":"<code>convert_csv_to_pq(csv_file=None, pq_file=None, dedupe=False)</code>","text":"<p>Read a CSV file into a DataFrame, then write the DataFrame to a Parquet file.</p> <p>Parameters:</p> Name Type Description Default <code>csv_file</code> <code>str | Path</code> <p>Path to a CSV file to read from</p> <code>None</code> <code>pq_file</code> <code>str | Path</code> <p>Path to a Parquet file to write to</p> <code>None</code> <code>dedupe</code> <code>bool</code> <p>Whether to run .drop_duplicates() on the DataFrame</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>csv_file</code> is converted to <code>pq_file</code> successfully</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If file cannot be saved, an <code>Exception</code> is raised instead of returning a bool value</p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\pandas_utils\\operations.py</code> <pre><code>def convert_csv_to_pq(\n    csv_file: Union[str, Path] = None,\n    pq_file: Union[str, Path] = None,\n    dedupe: bool = False,\n) -&gt; bool:\n    \"\"\"Read a CSV file into a DataFrame, then write the DataFrame to a Parquet file.\n\n    Params:\n        csv_file (str|Path): Path to a CSV file to read from\n        pq_file (str|Path): Path to a Parquet file to write to\n        dedupe (bool): Whether to run .drop_duplicates() on the DataFrame\n\n    Returns:\n        (bool): `True` if `csv_file` is converted to `pq_file` successfully\n\n    Raises:\n        Exception: If file cannot be saved, an `Exception` is raised instead of returning\n            a bool value\n\n    \"\"\"\n    if csv_file is None:\n        raise ValueError(\"Missing a CSV input file to read from\")\n    if pq_file is None:\n        raise ValueError(\"Missing a Parquet file to save to\")\n\n    if isinstance(csv_file, str):\n        csv_file: Path = Path(csv_file)\n    if isinstance(pq_file, str):\n        pq_file: Path = Path(pq_file)\n\n    if not csv_file.exists():\n        raise FileNotFoundError(f\"Could not find input CSV file at path: {csv_file}\")\n\n    try:\n        df = load_csv(csv_file=csv_file)\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception reading CSV file '{csv_file}' to DataFrame. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n\n    try:\n        success = save_pq(df=df, pq_file=pq_file, dedupe=dedupe)\n\n        return success\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception writing DataFrame to file: {pq_file}. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/__init__/#red_utils.ext.dataframe_utils.pandas_utils.convert_pq_to_csv","title":"<code>convert_pq_to_csv(pq_file=None, csv_file=None, dedupe=False)</code>","text":"<p>Read a Parquet file into a DataFrame, then write the DataFrame to a CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>pq_file</code> <code>str | Path</code> <p>Path to a Parquet file to read from</p> <code>None</code> <code>csv_file</code> <code>str | Path</code> <p>Path to a CSV file to write to</p> <code>None</code> <code>dedupe</code> <code>bool</code> <p>Whether to run .drop_duplicates() on the DataFrame</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>pq_file</code> is converted to <code>csv_file</code> successfully</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If file cannot be saved, an <code>Exception</code> is raised instead of returning a bool value</p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\pandas_utils\\operations.py</code> <pre><code>def convert_pq_to_csv(\n    pq_file: Union[str, Path] = None,\n    csv_file: Union[str, Path] = None,\n    dedupe: bool = False,\n) -&gt; bool:\n    \"\"\"Read a Parquet file into a DataFrame, then write the DataFrame to a CSV file.\n\n    Params:\n        pq_file (str|Path): Path to a Parquet file to read from\n        csv_file (str|Path): Path to a CSV file to write to\n        dedupe (bool): Whether to run .drop_duplicates() on the DataFrame\n\n    Returns:\n        (bool): `True` if `pq_file` is converted to `csv_file` successfully\n\n    Raises:\n        Exception: If file cannot be saved, an `Exception` is raised instead of returning\n            a bool value\n\n    \"\"\"\n    if csv_file is None:\n        raise ValueError(\"Missing a CSV file to save to\")\n    if pq_file is None:\n        raise ValueError(\"Missing an input Parquet file to read from\")\n\n    if isinstance(csv_file, str):\n        csv_file: Path = Path(csv_file)\n    if isinstance(pq_file, str):\n        pq_file: Path = Path(pq_file)\n\n    if not pq_file.exists():\n        raise FileNotFoundError(f\"Could not find input Parquet file at path: {pq_file}\")\n\n    try:\n        df = load_pq(pq_file=pq_file)\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception reading Parquet file '{pq_file}' to DataFrame. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n\n    try:\n        success = save_csv(df=df, csv_file=csv_file, columns=df.columns, dedupe=dedupe)\n\n        return success\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception writing DataFrame to file: {csv_file}. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/__init__/#red_utils.ext.dataframe_utils.pandas_utils.count_df_rows","title":"<code>count_df_rows(df=None)</code>","text":"<p>Return count of the number of rows in a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>A Pandas <code>DataFrame</code> to count the rows in</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>Count of rows in a <code>DataFrame</code></p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\pandas_utils\\operations.py</code> <pre><code>def count_df_rows(df: pd.DataFrame = None) -&gt; int:\n    \"\"\"Return count of the number of rows in a DataFrame.\n\n    Params:\n        df (pandas.DataFrame): A Pandas `DataFrame` to count the rows in\n\n    Returns:\n        (int): Count of rows in a `DataFrame`\n\n    \"\"\"\n    if df is not None:\n        if df.empty:\n            return\n    else:\n        return\n\n    if not isinstance(df, pd.DataFrame) and not isinstance(df, pd.Series):\n        raise TypeError(\n            f\"Invalid type for DataFrame: ({type(df)}). Must be a Pandas Series or DataFrame\"\n        )\n\n    return len(df.index)\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/__init__/#red_utils.ext.dataframe_utils.pandas_utils.get_oldest_newest","title":"<code>get_oldest_newest(df=None, date_col=None, filter_cols=None)</code>","text":"<p>Get the oldest and newest rows in a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Pandas DataFrame to work on</p> <code>None</code> <code>date_col</code> <code>str</code> <p>Name of the column to sort by</p> <code>None</code> <code>filter_cols</code> <code>list[str]</code> <p>List of column names to return with the oldest/newest record.</p> <code>None</code> <p>Returns:</p> Type Description <code>Series | DataFrame</code> <p>A Pandas <code>DataFrame</code> or <code>Series</code> containing oldest &amp; newest records</p> <code>Union[Series, DataFrame]</code> <p>in the input <code>DataFrame</code>.</p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\pandas_utils\\operations.py</code> <pre><code>def get_oldest_newest(\n    df: pd.DataFrame = None, date_col: str = None, filter_cols: list[str] | None = None\n) -&gt; Union[pd.Series, pd.DataFrame]:\n    \"\"\"Get the oldest and newest rows in a DataFrame.\n\n    Params:\n        df (pd.DataFrame): Pandas DataFrame to work on\n        date_col (str): Name of the column to sort by\n        filter_cols (list[str]): List of column names to return with the oldest/newest record.\n\n    Returns:\n        (pandas.Series|pandas.DataFrame): A Pandas `DataFrame` or `Series` containing oldest &amp; newest records\n        in the input `DataFrame`.\n\n    \"\"\"\n    if df is None or df.empty:\n        raise ValueError(\"Missing or empty DataFrame\")\n    if date_col is None:\n        raise ValueError(\"Missing name of date column to sort by\")\n\n    try:\n        min_date = df[date_col].min()\n        oldest = df.loc[df[date_col] == min_date]\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting min date value from column [{date_col}]. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n\n    try:\n        max_date = df[date_col].max()\n        newest = df.loc[df[date_col] == max_date]\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting max date value from column [{date_col}]. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n\n    if filter_cols is not None:\n        try:\n            oldest = oldest[filter_cols]\n            newest = newest[filter_cols]\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception filtering columns. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n    return oldest, newest\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/__init__/#red_utils.ext.dataframe_utils.pandas_utils.load_csv","title":"<code>load_csv(csv_file=None, delimiter=',')</code>","text":"<p>Load a CSV file into a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>csv_file</code> <code>str | Path</code> <p>The path to a <code>.csv</code> file to load into a `DataFrame</p> <code>None</code> <code>delimiter</code> <code>str</code> <p>The delimiter symbol the <code>csv_file</code> uses</p> <code>','</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A Pandas <code>DataFrame</code> with data loaded from the <code>csv_file</code></p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\pandas_utils\\operations.py</code> <pre><code>def load_csv(csv_file: Union[str, Path] = None, delimiter: str = \",\") -&gt; pd.DataFrame:\n    \"\"\"Load a CSV file into a DataFrame.\n\n    Params:\n        csv_file (str|Path): The path to a `.csv` file to load into a `DataFrame\n        delimiter (str): The delimiter symbol the `csv_file` uses\n\n    Returns:\n        (pandas.DataFrame): A Pandas `DataFrame` with data loaded from the `csv_file`\n\n    \"\"\"\n    if csv_file is None:\n        raise ValueError(\"Missing output path\")\n\n    if isinstance(csv_file, str):\n        csv_file: Path = Path(csv_file)\n\n    if csv_file.suffix != \".csv\":\n        new_str = str(f\"{csv_file}.csv\")\n        csv_file: Path = Path(new_str)\n\n    if not csv_file.exists():\n        msg = FileNotFoundError(f\"Could not find CSV file: '{csv_file}'.\")\n        log.error(msg)\n        raise exc\n\n    try:\n        df = pd.read_csv(csv_file, delimiter=delimiter)\n\n        return df\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception loading DataFrame from CSV file: {csv_file}. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/__init__/#red_utils.ext.dataframe_utils.pandas_utils.load_pq","title":"<code>load_pq(pq_file=None, pq_engine='pyarrow')</code>","text":"<p>Return a DataFrame from a previously saved .parquet file.</p> <p>Parameters:</p> Name Type Description Default <code>pq_file</code> <code>str | Path</code> <p>Path to a <code>.parquet</code> file to load</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A Pandas <code>DataFrame</code> loaded from a <code>.parquet</code> file</p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\pandas_utils\\operations.py</code> <pre><code>def load_pq(\n    pq_file: Union[str, Path] = None, pq_engine: str = \"pyarrow\"\n) -&gt; pd.DataFrame:\n    \"\"\"Return a DataFrame from a previously saved .parquet file.\n\n    Params:\n        pq_file (str|Path): Path to a `.parquet` file to load\n\n    Returns:\n        (pandas.DataFrame): A Pandas `DataFrame` loaded from a `.parquet` file\n\n    \"\"\"\n    if pq_file is None:\n        raise ValueError(\"Missing pq_file to load\")\n    if isinstance(pq_file, str):\n        pq_file: Path = Path(pq_file)\n\n    if not pq_file.suffix == \".parquet\":\n        pq_file: Path = Path(f\"{pq_file}.parquet\")\n\n    if not pq_file.exists():\n        msg = FileNotFoundError(f\"Could not find Parquet file at '{pq_file}'\")\n        # log.error(msg)\n        log.error(msg)\n\n        raise exc\n\n    try:\n        df = pd.read_parquet(pq_file, engine=pq_engine)\n\n        return df\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception loading Parquet file '{pq_file}' to DataFrame. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/__init__/#red_utils.ext.dataframe_utils.pandas_utils.load_pqs_to_df","title":"<code>load_pqs_to_df(search_dir=None, filetype='.parquet')</code>","text":"<p>Load data export files in search_dir into list of DataFrames.</p> <p>Parameters:</p> Name Type Description Default <code>search_dir</code> <code>str</code> <p>The directory to search for files in</p> <code>None</code> <code>filetype</code> <code>str</code> <p>The file extension to filter results by</p> <code>'.parquet'</code> <p>Returns:</p> Type Description <code>list[DataFrame]</code> <p>A list of Pandas <code>DataFrame</code>s created from files in <code>search_dir</code></p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\pandas_utils\\operations.py</code> <pre><code>def load_pqs_to_df(\n    search_dir: str = None, filetype: str = \".parquet\"\n) -&gt; list[pd.DataFrame]:\n    \"\"\"Load data export files in search_dir into list of DataFrames.\n\n    Params:\n        search_dir (str): The directory to search for files in\n        filetype (str): The file extension to filter results by\n\n    Returns:\n        (list[pandas.DataFrame]): A list of Pandas `DataFrame`s created from files in `search_dir`\n\n    \"\"\"\n    if search_dir is None:\n        raise ValueError(\"Missing a directory to search\")\n\n    if not filetype.startswith(\".\"):\n        filetype = f\".{filetype}\"\n\n    files: list[Path] = []\n\n    for f in Path(search_dir).glob(f\"**/*{filetype}\"):\n        if f.is_file():\n            files.append(f)\n\n    dataframes: list[pd.DataFrame] = []\n\n    if filetype == \".parquet\":\n        for pq in files:\n            df = load_pq(pq_file=pq)\n\n            dataframes.append(df)\n\n    elif filetype == \".csv\":\n        for f in files:\n            df = pd.read_csv(f)\n\n            dataframes.append(df)\n\n    return dataframes\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/__init__/#red_utils.ext.dataframe_utils.pandas_utils.rename_df_cols","title":"<code>rename_df_cols(df=None, col_rename_map=None)</code>","text":"<p>Return a DataFrame with columns renamed based on input col_rename_map.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>A Pandas <code>DataFrame</code> with columns to rename col_rename_map (dict[str, str]): A Python <code>dict</code> defining existing column names and the value they should be renamed to.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A renamed Pandas <code>DataFrame</code>.</p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\pandas_utils\\operations.py</code> <pre><code>def rename_df_cols(\n    df: pd.DataFrame = None, col_rename_map: dict[str, str] = None\n) -&gt; pd.DataFrame:\n    \"\"\"Return a DataFrame with columns renamed based on input col_rename_map.\n\n    Params:\n        df (pandas.DataFrame): A Pandas `DataFrame` with columns to rename\n            col_rename_map (dict[str, str]): A Python `dict` defining existing column names and the value\n            they should be renamed to.\n\n    Returns:\n        (pandas.DataFrame): A renamed Pandas `DataFrame`.\n\n    \"\"\"\n    if col_rename_map is None:\n        msg = ValueError(\"No col_rename_map passed\")\n        log.warning(msg)\n\n        return df\n\n    if df is None or df.empty:\n        msg = ValueError(\"Missing DataFrame, or DataFrame is empty\")\n        log.error(msg)\n\n        raise ValueError(msg)\n\n    try:\n        df = df.rename(columns=col_rename_map)\n\n        return df\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception renaming DataFrame columns. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/__init__/#red_utils.ext.dataframe_utils.pandas_utils.save_csv","title":"<code>save_csv(df=None, csv_file=None, columns=None, dedupe=False)</code>","text":"<p>Save DataFrame to a .csv file.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>A Pandas <code>DataFrame</code> to save</p> <code>None</code> <code>csv_file</code> <code>str | Path</code> <p>The path to a <code>.csv</code> file where the <code>DataFrame</code> should be saved</p> <code>None</code> <code>columns</code> <code>list[str]</code> <p>A list of string values representing column names for the <code>.csv</code> file</p> <code>None</code> <code>dedupe</code> <code>bool</code> <p>If <code>True</code>, deduplicate the <code>DataFrame</code> before saving</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>DataFrame</code> is saved to <code>csv_file</code> successfully</p> <code>bool</code> <p><code>False</code> if <code>DataFrame</code> is not saved to <code>csv_file</code> successfully</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If file cannot be saved, an <code>Exception</code> is raised</p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\pandas_utils\\operations.py</code> <pre><code>def save_csv(\n    df: pd.DataFrame = None,\n    csv_file: Union[str, Path] = None,\n    columns: list[str] = None,\n    dedupe: bool = False,\n) -&gt; bool:\n    \"\"\"Save DataFrame to a .csv file.\n\n    Params:\n        df (pandas.DataFrame): A Pandas `DataFrame` to save\n        csv_file (str|Path): The path to a `.csv` file where the `DataFrame` should be saved\n        columns (list[str]): A list of string values representing column names for the `.csv` file\n        dedupe (bool): If `True`, deduplicate the `DataFrame` before saving\n\n    Returns:\n        (bool): `True` if `DataFrame` is saved to `csv_file` successfully\n        (bool): `False` if `DataFrame` is not saved to `csv_file` successfully\n\n    Raises:\n        Exception: If file cannot be saved, an `Exception` is raised\n\n    \"\"\"\n    if df is None or df.empty:\n        msg = ValueError(\"DataFrame is None or empty\")\n\n        return False\n\n    if csv_file is None:\n        raise ValueError(\"Missing output path\")\n    if isinstance(csv_file, str):\n        csv_file: Path = Path(csv_file)\n\n    if csv_file.suffix != \".csv\":\n        new_str = str(f\"{csv_file}.csv\")\n        csv_file: Path = Path(new_str)\n\n    if not csv_file.parent.exists():\n        try:\n            csv_file.parent.mkdir(exist_ok=True, parents=True)\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception creating directory: {csv_file.parent}. Details: {exc}\"\n            )\n            log.error(msg)\n\n            return False\n\n    if columns is None:\n        columns = df.columns\n\n    try:\n        if dedupe:\n            df = df.drop_duplicates()\n\n        if columns is not None:\n            output = df.to_csv(csv_file, columns=columns)\n        else:\n            output = df.to_csv(csv_file)\n\n        return True\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception saving DataFrame to Parquet file: {csv_file}. Details: {exc}\"\n        )\n        log.error(msg)\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/__init__/#red_utils.ext.dataframe_utils.pandas_utils.save_pq","title":"<code>save_pq(df=None, pq_file=None, dedupe=False, pq_engine='pyarrow')</code>","text":"<p>Save DataFrame to a .parquet file.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>A Pandas <code>DataFrame</code> to save</p> <code>None</code> <code>pq_file</code> <code>str | Path</code> <p>The path to a <code>.parquet</code> file where the <code>DataFrame</code> should be saved</p> <code>None</code> <code>dedupe</code> <code>bool</code> <p>If <code>True</code>, deduplicate the <code>DataFrame</code> before saving</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>DataFrame</code> is saved to <code>pq_file</code> successfully</p> <code>bool</code> <p><code>False</code> if <code>DataFrame</code> is not saved to <code>pq_file</code> successfully</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If file cannot be saved, an <code>Exception</code> is raised</p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\pandas_utils\\operations.py</code> <pre><code>def save_pq(\n    df: pd.DataFrame = None,\n    pq_file: Union[str, Path] = None,\n    dedupe: bool = False,\n    pq_engine: str = \"pyarrow\",\n) -&gt; bool:\n    \"\"\"Save DataFrame to a .parquet file.\n\n    Params:\n        df (pandas.DataFrame): A Pandas `DataFrame` to save\n        pq_file (str|Path): The path to a `.parquet` file where the `DataFrame` should be saved\n        dedupe (bool): If `True`, deduplicate the `DataFrame` before saving\n\n    Returns:\n        (bool): `True` if `DataFrame` is saved to `pq_file` successfully\n        (bool): `False` if `DataFrame` is not saved to `pq_file` successfully\n\n    Raises:\n        Exception: If file cannot be saved, an `Exception` is raised\n\n    \"\"\"\n    if df is None or df.empty:\n        msg = ValueError(\"DataFrame is None or empty\")\n        log.warning(msg)\n\n        return False\n\n    if pq_file is None:\n        raise ValueError(\"Missing output path\")\n    if isinstance(pq_file, str):\n        pq_file: Path = Path(pq_file)\n\n    if pq_file.suffix != \".parquet\":\n        new_str = str(f\"{pq_file}.parquet\")\n        pq_file: Path = Path(new_str)\n\n    if not pq_file.parent.exists():\n        try:\n            pq_file.parent.mkdir(exist_ok=True, parents=True)\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception creating directory: {pq_file.parent}. Details: {exc}\"\n            )\n            log.error(msg)\n\n            return False\n\n    try:\n        if dedupe:\n            df = df.drop_duplicates()\n\n        output = df.to_parquet(path=pq_file, engine=pq_engine)\n\n        return True\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception saving DataFrame to Parquet file: {pq_file}. Details: {exc}\"\n        )\n        log.error(msg)\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/constants/","title":"constants","text":"<p>Pre-defined constants for use in <code>pandas</code> utility functions &amp; methods.</p> <p>Examples: - <code>PANDAS_DATETIME_FORMAT</code> (str): \"%Y-%m-%dT%H:%M:%SZ\" - <code>PANDAS_DATE_FORMAT</code> (str): \"%Y-%m-%d\" - <code>PANDAS_TIME_FORMAT</code> (str): \"%H:%M:%S\"</p>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/operations/","title":"operations","text":""},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/operations/#red_utils.ext.dataframe_utils.pandas_utils.operations.convert_csv_to_pq","title":"<code>convert_csv_to_pq(csv_file=None, pq_file=None, dedupe=False)</code>","text":"<p>Read a CSV file into a DataFrame, then write the DataFrame to a Parquet file.</p> <p>Parameters:</p> Name Type Description Default <code>csv_file</code> <code>str | Path</code> <p>Path to a CSV file to read from</p> <code>None</code> <code>pq_file</code> <code>str | Path</code> <p>Path to a Parquet file to write to</p> <code>None</code> <code>dedupe</code> <code>bool</code> <p>Whether to run .drop_duplicates() on the DataFrame</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>csv_file</code> is converted to <code>pq_file</code> successfully</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If file cannot be saved, an <code>Exception</code> is raised instead of returning a bool value</p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\pandas_utils\\operations.py</code> <pre><code>def convert_csv_to_pq(\n    csv_file: Union[str, Path] = None,\n    pq_file: Union[str, Path] = None,\n    dedupe: bool = False,\n) -&gt; bool:\n    \"\"\"Read a CSV file into a DataFrame, then write the DataFrame to a Parquet file.\n\n    Params:\n        csv_file (str|Path): Path to a CSV file to read from\n        pq_file (str|Path): Path to a Parquet file to write to\n        dedupe (bool): Whether to run .drop_duplicates() on the DataFrame\n\n    Returns:\n        (bool): `True` if `csv_file` is converted to `pq_file` successfully\n\n    Raises:\n        Exception: If file cannot be saved, an `Exception` is raised instead of returning\n            a bool value\n\n    \"\"\"\n    if csv_file is None:\n        raise ValueError(\"Missing a CSV input file to read from\")\n    if pq_file is None:\n        raise ValueError(\"Missing a Parquet file to save to\")\n\n    if isinstance(csv_file, str):\n        csv_file: Path = Path(csv_file)\n    if isinstance(pq_file, str):\n        pq_file: Path = Path(pq_file)\n\n    if not csv_file.exists():\n        raise FileNotFoundError(f\"Could not find input CSV file at path: {csv_file}\")\n\n    try:\n        df = load_csv(csv_file=csv_file)\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception reading CSV file '{csv_file}' to DataFrame. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n\n    try:\n        success = save_pq(df=df, pq_file=pq_file, dedupe=dedupe)\n\n        return success\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception writing DataFrame to file: {pq_file}. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/operations/#red_utils.ext.dataframe_utils.pandas_utils.operations.convert_pq_to_csv","title":"<code>convert_pq_to_csv(pq_file=None, csv_file=None, dedupe=False)</code>","text":"<p>Read a Parquet file into a DataFrame, then write the DataFrame to a CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>pq_file</code> <code>str | Path</code> <p>Path to a Parquet file to read from</p> <code>None</code> <code>csv_file</code> <code>str | Path</code> <p>Path to a CSV file to write to</p> <code>None</code> <code>dedupe</code> <code>bool</code> <p>Whether to run .drop_duplicates() on the DataFrame</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>pq_file</code> is converted to <code>csv_file</code> successfully</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If file cannot be saved, an <code>Exception</code> is raised instead of returning a bool value</p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\pandas_utils\\operations.py</code> <pre><code>def convert_pq_to_csv(\n    pq_file: Union[str, Path] = None,\n    csv_file: Union[str, Path] = None,\n    dedupe: bool = False,\n) -&gt; bool:\n    \"\"\"Read a Parquet file into a DataFrame, then write the DataFrame to a CSV file.\n\n    Params:\n        pq_file (str|Path): Path to a Parquet file to read from\n        csv_file (str|Path): Path to a CSV file to write to\n        dedupe (bool): Whether to run .drop_duplicates() on the DataFrame\n\n    Returns:\n        (bool): `True` if `pq_file` is converted to `csv_file` successfully\n\n    Raises:\n        Exception: If file cannot be saved, an `Exception` is raised instead of returning\n            a bool value\n\n    \"\"\"\n    if csv_file is None:\n        raise ValueError(\"Missing a CSV file to save to\")\n    if pq_file is None:\n        raise ValueError(\"Missing an input Parquet file to read from\")\n\n    if isinstance(csv_file, str):\n        csv_file: Path = Path(csv_file)\n    if isinstance(pq_file, str):\n        pq_file: Path = Path(pq_file)\n\n    if not pq_file.exists():\n        raise FileNotFoundError(f\"Could not find input Parquet file at path: {pq_file}\")\n\n    try:\n        df = load_pq(pq_file=pq_file)\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception reading Parquet file '{pq_file}' to DataFrame. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n\n    try:\n        success = save_csv(df=df, csv_file=csv_file, columns=df.columns, dedupe=dedupe)\n\n        return success\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception writing DataFrame to file: {csv_file}. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/operations/#red_utils.ext.dataframe_utils.pandas_utils.operations.count_df_rows","title":"<code>count_df_rows(df=None)</code>","text":"<p>Return count of the number of rows in a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>A Pandas <code>DataFrame</code> to count the rows in</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>Count of rows in a <code>DataFrame</code></p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\pandas_utils\\operations.py</code> <pre><code>def count_df_rows(df: pd.DataFrame = None) -&gt; int:\n    \"\"\"Return count of the number of rows in a DataFrame.\n\n    Params:\n        df (pandas.DataFrame): A Pandas `DataFrame` to count the rows in\n\n    Returns:\n        (int): Count of rows in a `DataFrame`\n\n    \"\"\"\n    if df is not None:\n        if df.empty:\n            return\n    else:\n        return\n\n    if not isinstance(df, pd.DataFrame) and not isinstance(df, pd.Series):\n        raise TypeError(\n            f\"Invalid type for DataFrame: ({type(df)}). Must be a Pandas Series or DataFrame\"\n        )\n\n    return len(df.index)\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/operations/#red_utils.ext.dataframe_utils.pandas_utils.operations.get_oldest_newest","title":"<code>get_oldest_newest(df=None, date_col=None, filter_cols=None)</code>","text":"<p>Get the oldest and newest rows in a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Pandas DataFrame to work on</p> <code>None</code> <code>date_col</code> <code>str</code> <p>Name of the column to sort by</p> <code>None</code> <code>filter_cols</code> <code>list[str]</code> <p>List of column names to return with the oldest/newest record.</p> <code>None</code> <p>Returns:</p> Type Description <code>Series | DataFrame</code> <p>A Pandas <code>DataFrame</code> or <code>Series</code> containing oldest &amp; newest records</p> <code>Union[Series, DataFrame]</code> <p>in the input <code>DataFrame</code>.</p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\pandas_utils\\operations.py</code> <pre><code>def get_oldest_newest(\n    df: pd.DataFrame = None, date_col: str = None, filter_cols: list[str] | None = None\n) -&gt; Union[pd.Series, pd.DataFrame]:\n    \"\"\"Get the oldest and newest rows in a DataFrame.\n\n    Params:\n        df (pd.DataFrame): Pandas DataFrame to work on\n        date_col (str): Name of the column to sort by\n        filter_cols (list[str]): List of column names to return with the oldest/newest record.\n\n    Returns:\n        (pandas.Series|pandas.DataFrame): A Pandas `DataFrame` or `Series` containing oldest &amp; newest records\n        in the input `DataFrame`.\n\n    \"\"\"\n    if df is None or df.empty:\n        raise ValueError(\"Missing or empty DataFrame\")\n    if date_col is None:\n        raise ValueError(\"Missing name of date column to sort by\")\n\n    try:\n        min_date = df[date_col].min()\n        oldest = df.loc[df[date_col] == min_date]\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting min date value from column [{date_col}]. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n\n    try:\n        max_date = df[date_col].max()\n        newest = df.loc[df[date_col] == max_date]\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting max date value from column [{date_col}]. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n\n    if filter_cols is not None:\n        try:\n            oldest = oldest[filter_cols]\n            newest = newest[filter_cols]\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception filtering columns. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n    return oldest, newest\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/operations/#red_utils.ext.dataframe_utils.pandas_utils.operations.load_csv","title":"<code>load_csv(csv_file=None, delimiter=',')</code>","text":"<p>Load a CSV file into a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>csv_file</code> <code>str | Path</code> <p>The path to a <code>.csv</code> file to load into a `DataFrame</p> <code>None</code> <code>delimiter</code> <code>str</code> <p>The delimiter symbol the <code>csv_file</code> uses</p> <code>','</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A Pandas <code>DataFrame</code> with data loaded from the <code>csv_file</code></p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\pandas_utils\\operations.py</code> <pre><code>def load_csv(csv_file: Union[str, Path] = None, delimiter: str = \",\") -&gt; pd.DataFrame:\n    \"\"\"Load a CSV file into a DataFrame.\n\n    Params:\n        csv_file (str|Path): The path to a `.csv` file to load into a `DataFrame\n        delimiter (str): The delimiter symbol the `csv_file` uses\n\n    Returns:\n        (pandas.DataFrame): A Pandas `DataFrame` with data loaded from the `csv_file`\n\n    \"\"\"\n    if csv_file is None:\n        raise ValueError(\"Missing output path\")\n\n    if isinstance(csv_file, str):\n        csv_file: Path = Path(csv_file)\n\n    if csv_file.suffix != \".csv\":\n        new_str = str(f\"{csv_file}.csv\")\n        csv_file: Path = Path(new_str)\n\n    if not csv_file.exists():\n        msg = FileNotFoundError(f\"Could not find CSV file: '{csv_file}'.\")\n        log.error(msg)\n        raise exc\n\n    try:\n        df = pd.read_csv(csv_file, delimiter=delimiter)\n\n        return df\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception loading DataFrame from CSV file: {csv_file}. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/operations/#red_utils.ext.dataframe_utils.pandas_utils.operations.load_pq","title":"<code>load_pq(pq_file=None, pq_engine='pyarrow')</code>","text":"<p>Return a DataFrame from a previously saved .parquet file.</p> <p>Parameters:</p> Name Type Description Default <code>pq_file</code> <code>str | Path</code> <p>Path to a <code>.parquet</code> file to load</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A Pandas <code>DataFrame</code> loaded from a <code>.parquet</code> file</p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\pandas_utils\\operations.py</code> <pre><code>def load_pq(\n    pq_file: Union[str, Path] = None, pq_engine: str = \"pyarrow\"\n) -&gt; pd.DataFrame:\n    \"\"\"Return a DataFrame from a previously saved .parquet file.\n\n    Params:\n        pq_file (str|Path): Path to a `.parquet` file to load\n\n    Returns:\n        (pandas.DataFrame): A Pandas `DataFrame` loaded from a `.parquet` file\n\n    \"\"\"\n    if pq_file is None:\n        raise ValueError(\"Missing pq_file to load\")\n    if isinstance(pq_file, str):\n        pq_file: Path = Path(pq_file)\n\n    if not pq_file.suffix == \".parquet\":\n        pq_file: Path = Path(f\"{pq_file}.parquet\")\n\n    if not pq_file.exists():\n        msg = FileNotFoundError(f\"Could not find Parquet file at '{pq_file}'\")\n        # log.error(msg)\n        log.error(msg)\n\n        raise exc\n\n    try:\n        df = pd.read_parquet(pq_file, engine=pq_engine)\n\n        return df\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception loading Parquet file '{pq_file}' to DataFrame. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/operations/#red_utils.ext.dataframe_utils.pandas_utils.operations.load_pqs_to_df","title":"<code>load_pqs_to_df(search_dir=None, filetype='.parquet')</code>","text":"<p>Load data export files in search_dir into list of DataFrames.</p> <p>Parameters:</p> Name Type Description Default <code>search_dir</code> <code>str</code> <p>The directory to search for files in</p> <code>None</code> <code>filetype</code> <code>str</code> <p>The file extension to filter results by</p> <code>'.parquet'</code> <p>Returns:</p> Type Description <code>list[DataFrame]</code> <p>A list of Pandas <code>DataFrame</code>s created from files in <code>search_dir</code></p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\pandas_utils\\operations.py</code> <pre><code>def load_pqs_to_df(\n    search_dir: str = None, filetype: str = \".parquet\"\n) -&gt; list[pd.DataFrame]:\n    \"\"\"Load data export files in search_dir into list of DataFrames.\n\n    Params:\n        search_dir (str): The directory to search for files in\n        filetype (str): The file extension to filter results by\n\n    Returns:\n        (list[pandas.DataFrame]): A list of Pandas `DataFrame`s created from files in `search_dir`\n\n    \"\"\"\n    if search_dir is None:\n        raise ValueError(\"Missing a directory to search\")\n\n    if not filetype.startswith(\".\"):\n        filetype = f\".{filetype}\"\n\n    files: list[Path] = []\n\n    for f in Path(search_dir).glob(f\"**/*{filetype}\"):\n        if f.is_file():\n            files.append(f)\n\n    dataframes: list[pd.DataFrame] = []\n\n    if filetype == \".parquet\":\n        for pq in files:\n            df = load_pq(pq_file=pq)\n\n            dataframes.append(df)\n\n    elif filetype == \".csv\":\n        for f in files:\n            df = pd.read_csv(f)\n\n            dataframes.append(df)\n\n    return dataframes\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/operations/#red_utils.ext.dataframe_utils.pandas_utils.operations.rename_df_cols","title":"<code>rename_df_cols(df=None, col_rename_map=None)</code>","text":"<p>Return a DataFrame with columns renamed based on input col_rename_map.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>A Pandas <code>DataFrame</code> with columns to rename col_rename_map (dict[str, str]): A Python <code>dict</code> defining existing column names and the value they should be renamed to.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A renamed Pandas <code>DataFrame</code>.</p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\pandas_utils\\operations.py</code> <pre><code>def rename_df_cols(\n    df: pd.DataFrame = None, col_rename_map: dict[str, str] = None\n) -&gt; pd.DataFrame:\n    \"\"\"Return a DataFrame with columns renamed based on input col_rename_map.\n\n    Params:\n        df (pandas.DataFrame): A Pandas `DataFrame` with columns to rename\n            col_rename_map (dict[str, str]): A Python `dict` defining existing column names and the value\n            they should be renamed to.\n\n    Returns:\n        (pandas.DataFrame): A renamed Pandas `DataFrame`.\n\n    \"\"\"\n    if col_rename_map is None:\n        msg = ValueError(\"No col_rename_map passed\")\n        log.warning(msg)\n\n        return df\n\n    if df is None or df.empty:\n        msg = ValueError(\"Missing DataFrame, or DataFrame is empty\")\n        log.error(msg)\n\n        raise ValueError(msg)\n\n    try:\n        df = df.rename(columns=col_rename_map)\n\n        return df\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception renaming DataFrame columns. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/operations/#red_utils.ext.dataframe_utils.pandas_utils.operations.save_csv","title":"<code>save_csv(df=None, csv_file=None, columns=None, dedupe=False)</code>","text":"<p>Save DataFrame to a .csv file.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>A Pandas <code>DataFrame</code> to save</p> <code>None</code> <code>csv_file</code> <code>str | Path</code> <p>The path to a <code>.csv</code> file where the <code>DataFrame</code> should be saved</p> <code>None</code> <code>columns</code> <code>list[str]</code> <p>A list of string values representing column names for the <code>.csv</code> file</p> <code>None</code> <code>dedupe</code> <code>bool</code> <p>If <code>True</code>, deduplicate the <code>DataFrame</code> before saving</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>DataFrame</code> is saved to <code>csv_file</code> successfully</p> <code>bool</code> <p><code>False</code> if <code>DataFrame</code> is not saved to <code>csv_file</code> successfully</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If file cannot be saved, an <code>Exception</code> is raised</p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\pandas_utils\\operations.py</code> <pre><code>def save_csv(\n    df: pd.DataFrame = None,\n    csv_file: Union[str, Path] = None,\n    columns: list[str] = None,\n    dedupe: bool = False,\n) -&gt; bool:\n    \"\"\"Save DataFrame to a .csv file.\n\n    Params:\n        df (pandas.DataFrame): A Pandas `DataFrame` to save\n        csv_file (str|Path): The path to a `.csv` file where the `DataFrame` should be saved\n        columns (list[str]): A list of string values representing column names for the `.csv` file\n        dedupe (bool): If `True`, deduplicate the `DataFrame` before saving\n\n    Returns:\n        (bool): `True` if `DataFrame` is saved to `csv_file` successfully\n        (bool): `False` if `DataFrame` is not saved to `csv_file` successfully\n\n    Raises:\n        Exception: If file cannot be saved, an `Exception` is raised\n\n    \"\"\"\n    if df is None or df.empty:\n        msg = ValueError(\"DataFrame is None or empty\")\n\n        return False\n\n    if csv_file is None:\n        raise ValueError(\"Missing output path\")\n    if isinstance(csv_file, str):\n        csv_file: Path = Path(csv_file)\n\n    if csv_file.suffix != \".csv\":\n        new_str = str(f\"{csv_file}.csv\")\n        csv_file: Path = Path(new_str)\n\n    if not csv_file.parent.exists():\n        try:\n            csv_file.parent.mkdir(exist_ok=True, parents=True)\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception creating directory: {csv_file.parent}. Details: {exc}\"\n            )\n            log.error(msg)\n\n            return False\n\n    if columns is None:\n        columns = df.columns\n\n    try:\n        if dedupe:\n            df = df.drop_duplicates()\n\n        if columns is not None:\n            output = df.to_csv(csv_file, columns=columns)\n        else:\n            output = df.to_csv(csv_file)\n\n        return True\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception saving DataFrame to Parquet file: {csv_file}. Details: {exc}\"\n        )\n        log.error(msg)\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/operations/#red_utils.ext.dataframe_utils.pandas_utils.operations.save_pq","title":"<code>save_pq(df=None, pq_file=None, dedupe=False, pq_engine='pyarrow')</code>","text":"<p>Save DataFrame to a .parquet file.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>A Pandas <code>DataFrame</code> to save</p> <code>None</code> <code>pq_file</code> <code>str | Path</code> <p>The path to a <code>.parquet</code> file where the <code>DataFrame</code> should be saved</p> <code>None</code> <code>dedupe</code> <code>bool</code> <p>If <code>True</code>, deduplicate the <code>DataFrame</code> before saving</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>DataFrame</code> is saved to <code>pq_file</code> successfully</p> <code>bool</code> <p><code>False</code> if <code>DataFrame</code> is not saved to <code>pq_file</code> successfully</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If file cannot be saved, an <code>Exception</code> is raised</p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\pandas_utils\\operations.py</code> <pre><code>def save_pq(\n    df: pd.DataFrame = None,\n    pq_file: Union[str, Path] = None,\n    dedupe: bool = False,\n    pq_engine: str = \"pyarrow\",\n) -&gt; bool:\n    \"\"\"Save DataFrame to a .parquet file.\n\n    Params:\n        df (pandas.DataFrame): A Pandas `DataFrame` to save\n        pq_file (str|Path): The path to a `.parquet` file where the `DataFrame` should be saved\n        dedupe (bool): If `True`, deduplicate the `DataFrame` before saving\n\n    Returns:\n        (bool): `True` if `DataFrame` is saved to `pq_file` successfully\n        (bool): `False` if `DataFrame` is not saved to `pq_file` successfully\n\n    Raises:\n        Exception: If file cannot be saved, an `Exception` is raised\n\n    \"\"\"\n    if df is None or df.empty:\n        msg = ValueError(\"DataFrame is None or empty\")\n        log.warning(msg)\n\n        return False\n\n    if pq_file is None:\n        raise ValueError(\"Missing output path\")\n    if isinstance(pq_file, str):\n        pq_file: Path = Path(pq_file)\n\n    if pq_file.suffix != \".parquet\":\n        new_str = str(f\"{pq_file}.parquet\")\n        pq_file: Path = Path(new_str)\n\n    if not pq_file.parent.exists():\n        try:\n            pq_file.parent.mkdir(exist_ok=True, parents=True)\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception creating directory: {pq_file.parent}. Details: {exc}\"\n            )\n            log.error(msg)\n\n            return False\n\n    try:\n        if dedupe:\n            df = df.drop_duplicates()\n\n        output = df.to_parquet(path=pq_file, engine=pq_engine)\n\n        return True\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception saving DataFrame to Parquet file: {pq_file}. Details: {exc}\"\n        )\n        log.error(msg)\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/pandas_utils/operations/#red_utils.ext.dataframe_utils.pandas_utils.operations.validate_df_col_type","title":"<code>validate_df_col_type(col_type=None)</code>","text":"<p>Validate a given column type is in the list of allowed column types.</p> <p>Parameters:</p> Name Type Description Default <code>col_type</code> <code>str</code> <p>The <code>pandas</code>/<code>numpy</code> datatype of a column.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The validated <code>col_type</code></p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a <code>col_type</code> does not exist in the list of <code>VALID_COL_TYPES</code>, a <code>ValueError</code> is raised</p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\validators\\pandas_validators\\validators.py</code> <pre><code>def validate_df_col_type(col_type: str = None) -&gt; str:\n    \"\"\"Validate a given column type is in the list of allowed column types.\n\n    Params:\n        col_type (str): The `pandas`/`numpy` datatype of a column.\n\n    Returns:\n        (str): The validated `col_type`\n\n    Raises:\n        ValueError: If a `col_type` does not exist in the list of `VALID_COL_TYPES`, a `ValueError` is raised\n\n    \"\"\"\n    if col_type is None:\n        raise ValueError(\"Missing a column type to validate\")\n\n    if col_type in VALID_COL_TYPES:\n        return col_type\n    else:\n        raise ValueError(\n            f\"Invalid column type: [{col_type}]. Must be one of {VALID_COL_TYPES}\"\n        )\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/polars_utils/__init__/","title":"polars_utils","text":"<p>Utilities for the <code>polars</code> <code>DataFrame</code> library</p>"},{"location":"reference/red_utils/ext/dataframe_utils/validators/__init__/","title":"validators","text":"<p>Validators for Pandas and Polars <code>DataFrame</code>s</p>"},{"location":"reference/red_utils/ext/dataframe_utils/validators/pandas_validators/__init__/","title":"pandas_validators","text":"<p>Validators for the Pandas <code>DataFrame</code> library</p>"},{"location":"reference/red_utils/ext/dataframe_utils/validators/pandas_validators/__init__/#red_utils.ext.dataframe_utils.validators.pandas_validators.validate_df_col_type","title":"<code>validate_df_col_type(col_type=None)</code>","text":"<p>Validate a given column type is in the list of allowed column types.</p> <p>Parameters:</p> Name Type Description Default <code>col_type</code> <code>str</code> <p>The <code>pandas</code>/<code>numpy</code> datatype of a column.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The validated <code>col_type</code></p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a <code>col_type</code> does not exist in the list of <code>VALID_COL_TYPES</code>, a <code>ValueError</code> is raised</p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\validators\\pandas_validators\\validators.py</code> <pre><code>def validate_df_col_type(col_type: str = None) -&gt; str:\n    \"\"\"Validate a given column type is in the list of allowed column types.\n\n    Params:\n        col_type (str): The `pandas`/`numpy` datatype of a column.\n\n    Returns:\n        (str): The validated `col_type`\n\n    Raises:\n        ValueError: If a `col_type` does not exist in the list of `VALID_COL_TYPES`, a `ValueError` is raised\n\n    \"\"\"\n    if col_type is None:\n        raise ValueError(\"Missing a column type to validate\")\n\n    if col_type in VALID_COL_TYPES:\n        return col_type\n    else:\n        raise ValueError(\n            f\"Invalid column type: [{col_type}]. Must be one of {VALID_COL_TYPES}\"\n        )\n</code></pre>"},{"location":"reference/red_utils/ext/dataframe_utils/validators/pandas_validators/validators/","title":"validators","text":""},{"location":"reference/red_utils/ext/dataframe_utils/validators/pandas_validators/validators/#red_utils.ext.dataframe_utils.validators.pandas_validators.validators.validate_df_col_type","title":"<code>validate_df_col_type(col_type=None)</code>","text":"<p>Validate a given column type is in the list of allowed column types.</p> <p>Parameters:</p> Name Type Description Default <code>col_type</code> <code>str</code> <p>The <code>pandas</code>/<code>numpy</code> datatype of a column.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The validated <code>col_type</code></p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a <code>col_type</code> does not exist in the list of <code>VALID_COL_TYPES</code>, a <code>ValueError</code> is raised</p> Source code in <code>src\\red_utils\\ext\\dataframe_utils\\validators\\pandas_validators\\validators.py</code> <pre><code>def validate_df_col_type(col_type: str = None) -&gt; str:\n    \"\"\"Validate a given column type is in the list of allowed column types.\n\n    Params:\n        col_type (str): The `pandas`/`numpy` datatype of a column.\n\n    Returns:\n        (str): The validated `col_type`\n\n    Raises:\n        ValueError: If a `col_type` does not exist in the list of `VALID_COL_TYPES`, a `ValueError` is raised\n\n    \"\"\"\n    if col_type is None:\n        raise ValueError(\"Missing a column type to validate\")\n\n    if col_type in VALID_COL_TYPES:\n        return col_type\n    else:\n        raise ValueError(\n            f\"Invalid column type: [{col_type}]. Must be one of {VALID_COL_TYPES}\"\n        )\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__defaults/","title":"__defaults","text":""},{"location":"reference/red_utils/ext/diskcache_utils/__defaults/#red_utils.ext.diskcache_utils.__defaults.TimeoutConf","title":"<code>TimeoutConf</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DictMixin</code></p> <p>Define cache timeout as a class.</p> <p>Inherits the .as_dict() method from DictMixin.</p> <p>Parameters:</p> Name Type Description Default <code>amount</code> <code>int</code> <p>Amount of time to allow for timeout</p> <code>15</code> <code>unit</code> <code>str</code> <p>Unit of time corresponding with the <code>amount</code> passed. Examples: [\"minutes\", \"hours\", \"days\", etc]</p> <code>'minutes'</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\constants.py</code> <pre><code>@dataclass\nclass TimeoutConf(DictMixin):\n    \"\"\"Define cache timeout as a class.\n\n    Inherits the .as_dict() method from DictMixin.\n\n    Params:\n        amount (int): Amount of time to allow for timeout\n        unit (str): Unit of time corresponding with the `amount` passed. Examples: [\"minutes\", \"hours\", \"days\", etc]\n    \"\"\"\n\n    unit: str | None = field(default=\"minutes\")\n    amount: int | None = field(default=15)\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__defaults/#red_utils.ext.diskcache_utils.__defaults.convert_to_seconds","title":"<code>convert_to_seconds(amount=None, unit=None)</code>","text":"<p>Convert an amount of time to seconds.</p> <p>Parameters:</p> Name Type Description Default <code>amount</code> <code>int</code> <p>Amount of time</p> <code>None</code> <code>unit</code> <code>str</code> <p>The starting unit of time to convert to seconds. Options: [\"seconds\", \"hours\", \"minutes\", \"days\", \"weeks\"]</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p><code>amount</code> of time converted to seconds representing the <code>unit</code> of time passed</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def convert_to_seconds(amount: int = None, unit: str = None) -&gt; int:\n    \"\"\"Convert an amount of time to seconds.\n\n    Params:\n        amount (int): Amount of time\n        unit (str): The starting unit of time to convert to seconds.\n            Options: [\"seconds\", \"hours\", \"minutes\", \"days\", \"weeks\"]\n\n    Returns:\n        (int): `amount` of time converted to seconds representing the `unit` of time passed\n\n    \"\"\"\n    ## Allowed strings for conversion\n    valid_time_units: list[int] = [\"seconds\", \"hours\", \"minutes\", \"days\", \"weeks\"]\n\n    assert unit is not None, ValueError(\n        f\"Missing unit. Must be one of {valid_time_units}\"\n    )\n\n    assert isinstance(unit, str), TypeError(\n        f\"Invalid type for unit: {type(unit)}. Must be str\"\n    )\n\n    assert unit in valid_time_units, TypeError(\n        f\"Invalid unit: {unit}. Must be one of {valid_time_units}\"\n    )\n\n    amount is not None, ValueError(\"Missing amount of unit, i.e. 3 days\")\n\n    assert isinstance(amount, int), TypeError(\n        f\"Invalid type for amount: ({type(amount)}). Must be of type int\"\n    )\n\n    match unit:\n        case \"weeks\":\n            _amount: int = amount * 7 * 24 * 60 * 60\n        case \"days\":\n            _amount: int = amount * 24 * 60 * 60\n        case \"hours\":\n            _amount: int = amount * 60 * 60\n        case \"minutes\":\n            _amount: int = amount * 60\n        case \"seconds\":\n            _amount: int = amount\n        case _:\n            raise ValueError(f\"Invalid input for unit: {unit}\")\n\n    return _amount\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/","title":"diskcache_utils","text":"<p>Utilities &amp; methods for interacting with the <code>DiskCache</code> library.</p>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.CacheInstance","title":"<code>CacheInstance</code>  <code>dataclass</code>","text":"<p>               Bases: <code>CacheInstanceBase</code></p> <p>Class to control a Diskcache Cache instance.</p> <p>Parameters:</p> Name Type Description Default <code>cache_dir</code> <code>str | Path</code> <p>Directory path where cache.db will be stored.</p> <code>CACHE_DIR</code> <code>index</code> <code>bool</code> <p>Controls creation of a tag index in the cache instance.</p> <code>True</code> <code>cache</code> <code>Cache</code> <p>A diskcache.Cache object. When the class is instantiated, a Cache will be created.</p> <code>None</code> <code>cache_timeout</code> <code>int</code> <p>Default key expiration (in seconds).</p> <code>default_timeout()</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\classes.py</code> <pre><code>@dataclass\nclass CacheInstance(CacheInstanceBase):\n    \"\"\"Class to control a Diskcache Cache instance.\n\n    Params:\n        cache_dir (str|Path): Directory path where cache.db will be stored.\n        index (bool): Controls creation of a tag index in the cache instance.\n        cache (diskcache.Cache): A diskcache.Cache object. When the class is instantiated, a Cache will be created.\n        cache_timeout (int): Default key expiration (in seconds).\n    \"\"\"\n\n    def check_key_exists(self, key: Union[str, int, tuple, frozenset] = None) -&gt; bool:\n        \"\"\"Check if a key exists in a cache.\n\n        Params:\n            key (str): The cache key to search for\n\n        Returns:\n            (bool): `True` if cache key found\n            (bool): `False` if cache key not found\n\n        \"\"\"\n        ## Key validation\n        validate_key(key=key)\n        validate_cache(cache=self.cache)\n\n        ## Check if key exists in cache\n        if key in self.cache:\n            return True\n        else:\n            return False\n\n    def set_val(\n        self,\n        key: Union[str, int, tuple, frozenset],\n        val: Union[str, bytes, float, int, list, dict],\n        expire: int = None,\n        read: bool = False,\n        tag: str = None,\n        retry: bool = False,\n    ) -&gt; None:\n        \"\"\"Set a key value pair in the cache.\n\n        Params:\n            key (str): The key to store the value under in the cache\n            val (str): The value to store in the cache\n            expire (int): Time (in seconds) before value expires\n            read (bool): If `True`, read value as a file-like object\n            tag (str): Applies a tag to the cached value\n            retry (bool): If `True`, retry setting cache key if first attempt fails\n        \"\"\"\n        validate_key(key)\n        validate_val(val)\n        validate_expire(expire, none_ok=True)\n        validate_read(read, none_ok=True)\n        validate_tag(tag=tag, none_ok=True)\n        validate_retry(retry=retry, none_ok=True)\n        validate_cache(cache=self.cache)\n\n        try:\n            with self.cache as ref:\n                ref.set(\n                    key=key, value=val, expire=expire, read=read, tag=tag, retry=retry\n                )\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception setting key/value pair for key: [{key}]. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def get_val(\n        self, key: Union[str, int, tuple, frozenset] = None, tags: list[str] = None\n    ):\n        \"\"\"Search for a key in a given cache.\n\n        Pass a diskcache.Cache object for cache, and a key (and optionally a list of tags).\n        Function will search the cache and return a value if found, or a structured\n        error dict describing the lack of key.\n\n        Params:\n            key (str): The key to search the cache for\n            tags (list[str]): List of tags to search the cache for\n        \"\"\"\n        validate_key(key)\n        validate_cache(self.cache)\n        validate_tags(tags)\n\n        try:\n            if check_cache_key_exists(key=key, cache=self.cache):\n                try:\n                    with self.cache as ref:\n                        _val = ref.get(key=key)\n\n                        return _val\n\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Unhandled exception retrieving value of key [{key}]. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n            else:\n                return {\n                    \"error\": \"Key not found in cache\",\n                    \"details\": {\"key\": key, \"cache_dir\": self.cache.directory},\n                }\n\n        except Exception as exc:\n            return {\n                \"error\": \"Error searching for key in cache\",\n                \"details\": {\"exception\": exc},\n            }\n\n    def set_expire(\n        self, key: Union[str, int, tuple, frozenset] = None, expire: int = None\n    ) -&gt; Union[dict[str, str], None]:\n        \"\"\"Set an expiration timeout (in seconds).\n\n        Params:\n            key (str): Name of the key to set expiration on. Must already exist in the cache.\n            expire (int): Time (in seconds) to wait before expiring cached value.\n        \"\"\"\n        validate_key(key)\n        validate_cache(self.cache)\n        validate_expire(expire)\n\n        if not check_cache_key_exists(key=key, cache=self.cache):\n            return {\n                \"warning\": f\"Cache item with key [{key}] does not exist in cache at {self.cache.directory}/\"\n            }\n\n        try:\n            with self.cache as ref:\n                ref.touch(key, expire=expire)\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception setting expiration of {expire} on key [{key}] in cache at {self.cache.directory}/. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def delete_val(\n        self, key: Union[str, int, tuple, frozenset] = None, tag: str = None\n    ) -&gt; tuple:\n        \"\"\"Delete a cached value.\n\n        If a tag is provided, only keys that also have that tag will be deleted.\n\n        Params:\n            key (str|int): Name of key in cache.\n        \"\"\"\n        validate_key(key)\n        validate_cache(self.cache)\n        validate_tag(tag)\n\n        try:\n            with self.cache as ref:\n                _delete = ref.pop(key=key, tag=tag)\n\n                return _delete\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception deleting key {key} from cache at {self.cache.directory}/. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def get_cache_size(self) -&gt; dict[str, int]:\n        \"\"\"Get a dict describing the size of the cache, in bytes.\n\n        Returns:\n            (dict): A Python `dict` with keys: 'unit', 'size'. Example return object:\n                `{'unit': 'bytes', 'size': 36864}`\n\n        \"\"\"\n        validate_cache(cache=self.cache)\n\n        try:\n            cache_size: int = self.cache.volume()\n\n            return {\"unit\": \"bytes\", \"size\": cache_size}\n\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception getting cache size. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n    def check_cache(self) -&gt; list[warnings.WarningMessage]:\n        \"\"\"Run checks on Cache instance.\n\n        Returns:\n            (list[warning.WarningMessage]): A list of Diskcache `WarningMessage` objects.\n\n        \"\"\"\n        validate_cache(cache=self.cache)\n\n        try:\n            warnings = self.cache.check()\n\n            return warnings\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception checking cache for warnings. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.CacheInstance.check_cache","title":"<code>check_cache()</code>","text":"<p>Run checks on Cache instance.</p> <p>Returns:</p> Type Description <code>list[WarningMessage]</code> <p>A list of Diskcache <code>WarningMessage</code> objects.</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\classes.py</code> <pre><code>def check_cache(self) -&gt; list[warnings.WarningMessage]:\n    \"\"\"Run checks on Cache instance.\n\n    Returns:\n        (list[warning.WarningMessage]): A list of Diskcache `WarningMessage` objects.\n\n    \"\"\"\n    validate_cache(cache=self.cache)\n\n    try:\n        warnings = self.cache.check()\n\n        return warnings\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception checking cache for warnings. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.CacheInstance.check_key_exists","title":"<code>check_key_exists(key=None)</code>","text":"<p>Check if a key exists in a cache.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The cache key to search for</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if cache key found</p> <code>bool</code> <p><code>False</code> if cache key not found</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\classes.py</code> <pre><code>def check_key_exists(self, key: Union[str, int, tuple, frozenset] = None) -&gt; bool:\n    \"\"\"Check if a key exists in a cache.\n\n    Params:\n        key (str): The cache key to search for\n\n    Returns:\n        (bool): `True` if cache key found\n        (bool): `False` if cache key not found\n\n    \"\"\"\n    ## Key validation\n    validate_key(key=key)\n    validate_cache(cache=self.cache)\n\n    ## Check if key exists in cache\n    if key in self.cache:\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.CacheInstance.delete_val","title":"<code>delete_val(key=None, tag=None)</code>","text":"<p>Delete a cached value.</p> <p>If a tag is provided, only keys that also have that tag will be deleted.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str | int</code> <p>Name of key in cache.</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\classes.py</code> <pre><code>def delete_val(\n    self, key: Union[str, int, tuple, frozenset] = None, tag: str = None\n) -&gt; tuple:\n    \"\"\"Delete a cached value.\n\n    If a tag is provided, only keys that also have that tag will be deleted.\n\n    Params:\n        key (str|int): Name of key in cache.\n    \"\"\"\n    validate_key(key)\n    validate_cache(self.cache)\n    validate_tag(tag)\n\n    try:\n        with self.cache as ref:\n            _delete = ref.pop(key=key, tag=tag)\n\n            return _delete\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception deleting key {key} from cache at {self.cache.directory}/. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.CacheInstance.get_cache_size","title":"<code>get_cache_size()</code>","text":"<p>Get a dict describing the size of the cache, in bytes.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A Python <code>dict</code> with keys: 'unit', 'size'. Example return object: <code>{'unit': 'bytes', 'size': 36864}</code></p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\classes.py</code> <pre><code>def get_cache_size(self) -&gt; dict[str, int]:\n    \"\"\"Get a dict describing the size of the cache, in bytes.\n\n    Returns:\n        (dict): A Python `dict` with keys: 'unit', 'size'. Example return object:\n            `{'unit': 'bytes', 'size': 36864}`\n\n    \"\"\"\n    validate_cache(cache=self.cache)\n\n    try:\n        cache_size: int = self.cache.volume()\n\n        return {\"unit\": \"bytes\", \"size\": cache_size}\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception getting cache size. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.CacheInstance.get_val","title":"<code>get_val(key=None, tags=None)</code>","text":"<p>Search for a key in a given cache.</p> <p>Pass a diskcache.Cache object for cache, and a key (and optionally a list of tags). Function will search the cache and return a value if found, or a structured error dict describing the lack of key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to search the cache for</p> <code>None</code> <code>tags</code> <code>list[str]</code> <p>List of tags to search the cache for</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\classes.py</code> <pre><code>def get_val(\n    self, key: Union[str, int, tuple, frozenset] = None, tags: list[str] = None\n):\n    \"\"\"Search for a key in a given cache.\n\n    Pass a diskcache.Cache object for cache, and a key (and optionally a list of tags).\n    Function will search the cache and return a value if found, or a structured\n    error dict describing the lack of key.\n\n    Params:\n        key (str): The key to search the cache for\n        tags (list[str]): List of tags to search the cache for\n    \"\"\"\n    validate_key(key)\n    validate_cache(self.cache)\n    validate_tags(tags)\n\n    try:\n        if check_cache_key_exists(key=key, cache=self.cache):\n            try:\n                with self.cache as ref:\n                    _val = ref.get(key=key)\n\n                    return _val\n\n            except Exception as exc:\n                msg = Exception(\n                    f\"Unhandled exception retrieving value of key [{key}]. Details: {exc}\"\n                )\n                log.error(msg)\n\n                raise exc\n\n        else:\n            return {\n                \"error\": \"Key not found in cache\",\n                \"details\": {\"key\": key, \"cache_dir\": self.cache.directory},\n            }\n\n    except Exception as exc:\n        return {\n            \"error\": \"Error searching for key in cache\",\n            \"details\": {\"exception\": exc},\n        }\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.CacheInstance.set_expire","title":"<code>set_expire(key=None, expire=None)</code>","text":"<p>Set an expiration timeout (in seconds).</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name of the key to set expiration on. Must already exist in the cache.</p> <code>None</code> <code>expire</code> <code>int</code> <p>Time (in seconds) to wait before expiring cached value.</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\classes.py</code> <pre><code>def set_expire(\n    self, key: Union[str, int, tuple, frozenset] = None, expire: int = None\n) -&gt; Union[dict[str, str], None]:\n    \"\"\"Set an expiration timeout (in seconds).\n\n    Params:\n        key (str): Name of the key to set expiration on. Must already exist in the cache.\n        expire (int): Time (in seconds) to wait before expiring cached value.\n    \"\"\"\n    validate_key(key)\n    validate_cache(self.cache)\n    validate_expire(expire)\n\n    if not check_cache_key_exists(key=key, cache=self.cache):\n        return {\n            \"warning\": f\"Cache item with key [{key}] does not exist in cache at {self.cache.directory}/\"\n        }\n\n    try:\n        with self.cache as ref:\n            ref.touch(key, expire=expire)\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception setting expiration of {expire} on key [{key}] in cache at {self.cache.directory}/. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.CacheInstance.set_val","title":"<code>set_val(key, val, expire=None, read=False, tag=None, retry=False)</code>","text":"<p>Set a key value pair in the cache.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to store the value under in the cache</p> required <code>val</code> <code>str</code> <p>The value to store in the cache</p> required <code>expire</code> <code>int</code> <p>Time (in seconds) before value expires</p> <code>None</code> <code>read</code> <code>bool</code> <p>If <code>True</code>, read value as a file-like object</p> <code>False</code> <code>tag</code> <code>str</code> <p>Applies a tag to the cached value</p> <code>None</code> <code>retry</code> <code>bool</code> <p>If <code>True</code>, retry setting cache key if first attempt fails</p> <code>False</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\classes.py</code> <pre><code>def set_val(\n    self,\n    key: Union[str, int, tuple, frozenset],\n    val: Union[str, bytes, float, int, list, dict],\n    expire: int = None,\n    read: bool = False,\n    tag: str = None,\n    retry: bool = False,\n) -&gt; None:\n    \"\"\"Set a key value pair in the cache.\n\n    Params:\n        key (str): The key to store the value under in the cache\n        val (str): The value to store in the cache\n        expire (int): Time (in seconds) before value expires\n        read (bool): If `True`, read value as a file-like object\n        tag (str): Applies a tag to the cached value\n        retry (bool): If `True`, retry setting cache key if first attempt fails\n    \"\"\"\n    validate_key(key)\n    validate_val(val)\n    validate_expire(expire, none_ok=True)\n    validate_read(read, none_ok=True)\n    validate_tag(tag=tag, none_ok=True)\n    validate_retry(retry=retry, none_ok=True)\n    validate_cache(cache=self.cache)\n\n    try:\n        with self.cache as ref:\n            ref.set(\n                key=key, value=val, expire=expire, read=read, tag=tag, retry=retry\n            )\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception setting key/value pair for key: [{key}]. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.DiskCacheController","title":"<code>DiskCacheController</code>","text":"<p>               Bases: <code>AbstractContextManager</code></p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>class DiskCacheController(AbstractContextManager):\n    def __init__(\n        self,\n        cache_directory: t.Union[str, Path] | None = None,\n        cache_timeout: int = 60,\n        cache_disk: t.Type[diskcache.Disk] = diskcache.Disk,\n        index: bool = True,\n    ):\n        self.cache_directory = Path(f\"{cache_directory}\")\n        self.cache_timeout = cache_timeout\n        self.cache_disk = cache_disk\n        self.create_index = index\n\n        self.cache = None\n\n    def __enter__(self) -&gt; t.Self:\n        try:\n            _cache: diskcache.Cache = diskcache.Cache(\n                directory=self.cache_directory,\n                timeout=self.cache_timeout,\n                disk=self.cache_disk,\n            )\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception getting DiskCache Cache. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n        self.cache = _cache\n\n        if self.create_index:\n            log.info(\"Creating cache index\")\n            try:\n                self.manage_cache_tag_index(\"create\")\n            except Exception as exc:\n                msg = Exception(\n                    f\"Unhandled exception creating cache index. Details: {exc}\"\n                )\n                log.error(msg)\n\n                raise exc\n\n        return self\n\n    def __exit__(self, exc_type, exc_val, traceback):\n        if self.cache:\n            self.cache.close()\n\n        if exc_val:\n            log.error(f\"({exc_type}): {exc_val}\")\n\n        if traceback:\n            raise traceback\n\n    def manage_cache_tag_index(self, operation: str = \"create\") -&gt; None:\n        \"\"\"Create or delete a cache index.\n\n        Params:\n            operation (str): The operation to perform on the cache's tag index.\n                Options: [\"create\", \"delete\"]\n        \"\"\"\n        valid_operations: list[str] = [\"create\", \"delete\"]\n\n        validators.validate_cache(cache=self.cache)\n\n        if not operation:\n            raise Exception(f\"Operation cannot be None.\")\n\n        try:\n            match operation:\n                case \"create\":\n                    if self.cache.tag_index == 0:\n                        self.cache.create_tag_index()\n                    else:\n                        pass\n\n                case \"delete\":\n                    if self.cache.tag_index == 1:\n                        self.cache.drop_tag_index()\n                    else:\n                        pass\n\n                case _:\n                    raise ValueError(\n                        f\"Invalid operation: {operation}. Must be one of {valid_operations}\"\n                    )\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception configuring tag_index. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def clear(self) -&gt; bool:\n        \"\"\"Clear the entire cache.\n\n        Returns:\n            (bool): `True` if clearing cache successful\n            (bool): `False` if clearing the cache not successful\n\n        \"\"\"\n        validators.validate_cache(self.cache)\n\n        try:\n            with self.cache as ref:\n                ref.clear()\n\n                return True\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception clearing cache at {self.cache.directory}. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def check_key_exists(self, key: t.Union[str, int, tuple, frozenset] = None) -&gt; bool:\n        \"\"\"Check if a key exists in a cache.\n\n        Params:\n            key (str): The cache key to search for\n\n        Returns:\n            (bool): `True` if cache key found\n            (bool): `False` if cache key not found\n\n        \"\"\"\n        ## Key validation\n        validators.validate_key(key=key)\n        validators.validate_cache(cache=self.cache)\n\n        ## Check if key exists in cache\n        if key in self.cache:\n            return True\n        else:\n            return False\n\n    def set(\n        self,\n        key: t.Union[str, int, tuple, frozenset] = None,\n        val: t.Union[str, bytes, float, int, list, dict] = None,\n        expire: int = None,\n        read: bool = False,\n        tag: t.Union[str, int, float, bytes] = None,\n        retry: bool = False,\n    ) -&gt; None:\n        \"\"\"Set a key value pair in the cache.\n\n        Params:\n            key (str): The key to store the value under in the cache\n            val (str): The value to store in the cache\n            expire (int): Time (in seconds) before value expires\n            read (bool): If `True`, read value as a file-like object\n            tag (str): Applies a tag to the cached value\n            retry (bool): If `True`, retry setting cache key if first attempt fails\n        \"\"\"\n        validators.validate_key(key)\n        validators.validate_val(val)\n        validators.validate_expire(expire, none_ok=True)\n        validators.validate_read(read, none_ok=True)\n        validators.validate_tag(tag=tag, none_ok=True)\n        validators.validate_retry(retry=retry, none_ok=True)\n        validators.validate_cache(cache=self.cache)\n\n        try:\n            with self.cache as ref:\n                ref.set(\n                    key=key, value=val, expire=expire, read=read, tag=tag, retry=retry\n                )\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception setting key/value pair for key: [{key}]. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def get(\n        self, key: t.Union[str, int, tuple, frozenset] = None, tags: list[str] = None\n    ):\n        \"\"\"Search for a key in a given cache.\n\n        Pass a diskcache.Cache object for cache, and a key (and optionally a list of tags).\n        Function will search the cache and return a value if found, or a structured\n        error dict describing the lack of key.\n\n        Params:\n            key (str): The key to search the cache for\n            tags (list[str]): List of tags to search the cache for\n        \"\"\"\n        validators.validate_key(key)\n        validators.validate_cache(self.cache)\n        validators.validate_tags(tags)\n\n        try:\n            if self.check_key_exists(key=key):\n                try:\n                    with self.cache as ref:\n                        _val = ref.get(key=key)\n\n                        return _val\n\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Unhandled exception retrieving value of key [{key}]. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n            else:\n                # return {\n                #     \"error\": \"Key not found in cache\",\n                #     \"details\": {\"key\": key, \"cache_dir\": self.cache.directory},\n                # }\n\n                return\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception checking cache for key '{key}'. Details: {exc}\"\n            )\n            log.error(msg)\n\n            return None\n\n    def set_expire(\n        self, key: t.Union[str, int, tuple, frozenset] = None, expire: int = None\n    ) -&gt; dict[str, str] | None:\n        \"\"\"Set an expiration timeout (in seconds).\n\n        Params:\n            key (str): Name of the key to set expiration on. Must already exist in the cache.\n            expire (int): Time (in seconds) to wait before expiring cached value.\n        \"\"\"\n        validators.validate_key(key)\n        validators.validate_cache(self.cache)\n        validators.validate_expire(expire)\n\n        if not self.check_key_exists(key=key):\n            log.warning(\n                f\"Cache item with key [{key}] does not exist in cache at {self.cache.directory}/\"\n            )\n\n            return None\n\n        try:\n            with self.cache as ref:\n                ref.touch(key, expire=expire)\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception setting expiration of {expire} on key [{key}] in cache at {self.cache.directory}/. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def delete(\n        self, key: t.Union[str, int, tuple, frozenset] = None, tag: str = None\n    ) -&gt; tuple:\n        \"\"\"Delete a cached value.\n\n        If a tag is provided, only keys that also have that tag will be deleted.\n\n        Params:\n            key (str|int): Name of key in cache.\n        \"\"\"\n        validators.validate_key(key)\n        validators.validate_cache(self.cache)\n        validators.validate_tag(tag)\n\n        try:\n            with self.cache as ref:\n                _delete = ref.pop(key=key, tag=tag)\n\n                return _delete\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception deleting key {key} from cache at {self.cache.directory}/. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def cull(self, retry: bool = False) -&gt; bool:\n        \"\"\"Cull items from cache to free space.\n\n        Params:\n            retry (bool): When `True`, cull will be retried if a database timeout occurs.\n\n        Returns:\n            (bool): `True` if culling successful, otherwise `False`.\n\n        \"\"\"\n        try:\n            self.cache.cull(retry=retry)\n\n            return True\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception culling cache. Details: {exc}\")\n            log.error(msg)\n\n            return False\n\n    def get_cache_size(self) -&gt; int:\n        \"\"\"Get a dict describing the size of the cache, in bytes.\n\n        Returns:\n            (int): An integer representing the cache's size in bytes.`\n\n        \"\"\"\n        validators.validate_cache(cache=self.cache)\n\n        try:\n            cache_size: int = self.cache.volume()\n\n            # return {\"unit\": \"bytes\", \"size\": cache_size}\n\n            return cache_size\n\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception getting cache size. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n    def healthcheck(self) -&gt; list[warnings.WarningMessage]:\n        \"\"\"Run checks on Cache instance.\n\n        Returns:\n            (list[warning.WarningMessage]): A list of Diskcache `WarningMessage` objects.\n\n        \"\"\"\n        validators.validate_cache(cache=self.cache)\n\n        try:\n            warnings = self.cache.check()\n\n            return warnings\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception checking cache for warnings. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.DiskCacheController.check_key_exists","title":"<code>check_key_exists(key=None)</code>","text":"<p>Check if a key exists in a cache.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The cache key to search for</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if cache key found</p> <code>bool</code> <p><code>False</code> if cache key not found</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def check_key_exists(self, key: t.Union[str, int, tuple, frozenset] = None) -&gt; bool:\n    \"\"\"Check if a key exists in a cache.\n\n    Params:\n        key (str): The cache key to search for\n\n    Returns:\n        (bool): `True` if cache key found\n        (bool): `False` if cache key not found\n\n    \"\"\"\n    ## Key validation\n    validators.validate_key(key=key)\n    validators.validate_cache(cache=self.cache)\n\n    ## Check if key exists in cache\n    if key in self.cache:\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.DiskCacheController.clear","title":"<code>clear()</code>","text":"<p>Clear the entire cache.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if clearing cache successful</p> <code>bool</code> <p><code>False</code> if clearing the cache not successful</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def clear(self) -&gt; bool:\n    \"\"\"Clear the entire cache.\n\n    Returns:\n        (bool): `True` if clearing cache successful\n        (bool): `False` if clearing the cache not successful\n\n    \"\"\"\n    validators.validate_cache(self.cache)\n\n    try:\n        with self.cache as ref:\n            ref.clear()\n\n            return True\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception clearing cache at {self.cache.directory}. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.DiskCacheController.cull","title":"<code>cull(retry=False)</code>","text":"<p>Cull items from cache to free space.</p> <p>Parameters:</p> Name Type Description Default <code>retry</code> <code>bool</code> <p>When <code>True</code>, cull will be retried if a database timeout occurs.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if culling successful, otherwise <code>False</code>.</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def cull(self, retry: bool = False) -&gt; bool:\n    \"\"\"Cull items from cache to free space.\n\n    Params:\n        retry (bool): When `True`, cull will be retried if a database timeout occurs.\n\n    Returns:\n        (bool): `True` if culling successful, otherwise `False`.\n\n    \"\"\"\n    try:\n        self.cache.cull(retry=retry)\n\n        return True\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception culling cache. Details: {exc}\")\n        log.error(msg)\n\n        return False\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.DiskCacheController.delete","title":"<code>delete(key=None, tag=None)</code>","text":"<p>Delete a cached value.</p> <p>If a tag is provided, only keys that also have that tag will be deleted.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str | int</code> <p>Name of key in cache.</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def delete(\n    self, key: t.Union[str, int, tuple, frozenset] = None, tag: str = None\n) -&gt; tuple:\n    \"\"\"Delete a cached value.\n\n    If a tag is provided, only keys that also have that tag will be deleted.\n\n    Params:\n        key (str|int): Name of key in cache.\n    \"\"\"\n    validators.validate_key(key)\n    validators.validate_cache(self.cache)\n    validators.validate_tag(tag)\n\n    try:\n        with self.cache as ref:\n            _delete = ref.pop(key=key, tag=tag)\n\n            return _delete\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception deleting key {key} from cache at {self.cache.directory}/. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.DiskCacheController.get","title":"<code>get(key=None, tags=None)</code>","text":"<p>Search for a key in a given cache.</p> <p>Pass a diskcache.Cache object for cache, and a key (and optionally a list of tags). Function will search the cache and return a value if found, or a structured error dict describing the lack of key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to search the cache for</p> <code>None</code> <code>tags</code> <code>list[str]</code> <p>List of tags to search the cache for</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def get(\n    self, key: t.Union[str, int, tuple, frozenset] = None, tags: list[str] = None\n):\n    \"\"\"Search for a key in a given cache.\n\n    Pass a diskcache.Cache object for cache, and a key (and optionally a list of tags).\n    Function will search the cache and return a value if found, or a structured\n    error dict describing the lack of key.\n\n    Params:\n        key (str): The key to search the cache for\n        tags (list[str]): List of tags to search the cache for\n    \"\"\"\n    validators.validate_key(key)\n    validators.validate_cache(self.cache)\n    validators.validate_tags(tags)\n\n    try:\n        if self.check_key_exists(key=key):\n            try:\n                with self.cache as ref:\n                    _val = ref.get(key=key)\n\n                    return _val\n\n            except Exception as exc:\n                msg = Exception(\n                    f\"Unhandled exception retrieving value of key [{key}]. Details: {exc}\"\n                )\n                log.error(msg)\n\n                raise exc\n\n        else:\n            # return {\n            #     \"error\": \"Key not found in cache\",\n            #     \"details\": {\"key\": key, \"cache_dir\": self.cache.directory},\n            # }\n\n            return\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception checking cache for key '{key}'. Details: {exc}\"\n        )\n        log.error(msg)\n\n        return None\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.DiskCacheController.get_cache_size","title":"<code>get_cache_size()</code>","text":"<p>Get a dict describing the size of the cache, in bytes.</p> <p>Returns:</p> Type Description <code>int</code> <p>An integer representing the cache's size in bytes.`</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def get_cache_size(self) -&gt; int:\n    \"\"\"Get a dict describing the size of the cache, in bytes.\n\n    Returns:\n        (int): An integer representing the cache's size in bytes.`\n\n    \"\"\"\n    validators.validate_cache(cache=self.cache)\n\n    try:\n        cache_size: int = self.cache.volume()\n\n        # return {\"unit\": \"bytes\", \"size\": cache_size}\n\n        return cache_size\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception getting cache size. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.DiskCacheController.healthcheck","title":"<code>healthcheck()</code>","text":"<p>Run checks on Cache instance.</p> <p>Returns:</p> Type Description <code>list[WarningMessage]</code> <p>A list of Diskcache <code>WarningMessage</code> objects.</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def healthcheck(self) -&gt; list[warnings.WarningMessage]:\n    \"\"\"Run checks on Cache instance.\n\n    Returns:\n        (list[warning.WarningMessage]): A list of Diskcache `WarningMessage` objects.\n\n    \"\"\"\n    validators.validate_cache(cache=self.cache)\n\n    try:\n        warnings = self.cache.check()\n\n        return warnings\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception checking cache for warnings. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.DiskCacheController.manage_cache_tag_index","title":"<code>manage_cache_tag_index(operation='create')</code>","text":"<p>Create or delete a cache index.</p> <p>Parameters:</p> Name Type Description Default <code>operation</code> <code>str</code> <p>The operation to perform on the cache's tag index. Options: [\"create\", \"delete\"]</p> <code>'create'</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def manage_cache_tag_index(self, operation: str = \"create\") -&gt; None:\n    \"\"\"Create or delete a cache index.\n\n    Params:\n        operation (str): The operation to perform on the cache's tag index.\n            Options: [\"create\", \"delete\"]\n    \"\"\"\n    valid_operations: list[str] = [\"create\", \"delete\"]\n\n    validators.validate_cache(cache=self.cache)\n\n    if not operation:\n        raise Exception(f\"Operation cannot be None.\")\n\n    try:\n        match operation:\n            case \"create\":\n                if self.cache.tag_index == 0:\n                    self.cache.create_tag_index()\n                else:\n                    pass\n\n            case \"delete\":\n                if self.cache.tag_index == 1:\n                    self.cache.drop_tag_index()\n                else:\n                    pass\n\n            case _:\n                raise ValueError(\n                    f\"Invalid operation: {operation}. Must be one of {valid_operations}\"\n                )\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception configuring tag_index. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.DiskCacheController.set","title":"<code>set(key=None, val=None, expire=None, read=False, tag=None, retry=False)</code>","text":"<p>Set a key value pair in the cache.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to store the value under in the cache</p> <code>None</code> <code>val</code> <code>str</code> <p>The value to store in the cache</p> <code>None</code> <code>expire</code> <code>int</code> <p>Time (in seconds) before value expires</p> <code>None</code> <code>read</code> <code>bool</code> <p>If <code>True</code>, read value as a file-like object</p> <code>False</code> <code>tag</code> <code>str</code> <p>Applies a tag to the cached value</p> <code>None</code> <code>retry</code> <code>bool</code> <p>If <code>True</code>, retry setting cache key if first attempt fails</p> <code>False</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def set(\n    self,\n    key: t.Union[str, int, tuple, frozenset] = None,\n    val: t.Union[str, bytes, float, int, list, dict] = None,\n    expire: int = None,\n    read: bool = False,\n    tag: t.Union[str, int, float, bytes] = None,\n    retry: bool = False,\n) -&gt; None:\n    \"\"\"Set a key value pair in the cache.\n\n    Params:\n        key (str): The key to store the value under in the cache\n        val (str): The value to store in the cache\n        expire (int): Time (in seconds) before value expires\n        read (bool): If `True`, read value as a file-like object\n        tag (str): Applies a tag to the cached value\n        retry (bool): If `True`, retry setting cache key if first attempt fails\n    \"\"\"\n    validators.validate_key(key)\n    validators.validate_val(val)\n    validators.validate_expire(expire, none_ok=True)\n    validators.validate_read(read, none_ok=True)\n    validators.validate_tag(tag=tag, none_ok=True)\n    validators.validate_retry(retry=retry, none_ok=True)\n    validators.validate_cache(cache=self.cache)\n\n    try:\n        with self.cache as ref:\n            ref.set(\n                key=key, value=val, expire=expire, read=read, tag=tag, retry=retry\n            )\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception setting key/value pair for key: [{key}]. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.DiskCacheController.set_expire","title":"<code>set_expire(key=None, expire=None)</code>","text":"<p>Set an expiration timeout (in seconds).</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name of the key to set expiration on. Must already exist in the cache.</p> <code>None</code> <code>expire</code> <code>int</code> <p>Time (in seconds) to wait before expiring cached value.</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def set_expire(\n    self, key: t.Union[str, int, tuple, frozenset] = None, expire: int = None\n) -&gt; dict[str, str] | None:\n    \"\"\"Set an expiration timeout (in seconds).\n\n    Params:\n        key (str): Name of the key to set expiration on. Must already exist in the cache.\n        expire (int): Time (in seconds) to wait before expiring cached value.\n    \"\"\"\n    validators.validate_key(key)\n    validators.validate_cache(self.cache)\n    validators.validate_expire(expire)\n\n    if not self.check_key_exists(key=key):\n        log.warning(\n            f\"Cache item with key [{key}] does not exist in cache at {self.cache.directory}/\"\n        )\n\n        return None\n\n    try:\n        with self.cache as ref:\n            ref.touch(key, expire=expire)\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception setting expiration of {expire} on key [{key}] in cache at {self.cache.directory}/. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.TimeoutConf","title":"<code>TimeoutConf</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DictMixin</code></p> <p>Define cache timeout as a class.</p> <p>Inherits the .as_dict() method from DictMixin.</p> <p>Parameters:</p> Name Type Description Default <code>amount</code> <code>int</code> <p>Amount of time to allow for timeout</p> <code>15</code> <code>unit</code> <code>str</code> <p>Unit of time corresponding with the <code>amount</code> passed. Examples: [\"minutes\", \"hours\", \"days\", etc]</p> <code>'minutes'</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\constants.py</code> <pre><code>@dataclass\nclass TimeoutConf(DictMixin):\n    \"\"\"Define cache timeout as a class.\n\n    Inherits the .as_dict() method from DictMixin.\n\n    Params:\n        amount (int): Amount of time to allow for timeout\n        unit (str): Unit of time corresponding with the `amount` passed. Examples: [\"minutes\", \"hours\", \"days\", etc]\n    \"\"\"\n\n    unit: str | None = field(default=\"minutes\")\n    amount: int | None = field(default=15)\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.check_cache","title":"<code>check_cache(cache=None)</code>","text":"<p>Run healthcheck on cache.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> instance to work on</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def check_cache(cache: Cache = None):\n    \"\"\"Run healthcheck on cache.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` instance to work on\n    \"\"\"\n    validate_cache(cache=cache)\n\n    try:\n        warnings = cache.check()\n\n        return warnings\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception checking cache for warnings. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.check_cache_key_exists","title":"<code>check_cache_key_exists(cache=None, key=None)</code>","text":"<p>Check if a key exists in a cache.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> instance to check</p> <code>None</code> <code>key</code> <code>str</code> <p>The key name to search the <code>cache</code> for</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the key exists</p> <code>bool</code> <p><code>False</code> if the key does not exist</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def check_cache_key_exists(cache: diskcache.core.Cache = None, key: str = None) -&gt; bool:\n    \"\"\"Check if a key exists in a cache.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` instance to check\n        key (str): The key name to search the `cache` for\n\n    Returns:\n        (bool): `True` if the key exists\n        (bool): `False` if the key does not exist\n\n    \"\"\"\n    ## Key validation\n    validate_key(key=key)\n    validate_cache(cache=cache)\n\n    ## Check if key exists in cache\n    if key in cache:\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.clear_cache","title":"<code>clear_cache(cache=None)</code>","text":"<p>Clear all items from the cache.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>The target cache to clear</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if cache cleared successfully</p> <code>bool</code> <p><code>False</code> if cache not cleared successfully</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def clear_cache(cache: Cache = None) -&gt; bool:\n    \"\"\"Clear all items from the cache.\n\n    Params:\n        cache (diskcache.Cache): The target cache to clear\n\n    Returns:\n        (bool): `True` if cache cleared successfully\n        (bool): `False` if cache not cleared successfully\n\n    \"\"\"\n    validate_cache(cache)\n\n    try:\n        with cache as ref:\n            ref.clear()\n\n            return True\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception clearing cache at {cache.directory}. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.convert_to_seconds","title":"<code>convert_to_seconds(amount=None, unit=None)</code>","text":"<p>Convert an amount of time to seconds.</p> <p>Parameters:</p> Name Type Description Default <code>amount</code> <code>int</code> <p>Amount of time</p> <code>None</code> <code>unit</code> <code>str</code> <p>The starting unit of time to convert to seconds. Options: [\"seconds\", \"hours\", \"minutes\", \"days\", \"weeks\"]</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p><code>amount</code> of time converted to seconds representing the <code>unit</code> of time passed</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def convert_to_seconds(amount: int = None, unit: str = None) -&gt; int:\n    \"\"\"Convert an amount of time to seconds.\n\n    Params:\n        amount (int): Amount of time\n        unit (str): The starting unit of time to convert to seconds.\n            Options: [\"seconds\", \"hours\", \"minutes\", \"days\", \"weeks\"]\n\n    Returns:\n        (int): `amount` of time converted to seconds representing the `unit` of time passed\n\n    \"\"\"\n    ## Allowed strings for conversion\n    valid_time_units: list[int] = [\"seconds\", \"hours\", \"minutes\", \"days\", \"weeks\"]\n\n    assert unit is not None, ValueError(\n        f\"Missing unit. Must be one of {valid_time_units}\"\n    )\n\n    assert isinstance(unit, str), TypeError(\n        f\"Invalid type for unit: {type(unit)}. Must be str\"\n    )\n\n    assert unit in valid_time_units, TypeError(\n        f\"Invalid unit: {unit}. Must be one of {valid_time_units}\"\n    )\n\n    amount is not None, ValueError(\"Missing amount of unit, i.e. 3 days\")\n\n    assert isinstance(amount, int), TypeError(\n        f\"Invalid type for amount: ({type(amount)}). Must be of type int\"\n    )\n\n    match unit:\n        case \"weeks\":\n            _amount: int = amount * 7 * 24 * 60 * 60\n        case \"days\":\n            _amount: int = amount * 24 * 60 * 60\n        case \"hours\":\n            _amount: int = amount * 60 * 60\n        case \"minutes\":\n            _amount: int = amount * 60\n        case \"seconds\":\n            _amount: int = amount\n        case _:\n            raise ValueError(f\"Invalid input for unit: {unit}\")\n\n    return _amount\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.delete_val","title":"<code>delete_val(cache=None, key=None, tag=None)</code>","text":"<p>Delete a value from the cache.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> instance to work on</p> <code>None</code> <code>key</code> <code>str</code> <p>The name of a key to delete</p> <code>None</code> <code>tag</code> <code>str</code> <p>Tag to filter by</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def delete_val(\n    cache: Cache = None, key: Union[str, int, tuple, frozenset] = None, tag: str = None\n) -&gt; tuple:\n    \"\"\"Delete a value from the cache.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` instance to work on\n        key (str): The name of a key to delete\n        tag (str): Tag to filter by\n    \"\"\"\n    validate_key(key)\n    validate_cache(cache)\n    validate_tag(tag)\n\n    try:\n        with cache as ref:\n            _delete = ref.pop(key=key, tag=tag)\n\n            return _delete\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception deleting key {key} from cache at {cache.directory}/. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.get_cache_size","title":"<code>get_cache_size(cache=None)</code>","text":"<p>Get the total size of a <code>diskcache.Cache</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> object to get the size of</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, int]</code> <p>Details about the cache's size. Example: <code>{\"unit\": \"bytes\", \"size\": cache_size}</code></p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def get_cache_size(cache: Cache = None) -&gt; dict[str, int]:\n    \"\"\"Get the total size of a `diskcache.Cache` instance.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` object to get the size of\n\n    Returns:\n        (dict[str, int]): Details about the cache's size. Example:\n            `{\"unit\": \"bytes\", \"size\": cache_size}`\n\n    \"\"\"\n    validate_cache(cache=cache)\n\n    try:\n        cache_size: int = cache.volume()\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception getting cache size. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n\n    return {\"unit\": \"bytes\", \"size\": cache_size}\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.get_val","title":"<code>get_val(cache=None, key=None, tags=None)</code>","text":"<p>Search for a key in a given cache.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> instance to work on</p> <code>None</code> <code>key</code> <code>str</code> <p>A key name to retrieve from the cache</p> <code>None</code> <code>tags</code> <code>list[str]</code> <p>A list of tags to filter by</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>The cached value</p> <code>dict[str, str]</code> <p>A structured dict with error details, if operation fails</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def get_val(cache: Cache = None, key: str = None, tags: list[str] = None):\n    \"\"\"Search for a key in a given cache.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` instance to work on\n        key (str): A key name to retrieve from the cache\n        tags: A list of tags to filter by\n\n    Returns:\n        (Any): The cached value\n        (dict[str, str]): A structured dict with error details, if operation fails\n\n    \"\"\"\n    validate_key(key)\n    validate_cache(cache)\n    validate_tags(tags)\n\n    try:\n        if check_cache_key_exists(key=key, cache=cache):\n            try:\n                with cache as ref:\n                    _val = ref.get(key=key)\n\n                    return _val\n\n            except Exception as exc:\n                msg = Exception(\n                    f\"Unhandled exception retrieving value of key [{key}]. Details: {exc}\"\n                )\n                log.error(msg)\n\n                raise exc\n\n        else:\n            return {\n                \"error\": \"Key not found in cache\",\n                \"details\": {\"key\": key, \"cache_dir\": cache.directory},\n            }\n\n    except Exception as exc:\n        return {\n            \"error\": \"Error searching for key in cache\",\n            \"details\": {\"exception\": exc},\n        }\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.manage_cache_tag_index","title":"<code>manage_cache_tag_index(cache=None, operation='create')</code>","text":"<p>Create or delete a cache's tag index.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> instance to work on</p> <code>None</code> <code>operation</code> <code>str</code> <p>The operation (create/delete) to perform on the tag index</p> <code>'create'</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def manage_cache_tag_index(cache: Cache = None, operation: str = \"create\") -&gt; None:\n    \"\"\"Create or delete a cache's tag index.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` instance to work on\n        operation (str): The operation (create/delete) to perform on the tag index\n    \"\"\"\n    valid_operations: list[str] = [\"create\", \"delete\"]\n\n    validate_cache(cache=cache)\n\n    if not operation:\n        raise Exception(f\"Operation cannot be None.\")\n\n    try:\n        match operation:\n            case \"create\":\n                if cache.tag_index == 0:\n                    cache.create_tag_index()\n                else:\n                    pass\n\n            case \"delete\":\n                if cache.tag_index == 1:\n                    cache.drop_tag_index()\n                else:\n                    pass\n\n            case _:\n                raise ValueError(\n                    f\"Invalid operation: {operation}. Must be one of {valid_operations}\"\n                )\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception configuring tag_index. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.new_cache","title":"<code>new_cache(cache_dir=CACHE_DIR, cache_conf=None, index=True)</code>","text":"<p>Prepare and return a diskcache.Cache object.</p> <p>Parameters:</p> Name Type Description Default <code>cache_dir</code> <code>str</code> <p>Directory path where cache will be created</p> <code>CACHE_DIR</code> <code>cache_conf</code> <code>dict</code> <p>A Python <code>dict</code> with cache configuration options</p> <code>None</code> <code>index</code> <code>bool</code> <p>Whether or not to create an index for the cache</p> <code>True</code> <p>Returns:</p> Type Description <code>Cache</code> <p>An initialized <code>diskcache.Cache</code> object</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def new_cache(\n    cache_dir: str = CACHE_DIR,\n    cache_conf: dict = None,\n    index: bool = True,\n) -&gt; diskcache.core.Cache:\n    \"\"\"Prepare and return a diskcache.Cache object.\n\n    Params:\n        cache_dir (str): Directory path where cache will be created\n        cache_conf (dict): A Python `dict` with cache configuration options\n        index (bool): Whether or not to create an index for the cache\n\n    Returns:\n        (diskcache.core.Cache): An initialized `diskcache.Cache` object\n\n    \"\"\"\n    assert cache_dir is not None, ValueError(\"Missing cache directory\")\n\n    assert isinstance(cache_dir, Union[str, Path]), TypeError(\n        f\"cache_dir must be of type str or Path, not {type(cache_dir)}\"\n    )\n\n    assert cache_conf is not None, ValueError(f\"Missing cache\")\n\n    assert isinstance(cache_conf, dict), TypeError(\n        f\"Invalid type for [cache_conf]: ({type(cache_conf)}). Must be of type dict.\"\n    )\n\n    try:\n        # _cache: diskcache.core.Cache = Cache(directory=cache_dir)\n        _cache: diskcache.core.Cache = Cache(**cache_conf)\n\n        if index:\n            manage_cache_tag_index(cache=_cache)\n\n        return _cache\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception creating cache. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.set_expire","title":"<code>set_expire(cache=None, key=None, expire=None)</code>","text":"<p>Set/change a cache key's expiration time.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> instance to work on</p> <code>None</code> <code>key</code> <code>str</code> <p>The cache key name to set an expiration time on</p> <code>None</code> <code>expire</code> <code>int</code> <p>Time (in seconds) before cache key expires</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def set_expire(\n    cache: Cache = None, key: str = None, expire: int = None\n) -&gt; Union[dict[str, str], None]:\n    \"\"\"Set/change a cache key's expiration time.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` instance to work on\n        key (str): The cache key name to set an expiration time on\n        expire (int): Time (in seconds) before cache key expires\n    \"\"\"\n    validate_key(key)\n    validate_cache(cache)\n    validate_expire(expire)\n\n    if not check_cache_key_exists(key=key, cache=cache):\n        return {\n            \"warning\": f\"Cache item with key [{key}] does not exist in cache at {cache.directory}/\"\n        }\n\n    try:\n        with cache as ref:\n            ref.touch(key, expire=expire)\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception setting expiration of {expire} on key [{key}] in cache at {cache.directory}/. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__init__/#red_utils.ext.diskcache_utils.set_val","title":"<code>set_val(cache=None, key=None, val=None, expire=None, read=False, tag=None, retry=False)</code>","text":"<p>Set a key value pair in the cache.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> object to work on</p> <code>None</code> <code>key</code> <code>str</code> <p>The key to store the value under in the cache</p> <code>None</code> <code>val</code> <code>str</code> <p>The value to store in the cache</p> <code>None</code> <code>expire</code> <code>int</code> <p>Time (in seconds) before value expires</p> <code>None</code> <code>read</code> <code>bool</code> <p>If <code>True</code>, read value as a file-like object</p> <code>False</code> <code>tag</code> <code>str</code> <p>Applies a tag to the cached value</p> <code>None</code> <code>retry</code> <code>bool</code> <p>If <code>True</code>, retry setting cache key if first attempt fails</p> <code>False</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def set_val(\n    cache: Cache = None,\n    key: Union[str, int, tuple, frozenset] = None,\n    val: Union[str, bytes, float, int, list, dict] = None,\n    expire: int = None,\n    read: bool = False,\n    tag: str = None,\n    retry: bool = False,\n) -&gt; None:\n    \"\"\"Set a key value pair in the cache.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` object to work on\n        key (str): The key to store the value under in the cache\n        val (str): The value to store in the cache\n        expire (int): Time (in seconds) before value expires\n        read (bool): If `True`, read value as a file-like object\n        tag (str): Applies a tag to the cached value\n        retry (bool): If `True`, retry setting cache key if first attempt fails\n    \"\"\"\n    validate_key(key)\n    validate_val(val)\n    validate_expire(expire, none_ok=True)\n    validate_read(read, none_ok=True)\n    validate_tag(tag=tag, none_ok=True)\n    validate_retry(retry=retry, none_ok=True)\n    validate_cache(cache=cache)\n\n    try:\n        with cache as ref:\n            ref.set(key=key, value=val, expire=expire, read=read, tag=tag, retry=retry)\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception setting key/value pair for key: [{key}]. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__methods/","title":"__methods","text":"<p>Extras for diskcache_utils.</p> <p>Separates some functions/classes from the main diskcache_utils to shorten length of individual scripts.</p>"},{"location":"reference/red_utils/ext/diskcache_utils/__methods/#red_utils.ext.diskcache_utils.__methods.check_cache","title":"<code>check_cache(cache=None)</code>","text":"<p>Run healthcheck on cache.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> instance to work on</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def check_cache(cache: Cache = None):\n    \"\"\"Run healthcheck on cache.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` instance to work on\n    \"\"\"\n    validate_cache(cache=cache)\n\n    try:\n        warnings = cache.check()\n\n        return warnings\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception checking cache for warnings. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__methods/#red_utils.ext.diskcache_utils.__methods.check_cache_key_exists","title":"<code>check_cache_key_exists(cache=None, key=None)</code>","text":"<p>Check if a key exists in a cache.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> instance to check</p> <code>None</code> <code>key</code> <code>str</code> <p>The key name to search the <code>cache</code> for</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the key exists</p> <code>bool</code> <p><code>False</code> if the key does not exist</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def check_cache_key_exists(cache: diskcache.core.Cache = None, key: str = None) -&gt; bool:\n    \"\"\"Check if a key exists in a cache.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` instance to check\n        key (str): The key name to search the `cache` for\n\n    Returns:\n        (bool): `True` if the key exists\n        (bool): `False` if the key does not exist\n\n    \"\"\"\n    ## Key validation\n    validate_key(key=key)\n    validate_cache(cache=cache)\n\n    ## Check if key exists in cache\n    if key in cache:\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__methods/#red_utils.ext.diskcache_utils.__methods.clear_cache","title":"<code>clear_cache(cache=None)</code>","text":"<p>Clear all items from the cache.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>The target cache to clear</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if cache cleared successfully</p> <code>bool</code> <p><code>False</code> if cache not cleared successfully</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def clear_cache(cache: Cache = None) -&gt; bool:\n    \"\"\"Clear all items from the cache.\n\n    Params:\n        cache (diskcache.Cache): The target cache to clear\n\n    Returns:\n        (bool): `True` if cache cleared successfully\n        (bool): `False` if cache not cleared successfully\n\n    \"\"\"\n    validate_cache(cache)\n\n    try:\n        with cache as ref:\n            ref.clear()\n\n            return True\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception clearing cache at {cache.directory}. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__methods/#red_utils.ext.diskcache_utils.__methods.convert_to_seconds","title":"<code>convert_to_seconds(amount=None, unit=None)</code>","text":"<p>Convert an amount of time to seconds.</p> <p>Parameters:</p> Name Type Description Default <code>amount</code> <code>int</code> <p>Amount of time</p> <code>None</code> <code>unit</code> <code>str</code> <p>The starting unit of time to convert to seconds. Options: [\"seconds\", \"hours\", \"minutes\", \"days\", \"weeks\"]</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p><code>amount</code> of time converted to seconds representing the <code>unit</code> of time passed</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def convert_to_seconds(amount: int = None, unit: str = None) -&gt; int:\n    \"\"\"Convert an amount of time to seconds.\n\n    Params:\n        amount (int): Amount of time\n        unit (str): The starting unit of time to convert to seconds.\n            Options: [\"seconds\", \"hours\", \"minutes\", \"days\", \"weeks\"]\n\n    Returns:\n        (int): `amount` of time converted to seconds representing the `unit` of time passed\n\n    \"\"\"\n    ## Allowed strings for conversion\n    valid_time_units: list[int] = [\"seconds\", \"hours\", \"minutes\", \"days\", \"weeks\"]\n\n    assert unit is not None, ValueError(\n        f\"Missing unit. Must be one of {valid_time_units}\"\n    )\n\n    assert isinstance(unit, str), TypeError(\n        f\"Invalid type for unit: {type(unit)}. Must be str\"\n    )\n\n    assert unit in valid_time_units, TypeError(\n        f\"Invalid unit: {unit}. Must be one of {valid_time_units}\"\n    )\n\n    amount is not None, ValueError(\"Missing amount of unit, i.e. 3 days\")\n\n    assert isinstance(amount, int), TypeError(\n        f\"Invalid type for amount: ({type(amount)}). Must be of type int\"\n    )\n\n    match unit:\n        case \"weeks\":\n            _amount: int = amount * 7 * 24 * 60 * 60\n        case \"days\":\n            _amount: int = amount * 24 * 60 * 60\n        case \"hours\":\n            _amount: int = amount * 60 * 60\n        case \"minutes\":\n            _amount: int = amount * 60\n        case \"seconds\":\n            _amount: int = amount\n        case _:\n            raise ValueError(f\"Invalid input for unit: {unit}\")\n\n    return _amount\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__methods/#red_utils.ext.diskcache_utils.__methods.delete_val","title":"<code>delete_val(cache=None, key=None, tag=None)</code>","text":"<p>Delete a value from the cache.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> instance to work on</p> <code>None</code> <code>key</code> <code>str</code> <p>The name of a key to delete</p> <code>None</code> <code>tag</code> <code>str</code> <p>Tag to filter by</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def delete_val(\n    cache: Cache = None, key: Union[str, int, tuple, frozenset] = None, tag: str = None\n) -&gt; tuple:\n    \"\"\"Delete a value from the cache.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` instance to work on\n        key (str): The name of a key to delete\n        tag (str): Tag to filter by\n    \"\"\"\n    validate_key(key)\n    validate_cache(cache)\n    validate_tag(tag)\n\n    try:\n        with cache as ref:\n            _delete = ref.pop(key=key, tag=tag)\n\n            return _delete\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception deleting key {key} from cache at {cache.directory}/. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__methods/#red_utils.ext.diskcache_utils.__methods.get_cache_size","title":"<code>get_cache_size(cache=None)</code>","text":"<p>Get the total size of a <code>diskcache.Cache</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> object to get the size of</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, int]</code> <p>Details about the cache's size. Example: <code>{\"unit\": \"bytes\", \"size\": cache_size}</code></p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def get_cache_size(cache: Cache = None) -&gt; dict[str, int]:\n    \"\"\"Get the total size of a `diskcache.Cache` instance.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` object to get the size of\n\n    Returns:\n        (dict[str, int]): Details about the cache's size. Example:\n            `{\"unit\": \"bytes\", \"size\": cache_size}`\n\n    \"\"\"\n    validate_cache(cache=cache)\n\n    try:\n        cache_size: int = cache.volume()\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception getting cache size. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n\n    return {\"unit\": \"bytes\", \"size\": cache_size}\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__methods/#red_utils.ext.diskcache_utils.__methods.get_val","title":"<code>get_val(cache=None, key=None, tags=None)</code>","text":"<p>Search for a key in a given cache.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> instance to work on</p> <code>None</code> <code>key</code> <code>str</code> <p>A key name to retrieve from the cache</p> <code>None</code> <code>tags</code> <code>list[str]</code> <p>A list of tags to filter by</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>The cached value</p> <code>dict[str, str]</code> <p>A structured dict with error details, if operation fails</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def get_val(cache: Cache = None, key: str = None, tags: list[str] = None):\n    \"\"\"Search for a key in a given cache.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` instance to work on\n        key (str): A key name to retrieve from the cache\n        tags: A list of tags to filter by\n\n    Returns:\n        (Any): The cached value\n        (dict[str, str]): A structured dict with error details, if operation fails\n\n    \"\"\"\n    validate_key(key)\n    validate_cache(cache)\n    validate_tags(tags)\n\n    try:\n        if check_cache_key_exists(key=key, cache=cache):\n            try:\n                with cache as ref:\n                    _val = ref.get(key=key)\n\n                    return _val\n\n            except Exception as exc:\n                msg = Exception(\n                    f\"Unhandled exception retrieving value of key [{key}]. Details: {exc}\"\n                )\n                log.error(msg)\n\n                raise exc\n\n        else:\n            return {\n                \"error\": \"Key not found in cache\",\n                \"details\": {\"key\": key, \"cache_dir\": cache.directory},\n            }\n\n    except Exception as exc:\n        return {\n            \"error\": \"Error searching for key in cache\",\n            \"details\": {\"exception\": exc},\n        }\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__methods/#red_utils.ext.diskcache_utils.__methods.manage_cache_tag_index","title":"<code>manage_cache_tag_index(cache=None, operation='create')</code>","text":"<p>Create or delete a cache's tag index.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> instance to work on</p> <code>None</code> <code>operation</code> <code>str</code> <p>The operation (create/delete) to perform on the tag index</p> <code>'create'</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def manage_cache_tag_index(cache: Cache = None, operation: str = \"create\") -&gt; None:\n    \"\"\"Create or delete a cache's tag index.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` instance to work on\n        operation (str): The operation (create/delete) to perform on the tag index\n    \"\"\"\n    valid_operations: list[str] = [\"create\", \"delete\"]\n\n    validate_cache(cache=cache)\n\n    if not operation:\n        raise Exception(f\"Operation cannot be None.\")\n\n    try:\n        match operation:\n            case \"create\":\n                if cache.tag_index == 0:\n                    cache.create_tag_index()\n                else:\n                    pass\n\n            case \"delete\":\n                if cache.tag_index == 1:\n                    cache.drop_tag_index()\n                else:\n                    pass\n\n            case _:\n                raise ValueError(\n                    f\"Invalid operation: {operation}. Must be one of {valid_operations}\"\n                )\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception configuring tag_index. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__methods/#red_utils.ext.diskcache_utils.__methods.new_cache","title":"<code>new_cache(cache_dir=CACHE_DIR, cache_conf=None, index=True)</code>","text":"<p>Prepare and return a diskcache.Cache object.</p> <p>Parameters:</p> Name Type Description Default <code>cache_dir</code> <code>str</code> <p>Directory path where cache will be created</p> <code>CACHE_DIR</code> <code>cache_conf</code> <code>dict</code> <p>A Python <code>dict</code> with cache configuration options</p> <code>None</code> <code>index</code> <code>bool</code> <p>Whether or not to create an index for the cache</p> <code>True</code> <p>Returns:</p> Type Description <code>Cache</code> <p>An initialized <code>diskcache.Cache</code> object</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def new_cache(\n    cache_dir: str = CACHE_DIR,\n    cache_conf: dict = None,\n    index: bool = True,\n) -&gt; diskcache.core.Cache:\n    \"\"\"Prepare and return a diskcache.Cache object.\n\n    Params:\n        cache_dir (str): Directory path where cache will be created\n        cache_conf (dict): A Python `dict` with cache configuration options\n        index (bool): Whether or not to create an index for the cache\n\n    Returns:\n        (diskcache.core.Cache): An initialized `diskcache.Cache` object\n\n    \"\"\"\n    assert cache_dir is not None, ValueError(\"Missing cache directory\")\n\n    assert isinstance(cache_dir, Union[str, Path]), TypeError(\n        f\"cache_dir must be of type str or Path, not {type(cache_dir)}\"\n    )\n\n    assert cache_conf is not None, ValueError(f\"Missing cache\")\n\n    assert isinstance(cache_conf, dict), TypeError(\n        f\"Invalid type for [cache_conf]: ({type(cache_conf)}). Must be of type dict.\"\n    )\n\n    try:\n        # _cache: diskcache.core.Cache = Cache(directory=cache_dir)\n        _cache: diskcache.core.Cache = Cache(**cache_conf)\n\n        if index:\n            manage_cache_tag_index(cache=_cache)\n\n        return _cache\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception creating cache. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__methods/#red_utils.ext.diskcache_utils.__methods.set_expire","title":"<code>set_expire(cache=None, key=None, expire=None)</code>","text":"<p>Set/change a cache key's expiration time.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> instance to work on</p> <code>None</code> <code>key</code> <code>str</code> <p>The cache key name to set an expiration time on</p> <code>None</code> <code>expire</code> <code>int</code> <p>Time (in seconds) before cache key expires</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def set_expire(\n    cache: Cache = None, key: str = None, expire: int = None\n) -&gt; Union[dict[str, str], None]:\n    \"\"\"Set/change a cache key's expiration time.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` instance to work on\n        key (str): The cache key name to set an expiration time on\n        expire (int): Time (in seconds) before cache key expires\n    \"\"\"\n    validate_key(key)\n    validate_cache(cache)\n    validate_expire(expire)\n\n    if not check_cache_key_exists(key=key, cache=cache):\n        return {\n            \"warning\": f\"Cache item with key [{key}] does not exist in cache at {cache.directory}/\"\n        }\n\n    try:\n        with cache as ref:\n            ref.touch(key, expire=expire)\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception setting expiration of {expire} on key [{key}] in cache at {cache.directory}/. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__methods/#red_utils.ext.diskcache_utils.__methods.set_val","title":"<code>set_val(cache=None, key=None, val=None, expire=None, read=False, tag=None, retry=False)</code>","text":"<p>Set a key value pair in the cache.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> object to work on</p> <code>None</code> <code>key</code> <code>str</code> <p>The key to store the value under in the cache</p> <code>None</code> <code>val</code> <code>str</code> <p>The value to store in the cache</p> <code>None</code> <code>expire</code> <code>int</code> <p>Time (in seconds) before value expires</p> <code>None</code> <code>read</code> <code>bool</code> <p>If <code>True</code>, read value as a file-like object</p> <code>False</code> <code>tag</code> <code>str</code> <p>Applies a tag to the cached value</p> <code>None</code> <code>retry</code> <code>bool</code> <p>If <code>True</code>, retry setting cache key if first attempt fails</p> <code>False</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def set_val(\n    cache: Cache = None,\n    key: Union[str, int, tuple, frozenset] = None,\n    val: Union[str, bytes, float, int, list, dict] = None,\n    expire: int = None,\n    read: bool = False,\n    tag: str = None,\n    retry: bool = False,\n) -&gt; None:\n    \"\"\"Set a key value pair in the cache.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` object to work on\n        key (str): The key to store the value under in the cache\n        val (str): The value to store in the cache\n        expire (int): Time (in seconds) before value expires\n        read (bool): If `True`, read value as a file-like object\n        tag (str): Applies a tag to the cached value\n        retry (bool): If `True`, retry setting cache key if first attempt fails\n    \"\"\"\n    validate_key(key)\n    validate_val(val)\n    validate_expire(expire, none_ok=True)\n    validate_read(read, none_ok=True)\n    validate_tag(tag=tag, none_ok=True)\n    validate_retry(retry=retry, none_ok=True)\n    validate_cache(cache=cache)\n\n    try:\n        with cache as ref:\n            ref.set(key=key, value=val, expire=expire, read=read, tag=tag, retry=retry)\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception setting key/value pair for key: [{key}]. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__methods/#red_utils.ext.diskcache_utils.__methods.validate_cache","title":"<code>validate_cache(cache=None, none_ok=True)</code>","text":"<p>Validate a DiskCache cache object.</p> <p>Checks for existence and correct type.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> instance to validate</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>Allow null values</p> <code>True</code> <p>Returns:</p> Type Description <code>Cache</code> <p>The original <code>Cache</code> instance after validation passes</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_cache(cache: Cache = None, none_ok: bool = True) -&gt; diskcache.core.Cache:\n    \"\"\"Validate a DiskCache cache object.\n\n    Checks for existence and correct type.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` instance to validate\n        none_ok (bool): Allow null values\n\n    Returns:\n        (diskcache.Cache): The original `Cache` instance after validation passes\n\n    \"\"\"\n    ## Check existence\n    if cache is None:\n        if not none_ok:\n            raise ValueError(\"Missing diskcache.Cache object to perform lookup against\")\n\n    else:\n        ## Only validate an existing cache\n        assert isinstance(cache, Cache), TypeError(\n            f\"Cache must be of type diskcache.Cache, not {type(cache)}\"\n        )\n\n    return cache\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__methods/#red_utils.ext.diskcache_utils.__methods.validate_expire","title":"<code>validate_expire(expire=None, none_ok=False)</code>","text":"<p>Validate input diskcache expiration time.</p> <p>Only int types allowed. Expiration time is in seconds.</p> <p>Parameters:</p> Name Type Description Default <code>expire</code> <code>int</code> <p>The amount of seconds for an expiration value</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>none_ok (bool): Allow null values</p> <code>False</code> <p>Returns:</p> Type Description <code>int</code> <p>The original expiration time (in seconds) if validation passes</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_expire(expire: int = None, none_ok: bool = False) -&gt; int:\n    \"\"\"Validate input diskcache expiration time.\n\n    Only int types allowed. Expiration time is in seconds.\n\n    Params:\n        expire (int): The amount of seconds for an expiration value\n        none_ok (bool): none_ok (bool): Allow null values\n\n    Returns:\n        (int): The original expiration time (in seconds) if validation passes\n\n    \"\"\"\n    ## Evaluate var existence\n    if not expire:\n        if none_ok:\n            return expire\n        else:\n            raise ValueError(\"Missing expire value to evaluate\")\n\n    ## Evaluate var type\n    if not isinstance(expire, int):\n        try:\n            expire: int = int(expire)\n\n            return expire\n\n        except Exception as exc:\n            raise TypeError(\n                f\"Expire value is not of type int. Conversion to int failed. Details: {exc}\"\n            )\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__methods/#red_utils.ext.diskcache_utils.__methods.validate_key","title":"<code>validate_key(key=None, none_ok=False)</code>","text":"<p>Validate input diskcache key.</p> <p>Supported key types: - int - str</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to evaluate</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>Allow null keys</p> <code>False</code> <p>Returns:</p> Type Description <code>str | int</code> <p>The original key after all validations are passed</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_key(key: valid_key_types = None, none_ok: bool = False) -&gt; Union[str, int]:\n    \"\"\"Validate input diskcache key.\n\n    Supported key types:\n    - int\n    - str\n\n    Params:\n        key (str): The key to evaluate\n        none_ok (bool): Allow null keys\n\n    Returns:\n        (str|int): The original key after all validations are passed\n\n    \"\"\"\n    ## Evaluate key existence\n    if key is False or None:\n        if none_ok:\n            return key\n\n        else:\n            raise ValueError(\"Missing key to evaluate\")\n\n    ## Key exists, validate type\n    if type(key) not in valid_key_types:\n        raise TypeError(\n            f\"Invalid type for key: ({type(key)}). Must be one of {valid_key_types}\"\n        )\n\n    return key\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__methods/#red_utils.ext.diskcache_utils.__methods.validate_read","title":"<code>validate_read(read=None, none_ok=True)</code>","text":"<p>Validate input diskcache read value.</p> <p>Read is a bool that enables/disables reading input as a file. Docs: https://grantjenks.com/docs/diskcache/tutorial.html#cache</p> <p>Only int types allowed. Expiration time is in seconds.</p> <p>Parameters:</p> Name Type Description Default <code>read</code> <code>bool</code> <p><code>True</code>/<code>False</code> state</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>none_ok (bool): Allow null values</p> <code>True</code> <p>Returns:</p> Type Description <code>bool</code> <p>The original value of <code>read</code> if all validations pass</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_read(read: bool = None, none_ok: bool = True) -&gt; bool:\n    \"\"\"Validate input diskcache read value.\n\n    Read is a bool that enables/disables reading input as a file.\n    Docs: https://grantjenks.com/docs/diskcache/tutorial.html#cache\n\n    Only int types allowed. Expiration time is in seconds.\n\n    Params:\n        read (bool): `True`/`False` state\n        none_ok (bool): none_ok (bool): Allow null values\n\n    Returns:\n        (bool): The original value of `read` if all validations pass\n\n    \"\"\"\n    ## Evaluate var existence\n    if not read:\n        if none_ok:\n            return read\n        else:\n            raise ValueError(\"Missing read bool to evaluate\")\n\n    ## Evaluate var type\n    if not isinstance(read, bool):\n        try:\n            read: bool = bool(read)\n\n        except Exception as exc:\n            raise TypeError(\n                f\"Read value is not of type bool. Conversion to bool failed. Details: {exc}\"\n            )\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__methods/#red_utils.ext.diskcache_utils.__methods.validate_retry","title":"<code>validate_retry(retry=None, none_ok=True)</code>","text":"<p>Validate input diskcache retry.</p> <p>Determines whether or not cache will retry on failure before exiting.</p> <p>Parameters:</p> Name Type Description Default <code>retry</code> <code>bool</code> <p><code>True</code>/<code>False</code> state of retry</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>Allow nullable values</p> <code>True</code> <p>Returns:</p> Type Description <code>bool</code> <p>The original value of <code>retry</code> if validations pass</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_retry(retry: bool = None, none_ok: bool = True) -&gt; bool:\n    \"\"\"Validate input diskcache retry.\n\n    Determines whether or not cache will retry on failure before exiting.\n\n    Params:\n        retry (bool): `True`/`False` state of retry\n        none_ok (bool): Allow nullable values\n\n    Returns:\n        (bool): The original value of `retry` if validations pass\n\n    \"\"\"\n    ## Evaluate var existence\n    if not retry:\n        if none_ok:\n            return retry\n        else:\n            raise ValueError(\"Missing retry to evaluate\")\n\n    ## Evaluate var type\n    if not isinstance(retry, str):\n        try:\n            retry: str = str(retry)\n\n        except Exception as exc:\n            raise TypeError(\n                f\"Retry value is not of type str. Conversion to str failed. Details: {exc}\"\n            )\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__methods/#red_utils.ext.diskcache_utils.__methods.validate_tag","title":"<code>validate_tag(tag=None, none_ok=True)</code>","text":"<p>Validate input diskcache tag.</p> <p>A tag is an optional user-defined string that groups cache entries.</p> <p>Parameters:</p> Name Type Description Default <code>tag</code> <code>str</code> <p>A tag to validate</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>Allow null values</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>A validated tag</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_tag(tag: valid_tag_types = None, none_ok: bool = True) -&gt; str:\n    \"\"\"Validate input diskcache tag.\n\n    A tag is an optional user-defined string that groups cache entries.\n\n    Params:\n        tag (str): A tag to validate\n        none_ok (bool): Allow null values\n\n    Returns:\n        (str): A validated tag\n\n    \"\"\"\n    ## Evaluate var existence\n    if not tag:\n        if none_ok:\n            return tag\n        else:\n            raise ValueError(\"Missing tag to evaluate\")\n\n    ## Evaluate var type\n    if type(tag) not in valid_tag_types:\n        raise TypeError(\n            f\"Invalid type for tag [{tag}]: {type(tag)}. Must be one of {valid_tag_types}\"\n        )\n\n    if not isinstance(tag, str):\n        try:\n            tag: str = str(tag)\n\n        except Exception as exc:\n            raise TypeError(\n                f\"tag value is not of type str. Conversion to str failed. Details: {exc}\"\n            )\n\n    return tag\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__methods/#red_utils.ext.diskcache_utils.__methods.validate_tags","title":"<code>validate_tags(tags=None, none_ok=True)</code>","text":"<p>Validate a list of tags.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>list[str]</code> <p>A list of tags to validate</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>Allow null values</p> <code>True</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>A validated list of tags</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_tags(\n    tags: list[valid_tag_types] = None, none_ok: bool = True\n) -&gt; list[valid_tag_types]:\n    \"\"\"Validate a list of tags.\n\n    Params:\n        tags (list[str]): A list of tags to validate\n        none_ok (bool): Allow null values\n\n    Returns:\n        (list[str]): A validated list of tags\n\n    \"\"\"\n    if not tags:\n        if none_ok:\n            return tags\n        else:\n            raise ValueError(\"Missing tags list\")\n\n    if not isinstance(tags, list):\n        raise TypeError(f\"Input must be a list of strings, not {type(tags)}\")\n\n    for _tag in tags:\n        if type(_tag) not in valid_tag_types:\n            raise TypeError(\n                f\"Invalid type for tag [{_tag}]: {type(_tag)}. Must be one of {valid_tag_types}\"\n            )\n\n    return tags\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/__methods/#red_utils.ext.diskcache_utils.__methods.validate_val","title":"<code>validate_val(val=None, none_ok=False)</code>","text":"<p>Validate input diskcache value.</p> <p>Supported value types: - int - str</p> <p>Parameters:</p> Name Type Description Default <code>val</code> <code>str</code> <p>The value to evaluate</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>Allow null keys</p> <code>False</code> <p>Returns:</p> Type Description <code>str | bytes | float | int</code> <p>The original value after all validations are passed</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_val(\n    val: valid_val_types = None, none_ok: bool = False\n) -&gt; Union[str, bytes, float, int]:\n    \"\"\"Validate input diskcache value.\n\n    Supported value types:\n    - int\n    - str\n\n    Params:\n        val (str): The value to evaluate\n        none_ok (bool): Allow null keys\n\n    Returns:\n        (str|bytes|float|int): The original value after all validations are passed\n\n    \"\"\"\n    if not val:\n        if none_ok:\n            return val\n        else:\n            raise ValueError(\"Missing value to evaluate\")\n\n    if type(val) not in valid_val_types:\n        raise TypeError(\n            f\"Invalid type for val: ({type(val)}). Must be one of {valid_val_types}\"\n        )\n\n    return val\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/","title":"classes","text":""},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.CacheInstance","title":"<code>CacheInstance</code>  <code>dataclass</code>","text":"<p>               Bases: <code>CacheInstanceBase</code></p> <p>Class to control a Diskcache Cache instance.</p> <p>Parameters:</p> Name Type Description Default <code>cache_dir</code> <code>str | Path</code> <p>Directory path where cache.db will be stored.</p> <code>CACHE_DIR</code> <code>index</code> <code>bool</code> <p>Controls creation of a tag index in the cache instance.</p> <code>True</code> <code>cache</code> <code>Cache</code> <p>A diskcache.Cache object. When the class is instantiated, a Cache will be created.</p> <code>None</code> <code>cache_timeout</code> <code>int</code> <p>Default key expiration (in seconds).</p> <code>default_timeout()</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\classes.py</code> <pre><code>@dataclass\nclass CacheInstance(CacheInstanceBase):\n    \"\"\"Class to control a Diskcache Cache instance.\n\n    Params:\n        cache_dir (str|Path): Directory path where cache.db will be stored.\n        index (bool): Controls creation of a tag index in the cache instance.\n        cache (diskcache.Cache): A diskcache.Cache object. When the class is instantiated, a Cache will be created.\n        cache_timeout (int): Default key expiration (in seconds).\n    \"\"\"\n\n    def check_key_exists(self, key: Union[str, int, tuple, frozenset] = None) -&gt; bool:\n        \"\"\"Check if a key exists in a cache.\n\n        Params:\n            key (str): The cache key to search for\n\n        Returns:\n            (bool): `True` if cache key found\n            (bool): `False` if cache key not found\n\n        \"\"\"\n        ## Key validation\n        validate_key(key=key)\n        validate_cache(cache=self.cache)\n\n        ## Check if key exists in cache\n        if key in self.cache:\n            return True\n        else:\n            return False\n\n    def set_val(\n        self,\n        key: Union[str, int, tuple, frozenset],\n        val: Union[str, bytes, float, int, list, dict],\n        expire: int = None,\n        read: bool = False,\n        tag: str = None,\n        retry: bool = False,\n    ) -&gt; None:\n        \"\"\"Set a key value pair in the cache.\n\n        Params:\n            key (str): The key to store the value under in the cache\n            val (str): The value to store in the cache\n            expire (int): Time (in seconds) before value expires\n            read (bool): If `True`, read value as a file-like object\n            tag (str): Applies a tag to the cached value\n            retry (bool): If `True`, retry setting cache key if first attempt fails\n        \"\"\"\n        validate_key(key)\n        validate_val(val)\n        validate_expire(expire, none_ok=True)\n        validate_read(read, none_ok=True)\n        validate_tag(tag=tag, none_ok=True)\n        validate_retry(retry=retry, none_ok=True)\n        validate_cache(cache=self.cache)\n\n        try:\n            with self.cache as ref:\n                ref.set(\n                    key=key, value=val, expire=expire, read=read, tag=tag, retry=retry\n                )\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception setting key/value pair for key: [{key}]. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def get_val(\n        self, key: Union[str, int, tuple, frozenset] = None, tags: list[str] = None\n    ):\n        \"\"\"Search for a key in a given cache.\n\n        Pass a diskcache.Cache object for cache, and a key (and optionally a list of tags).\n        Function will search the cache and return a value if found, or a structured\n        error dict describing the lack of key.\n\n        Params:\n            key (str): The key to search the cache for\n            tags (list[str]): List of tags to search the cache for\n        \"\"\"\n        validate_key(key)\n        validate_cache(self.cache)\n        validate_tags(tags)\n\n        try:\n            if check_cache_key_exists(key=key, cache=self.cache):\n                try:\n                    with self.cache as ref:\n                        _val = ref.get(key=key)\n\n                        return _val\n\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Unhandled exception retrieving value of key [{key}]. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n            else:\n                return {\n                    \"error\": \"Key not found in cache\",\n                    \"details\": {\"key\": key, \"cache_dir\": self.cache.directory},\n                }\n\n        except Exception as exc:\n            return {\n                \"error\": \"Error searching for key in cache\",\n                \"details\": {\"exception\": exc},\n            }\n\n    def set_expire(\n        self, key: Union[str, int, tuple, frozenset] = None, expire: int = None\n    ) -&gt; Union[dict[str, str], None]:\n        \"\"\"Set an expiration timeout (in seconds).\n\n        Params:\n            key (str): Name of the key to set expiration on. Must already exist in the cache.\n            expire (int): Time (in seconds) to wait before expiring cached value.\n        \"\"\"\n        validate_key(key)\n        validate_cache(self.cache)\n        validate_expire(expire)\n\n        if not check_cache_key_exists(key=key, cache=self.cache):\n            return {\n                \"warning\": f\"Cache item with key [{key}] does not exist in cache at {self.cache.directory}/\"\n            }\n\n        try:\n            with self.cache as ref:\n                ref.touch(key, expire=expire)\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception setting expiration of {expire} on key [{key}] in cache at {self.cache.directory}/. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def delete_val(\n        self, key: Union[str, int, tuple, frozenset] = None, tag: str = None\n    ) -&gt; tuple:\n        \"\"\"Delete a cached value.\n\n        If a tag is provided, only keys that also have that tag will be deleted.\n\n        Params:\n            key (str|int): Name of key in cache.\n        \"\"\"\n        validate_key(key)\n        validate_cache(self.cache)\n        validate_tag(tag)\n\n        try:\n            with self.cache as ref:\n                _delete = ref.pop(key=key, tag=tag)\n\n                return _delete\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception deleting key {key} from cache at {self.cache.directory}/. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def get_cache_size(self) -&gt; dict[str, int]:\n        \"\"\"Get a dict describing the size of the cache, in bytes.\n\n        Returns:\n            (dict): A Python `dict` with keys: 'unit', 'size'. Example return object:\n                `{'unit': 'bytes', 'size': 36864}`\n\n        \"\"\"\n        validate_cache(cache=self.cache)\n\n        try:\n            cache_size: int = self.cache.volume()\n\n            return {\"unit\": \"bytes\", \"size\": cache_size}\n\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception getting cache size. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n    def check_cache(self) -&gt; list[warnings.WarningMessage]:\n        \"\"\"Run checks on Cache instance.\n\n        Returns:\n            (list[warning.WarningMessage]): A list of Diskcache `WarningMessage` objects.\n\n        \"\"\"\n        validate_cache(cache=self.cache)\n\n        try:\n            warnings = self.cache.check()\n\n            return warnings\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception checking cache for warnings. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.CacheInstance.check_cache","title":"<code>check_cache()</code>","text":"<p>Run checks on Cache instance.</p> <p>Returns:</p> Type Description <code>list[WarningMessage]</code> <p>A list of Diskcache <code>WarningMessage</code> objects.</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\classes.py</code> <pre><code>def check_cache(self) -&gt; list[warnings.WarningMessage]:\n    \"\"\"Run checks on Cache instance.\n\n    Returns:\n        (list[warning.WarningMessage]): A list of Diskcache `WarningMessage` objects.\n\n    \"\"\"\n    validate_cache(cache=self.cache)\n\n    try:\n        warnings = self.cache.check()\n\n        return warnings\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception checking cache for warnings. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.CacheInstance.check_key_exists","title":"<code>check_key_exists(key=None)</code>","text":"<p>Check if a key exists in a cache.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The cache key to search for</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if cache key found</p> <code>bool</code> <p><code>False</code> if cache key not found</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\classes.py</code> <pre><code>def check_key_exists(self, key: Union[str, int, tuple, frozenset] = None) -&gt; bool:\n    \"\"\"Check if a key exists in a cache.\n\n    Params:\n        key (str): The cache key to search for\n\n    Returns:\n        (bool): `True` if cache key found\n        (bool): `False` if cache key not found\n\n    \"\"\"\n    ## Key validation\n    validate_key(key=key)\n    validate_cache(cache=self.cache)\n\n    ## Check if key exists in cache\n    if key in self.cache:\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.CacheInstance.delete_val","title":"<code>delete_val(key=None, tag=None)</code>","text":"<p>Delete a cached value.</p> <p>If a tag is provided, only keys that also have that tag will be deleted.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str | int</code> <p>Name of key in cache.</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\classes.py</code> <pre><code>def delete_val(\n    self, key: Union[str, int, tuple, frozenset] = None, tag: str = None\n) -&gt; tuple:\n    \"\"\"Delete a cached value.\n\n    If a tag is provided, only keys that also have that tag will be deleted.\n\n    Params:\n        key (str|int): Name of key in cache.\n    \"\"\"\n    validate_key(key)\n    validate_cache(self.cache)\n    validate_tag(tag)\n\n    try:\n        with self.cache as ref:\n            _delete = ref.pop(key=key, tag=tag)\n\n            return _delete\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception deleting key {key} from cache at {self.cache.directory}/. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.CacheInstance.get_cache_size","title":"<code>get_cache_size()</code>","text":"<p>Get a dict describing the size of the cache, in bytes.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A Python <code>dict</code> with keys: 'unit', 'size'. Example return object: <code>{'unit': 'bytes', 'size': 36864}</code></p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\classes.py</code> <pre><code>def get_cache_size(self) -&gt; dict[str, int]:\n    \"\"\"Get a dict describing the size of the cache, in bytes.\n\n    Returns:\n        (dict): A Python `dict` with keys: 'unit', 'size'. Example return object:\n            `{'unit': 'bytes', 'size': 36864}`\n\n    \"\"\"\n    validate_cache(cache=self.cache)\n\n    try:\n        cache_size: int = self.cache.volume()\n\n        return {\"unit\": \"bytes\", \"size\": cache_size}\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception getting cache size. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.CacheInstance.get_val","title":"<code>get_val(key=None, tags=None)</code>","text":"<p>Search for a key in a given cache.</p> <p>Pass a diskcache.Cache object for cache, and a key (and optionally a list of tags). Function will search the cache and return a value if found, or a structured error dict describing the lack of key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to search the cache for</p> <code>None</code> <code>tags</code> <code>list[str]</code> <p>List of tags to search the cache for</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\classes.py</code> <pre><code>def get_val(\n    self, key: Union[str, int, tuple, frozenset] = None, tags: list[str] = None\n):\n    \"\"\"Search for a key in a given cache.\n\n    Pass a diskcache.Cache object for cache, and a key (and optionally a list of tags).\n    Function will search the cache and return a value if found, or a structured\n    error dict describing the lack of key.\n\n    Params:\n        key (str): The key to search the cache for\n        tags (list[str]): List of tags to search the cache for\n    \"\"\"\n    validate_key(key)\n    validate_cache(self.cache)\n    validate_tags(tags)\n\n    try:\n        if check_cache_key_exists(key=key, cache=self.cache):\n            try:\n                with self.cache as ref:\n                    _val = ref.get(key=key)\n\n                    return _val\n\n            except Exception as exc:\n                msg = Exception(\n                    f\"Unhandled exception retrieving value of key [{key}]. Details: {exc}\"\n                )\n                log.error(msg)\n\n                raise exc\n\n        else:\n            return {\n                \"error\": \"Key not found in cache\",\n                \"details\": {\"key\": key, \"cache_dir\": self.cache.directory},\n            }\n\n    except Exception as exc:\n        return {\n            \"error\": \"Error searching for key in cache\",\n            \"details\": {\"exception\": exc},\n        }\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.CacheInstance.set_expire","title":"<code>set_expire(key=None, expire=None)</code>","text":"<p>Set an expiration timeout (in seconds).</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name of the key to set expiration on. Must already exist in the cache.</p> <code>None</code> <code>expire</code> <code>int</code> <p>Time (in seconds) to wait before expiring cached value.</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\classes.py</code> <pre><code>def set_expire(\n    self, key: Union[str, int, tuple, frozenset] = None, expire: int = None\n) -&gt; Union[dict[str, str], None]:\n    \"\"\"Set an expiration timeout (in seconds).\n\n    Params:\n        key (str): Name of the key to set expiration on. Must already exist in the cache.\n        expire (int): Time (in seconds) to wait before expiring cached value.\n    \"\"\"\n    validate_key(key)\n    validate_cache(self.cache)\n    validate_expire(expire)\n\n    if not check_cache_key_exists(key=key, cache=self.cache):\n        return {\n            \"warning\": f\"Cache item with key [{key}] does not exist in cache at {self.cache.directory}/\"\n        }\n\n    try:\n        with self.cache as ref:\n            ref.touch(key, expire=expire)\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception setting expiration of {expire} on key [{key}] in cache at {self.cache.directory}/. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.CacheInstance.set_val","title":"<code>set_val(key, val, expire=None, read=False, tag=None, retry=False)</code>","text":"<p>Set a key value pair in the cache.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to store the value under in the cache</p> required <code>val</code> <code>str</code> <p>The value to store in the cache</p> required <code>expire</code> <code>int</code> <p>Time (in seconds) before value expires</p> <code>None</code> <code>read</code> <code>bool</code> <p>If <code>True</code>, read value as a file-like object</p> <code>False</code> <code>tag</code> <code>str</code> <p>Applies a tag to the cached value</p> <code>None</code> <code>retry</code> <code>bool</code> <p>If <code>True</code>, retry setting cache key if first attempt fails</p> <code>False</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\classes.py</code> <pre><code>def set_val(\n    self,\n    key: Union[str, int, tuple, frozenset],\n    val: Union[str, bytes, float, int, list, dict],\n    expire: int = None,\n    read: bool = False,\n    tag: str = None,\n    retry: bool = False,\n) -&gt; None:\n    \"\"\"Set a key value pair in the cache.\n\n    Params:\n        key (str): The key to store the value under in the cache\n        val (str): The value to store in the cache\n        expire (int): Time (in seconds) before value expires\n        read (bool): If `True`, read value as a file-like object\n        tag (str): Applies a tag to the cached value\n        retry (bool): If `True`, retry setting cache key if first attempt fails\n    \"\"\"\n    validate_key(key)\n    validate_val(val)\n    validate_expire(expire, none_ok=True)\n    validate_read(read, none_ok=True)\n    validate_tag(tag=tag, none_ok=True)\n    validate_retry(retry=retry, none_ok=True)\n    validate_cache(cache=self.cache)\n\n    try:\n        with self.cache as ref:\n            ref.set(\n                key=key, value=val, expire=expire, read=read, tag=tag, retry=retry\n            )\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception setting key/value pair for key: [{key}]. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.CacheInstanceBase","title":"<code>CacheInstanceBase</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DictMixin</code></p> <p>Compose a Diskcache Cache from class parameters.</p> <p>Parameters:</p> Name Type Description Default <code>cache_dir</code> <code>str | Path</code> <p>The directory where the cache database should be created</p> <code>CACHE_DIR</code> <code>index</code> <code>bool</code> <p>If <code>True</code>, a database index will be created</p> <code>True</code> <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> instance</p> <code>None</code> <code>cache_timeout</code> <code>int</code> <p>Default expiration time (in seconds)</p> <code>default_timeout()</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\classes.py</code> <pre><code>@dataclass\nclass CacheInstanceBase(DictMixin):\n    \"\"\"Compose a Diskcache Cache from class parameters.\n\n    Params:\n        cache_dir (str|Path): The directory where the cache database should be created\n        index (bool): If `True`, a database index will be created\n        cache (diskcache.Cache): A `diskcache.Cache` instance\n        cache_timeout (int): Default expiration time (in seconds)\n    \"\"\"\n\n    cache_dir: Union[str, Path] | None = field(default=CACHE_DIR)\n    index: bool = field(default=True)\n    cache: Cache | None = field(default=None)\n    cache_timeout: int | None = field(default_factory=default_timeout)\n\n    def __post_init__(self):  # noqa: D105\n        if isinstance(self.cache_dir, str):\n            if self.cache_dir == \".\":\n                self.cache_dir = Path().absolute()\n            else:\n                self.cache_dir = Path(self.cache_dir)\n\n    def exists(self) -&gt; bool:\n        return Path(f\"{self.cache_dir}/cache.db\").exists()\n\n    @property\n    def cache_path(self) -&gt; Path:\n        return Path(f\"{self.cache_dir}/cache.db\")\n\n    @property\n    def cache_conf_dict(self) -&gt; dict[str, Any]:\n        _config = {\n            \"directory\": self.cache_dir,\n            \"timeout\": self.cache_timeout,\n        }\n\n        return _config\n\n    def init(self) -&gt; Cache:\n        \"\"\"Initialize a Diskcache Cache from class parameters.\n\n        Sets the self.cache parameter to the initialized Cache,\n        and also returns Cache directly.\n\n        Returns:\n            (diskcache.Cache): An initialized `DiskCache.Cache` object\n\n        \"\"\"\n        try:\n            cache = Cache(self.cache_dir, timeout=self.cache_timeout)\n            self.cache = cache\n\n            self.manage_cache_tag_index(\"create\")\n\n            return cache\n\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception creating cache. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n    def manage_cache_tag_index(self, operation: str = \"create\") -&gt; None:\n        \"\"\"Create or delete a cache index.\n\n        Params:\n            operation (str): The operation to perform on the cache's tag index.\n                Options: [\"create\", \"delete\"]\n        \"\"\"\n        valid_operations: list[str] = [\"create\", \"delete\"]\n\n        validate_cache(cache=self.cache)\n\n        if not operation:\n            raise Exception(f\"Operation cannot be None.\")\n\n        try:\n            match operation:\n                case \"create\":\n                    if self.cache.tag_index == 0:\n                        self.cache.create_tag_index()\n                    else:\n                        pass\n\n                case \"delete\":\n                    if self.cache.tag_index == 1:\n                        self.cache.drop_tag_index()\n                    else:\n                        pass\n\n                case _:\n                    raise ValueError(\n                        f\"Invalid operation: {operation}. Must be one of {valid_operations}\"\n                    )\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception configuring tag_index. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def clear(self) -&gt; bool:\n        \"\"\"Clear the entire cache.\n\n        Returns:\n            (bool): `True` if clearing cache successful\n            (bool): `False` if clearing the cache not successful\n\n        \"\"\"\n        validate_cache(self.cache)\n\n        try:\n            with self.cache as ref:\n                ref.clear()\n\n                return True\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception clearing cache at {self.cache.directory}. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.CacheInstanceBase.clear","title":"<code>clear()</code>","text":"<p>Clear the entire cache.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if clearing cache successful</p> <code>bool</code> <p><code>False</code> if clearing the cache not successful</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\classes.py</code> <pre><code>def clear(self) -&gt; bool:\n    \"\"\"Clear the entire cache.\n\n    Returns:\n        (bool): `True` if clearing cache successful\n        (bool): `False` if clearing the cache not successful\n\n    \"\"\"\n    validate_cache(self.cache)\n\n    try:\n        with self.cache as ref:\n            ref.clear()\n\n            return True\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception clearing cache at {self.cache.directory}. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.CacheInstanceBase.init","title":"<code>init()</code>","text":"<p>Initialize a Diskcache Cache from class parameters.</p> <p>Sets the self.cache parameter to the initialized Cache, and also returns Cache directly.</p> <p>Returns:</p> Type Description <code>Cache</code> <p>An initialized <code>DiskCache.Cache</code> object</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\classes.py</code> <pre><code>def init(self) -&gt; Cache:\n    \"\"\"Initialize a Diskcache Cache from class parameters.\n\n    Sets the self.cache parameter to the initialized Cache,\n    and also returns Cache directly.\n\n    Returns:\n        (diskcache.Cache): An initialized `DiskCache.Cache` object\n\n    \"\"\"\n    try:\n        cache = Cache(self.cache_dir, timeout=self.cache_timeout)\n        self.cache = cache\n\n        self.manage_cache_tag_index(\"create\")\n\n        return cache\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception creating cache. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.CacheInstanceBase.manage_cache_tag_index","title":"<code>manage_cache_tag_index(operation='create')</code>","text":"<p>Create or delete a cache index.</p> <p>Parameters:</p> Name Type Description Default <code>operation</code> <code>str</code> <p>The operation to perform on the cache's tag index. Options: [\"create\", \"delete\"]</p> <code>'create'</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\classes.py</code> <pre><code>def manage_cache_tag_index(self, operation: str = \"create\") -&gt; None:\n    \"\"\"Create or delete a cache index.\n\n    Params:\n        operation (str): The operation to perform on the cache's tag index.\n            Options: [\"create\", \"delete\"]\n    \"\"\"\n    valid_operations: list[str] = [\"create\", \"delete\"]\n\n    validate_cache(cache=self.cache)\n\n    if not operation:\n        raise Exception(f\"Operation cannot be None.\")\n\n    try:\n        match operation:\n            case \"create\":\n                if self.cache.tag_index == 0:\n                    self.cache.create_tag_index()\n                else:\n                    pass\n\n            case \"delete\":\n                if self.cache.tag_index == 1:\n                    self.cache.drop_tag_index()\n                else:\n                    pass\n\n            case _:\n                raise ValueError(\n                    f\"Invalid operation: {operation}. Must be one of {valid_operations}\"\n                )\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception configuring tag_index. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.DictMixin","title":"<code>DictMixin</code>  <code>dataclass</code>","text":"<p>Mixin class to add \"as_dict()\" method to classes. Equivalent to .dict.</p> <p>Adds a <code>.as_dict()</code> method to classes that inherit from this mixin. For example, to add <code>.as_dict()</code> method to a parent class, where all children inherit the .as_dict() function, declare parent as:</p> <pre><code>@dataclass\nclass Parent(DictMixin):\n    ...\n</code></pre> <p>and call like:</p> <pre><code>p = Parent()\np_dict = p.as_dict()\n</code></pre> Source code in <code>src\\red_utils\\core\\dataclass_utils\\mixins\\mixin_classes.py</code> <pre><code>@dataclass\nclass DictMixin:\n    \"\"\"Mixin class to add \"as_dict()\" method to classes. Equivalent to .__dict__.\n\n    Adds a `.as_dict()` method to classes that inherit from this mixin. For example,\n    to add `.as_dict()` method to a parent class, where all children inherit the .as_dict()\n    function, declare parent as:\n\n    ``` py linenums=\"1\"\n    @dataclass\n    class Parent(DictMixin):\n        ...\n    ```\n\n    and call like:\n\n    ``` py linenums=\"1\"\n    p = Parent()\n    p_dict = p.as_dict()\n    ```\n    \"\"\"\n\n    def as_dict(self: Generic[T]):\n        \"\"\"Return dict representation of a dataclass instance.\n\n        Description:\n            Any class that inherits from `DictMixin` will automatically have a method `.as_dict()`.\n                There are no extra params.\n\n        Returns:\n            (dict): A Python `dict` representation of a Python `dataclass` class.\n\n        \"\"\"\n        try:\n            return self.__dict__.copy()\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception converting class instance to dict. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.DictMixin.as_dict","title":"<code>as_dict()</code>","text":"<p>Return dict representation of a dataclass instance.</p> Description <p>Any class that inherits from <code>DictMixin</code> will automatically have a method <code>.as_dict()</code>.     There are no extra params.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A Python <code>dict</code> representation of a Python <code>dataclass</code> class.</p> Source code in <code>src\\red_utils\\core\\dataclass_utils\\mixins\\mixin_classes.py</code> <pre><code>def as_dict(self: Generic[T]):\n    \"\"\"Return dict representation of a dataclass instance.\n\n    Description:\n        Any class that inherits from `DictMixin` will automatically have a method `.as_dict()`.\n            There are no extra params.\n\n    Returns:\n        (dict): A Python `dict` representation of a Python `dataclass` class.\n\n    \"\"\"\n    try:\n        return self.__dict__.copy()\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception converting class instance to dict. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.check_cache","title":"<code>check_cache(cache=None)</code>","text":"<p>Run healthcheck on cache.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> instance to work on</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def check_cache(cache: Cache = None):\n    \"\"\"Run healthcheck on cache.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` instance to work on\n    \"\"\"\n    validate_cache(cache=cache)\n\n    try:\n        warnings = cache.check()\n\n        return warnings\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception checking cache for warnings. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.check_cache_key_exists","title":"<code>check_cache_key_exists(cache=None, key=None)</code>","text":"<p>Check if a key exists in a cache.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> instance to check</p> <code>None</code> <code>key</code> <code>str</code> <p>The key name to search the <code>cache</code> for</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the key exists</p> <code>bool</code> <p><code>False</code> if the key does not exist</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def check_cache_key_exists(cache: diskcache.core.Cache = None, key: str = None) -&gt; bool:\n    \"\"\"Check if a key exists in a cache.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` instance to check\n        key (str): The key name to search the `cache` for\n\n    Returns:\n        (bool): `True` if the key exists\n        (bool): `False` if the key does not exist\n\n    \"\"\"\n    ## Key validation\n    validate_key(key=key)\n    validate_cache(cache=cache)\n\n    ## Check if key exists in cache\n    if key in cache:\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.clear_cache","title":"<code>clear_cache(cache=None)</code>","text":"<p>Clear all items from the cache.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>The target cache to clear</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if cache cleared successfully</p> <code>bool</code> <p><code>False</code> if cache not cleared successfully</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def clear_cache(cache: Cache = None) -&gt; bool:\n    \"\"\"Clear all items from the cache.\n\n    Params:\n        cache (diskcache.Cache): The target cache to clear\n\n    Returns:\n        (bool): `True` if cache cleared successfully\n        (bool): `False` if cache not cleared successfully\n\n    \"\"\"\n    validate_cache(cache)\n\n    try:\n        with cache as ref:\n            ref.clear()\n\n            return True\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception clearing cache at {cache.directory}. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.convert_to_seconds","title":"<code>convert_to_seconds(amount=None, unit=None)</code>","text":"<p>Convert an amount of time to seconds.</p> <p>Parameters:</p> Name Type Description Default <code>amount</code> <code>int</code> <p>Amount of time</p> <code>None</code> <code>unit</code> <code>str</code> <p>The starting unit of time to convert to seconds. Options: [\"seconds\", \"hours\", \"minutes\", \"days\", \"weeks\"]</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p><code>amount</code> of time converted to seconds representing the <code>unit</code> of time passed</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def convert_to_seconds(amount: int = None, unit: str = None) -&gt; int:\n    \"\"\"Convert an amount of time to seconds.\n\n    Params:\n        amount (int): Amount of time\n        unit (str): The starting unit of time to convert to seconds.\n            Options: [\"seconds\", \"hours\", \"minutes\", \"days\", \"weeks\"]\n\n    Returns:\n        (int): `amount` of time converted to seconds representing the `unit` of time passed\n\n    \"\"\"\n    ## Allowed strings for conversion\n    valid_time_units: list[int] = [\"seconds\", \"hours\", \"minutes\", \"days\", \"weeks\"]\n\n    assert unit is not None, ValueError(\n        f\"Missing unit. Must be one of {valid_time_units}\"\n    )\n\n    assert isinstance(unit, str), TypeError(\n        f\"Invalid type for unit: {type(unit)}. Must be str\"\n    )\n\n    assert unit in valid_time_units, TypeError(\n        f\"Invalid unit: {unit}. Must be one of {valid_time_units}\"\n    )\n\n    amount is not None, ValueError(\"Missing amount of unit, i.e. 3 days\")\n\n    assert isinstance(amount, int), TypeError(\n        f\"Invalid type for amount: ({type(amount)}). Must be of type int\"\n    )\n\n    match unit:\n        case \"weeks\":\n            _amount: int = amount * 7 * 24 * 60 * 60\n        case \"days\":\n            _amount: int = amount * 24 * 60 * 60\n        case \"hours\":\n            _amount: int = amount * 60 * 60\n        case \"minutes\":\n            _amount: int = amount * 60\n        case \"seconds\":\n            _amount: int = amount\n        case _:\n            raise ValueError(f\"Invalid input for unit: {unit}\")\n\n    return _amount\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.default_timeout","title":"<code>default_timeout()</code>","text":"<p>Return the default timeout period.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of seconds in 24 hours</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\classes.py</code> <pre><code>def default_timeout() -&gt; int:\n    \"\"\"Return the default timeout period.\n\n    Returns:\n        (int): The number of seconds in 24 hours\n\n    \"\"\"\n    timeout = convert_to_seconds(amount=24, unit=\"hours\")\n    return timeout\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.delete_val","title":"<code>delete_val(cache=None, key=None, tag=None)</code>","text":"<p>Delete a value from the cache.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> instance to work on</p> <code>None</code> <code>key</code> <code>str</code> <p>The name of a key to delete</p> <code>None</code> <code>tag</code> <code>str</code> <p>Tag to filter by</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def delete_val(\n    cache: Cache = None, key: Union[str, int, tuple, frozenset] = None, tag: str = None\n) -&gt; tuple:\n    \"\"\"Delete a value from the cache.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` instance to work on\n        key (str): The name of a key to delete\n        tag (str): Tag to filter by\n    \"\"\"\n    validate_key(key)\n    validate_cache(cache)\n    validate_tag(tag)\n\n    try:\n        with cache as ref:\n            _delete = ref.pop(key=key, tag=tag)\n\n            return _delete\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception deleting key {key} from cache at {cache.directory}/. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.get_cache_size","title":"<code>get_cache_size(cache=None)</code>","text":"<p>Get the total size of a <code>diskcache.Cache</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> object to get the size of</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, int]</code> <p>Details about the cache's size. Example: <code>{\"unit\": \"bytes\", \"size\": cache_size}</code></p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def get_cache_size(cache: Cache = None) -&gt; dict[str, int]:\n    \"\"\"Get the total size of a `diskcache.Cache` instance.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` object to get the size of\n\n    Returns:\n        (dict[str, int]): Details about the cache's size. Example:\n            `{\"unit\": \"bytes\", \"size\": cache_size}`\n\n    \"\"\"\n    validate_cache(cache=cache)\n\n    try:\n        cache_size: int = cache.volume()\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception getting cache size. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n\n    return {\"unit\": \"bytes\", \"size\": cache_size}\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.manage_cache_tag_index","title":"<code>manage_cache_tag_index(cache=None, operation='create')</code>","text":"<p>Create or delete a cache's tag index.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> instance to work on</p> <code>None</code> <code>operation</code> <code>str</code> <p>The operation (create/delete) to perform on the tag index</p> <code>'create'</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def manage_cache_tag_index(cache: Cache = None, operation: str = \"create\") -&gt; None:\n    \"\"\"Create or delete a cache's tag index.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` instance to work on\n        operation (str): The operation (create/delete) to perform on the tag index\n    \"\"\"\n    valid_operations: list[str] = [\"create\", \"delete\"]\n\n    validate_cache(cache=cache)\n\n    if not operation:\n        raise Exception(f\"Operation cannot be None.\")\n\n    try:\n        match operation:\n            case \"create\":\n                if cache.tag_index == 0:\n                    cache.create_tag_index()\n                else:\n                    pass\n\n            case \"delete\":\n                if cache.tag_index == 1:\n                    cache.drop_tag_index()\n                else:\n                    pass\n\n            case _:\n                raise ValueError(\n                    f\"Invalid operation: {operation}. Must be one of {valid_operations}\"\n                )\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception configuring tag_index. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.set_expire","title":"<code>set_expire(cache=None, key=None, expire=None)</code>","text":"<p>Set/change a cache key's expiration time.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> instance to work on</p> <code>None</code> <code>key</code> <code>str</code> <p>The cache key name to set an expiration time on</p> <code>None</code> <code>expire</code> <code>int</code> <p>Time (in seconds) before cache key expires</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def set_expire(\n    cache: Cache = None, key: str = None, expire: int = None\n) -&gt; Union[dict[str, str], None]:\n    \"\"\"Set/change a cache key's expiration time.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` instance to work on\n        key (str): The cache key name to set an expiration time on\n        expire (int): Time (in seconds) before cache key expires\n    \"\"\"\n    validate_key(key)\n    validate_cache(cache)\n    validate_expire(expire)\n\n    if not check_cache_key_exists(key=key, cache=cache):\n        return {\n            \"warning\": f\"Cache item with key [{key}] does not exist in cache at {cache.directory}/\"\n        }\n\n    try:\n        with cache as ref:\n            ref.touch(key, expire=expire)\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception setting expiration of {expire} on key [{key}] in cache at {cache.directory}/. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.set_val","title":"<code>set_val(cache=None, key=None, val=None, expire=None, read=False, tag=None, retry=False)</code>","text":"<p>Set a key value pair in the cache.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> object to work on</p> <code>None</code> <code>key</code> <code>str</code> <p>The key to store the value under in the cache</p> <code>None</code> <code>val</code> <code>str</code> <p>The value to store in the cache</p> <code>None</code> <code>expire</code> <code>int</code> <p>Time (in seconds) before value expires</p> <code>None</code> <code>read</code> <code>bool</code> <p>If <code>True</code>, read value as a file-like object</p> <code>False</code> <code>tag</code> <code>str</code> <p>Applies a tag to the cached value</p> <code>None</code> <code>retry</code> <code>bool</code> <p>If <code>True</code>, retry setting cache key if first attempt fails</p> <code>False</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\__methods.py</code> <pre><code>def set_val(\n    cache: Cache = None,\n    key: Union[str, int, tuple, frozenset] = None,\n    val: Union[str, bytes, float, int, list, dict] = None,\n    expire: int = None,\n    read: bool = False,\n    tag: str = None,\n    retry: bool = False,\n) -&gt; None:\n    \"\"\"Set a key value pair in the cache.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` object to work on\n        key (str): The key to store the value under in the cache\n        val (str): The value to store in the cache\n        expire (int): Time (in seconds) before value expires\n        read (bool): If `True`, read value as a file-like object\n        tag (str): Applies a tag to the cached value\n        retry (bool): If `True`, retry setting cache key if first attempt fails\n    \"\"\"\n    validate_key(key)\n    validate_val(val)\n    validate_expire(expire, none_ok=True)\n    validate_read(read, none_ok=True)\n    validate_tag(tag=tag, none_ok=True)\n    validate_retry(retry=retry, none_ok=True)\n    validate_cache(cache=cache)\n\n    try:\n        with cache as ref:\n            ref.set(key=key, value=val, expire=expire, read=read, tag=tag, retry=retry)\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception setting key/value pair for key: [{key}]. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.validate_cache","title":"<code>validate_cache(cache=None, none_ok=True)</code>","text":"<p>Validate a DiskCache cache object.</p> <p>Checks for existence and correct type.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> instance to validate</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>Allow null values</p> <code>True</code> <p>Returns:</p> Type Description <code>Cache</code> <p>The original <code>Cache</code> instance after validation passes</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_cache(cache: Cache = None, none_ok: bool = True) -&gt; diskcache.core.Cache:\n    \"\"\"Validate a DiskCache cache object.\n\n    Checks for existence and correct type.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` instance to validate\n        none_ok (bool): Allow null values\n\n    Returns:\n        (diskcache.Cache): The original `Cache` instance after validation passes\n\n    \"\"\"\n    ## Check existence\n    if cache is None:\n        if not none_ok:\n            raise ValueError(\"Missing diskcache.Cache object to perform lookup against\")\n\n    else:\n        ## Only validate an existing cache\n        assert isinstance(cache, Cache), TypeError(\n            f\"Cache must be of type diskcache.Cache, not {type(cache)}\"\n        )\n\n    return cache\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.validate_expire","title":"<code>validate_expire(expire=None, none_ok=False)</code>","text":"<p>Validate input diskcache expiration time.</p> <p>Only int types allowed. Expiration time is in seconds.</p> <p>Parameters:</p> Name Type Description Default <code>expire</code> <code>int</code> <p>The amount of seconds for an expiration value</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>none_ok (bool): Allow null values</p> <code>False</code> <p>Returns:</p> Type Description <code>int</code> <p>The original expiration time (in seconds) if validation passes</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_expire(expire: int = None, none_ok: bool = False) -&gt; int:\n    \"\"\"Validate input diskcache expiration time.\n\n    Only int types allowed. Expiration time is in seconds.\n\n    Params:\n        expire (int): The amount of seconds for an expiration value\n        none_ok (bool): none_ok (bool): Allow null values\n\n    Returns:\n        (int): The original expiration time (in seconds) if validation passes\n\n    \"\"\"\n    ## Evaluate var existence\n    if not expire:\n        if none_ok:\n            return expire\n        else:\n            raise ValueError(\"Missing expire value to evaluate\")\n\n    ## Evaluate var type\n    if not isinstance(expire, int):\n        try:\n            expire: int = int(expire)\n\n            return expire\n\n        except Exception as exc:\n            raise TypeError(\n                f\"Expire value is not of type int. Conversion to int failed. Details: {exc}\"\n            )\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.validate_key","title":"<code>validate_key(key=None, none_ok=False)</code>","text":"<p>Validate input diskcache key.</p> <p>Supported key types: - int - str</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to evaluate</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>Allow null keys</p> <code>False</code> <p>Returns:</p> Type Description <code>str | int</code> <p>The original key after all validations are passed</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_key(key: valid_key_types = None, none_ok: bool = False) -&gt; Union[str, int]:\n    \"\"\"Validate input diskcache key.\n\n    Supported key types:\n    - int\n    - str\n\n    Params:\n        key (str): The key to evaluate\n        none_ok (bool): Allow null keys\n\n    Returns:\n        (str|int): The original key after all validations are passed\n\n    \"\"\"\n    ## Evaluate key existence\n    if key is False or None:\n        if none_ok:\n            return key\n\n        else:\n            raise ValueError(\"Missing key to evaluate\")\n\n    ## Key exists, validate type\n    if type(key) not in valid_key_types:\n        raise TypeError(\n            f\"Invalid type for key: ({type(key)}). Must be one of {valid_key_types}\"\n        )\n\n    return key\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.validate_read","title":"<code>validate_read(read=None, none_ok=True)</code>","text":"<p>Validate input diskcache read value.</p> <p>Read is a bool that enables/disables reading input as a file. Docs: https://grantjenks.com/docs/diskcache/tutorial.html#cache</p> <p>Only int types allowed. Expiration time is in seconds.</p> <p>Parameters:</p> Name Type Description Default <code>read</code> <code>bool</code> <p><code>True</code>/<code>False</code> state</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>none_ok (bool): Allow null values</p> <code>True</code> <p>Returns:</p> Type Description <code>bool</code> <p>The original value of <code>read</code> if all validations pass</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_read(read: bool = None, none_ok: bool = True) -&gt; bool:\n    \"\"\"Validate input diskcache read value.\n\n    Read is a bool that enables/disables reading input as a file.\n    Docs: https://grantjenks.com/docs/diskcache/tutorial.html#cache\n\n    Only int types allowed. Expiration time is in seconds.\n\n    Params:\n        read (bool): `True`/`False` state\n        none_ok (bool): none_ok (bool): Allow null values\n\n    Returns:\n        (bool): The original value of `read` if all validations pass\n\n    \"\"\"\n    ## Evaluate var existence\n    if not read:\n        if none_ok:\n            return read\n        else:\n            raise ValueError(\"Missing read bool to evaluate\")\n\n    ## Evaluate var type\n    if not isinstance(read, bool):\n        try:\n            read: bool = bool(read)\n\n        except Exception as exc:\n            raise TypeError(\n                f\"Read value is not of type bool. Conversion to bool failed. Details: {exc}\"\n            )\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.validate_retry","title":"<code>validate_retry(retry=None, none_ok=True)</code>","text":"<p>Validate input diskcache retry.</p> <p>Determines whether or not cache will retry on failure before exiting.</p> <p>Parameters:</p> Name Type Description Default <code>retry</code> <code>bool</code> <p><code>True</code>/<code>False</code> state of retry</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>Allow nullable values</p> <code>True</code> <p>Returns:</p> Type Description <code>bool</code> <p>The original value of <code>retry</code> if validations pass</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_retry(retry: bool = None, none_ok: bool = True) -&gt; bool:\n    \"\"\"Validate input diskcache retry.\n\n    Determines whether or not cache will retry on failure before exiting.\n\n    Params:\n        retry (bool): `True`/`False` state of retry\n        none_ok (bool): Allow nullable values\n\n    Returns:\n        (bool): The original value of `retry` if validations pass\n\n    \"\"\"\n    ## Evaluate var existence\n    if not retry:\n        if none_ok:\n            return retry\n        else:\n            raise ValueError(\"Missing retry to evaluate\")\n\n    ## Evaluate var type\n    if not isinstance(retry, str):\n        try:\n            retry: str = str(retry)\n\n        except Exception as exc:\n            raise TypeError(\n                f\"Retry value is not of type str. Conversion to str failed. Details: {exc}\"\n            )\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.validate_tag","title":"<code>validate_tag(tag=None, none_ok=True)</code>","text":"<p>Validate input diskcache tag.</p> <p>A tag is an optional user-defined string that groups cache entries.</p> <p>Parameters:</p> Name Type Description Default <code>tag</code> <code>str</code> <p>A tag to validate</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>Allow null values</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>A validated tag</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_tag(tag: valid_tag_types = None, none_ok: bool = True) -&gt; str:\n    \"\"\"Validate input diskcache tag.\n\n    A tag is an optional user-defined string that groups cache entries.\n\n    Params:\n        tag (str): A tag to validate\n        none_ok (bool): Allow null values\n\n    Returns:\n        (str): A validated tag\n\n    \"\"\"\n    ## Evaluate var existence\n    if not tag:\n        if none_ok:\n            return tag\n        else:\n            raise ValueError(\"Missing tag to evaluate\")\n\n    ## Evaluate var type\n    if type(tag) not in valid_tag_types:\n        raise TypeError(\n            f\"Invalid type for tag [{tag}]: {type(tag)}. Must be one of {valid_tag_types}\"\n        )\n\n    if not isinstance(tag, str):\n        try:\n            tag: str = str(tag)\n\n        except Exception as exc:\n            raise TypeError(\n                f\"tag value is not of type str. Conversion to str failed. Details: {exc}\"\n            )\n\n    return tag\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.validate_tags","title":"<code>validate_tags(tags=None, none_ok=True)</code>","text":"<p>Validate a list of tags.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>list[str]</code> <p>A list of tags to validate</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>Allow null values</p> <code>True</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>A validated list of tags</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_tags(\n    tags: list[valid_tag_types] = None, none_ok: bool = True\n) -&gt; list[valid_tag_types]:\n    \"\"\"Validate a list of tags.\n\n    Params:\n        tags (list[str]): A list of tags to validate\n        none_ok (bool): Allow null values\n\n    Returns:\n        (list[str]): A validated list of tags\n\n    \"\"\"\n    if not tags:\n        if none_ok:\n            return tags\n        else:\n            raise ValueError(\"Missing tags list\")\n\n    if not isinstance(tags, list):\n        raise TypeError(f\"Input must be a list of strings, not {type(tags)}\")\n\n    for _tag in tags:\n        if type(_tag) not in valid_tag_types:\n            raise TypeError(\n                f\"Invalid type for tag [{_tag}]: {type(_tag)}. Must be one of {valid_tag_types}\"\n            )\n\n    return tags\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/classes/#red_utils.ext.diskcache_utils.classes.validate_val","title":"<code>validate_val(val=None, none_ok=False)</code>","text":"<p>Validate input diskcache value.</p> <p>Supported value types: - int - str</p> <p>Parameters:</p> Name Type Description Default <code>val</code> <code>str</code> <p>The value to evaluate</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>Allow null keys</p> <code>False</code> <p>Returns:</p> Type Description <code>str | bytes | float | int</code> <p>The original value after all validations are passed</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_val(\n    val: valid_val_types = None, none_ok: bool = False\n) -&gt; Union[str, bytes, float, int]:\n    \"\"\"Validate input diskcache value.\n\n    Supported value types:\n    - int\n    - str\n\n    Params:\n        val (str): The value to evaluate\n        none_ok (bool): Allow null keys\n\n    Returns:\n        (str|bytes|float|int): The original value after all validations are passed\n\n    \"\"\"\n    if not val:\n        if none_ok:\n            return val\n        else:\n            raise ValueError(\"Missing value to evaluate\")\n\n    if type(val) not in valid_val_types:\n        raise TypeError(\n            f\"Invalid type for val: ({type(val)}). Must be one of {valid_val_types}\"\n        )\n\n    return val\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/constants/","title":"constants","text":""},{"location":"reference/red_utils/ext/diskcache_utils/constants/#red_utils.ext.diskcache_utils.constants.DictMixin","title":"<code>DictMixin</code>  <code>dataclass</code>","text":"<p>Mixin class to add \"as_dict()\" method to classes. Equivalent to .dict.</p> <p>Adds a <code>.as_dict()</code> method to classes that inherit from this mixin. For example, to add <code>.as_dict()</code> method to a parent class, where all children inherit the .as_dict() function, declare parent as:</p> <pre><code>@dataclass\nclass Parent(DictMixin):\n    ...\n</code></pre> <p>and call like:</p> <pre><code>p = Parent()\np_dict = p.as_dict()\n</code></pre> Source code in <code>src\\red_utils\\core\\dataclass_utils\\mixins\\mixin_classes.py</code> <pre><code>@dataclass\nclass DictMixin:\n    \"\"\"Mixin class to add \"as_dict()\" method to classes. Equivalent to .__dict__.\n\n    Adds a `.as_dict()` method to classes that inherit from this mixin. For example,\n    to add `.as_dict()` method to a parent class, where all children inherit the .as_dict()\n    function, declare parent as:\n\n    ``` py linenums=\"1\"\n    @dataclass\n    class Parent(DictMixin):\n        ...\n    ```\n\n    and call like:\n\n    ``` py linenums=\"1\"\n    p = Parent()\n    p_dict = p.as_dict()\n    ```\n    \"\"\"\n\n    def as_dict(self: Generic[T]):\n        \"\"\"Return dict representation of a dataclass instance.\n\n        Description:\n            Any class that inherits from `DictMixin` will automatically have a method `.as_dict()`.\n                There are no extra params.\n\n        Returns:\n            (dict): A Python `dict` representation of a Python `dataclass` class.\n\n        \"\"\"\n        try:\n            return self.__dict__.copy()\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception converting class instance to dict. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/constants/#red_utils.ext.diskcache_utils.constants.DictMixin.as_dict","title":"<code>as_dict()</code>","text":"<p>Return dict representation of a dataclass instance.</p> Description <p>Any class that inherits from <code>DictMixin</code> will automatically have a method <code>.as_dict()</code>.     There are no extra params.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A Python <code>dict</code> representation of a Python <code>dataclass</code> class.</p> Source code in <code>src\\red_utils\\core\\dataclass_utils\\mixins\\mixin_classes.py</code> <pre><code>def as_dict(self: Generic[T]):\n    \"\"\"Return dict representation of a dataclass instance.\n\n    Description:\n        Any class that inherits from `DictMixin` will automatically have a method `.as_dict()`.\n            There are no extra params.\n\n    Returns:\n        (dict): A Python `dict` representation of a Python `dataclass` class.\n\n    \"\"\"\n    try:\n        return self.__dict__.copy()\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception converting class instance to dict. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/constants/#red_utils.ext.diskcache_utils.constants.TimeoutConf","title":"<code>TimeoutConf</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DictMixin</code></p> <p>Define cache timeout as a class.</p> <p>Inherits the .as_dict() method from DictMixin.</p> <p>Parameters:</p> Name Type Description Default <code>amount</code> <code>int</code> <p>Amount of time to allow for timeout</p> <code>15</code> <code>unit</code> <code>str</code> <p>Unit of time corresponding with the <code>amount</code> passed. Examples: [\"minutes\", \"hours\", \"days\", etc]</p> <code>'minutes'</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\constants.py</code> <pre><code>@dataclass\nclass TimeoutConf(DictMixin):\n    \"\"\"Define cache timeout as a class.\n\n    Inherits the .as_dict() method from DictMixin.\n\n    Params:\n        amount (int): Amount of time to allow for timeout\n        unit (str): Unit of time corresponding with the `amount` passed. Examples: [\"minutes\", \"hours\", \"days\", etc]\n    \"\"\"\n\n    unit: str | None = field(default=\"minutes\")\n    amount: int | None = field(default=15)\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/validators/","title":"validators","text":""},{"location":"reference/red_utils/ext/diskcache_utils/validators/#red_utils.ext.diskcache_utils.validators.validate_cache","title":"<code>validate_cache(cache=None, none_ok=True)</code>","text":"<p>Validate a DiskCache cache object.</p> <p>Checks for existence and correct type.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Cache</code> <p>A <code>diskcache.Cache</code> instance to validate</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>Allow null values</p> <code>True</code> <p>Returns:</p> Type Description <code>Cache</code> <p>The original <code>Cache</code> instance after validation passes</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_cache(cache: Cache = None, none_ok: bool = True) -&gt; diskcache.core.Cache:\n    \"\"\"Validate a DiskCache cache object.\n\n    Checks for existence and correct type.\n\n    Params:\n        cache (diskcache.Cache): A `diskcache.Cache` instance to validate\n        none_ok (bool): Allow null values\n\n    Returns:\n        (diskcache.Cache): The original `Cache` instance after validation passes\n\n    \"\"\"\n    ## Check existence\n    if cache is None:\n        if not none_ok:\n            raise ValueError(\"Missing diskcache.Cache object to perform lookup against\")\n\n    else:\n        ## Only validate an existing cache\n        assert isinstance(cache, Cache), TypeError(\n            f\"Cache must be of type diskcache.Cache, not {type(cache)}\"\n        )\n\n    return cache\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/validators/#red_utils.ext.diskcache_utils.validators.validate_expire","title":"<code>validate_expire(expire=None, none_ok=False)</code>","text":"<p>Validate input diskcache expiration time.</p> <p>Only int types allowed. Expiration time is in seconds.</p> <p>Parameters:</p> Name Type Description Default <code>expire</code> <code>int</code> <p>The amount of seconds for an expiration value</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>none_ok (bool): Allow null values</p> <code>False</code> <p>Returns:</p> Type Description <code>int</code> <p>The original expiration time (in seconds) if validation passes</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_expire(expire: int = None, none_ok: bool = False) -&gt; int:\n    \"\"\"Validate input diskcache expiration time.\n\n    Only int types allowed. Expiration time is in seconds.\n\n    Params:\n        expire (int): The amount of seconds for an expiration value\n        none_ok (bool): none_ok (bool): Allow null values\n\n    Returns:\n        (int): The original expiration time (in seconds) if validation passes\n\n    \"\"\"\n    ## Evaluate var existence\n    if not expire:\n        if none_ok:\n            return expire\n        else:\n            raise ValueError(\"Missing expire value to evaluate\")\n\n    ## Evaluate var type\n    if not isinstance(expire, int):\n        try:\n            expire: int = int(expire)\n\n            return expire\n\n        except Exception as exc:\n            raise TypeError(\n                f\"Expire value is not of type int. Conversion to int failed. Details: {exc}\"\n            )\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/validators/#red_utils.ext.diskcache_utils.validators.validate_key","title":"<code>validate_key(key=None, none_ok=False)</code>","text":"<p>Validate input diskcache key.</p> <p>Supported key types: - int - str</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to evaluate</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>Allow null keys</p> <code>False</code> <p>Returns:</p> Type Description <code>str | int</code> <p>The original key after all validations are passed</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_key(key: valid_key_types = None, none_ok: bool = False) -&gt; Union[str, int]:\n    \"\"\"Validate input diskcache key.\n\n    Supported key types:\n    - int\n    - str\n\n    Params:\n        key (str): The key to evaluate\n        none_ok (bool): Allow null keys\n\n    Returns:\n        (str|int): The original key after all validations are passed\n\n    \"\"\"\n    ## Evaluate key existence\n    if key is False or None:\n        if none_ok:\n            return key\n\n        else:\n            raise ValueError(\"Missing key to evaluate\")\n\n    ## Key exists, validate type\n    if type(key) not in valid_key_types:\n        raise TypeError(\n            f\"Invalid type for key: ({type(key)}). Must be one of {valid_key_types}\"\n        )\n\n    return key\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/validators/#red_utils.ext.diskcache_utils.validators.validate_read","title":"<code>validate_read(read=None, none_ok=True)</code>","text":"<p>Validate input diskcache read value.</p> <p>Read is a bool that enables/disables reading input as a file. Docs: https://grantjenks.com/docs/diskcache/tutorial.html#cache</p> <p>Only int types allowed. Expiration time is in seconds.</p> <p>Parameters:</p> Name Type Description Default <code>read</code> <code>bool</code> <p><code>True</code>/<code>False</code> state</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>none_ok (bool): Allow null values</p> <code>True</code> <p>Returns:</p> Type Description <code>bool</code> <p>The original value of <code>read</code> if all validations pass</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_read(read: bool = None, none_ok: bool = True) -&gt; bool:\n    \"\"\"Validate input diskcache read value.\n\n    Read is a bool that enables/disables reading input as a file.\n    Docs: https://grantjenks.com/docs/diskcache/tutorial.html#cache\n\n    Only int types allowed. Expiration time is in seconds.\n\n    Params:\n        read (bool): `True`/`False` state\n        none_ok (bool): none_ok (bool): Allow null values\n\n    Returns:\n        (bool): The original value of `read` if all validations pass\n\n    \"\"\"\n    ## Evaluate var existence\n    if not read:\n        if none_ok:\n            return read\n        else:\n            raise ValueError(\"Missing read bool to evaluate\")\n\n    ## Evaluate var type\n    if not isinstance(read, bool):\n        try:\n            read: bool = bool(read)\n\n        except Exception as exc:\n            raise TypeError(\n                f\"Read value is not of type bool. Conversion to bool failed. Details: {exc}\"\n            )\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/validators/#red_utils.ext.diskcache_utils.validators.validate_retry","title":"<code>validate_retry(retry=None, none_ok=True)</code>","text":"<p>Validate input diskcache retry.</p> <p>Determines whether or not cache will retry on failure before exiting.</p> <p>Parameters:</p> Name Type Description Default <code>retry</code> <code>bool</code> <p><code>True</code>/<code>False</code> state of retry</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>Allow nullable values</p> <code>True</code> <p>Returns:</p> Type Description <code>bool</code> <p>The original value of <code>retry</code> if validations pass</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_retry(retry: bool = None, none_ok: bool = True) -&gt; bool:\n    \"\"\"Validate input diskcache retry.\n\n    Determines whether or not cache will retry on failure before exiting.\n\n    Params:\n        retry (bool): `True`/`False` state of retry\n        none_ok (bool): Allow nullable values\n\n    Returns:\n        (bool): The original value of `retry` if validations pass\n\n    \"\"\"\n    ## Evaluate var existence\n    if not retry:\n        if none_ok:\n            return retry\n        else:\n            raise ValueError(\"Missing retry to evaluate\")\n\n    ## Evaluate var type\n    if not isinstance(retry, str):\n        try:\n            retry: str = str(retry)\n\n        except Exception as exc:\n            raise TypeError(\n                f\"Retry value is not of type str. Conversion to str failed. Details: {exc}\"\n            )\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/validators/#red_utils.ext.diskcache_utils.validators.validate_tag","title":"<code>validate_tag(tag=None, none_ok=True)</code>","text":"<p>Validate input diskcache tag.</p> <p>A tag is an optional user-defined string that groups cache entries.</p> <p>Parameters:</p> Name Type Description Default <code>tag</code> <code>str</code> <p>A tag to validate</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>Allow null values</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>A validated tag</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_tag(tag: valid_tag_types = None, none_ok: bool = True) -&gt; str:\n    \"\"\"Validate input diskcache tag.\n\n    A tag is an optional user-defined string that groups cache entries.\n\n    Params:\n        tag (str): A tag to validate\n        none_ok (bool): Allow null values\n\n    Returns:\n        (str): A validated tag\n\n    \"\"\"\n    ## Evaluate var existence\n    if not tag:\n        if none_ok:\n            return tag\n        else:\n            raise ValueError(\"Missing tag to evaluate\")\n\n    ## Evaluate var type\n    if type(tag) not in valid_tag_types:\n        raise TypeError(\n            f\"Invalid type for tag [{tag}]: {type(tag)}. Must be one of {valid_tag_types}\"\n        )\n\n    if not isinstance(tag, str):\n        try:\n            tag: str = str(tag)\n\n        except Exception as exc:\n            raise TypeError(\n                f\"tag value is not of type str. Conversion to str failed. Details: {exc}\"\n            )\n\n    return tag\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/validators/#red_utils.ext.diskcache_utils.validators.validate_tags","title":"<code>validate_tags(tags=None, none_ok=True)</code>","text":"<p>Validate a list of tags.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>list[str]</code> <p>A list of tags to validate</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>Allow null values</p> <code>True</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>A validated list of tags</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_tags(\n    tags: list[valid_tag_types] = None, none_ok: bool = True\n) -&gt; list[valid_tag_types]:\n    \"\"\"Validate a list of tags.\n\n    Params:\n        tags (list[str]): A list of tags to validate\n        none_ok (bool): Allow null values\n\n    Returns:\n        (list[str]): A validated list of tags\n\n    \"\"\"\n    if not tags:\n        if none_ok:\n            return tags\n        else:\n            raise ValueError(\"Missing tags list\")\n\n    if not isinstance(tags, list):\n        raise TypeError(f\"Input must be a list of strings, not {type(tags)}\")\n\n    for _tag in tags:\n        if type(_tag) not in valid_tag_types:\n            raise TypeError(\n                f\"Invalid type for tag [{_tag}]: {type(_tag)}. Must be one of {valid_tag_types}\"\n            )\n\n    return tags\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/validators/#red_utils.ext.diskcache_utils.validators.validate_val","title":"<code>validate_val(val=None, none_ok=False)</code>","text":"<p>Validate input diskcache value.</p> <p>Supported value types: - int - str</p> <p>Parameters:</p> Name Type Description Default <code>val</code> <code>str</code> <p>The value to evaluate</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>Allow null keys</p> <code>False</code> <p>Returns:</p> Type Description <code>str | bytes | float | int</code> <p>The original value after all validations are passed</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\validators.py</code> <pre><code>def validate_val(\n    val: valid_val_types = None, none_ok: bool = False\n) -&gt; Union[str, bytes, float, int]:\n    \"\"\"Validate input diskcache value.\n\n    Supported value types:\n    - int\n    - str\n\n    Params:\n        val (str): The value to evaluate\n        none_ok (bool): Allow null keys\n\n    Returns:\n        (str|bytes|float|int): The original value after all validations are passed\n\n    \"\"\"\n    if not val:\n        if none_ok:\n            return val\n        else:\n            raise ValueError(\"Missing value to evaluate\")\n\n    if type(val) not in valid_val_types:\n        raise TypeError(\n            f\"Invalid type for val: ({type(val)}). Must be one of {valid_val_types}\"\n        )\n\n    return val\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/controllers/__init__/","title":"controllers","text":""},{"location":"reference/red_utils/ext/diskcache_utils/controllers/__init__/#red_utils.ext.diskcache_utils.controllers.DiskCacheController","title":"<code>DiskCacheController</code>","text":"<p>               Bases: <code>AbstractContextManager</code></p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>class DiskCacheController(AbstractContextManager):\n    def __init__(\n        self,\n        cache_directory: t.Union[str, Path] | None = None,\n        cache_timeout: int = 60,\n        cache_disk: t.Type[diskcache.Disk] = diskcache.Disk,\n        index: bool = True,\n    ):\n        self.cache_directory = Path(f\"{cache_directory}\")\n        self.cache_timeout = cache_timeout\n        self.cache_disk = cache_disk\n        self.create_index = index\n\n        self.cache = None\n\n    def __enter__(self) -&gt; t.Self:\n        try:\n            _cache: diskcache.Cache = diskcache.Cache(\n                directory=self.cache_directory,\n                timeout=self.cache_timeout,\n                disk=self.cache_disk,\n            )\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception getting DiskCache Cache. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n        self.cache = _cache\n\n        if self.create_index:\n            log.info(\"Creating cache index\")\n            try:\n                self.manage_cache_tag_index(\"create\")\n            except Exception as exc:\n                msg = Exception(\n                    f\"Unhandled exception creating cache index. Details: {exc}\"\n                )\n                log.error(msg)\n\n                raise exc\n\n        return self\n\n    def __exit__(self, exc_type, exc_val, traceback):\n        if self.cache:\n            self.cache.close()\n\n        if exc_val:\n            log.error(f\"({exc_type}): {exc_val}\")\n\n        if traceback:\n            raise traceback\n\n    def manage_cache_tag_index(self, operation: str = \"create\") -&gt; None:\n        \"\"\"Create or delete a cache index.\n\n        Params:\n            operation (str): The operation to perform on the cache's tag index.\n                Options: [\"create\", \"delete\"]\n        \"\"\"\n        valid_operations: list[str] = [\"create\", \"delete\"]\n\n        validators.validate_cache(cache=self.cache)\n\n        if not operation:\n            raise Exception(f\"Operation cannot be None.\")\n\n        try:\n            match operation:\n                case \"create\":\n                    if self.cache.tag_index == 0:\n                        self.cache.create_tag_index()\n                    else:\n                        pass\n\n                case \"delete\":\n                    if self.cache.tag_index == 1:\n                        self.cache.drop_tag_index()\n                    else:\n                        pass\n\n                case _:\n                    raise ValueError(\n                        f\"Invalid operation: {operation}. Must be one of {valid_operations}\"\n                    )\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception configuring tag_index. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def clear(self) -&gt; bool:\n        \"\"\"Clear the entire cache.\n\n        Returns:\n            (bool): `True` if clearing cache successful\n            (bool): `False` if clearing the cache not successful\n\n        \"\"\"\n        validators.validate_cache(self.cache)\n\n        try:\n            with self.cache as ref:\n                ref.clear()\n\n                return True\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception clearing cache at {self.cache.directory}. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def check_key_exists(self, key: t.Union[str, int, tuple, frozenset] = None) -&gt; bool:\n        \"\"\"Check if a key exists in a cache.\n\n        Params:\n            key (str): The cache key to search for\n\n        Returns:\n            (bool): `True` if cache key found\n            (bool): `False` if cache key not found\n\n        \"\"\"\n        ## Key validation\n        validators.validate_key(key=key)\n        validators.validate_cache(cache=self.cache)\n\n        ## Check if key exists in cache\n        if key in self.cache:\n            return True\n        else:\n            return False\n\n    def set(\n        self,\n        key: t.Union[str, int, tuple, frozenset] = None,\n        val: t.Union[str, bytes, float, int, list, dict] = None,\n        expire: int = None,\n        read: bool = False,\n        tag: t.Union[str, int, float, bytes] = None,\n        retry: bool = False,\n    ) -&gt; None:\n        \"\"\"Set a key value pair in the cache.\n\n        Params:\n            key (str): The key to store the value under in the cache\n            val (str): The value to store in the cache\n            expire (int): Time (in seconds) before value expires\n            read (bool): If `True`, read value as a file-like object\n            tag (str): Applies a tag to the cached value\n            retry (bool): If `True`, retry setting cache key if first attempt fails\n        \"\"\"\n        validators.validate_key(key)\n        validators.validate_val(val)\n        validators.validate_expire(expire, none_ok=True)\n        validators.validate_read(read, none_ok=True)\n        validators.validate_tag(tag=tag, none_ok=True)\n        validators.validate_retry(retry=retry, none_ok=True)\n        validators.validate_cache(cache=self.cache)\n\n        try:\n            with self.cache as ref:\n                ref.set(\n                    key=key, value=val, expire=expire, read=read, tag=tag, retry=retry\n                )\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception setting key/value pair for key: [{key}]. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def get(\n        self, key: t.Union[str, int, tuple, frozenset] = None, tags: list[str] = None\n    ):\n        \"\"\"Search for a key in a given cache.\n\n        Pass a diskcache.Cache object for cache, and a key (and optionally a list of tags).\n        Function will search the cache and return a value if found, or a structured\n        error dict describing the lack of key.\n\n        Params:\n            key (str): The key to search the cache for\n            tags (list[str]): List of tags to search the cache for\n        \"\"\"\n        validators.validate_key(key)\n        validators.validate_cache(self.cache)\n        validators.validate_tags(tags)\n\n        try:\n            if self.check_key_exists(key=key):\n                try:\n                    with self.cache as ref:\n                        _val = ref.get(key=key)\n\n                        return _val\n\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Unhandled exception retrieving value of key [{key}]. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n            else:\n                # return {\n                #     \"error\": \"Key not found in cache\",\n                #     \"details\": {\"key\": key, \"cache_dir\": self.cache.directory},\n                # }\n\n                return\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception checking cache for key '{key}'. Details: {exc}\"\n            )\n            log.error(msg)\n\n            return None\n\n    def set_expire(\n        self, key: t.Union[str, int, tuple, frozenset] = None, expire: int = None\n    ) -&gt; dict[str, str] | None:\n        \"\"\"Set an expiration timeout (in seconds).\n\n        Params:\n            key (str): Name of the key to set expiration on. Must already exist in the cache.\n            expire (int): Time (in seconds) to wait before expiring cached value.\n        \"\"\"\n        validators.validate_key(key)\n        validators.validate_cache(self.cache)\n        validators.validate_expire(expire)\n\n        if not self.check_key_exists(key=key):\n            log.warning(\n                f\"Cache item with key [{key}] does not exist in cache at {self.cache.directory}/\"\n            )\n\n            return None\n\n        try:\n            with self.cache as ref:\n                ref.touch(key, expire=expire)\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception setting expiration of {expire} on key [{key}] in cache at {self.cache.directory}/. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def delete(\n        self, key: t.Union[str, int, tuple, frozenset] = None, tag: str = None\n    ) -&gt; tuple:\n        \"\"\"Delete a cached value.\n\n        If a tag is provided, only keys that also have that tag will be deleted.\n\n        Params:\n            key (str|int): Name of key in cache.\n        \"\"\"\n        validators.validate_key(key)\n        validators.validate_cache(self.cache)\n        validators.validate_tag(tag)\n\n        try:\n            with self.cache as ref:\n                _delete = ref.pop(key=key, tag=tag)\n\n                return _delete\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception deleting key {key} from cache at {self.cache.directory}/. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def cull(self, retry: bool = False) -&gt; bool:\n        \"\"\"Cull items from cache to free space.\n\n        Params:\n            retry (bool): When `True`, cull will be retried if a database timeout occurs.\n\n        Returns:\n            (bool): `True` if culling successful, otherwise `False`.\n\n        \"\"\"\n        try:\n            self.cache.cull(retry=retry)\n\n            return True\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception culling cache. Details: {exc}\")\n            log.error(msg)\n\n            return False\n\n    def get_cache_size(self) -&gt; int:\n        \"\"\"Get a dict describing the size of the cache, in bytes.\n\n        Returns:\n            (int): An integer representing the cache's size in bytes.`\n\n        \"\"\"\n        validators.validate_cache(cache=self.cache)\n\n        try:\n            cache_size: int = self.cache.volume()\n\n            # return {\"unit\": \"bytes\", \"size\": cache_size}\n\n            return cache_size\n\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception getting cache size. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n    def healthcheck(self) -&gt; list[warnings.WarningMessage]:\n        \"\"\"Run checks on Cache instance.\n\n        Returns:\n            (list[warning.WarningMessage]): A list of Diskcache `WarningMessage` objects.\n\n        \"\"\"\n        validators.validate_cache(cache=self.cache)\n\n        try:\n            warnings = self.cache.check()\n\n            return warnings\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception checking cache for warnings. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/controllers/__init__/#red_utils.ext.diskcache_utils.controllers.DiskCacheController.check_key_exists","title":"<code>check_key_exists(key=None)</code>","text":"<p>Check if a key exists in a cache.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The cache key to search for</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if cache key found</p> <code>bool</code> <p><code>False</code> if cache key not found</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def check_key_exists(self, key: t.Union[str, int, tuple, frozenset] = None) -&gt; bool:\n    \"\"\"Check if a key exists in a cache.\n\n    Params:\n        key (str): The cache key to search for\n\n    Returns:\n        (bool): `True` if cache key found\n        (bool): `False` if cache key not found\n\n    \"\"\"\n    ## Key validation\n    validators.validate_key(key=key)\n    validators.validate_cache(cache=self.cache)\n\n    ## Check if key exists in cache\n    if key in self.cache:\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/controllers/__init__/#red_utils.ext.diskcache_utils.controllers.DiskCacheController.clear","title":"<code>clear()</code>","text":"<p>Clear the entire cache.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if clearing cache successful</p> <code>bool</code> <p><code>False</code> if clearing the cache not successful</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def clear(self) -&gt; bool:\n    \"\"\"Clear the entire cache.\n\n    Returns:\n        (bool): `True` if clearing cache successful\n        (bool): `False` if clearing the cache not successful\n\n    \"\"\"\n    validators.validate_cache(self.cache)\n\n    try:\n        with self.cache as ref:\n            ref.clear()\n\n            return True\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception clearing cache at {self.cache.directory}. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/controllers/__init__/#red_utils.ext.diskcache_utils.controllers.DiskCacheController.cull","title":"<code>cull(retry=False)</code>","text":"<p>Cull items from cache to free space.</p> <p>Parameters:</p> Name Type Description Default <code>retry</code> <code>bool</code> <p>When <code>True</code>, cull will be retried if a database timeout occurs.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if culling successful, otherwise <code>False</code>.</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def cull(self, retry: bool = False) -&gt; bool:\n    \"\"\"Cull items from cache to free space.\n\n    Params:\n        retry (bool): When `True`, cull will be retried if a database timeout occurs.\n\n    Returns:\n        (bool): `True` if culling successful, otherwise `False`.\n\n    \"\"\"\n    try:\n        self.cache.cull(retry=retry)\n\n        return True\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception culling cache. Details: {exc}\")\n        log.error(msg)\n\n        return False\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/controllers/__init__/#red_utils.ext.diskcache_utils.controllers.DiskCacheController.delete","title":"<code>delete(key=None, tag=None)</code>","text":"<p>Delete a cached value.</p> <p>If a tag is provided, only keys that also have that tag will be deleted.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str | int</code> <p>Name of key in cache.</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def delete(\n    self, key: t.Union[str, int, tuple, frozenset] = None, tag: str = None\n) -&gt; tuple:\n    \"\"\"Delete a cached value.\n\n    If a tag is provided, only keys that also have that tag will be deleted.\n\n    Params:\n        key (str|int): Name of key in cache.\n    \"\"\"\n    validators.validate_key(key)\n    validators.validate_cache(self.cache)\n    validators.validate_tag(tag)\n\n    try:\n        with self.cache as ref:\n            _delete = ref.pop(key=key, tag=tag)\n\n            return _delete\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception deleting key {key} from cache at {self.cache.directory}/. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/controllers/__init__/#red_utils.ext.diskcache_utils.controllers.DiskCacheController.get","title":"<code>get(key=None, tags=None)</code>","text":"<p>Search for a key in a given cache.</p> <p>Pass a diskcache.Cache object for cache, and a key (and optionally a list of tags). Function will search the cache and return a value if found, or a structured error dict describing the lack of key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to search the cache for</p> <code>None</code> <code>tags</code> <code>list[str]</code> <p>List of tags to search the cache for</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def get(\n    self, key: t.Union[str, int, tuple, frozenset] = None, tags: list[str] = None\n):\n    \"\"\"Search for a key in a given cache.\n\n    Pass a diskcache.Cache object for cache, and a key (and optionally a list of tags).\n    Function will search the cache and return a value if found, or a structured\n    error dict describing the lack of key.\n\n    Params:\n        key (str): The key to search the cache for\n        tags (list[str]): List of tags to search the cache for\n    \"\"\"\n    validators.validate_key(key)\n    validators.validate_cache(self.cache)\n    validators.validate_tags(tags)\n\n    try:\n        if self.check_key_exists(key=key):\n            try:\n                with self.cache as ref:\n                    _val = ref.get(key=key)\n\n                    return _val\n\n            except Exception as exc:\n                msg = Exception(\n                    f\"Unhandled exception retrieving value of key [{key}]. Details: {exc}\"\n                )\n                log.error(msg)\n\n                raise exc\n\n        else:\n            # return {\n            #     \"error\": \"Key not found in cache\",\n            #     \"details\": {\"key\": key, \"cache_dir\": self.cache.directory},\n            # }\n\n            return\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception checking cache for key '{key}'. Details: {exc}\"\n        )\n        log.error(msg)\n\n        return None\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/controllers/__init__/#red_utils.ext.diskcache_utils.controllers.DiskCacheController.get_cache_size","title":"<code>get_cache_size()</code>","text":"<p>Get a dict describing the size of the cache, in bytes.</p> <p>Returns:</p> Type Description <code>int</code> <p>An integer representing the cache's size in bytes.`</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def get_cache_size(self) -&gt; int:\n    \"\"\"Get a dict describing the size of the cache, in bytes.\n\n    Returns:\n        (int): An integer representing the cache's size in bytes.`\n\n    \"\"\"\n    validators.validate_cache(cache=self.cache)\n\n    try:\n        cache_size: int = self.cache.volume()\n\n        # return {\"unit\": \"bytes\", \"size\": cache_size}\n\n        return cache_size\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception getting cache size. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/controllers/__init__/#red_utils.ext.diskcache_utils.controllers.DiskCacheController.healthcheck","title":"<code>healthcheck()</code>","text":"<p>Run checks on Cache instance.</p> <p>Returns:</p> Type Description <code>list[WarningMessage]</code> <p>A list of Diskcache <code>WarningMessage</code> objects.</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def healthcheck(self) -&gt; list[warnings.WarningMessage]:\n    \"\"\"Run checks on Cache instance.\n\n    Returns:\n        (list[warning.WarningMessage]): A list of Diskcache `WarningMessage` objects.\n\n    \"\"\"\n    validators.validate_cache(cache=self.cache)\n\n    try:\n        warnings = self.cache.check()\n\n        return warnings\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception checking cache for warnings. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/controllers/__init__/#red_utils.ext.diskcache_utils.controllers.DiskCacheController.manage_cache_tag_index","title":"<code>manage_cache_tag_index(operation='create')</code>","text":"<p>Create or delete a cache index.</p> <p>Parameters:</p> Name Type Description Default <code>operation</code> <code>str</code> <p>The operation to perform on the cache's tag index. Options: [\"create\", \"delete\"]</p> <code>'create'</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def manage_cache_tag_index(self, operation: str = \"create\") -&gt; None:\n    \"\"\"Create or delete a cache index.\n\n    Params:\n        operation (str): The operation to perform on the cache's tag index.\n            Options: [\"create\", \"delete\"]\n    \"\"\"\n    valid_operations: list[str] = [\"create\", \"delete\"]\n\n    validators.validate_cache(cache=self.cache)\n\n    if not operation:\n        raise Exception(f\"Operation cannot be None.\")\n\n    try:\n        match operation:\n            case \"create\":\n                if self.cache.tag_index == 0:\n                    self.cache.create_tag_index()\n                else:\n                    pass\n\n            case \"delete\":\n                if self.cache.tag_index == 1:\n                    self.cache.drop_tag_index()\n                else:\n                    pass\n\n            case _:\n                raise ValueError(\n                    f\"Invalid operation: {operation}. Must be one of {valid_operations}\"\n                )\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception configuring tag_index. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/controllers/__init__/#red_utils.ext.diskcache_utils.controllers.DiskCacheController.set","title":"<code>set(key=None, val=None, expire=None, read=False, tag=None, retry=False)</code>","text":"<p>Set a key value pair in the cache.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to store the value under in the cache</p> <code>None</code> <code>val</code> <code>str</code> <p>The value to store in the cache</p> <code>None</code> <code>expire</code> <code>int</code> <p>Time (in seconds) before value expires</p> <code>None</code> <code>read</code> <code>bool</code> <p>If <code>True</code>, read value as a file-like object</p> <code>False</code> <code>tag</code> <code>str</code> <p>Applies a tag to the cached value</p> <code>None</code> <code>retry</code> <code>bool</code> <p>If <code>True</code>, retry setting cache key if first attempt fails</p> <code>False</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def set(\n    self,\n    key: t.Union[str, int, tuple, frozenset] = None,\n    val: t.Union[str, bytes, float, int, list, dict] = None,\n    expire: int = None,\n    read: bool = False,\n    tag: t.Union[str, int, float, bytes] = None,\n    retry: bool = False,\n) -&gt; None:\n    \"\"\"Set a key value pair in the cache.\n\n    Params:\n        key (str): The key to store the value under in the cache\n        val (str): The value to store in the cache\n        expire (int): Time (in seconds) before value expires\n        read (bool): If `True`, read value as a file-like object\n        tag (str): Applies a tag to the cached value\n        retry (bool): If `True`, retry setting cache key if first attempt fails\n    \"\"\"\n    validators.validate_key(key)\n    validators.validate_val(val)\n    validators.validate_expire(expire, none_ok=True)\n    validators.validate_read(read, none_ok=True)\n    validators.validate_tag(tag=tag, none_ok=True)\n    validators.validate_retry(retry=retry, none_ok=True)\n    validators.validate_cache(cache=self.cache)\n\n    try:\n        with self.cache as ref:\n            ref.set(\n                key=key, value=val, expire=expire, read=read, tag=tag, retry=retry\n            )\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception setting key/value pair for key: [{key}]. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/controllers/__init__/#red_utils.ext.diskcache_utils.controllers.DiskCacheController.set_expire","title":"<code>set_expire(key=None, expire=None)</code>","text":"<p>Set an expiration timeout (in seconds).</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name of the key to set expiration on. Must already exist in the cache.</p> <code>None</code> <code>expire</code> <code>int</code> <p>Time (in seconds) to wait before expiring cached value.</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def set_expire(\n    self, key: t.Union[str, int, tuple, frozenset] = None, expire: int = None\n) -&gt; dict[str, str] | None:\n    \"\"\"Set an expiration timeout (in seconds).\n\n    Params:\n        key (str): Name of the key to set expiration on. Must already exist in the cache.\n        expire (int): Time (in seconds) to wait before expiring cached value.\n    \"\"\"\n    validators.validate_key(key)\n    validators.validate_cache(self.cache)\n    validators.validate_expire(expire)\n\n    if not self.check_key_exists(key=key):\n        log.warning(\n            f\"Cache item with key [{key}] does not exist in cache at {self.cache.directory}/\"\n        )\n\n        return None\n\n    try:\n        with self.cache as ref:\n            ref.touch(key, expire=expire)\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception setting expiration of {expire} on key [{key}] in cache at {self.cache.directory}/. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/controllers/_controller/","title":"_controller","text":""},{"location":"reference/red_utils/ext/diskcache_utils/controllers/_controller/#red_utils.ext.diskcache_utils.controllers._controller.DiskCacheController","title":"<code>DiskCacheController</code>","text":"<p>               Bases: <code>AbstractContextManager</code></p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>class DiskCacheController(AbstractContextManager):\n    def __init__(\n        self,\n        cache_directory: t.Union[str, Path] | None = None,\n        cache_timeout: int = 60,\n        cache_disk: t.Type[diskcache.Disk] = diskcache.Disk,\n        index: bool = True,\n    ):\n        self.cache_directory = Path(f\"{cache_directory}\")\n        self.cache_timeout = cache_timeout\n        self.cache_disk = cache_disk\n        self.create_index = index\n\n        self.cache = None\n\n    def __enter__(self) -&gt; t.Self:\n        try:\n            _cache: diskcache.Cache = diskcache.Cache(\n                directory=self.cache_directory,\n                timeout=self.cache_timeout,\n                disk=self.cache_disk,\n            )\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception getting DiskCache Cache. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n        self.cache = _cache\n\n        if self.create_index:\n            log.info(\"Creating cache index\")\n            try:\n                self.manage_cache_tag_index(\"create\")\n            except Exception as exc:\n                msg = Exception(\n                    f\"Unhandled exception creating cache index. Details: {exc}\"\n                )\n                log.error(msg)\n\n                raise exc\n\n        return self\n\n    def __exit__(self, exc_type, exc_val, traceback):\n        if self.cache:\n            self.cache.close()\n\n        if exc_val:\n            log.error(f\"({exc_type}): {exc_val}\")\n\n        if traceback:\n            raise traceback\n\n    def manage_cache_tag_index(self, operation: str = \"create\") -&gt; None:\n        \"\"\"Create or delete a cache index.\n\n        Params:\n            operation (str): The operation to perform on the cache's tag index.\n                Options: [\"create\", \"delete\"]\n        \"\"\"\n        valid_operations: list[str] = [\"create\", \"delete\"]\n\n        validators.validate_cache(cache=self.cache)\n\n        if not operation:\n            raise Exception(f\"Operation cannot be None.\")\n\n        try:\n            match operation:\n                case \"create\":\n                    if self.cache.tag_index == 0:\n                        self.cache.create_tag_index()\n                    else:\n                        pass\n\n                case \"delete\":\n                    if self.cache.tag_index == 1:\n                        self.cache.drop_tag_index()\n                    else:\n                        pass\n\n                case _:\n                    raise ValueError(\n                        f\"Invalid operation: {operation}. Must be one of {valid_operations}\"\n                    )\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception configuring tag_index. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def clear(self) -&gt; bool:\n        \"\"\"Clear the entire cache.\n\n        Returns:\n            (bool): `True` if clearing cache successful\n            (bool): `False` if clearing the cache not successful\n\n        \"\"\"\n        validators.validate_cache(self.cache)\n\n        try:\n            with self.cache as ref:\n                ref.clear()\n\n                return True\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception clearing cache at {self.cache.directory}. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def check_key_exists(self, key: t.Union[str, int, tuple, frozenset] = None) -&gt; bool:\n        \"\"\"Check if a key exists in a cache.\n\n        Params:\n            key (str): The cache key to search for\n\n        Returns:\n            (bool): `True` if cache key found\n            (bool): `False` if cache key not found\n\n        \"\"\"\n        ## Key validation\n        validators.validate_key(key=key)\n        validators.validate_cache(cache=self.cache)\n\n        ## Check if key exists in cache\n        if key in self.cache:\n            return True\n        else:\n            return False\n\n    def set(\n        self,\n        key: t.Union[str, int, tuple, frozenset] = None,\n        val: t.Union[str, bytes, float, int, list, dict] = None,\n        expire: int = None,\n        read: bool = False,\n        tag: t.Union[str, int, float, bytes] = None,\n        retry: bool = False,\n    ) -&gt; None:\n        \"\"\"Set a key value pair in the cache.\n\n        Params:\n            key (str): The key to store the value under in the cache\n            val (str): The value to store in the cache\n            expire (int): Time (in seconds) before value expires\n            read (bool): If `True`, read value as a file-like object\n            tag (str): Applies a tag to the cached value\n            retry (bool): If `True`, retry setting cache key if first attempt fails\n        \"\"\"\n        validators.validate_key(key)\n        validators.validate_val(val)\n        validators.validate_expire(expire, none_ok=True)\n        validators.validate_read(read, none_ok=True)\n        validators.validate_tag(tag=tag, none_ok=True)\n        validators.validate_retry(retry=retry, none_ok=True)\n        validators.validate_cache(cache=self.cache)\n\n        try:\n            with self.cache as ref:\n                ref.set(\n                    key=key, value=val, expire=expire, read=read, tag=tag, retry=retry\n                )\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception setting key/value pair for key: [{key}]. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def get(\n        self, key: t.Union[str, int, tuple, frozenset] = None, tags: list[str] = None\n    ):\n        \"\"\"Search for a key in a given cache.\n\n        Pass a diskcache.Cache object for cache, and a key (and optionally a list of tags).\n        Function will search the cache and return a value if found, or a structured\n        error dict describing the lack of key.\n\n        Params:\n            key (str): The key to search the cache for\n            tags (list[str]): List of tags to search the cache for\n        \"\"\"\n        validators.validate_key(key)\n        validators.validate_cache(self.cache)\n        validators.validate_tags(tags)\n\n        try:\n            if self.check_key_exists(key=key):\n                try:\n                    with self.cache as ref:\n                        _val = ref.get(key=key)\n\n                        return _val\n\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Unhandled exception retrieving value of key [{key}]. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n            else:\n                # return {\n                #     \"error\": \"Key not found in cache\",\n                #     \"details\": {\"key\": key, \"cache_dir\": self.cache.directory},\n                # }\n\n                return\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception checking cache for key '{key}'. Details: {exc}\"\n            )\n            log.error(msg)\n\n            return None\n\n    def set_expire(\n        self, key: t.Union[str, int, tuple, frozenset] = None, expire: int = None\n    ) -&gt; dict[str, str] | None:\n        \"\"\"Set an expiration timeout (in seconds).\n\n        Params:\n            key (str): Name of the key to set expiration on. Must already exist in the cache.\n            expire (int): Time (in seconds) to wait before expiring cached value.\n        \"\"\"\n        validators.validate_key(key)\n        validators.validate_cache(self.cache)\n        validators.validate_expire(expire)\n\n        if not self.check_key_exists(key=key):\n            log.warning(\n                f\"Cache item with key [{key}] does not exist in cache at {self.cache.directory}/\"\n            )\n\n            return None\n\n        try:\n            with self.cache as ref:\n                ref.touch(key, expire=expire)\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception setting expiration of {expire} on key [{key}] in cache at {self.cache.directory}/. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def delete(\n        self, key: t.Union[str, int, tuple, frozenset] = None, tag: str = None\n    ) -&gt; tuple:\n        \"\"\"Delete a cached value.\n\n        If a tag is provided, only keys that also have that tag will be deleted.\n\n        Params:\n            key (str|int): Name of key in cache.\n        \"\"\"\n        validators.validate_key(key)\n        validators.validate_cache(self.cache)\n        validators.validate_tag(tag)\n\n        try:\n            with self.cache as ref:\n                _delete = ref.pop(key=key, tag=tag)\n\n                return _delete\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception deleting key {key} from cache at {self.cache.directory}/. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def cull(self, retry: bool = False) -&gt; bool:\n        \"\"\"Cull items from cache to free space.\n\n        Params:\n            retry (bool): When `True`, cull will be retried if a database timeout occurs.\n\n        Returns:\n            (bool): `True` if culling successful, otherwise `False`.\n\n        \"\"\"\n        try:\n            self.cache.cull(retry=retry)\n\n            return True\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception culling cache. Details: {exc}\")\n            log.error(msg)\n\n            return False\n\n    def get_cache_size(self) -&gt; int:\n        \"\"\"Get a dict describing the size of the cache, in bytes.\n\n        Returns:\n            (int): An integer representing the cache's size in bytes.`\n\n        \"\"\"\n        validators.validate_cache(cache=self.cache)\n\n        try:\n            cache_size: int = self.cache.volume()\n\n            # return {\"unit\": \"bytes\", \"size\": cache_size}\n\n            return cache_size\n\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception getting cache size. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n    def healthcheck(self) -&gt; list[warnings.WarningMessage]:\n        \"\"\"Run checks on Cache instance.\n\n        Returns:\n            (list[warning.WarningMessage]): A list of Diskcache `WarningMessage` objects.\n\n        \"\"\"\n        validators.validate_cache(cache=self.cache)\n\n        try:\n            warnings = self.cache.check()\n\n            return warnings\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception checking cache for warnings. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/controllers/_controller/#red_utils.ext.diskcache_utils.controllers._controller.DiskCacheController.check_key_exists","title":"<code>check_key_exists(key=None)</code>","text":"<p>Check if a key exists in a cache.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The cache key to search for</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if cache key found</p> <code>bool</code> <p><code>False</code> if cache key not found</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def check_key_exists(self, key: t.Union[str, int, tuple, frozenset] = None) -&gt; bool:\n    \"\"\"Check if a key exists in a cache.\n\n    Params:\n        key (str): The cache key to search for\n\n    Returns:\n        (bool): `True` if cache key found\n        (bool): `False` if cache key not found\n\n    \"\"\"\n    ## Key validation\n    validators.validate_key(key=key)\n    validators.validate_cache(cache=self.cache)\n\n    ## Check if key exists in cache\n    if key in self.cache:\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/controllers/_controller/#red_utils.ext.diskcache_utils.controllers._controller.DiskCacheController.clear","title":"<code>clear()</code>","text":"<p>Clear the entire cache.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if clearing cache successful</p> <code>bool</code> <p><code>False</code> if clearing the cache not successful</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def clear(self) -&gt; bool:\n    \"\"\"Clear the entire cache.\n\n    Returns:\n        (bool): `True` if clearing cache successful\n        (bool): `False` if clearing the cache not successful\n\n    \"\"\"\n    validators.validate_cache(self.cache)\n\n    try:\n        with self.cache as ref:\n            ref.clear()\n\n            return True\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception clearing cache at {self.cache.directory}. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/controllers/_controller/#red_utils.ext.diskcache_utils.controllers._controller.DiskCacheController.cull","title":"<code>cull(retry=False)</code>","text":"<p>Cull items from cache to free space.</p> <p>Parameters:</p> Name Type Description Default <code>retry</code> <code>bool</code> <p>When <code>True</code>, cull will be retried if a database timeout occurs.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if culling successful, otherwise <code>False</code>.</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def cull(self, retry: bool = False) -&gt; bool:\n    \"\"\"Cull items from cache to free space.\n\n    Params:\n        retry (bool): When `True`, cull will be retried if a database timeout occurs.\n\n    Returns:\n        (bool): `True` if culling successful, otherwise `False`.\n\n    \"\"\"\n    try:\n        self.cache.cull(retry=retry)\n\n        return True\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception culling cache. Details: {exc}\")\n        log.error(msg)\n\n        return False\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/controllers/_controller/#red_utils.ext.diskcache_utils.controllers._controller.DiskCacheController.delete","title":"<code>delete(key=None, tag=None)</code>","text":"<p>Delete a cached value.</p> <p>If a tag is provided, only keys that also have that tag will be deleted.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str | int</code> <p>Name of key in cache.</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def delete(\n    self, key: t.Union[str, int, tuple, frozenset] = None, tag: str = None\n) -&gt; tuple:\n    \"\"\"Delete a cached value.\n\n    If a tag is provided, only keys that also have that tag will be deleted.\n\n    Params:\n        key (str|int): Name of key in cache.\n    \"\"\"\n    validators.validate_key(key)\n    validators.validate_cache(self.cache)\n    validators.validate_tag(tag)\n\n    try:\n        with self.cache as ref:\n            _delete = ref.pop(key=key, tag=tag)\n\n            return _delete\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception deleting key {key} from cache at {self.cache.directory}/. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/controllers/_controller/#red_utils.ext.diskcache_utils.controllers._controller.DiskCacheController.get","title":"<code>get(key=None, tags=None)</code>","text":"<p>Search for a key in a given cache.</p> <p>Pass a diskcache.Cache object for cache, and a key (and optionally a list of tags). Function will search the cache and return a value if found, or a structured error dict describing the lack of key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to search the cache for</p> <code>None</code> <code>tags</code> <code>list[str]</code> <p>List of tags to search the cache for</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def get(\n    self, key: t.Union[str, int, tuple, frozenset] = None, tags: list[str] = None\n):\n    \"\"\"Search for a key in a given cache.\n\n    Pass a diskcache.Cache object for cache, and a key (and optionally a list of tags).\n    Function will search the cache and return a value if found, or a structured\n    error dict describing the lack of key.\n\n    Params:\n        key (str): The key to search the cache for\n        tags (list[str]): List of tags to search the cache for\n    \"\"\"\n    validators.validate_key(key)\n    validators.validate_cache(self.cache)\n    validators.validate_tags(tags)\n\n    try:\n        if self.check_key_exists(key=key):\n            try:\n                with self.cache as ref:\n                    _val = ref.get(key=key)\n\n                    return _val\n\n            except Exception as exc:\n                msg = Exception(\n                    f\"Unhandled exception retrieving value of key [{key}]. Details: {exc}\"\n                )\n                log.error(msg)\n\n                raise exc\n\n        else:\n            # return {\n            #     \"error\": \"Key not found in cache\",\n            #     \"details\": {\"key\": key, \"cache_dir\": self.cache.directory},\n            # }\n\n            return\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception checking cache for key '{key}'. Details: {exc}\"\n        )\n        log.error(msg)\n\n        return None\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/controllers/_controller/#red_utils.ext.diskcache_utils.controllers._controller.DiskCacheController.get_cache_size","title":"<code>get_cache_size()</code>","text":"<p>Get a dict describing the size of the cache, in bytes.</p> <p>Returns:</p> Type Description <code>int</code> <p>An integer representing the cache's size in bytes.`</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def get_cache_size(self) -&gt; int:\n    \"\"\"Get a dict describing the size of the cache, in bytes.\n\n    Returns:\n        (int): An integer representing the cache's size in bytes.`\n\n    \"\"\"\n    validators.validate_cache(cache=self.cache)\n\n    try:\n        cache_size: int = self.cache.volume()\n\n        # return {\"unit\": \"bytes\", \"size\": cache_size}\n\n        return cache_size\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception getting cache size. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/controllers/_controller/#red_utils.ext.diskcache_utils.controllers._controller.DiskCacheController.healthcheck","title":"<code>healthcheck()</code>","text":"<p>Run checks on Cache instance.</p> <p>Returns:</p> Type Description <code>list[WarningMessage]</code> <p>A list of Diskcache <code>WarningMessage</code> objects.</p> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def healthcheck(self) -&gt; list[warnings.WarningMessage]:\n    \"\"\"Run checks on Cache instance.\n\n    Returns:\n        (list[warning.WarningMessage]): A list of Diskcache `WarningMessage` objects.\n\n    \"\"\"\n    validators.validate_cache(cache=self.cache)\n\n    try:\n        warnings = self.cache.check()\n\n        return warnings\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception checking cache for warnings. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/controllers/_controller/#red_utils.ext.diskcache_utils.controllers._controller.DiskCacheController.manage_cache_tag_index","title":"<code>manage_cache_tag_index(operation='create')</code>","text":"<p>Create or delete a cache index.</p> <p>Parameters:</p> Name Type Description Default <code>operation</code> <code>str</code> <p>The operation to perform on the cache's tag index. Options: [\"create\", \"delete\"]</p> <code>'create'</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def manage_cache_tag_index(self, operation: str = \"create\") -&gt; None:\n    \"\"\"Create or delete a cache index.\n\n    Params:\n        operation (str): The operation to perform on the cache's tag index.\n            Options: [\"create\", \"delete\"]\n    \"\"\"\n    valid_operations: list[str] = [\"create\", \"delete\"]\n\n    validators.validate_cache(cache=self.cache)\n\n    if not operation:\n        raise Exception(f\"Operation cannot be None.\")\n\n    try:\n        match operation:\n            case \"create\":\n                if self.cache.tag_index == 0:\n                    self.cache.create_tag_index()\n                else:\n                    pass\n\n            case \"delete\":\n                if self.cache.tag_index == 1:\n                    self.cache.drop_tag_index()\n                else:\n                    pass\n\n            case _:\n                raise ValueError(\n                    f\"Invalid operation: {operation}. Must be one of {valid_operations}\"\n                )\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception configuring tag_index. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/controllers/_controller/#red_utils.ext.diskcache_utils.controllers._controller.DiskCacheController.set","title":"<code>set(key=None, val=None, expire=None, read=False, tag=None, retry=False)</code>","text":"<p>Set a key value pair in the cache.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to store the value under in the cache</p> <code>None</code> <code>val</code> <code>str</code> <p>The value to store in the cache</p> <code>None</code> <code>expire</code> <code>int</code> <p>Time (in seconds) before value expires</p> <code>None</code> <code>read</code> <code>bool</code> <p>If <code>True</code>, read value as a file-like object</p> <code>False</code> <code>tag</code> <code>str</code> <p>Applies a tag to the cached value</p> <code>None</code> <code>retry</code> <code>bool</code> <p>If <code>True</code>, retry setting cache key if first attempt fails</p> <code>False</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def set(\n    self,\n    key: t.Union[str, int, tuple, frozenset] = None,\n    val: t.Union[str, bytes, float, int, list, dict] = None,\n    expire: int = None,\n    read: bool = False,\n    tag: t.Union[str, int, float, bytes] = None,\n    retry: bool = False,\n) -&gt; None:\n    \"\"\"Set a key value pair in the cache.\n\n    Params:\n        key (str): The key to store the value under in the cache\n        val (str): The value to store in the cache\n        expire (int): Time (in seconds) before value expires\n        read (bool): If `True`, read value as a file-like object\n        tag (str): Applies a tag to the cached value\n        retry (bool): If `True`, retry setting cache key if first attempt fails\n    \"\"\"\n    validators.validate_key(key)\n    validators.validate_val(val)\n    validators.validate_expire(expire, none_ok=True)\n    validators.validate_read(read, none_ok=True)\n    validators.validate_tag(tag=tag, none_ok=True)\n    validators.validate_retry(retry=retry, none_ok=True)\n    validators.validate_cache(cache=self.cache)\n\n    try:\n        with self.cache as ref:\n            ref.set(\n                key=key, value=val, expire=expire, read=read, tag=tag, retry=retry\n            )\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception setting key/value pair for key: [{key}]. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/diskcache_utils/controllers/_controller/#red_utils.ext.diskcache_utils.controllers._controller.DiskCacheController.set_expire","title":"<code>set_expire(key=None, expire=None)</code>","text":"<p>Set an expiration timeout (in seconds).</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name of the key to set expiration on. Must already exist in the cache.</p> <code>None</code> <code>expire</code> <code>int</code> <p>Time (in seconds) to wait before expiring cached value.</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\diskcache_utils\\controllers\\_controller.py</code> <pre><code>def set_expire(\n    self, key: t.Union[str, int, tuple, frozenset] = None, expire: int = None\n) -&gt; dict[str, str] | None:\n    \"\"\"Set an expiration timeout (in seconds).\n\n    Params:\n        key (str): Name of the key to set expiration on. Must already exist in the cache.\n        expire (int): Time (in seconds) to wait before expiring cached value.\n    \"\"\"\n    validators.validate_key(key)\n    validators.validate_cache(self.cache)\n    validators.validate_expire(expire)\n\n    if not self.check_key_exists(key=key):\n        log.warning(\n            f\"Cache item with key [{key}] does not exist in cache at {self.cache.directory}/\"\n        )\n\n        return None\n\n    try:\n        with self.cache as ref:\n            ref.touch(key, expire=expire)\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception setting expiration of {expire} on key [{key}] in cache at {self.cache.directory}/. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/fastapi_utils/__init__/","title":"fastapi_utils","text":""},{"location":"reference/red_utils/ext/fastapi_utils/__init__/#red_utils.ext.fastapi_utils.fix_api_docs","title":"<code>fix_api_docs(app=None)</code>","text":"<p>Fix error loading /docs when a root_path is set.</p> <p>Call after declaring an app with a root_path set, for example:     app = FastAPI(root_path=\"/some/path\")     fix_api_docs(app)</p> <p>When a root_path is declared, the default /docs URL breaks, and returns an error:     Fetch error     Not Found /api/v1/openapi.json</p> Source code in <code>src\\red_utils\\ext\\fastapi_utils\\operations.py</code> <pre><code>def fix_api_docs(app: FastAPI = None):\n    \"\"\"Fix error loading /docs when a root_path is set.\n\n    Call after declaring an app with a root_path set, for example:\n        app = FastAPI(root_path=\"/some/path\")\n        fix_api_docs(app)\n\n    When a root_path is declared, the default /docs URL breaks, and returns\n    an error:\n        Fetch error\n        Not Found /api/v1/openapi.json\n    \"\"\"\n    if not app:\n        raise ValueError(\"Missing a FastAPI app with a root_path var declared\")\n\n    if not isinstance(app, FastAPI):\n        raise TypeError(\n            f\"Invalid type for FastAPI app: ({type(app)}). Value must be of type FastAPI.\"\n        )\n\n    @app.get(app.root_path + \"/openapi.json\", include_in_schema=False)\n    def custom_swagger_ui_html():\n        return app.openapi()\n</code></pre>"},{"location":"reference/red_utils/ext/fastapi_utils/__init__/#red_utils.ext.fastapi_utils.get_app","title":"<code>get_app(debug=False, cors=True, root_path='/', title='DEFAULT_TITLE', description='DEFAULT_DESCRIPTION', version='0.0.0', openapi_url=default_openapi_url, openapi_tags=tags_metadata, routers=None)</code>","text":"<p>Generate a FastAPI app and return.</p> Source code in <code>src\\red_utils\\ext\\fastapi_utils\\operations.py</code> <pre><code>def get_app(\n    debug: bool = False,\n    cors: bool = True,\n    root_path: str = \"/\",\n    title: str = \"DEFAULT_TITLE\",\n    description: str = \"DEFAULT_DESCRIPTION\",\n    version: str = \"0.0.0\",\n    openapi_url: str = default_openapi_url,\n    openapi_tags: list = tags_metadata,\n    routers: list[APIRouter] = None,\n) -&gt; FastAPI:\n    \"\"\"Generate a FastAPI app and return.\"\"\"\n    for _var in [root_path, title, description, version, openapi_url]:\n        is_str(input=_var)\n\n    validate_openapi_tags(openapi_tags)\n\n    if routers:\n        for r in routers:\n            validate_router(r, none_ok=True)\n\n    try:\n        app: FastAPI = FastAPI(\n            root_path=root_path,\n            title=title,\n            description=description,\n            version=version,\n            openapi_url=openapi_url,\n            openapi_tags=openapi_tags,\n            debug=debug,\n        )\n\n        if cors:\n            add_cors_middleware(app=app)\n\n        if routers:\n            for router in routers:\n                app.include_router(router)\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception creating FastAPI App. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n\n    return app\n</code></pre>"},{"location":"reference/red_utils/ext/fastapi_utils/__init__/#red_utils.ext.fastapi_utils.logging_dependency","title":"<code>logging_dependency(request)</code>  <code>async</code>","text":"<p>https://stackoverflow.com/a/63413392.</p> Source code in <code>src\\red_utils\\ext\\fastapi_utils\\dependencies.py</code> <pre><code>async def logging_dependency(request: Request) -&gt; None:\n    \"\"\"https://stackoverflow.com/a/63413392.\"\"\"\n    # log.debug(f\"{request.method} {request.url}\")\n\n    _params = []\n    _headers = []\n\n    # log.debug(f\"Params:\")\n    for name, value in request.path_params.items():\n        # log.debug(f\"\\t{name}: {value}\")\n        _params.append({name: value})\n\n    # log.debug(f\"Headers:\")\n    for name, value in request.headers.items():\n        # log.debug(f\"\\t{name}: {value}\")\n        _headers.append({name: value})\n\n    req_log: dict = {\n        \"method\": request.method,\n        \"url\": request.url,\n        \"params\": _params,\n        \"headers\": _headers,\n    }\n\n    log.debug(req_log)\n</code></pre>"},{"location":"reference/red_utils/ext/fastapi_utils/__init__/#red_utils.ext.fastapi_utils.update_tags_metadata","title":"<code>update_tags_metadata(tags_metadata=tags_metadata, update_metadata=None)</code>","text":"<p>Update the global tags_metadata list with new values.</p> <p>Import this function in another app, create a new list of tags (or a single tag dict, {\"name\": ..., \"description\": ...}), then pass both the imported tags_metadata and the new list/single instance of tag objects.</p> <p>This funciton will combine them into a new tags_metadata object</p> Source code in <code>src\\red_utils\\ext\\fastapi_utils\\operations.py</code> <pre><code>def update_tags_metadata(\n    tags_metadata: list = tags_metadata,\n    update_metadata: Union[list[dict[str, str]], dict[str, str]] = None,\n):\n    \"\"\"Update the global tags_metadata list with new values.\n\n    Import this function in another app, create a new list of tags (or\n    a single tag dict, {\"name\": ..., \"description\": ...}), then pass both\n    the imported tags_metadata and the new list/single instance of tag objects.\n\n    This funciton will combine them into a new tags_metadata object\n    \"\"\"\n    if not tags_metadata:\n        raise ValueError(\"Missing value for tags_metadata\")\n\n    if not update_metadata:\n        raise ValueError(\"Missing value for update_metadata\")\n\n    if isinstance(update_metadata, list):\n        ## List of dicts was passed\n\n        # print(f\"[DEBUG] Detected list of new tags: {update_metadata}\")\n\n        tags_metadata = tags_metadata + update_metadata\n\n        return_obj = tags_metadata\n\n    elif isinstance(update_metadata, dict):\n        ## Single tag dict was passed\n\n        # print(f\"[DEBUG] Detected single dict for new tag: {update_metadata}\")\n\n        tags_metadata.append(update_metadata)\n\n        return_obj = tags_metadata\n\n    else:\n        raise ValueError(\n            \"Type of update_metadata must be one of list[dict[str,str]] or dict[str,str]\"\n        )\n\n    return return_obj\n</code></pre>"},{"location":"reference/red_utils/ext/fastapi_utils/constants/","title":"constants","text":""},{"location":"reference/red_utils/ext/fastapi_utils/dependencies/","title":"dependencies","text":""},{"location":"reference/red_utils/ext/fastapi_utils/dependencies/#red_utils.ext.fastapi_utils.dependencies.logging_dependency","title":"<code>logging_dependency(request)</code>  <code>async</code>","text":"<p>https://stackoverflow.com/a/63413392.</p> Source code in <code>src\\red_utils\\ext\\fastapi_utils\\dependencies.py</code> <pre><code>async def logging_dependency(request: Request) -&gt; None:\n    \"\"\"https://stackoverflow.com/a/63413392.\"\"\"\n    # log.debug(f\"{request.method} {request.url}\")\n\n    _params = []\n    _headers = []\n\n    # log.debug(f\"Params:\")\n    for name, value in request.path_params.items():\n        # log.debug(f\"\\t{name}: {value}\")\n        _params.append({name: value})\n\n    # log.debug(f\"Headers:\")\n    for name, value in request.headers.items():\n        # log.debug(f\"\\t{name}: {value}\")\n        _headers.append({name: value})\n\n    req_log: dict = {\n        \"method\": request.method,\n        \"url\": request.url,\n        \"params\": _params,\n        \"headers\": _headers,\n    }\n\n    log.debug(req_log)\n</code></pre>"},{"location":"reference/red_utils/ext/fastapi_utils/healthcheck/","title":"healthcheck","text":"<p>Add a health check.</p>"},{"location":"reference/red_utils/ext/fastapi_utils/healthcheck/#red_utils.ext.fastapi_utils.healthcheck.EndpointFilter","title":"<code>EndpointFilter</code>","text":"<p>               Bases: <code>Filter</code></p> <p>Filter pings to /health.</p> <p>https://stackoverflow.com/a/70810102</p> Source code in <code>src\\red_utils\\ext\\fastapi_utils\\healthcheck.py</code> <pre><code>class EndpointFilter(logging.Filter):\n    \"\"\"Filter pings to /health.\n\n    https://stackoverflow.com/a/70810102\n    \"\"\"\n\n    def filter(self, record: logging.LogRecord) -&gt; bool:\n        return record.args and len(record.args) &gt;= 3 and record.args[2] != \"/health\"\n</code></pre>"},{"location":"reference/red_utils/ext/fastapi_utils/healthcheck/#red_utils.ext.fastapi_utils.healthcheck.healthy","title":"<code>healthy()</code>  <code>async</code>","text":"<p>Respond to healthchecks.</p> <p>Endpoint does not take any parameters or request bodies.</p> <p>Response: a 200 'OK', with a response body containing 'healthy'.</p> Source code in <code>src\\red_utils\\ext\\fastapi_utils\\healthcheck.py</code> <pre><code>@router.get(\"/health\", summary=\"Healthcheck\")\nasync def healthy() -&gt; JSONResponse:\n    \"\"\"Respond to healthchecks.\n\n    Endpoint does not take any parameters or request bodies.\n\n    Response: a 200 'OK', with a response body containing 'healthy'.\n    \"\"\"\n    health: dict = jsonable_encoder({\"healthy\": True})\n    response = JSONResponse(\n        status_code=status.HTTP_200_OK, headers={\"X-HEALTHY\": \"true\"}, content=health\n    )\n    return response\n</code></pre>"},{"location":"reference/red_utils/ext/fastapi_utils/operations/","title":"operations","text":""},{"location":"reference/red_utils/ext/fastapi_utils/operations/#red_utils.ext.fastapi_utils.operations.fix_api_docs","title":"<code>fix_api_docs(app=None)</code>","text":"<p>Fix error loading /docs when a root_path is set.</p> <p>Call after declaring an app with a root_path set, for example:     app = FastAPI(root_path=\"/some/path\")     fix_api_docs(app)</p> <p>When a root_path is declared, the default /docs URL breaks, and returns an error:     Fetch error     Not Found /api/v1/openapi.json</p> Source code in <code>src\\red_utils\\ext\\fastapi_utils\\operations.py</code> <pre><code>def fix_api_docs(app: FastAPI = None):\n    \"\"\"Fix error loading /docs when a root_path is set.\n\n    Call after declaring an app with a root_path set, for example:\n        app = FastAPI(root_path=\"/some/path\")\n        fix_api_docs(app)\n\n    When a root_path is declared, the default /docs URL breaks, and returns\n    an error:\n        Fetch error\n        Not Found /api/v1/openapi.json\n    \"\"\"\n    if not app:\n        raise ValueError(\"Missing a FastAPI app with a root_path var declared\")\n\n    if not isinstance(app, FastAPI):\n        raise TypeError(\n            f\"Invalid type for FastAPI app: ({type(app)}). Value must be of type FastAPI.\"\n        )\n\n    @app.get(app.root_path + \"/openapi.json\", include_in_schema=False)\n    def custom_swagger_ui_html():\n        return app.openapi()\n</code></pre>"},{"location":"reference/red_utils/ext/fastapi_utils/operations/#red_utils.ext.fastapi_utils.operations.get_app","title":"<code>get_app(debug=False, cors=True, root_path='/', title='DEFAULT_TITLE', description='DEFAULT_DESCRIPTION', version='0.0.0', openapi_url=default_openapi_url, openapi_tags=tags_metadata, routers=None)</code>","text":"<p>Generate a FastAPI app and return.</p> Source code in <code>src\\red_utils\\ext\\fastapi_utils\\operations.py</code> <pre><code>def get_app(\n    debug: bool = False,\n    cors: bool = True,\n    root_path: str = \"/\",\n    title: str = \"DEFAULT_TITLE\",\n    description: str = \"DEFAULT_DESCRIPTION\",\n    version: str = \"0.0.0\",\n    openapi_url: str = default_openapi_url,\n    openapi_tags: list = tags_metadata,\n    routers: list[APIRouter] = None,\n) -&gt; FastAPI:\n    \"\"\"Generate a FastAPI app and return.\"\"\"\n    for _var in [root_path, title, description, version, openapi_url]:\n        is_str(input=_var)\n\n    validate_openapi_tags(openapi_tags)\n\n    if routers:\n        for r in routers:\n            validate_router(r, none_ok=True)\n\n    try:\n        app: FastAPI = FastAPI(\n            root_path=root_path,\n            title=title,\n            description=description,\n            version=version,\n            openapi_url=openapi_url,\n            openapi_tags=openapi_tags,\n            debug=debug,\n        )\n\n        if cors:\n            add_cors_middleware(app=app)\n\n        if routers:\n            for router in routers:\n                app.include_router(router)\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception creating FastAPI App. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n\n    return app\n</code></pre>"},{"location":"reference/red_utils/ext/fastapi_utils/operations/#red_utils.ext.fastapi_utils.operations.update_tags_metadata","title":"<code>update_tags_metadata(tags_metadata=tags_metadata, update_metadata=None)</code>","text":"<p>Update the global tags_metadata list with new values.</p> <p>Import this function in another app, create a new list of tags (or a single tag dict, {\"name\": ..., \"description\": ...}), then pass both the imported tags_metadata and the new list/single instance of tag objects.</p> <p>This funciton will combine them into a new tags_metadata object</p> Source code in <code>src\\red_utils\\ext\\fastapi_utils\\operations.py</code> <pre><code>def update_tags_metadata(\n    tags_metadata: list = tags_metadata,\n    update_metadata: Union[list[dict[str, str]], dict[str, str]] = None,\n):\n    \"\"\"Update the global tags_metadata list with new values.\n\n    Import this function in another app, create a new list of tags (or\n    a single tag dict, {\"name\": ..., \"description\": ...}), then pass both\n    the imported tags_metadata and the new list/single instance of tag objects.\n\n    This funciton will combine them into a new tags_metadata object\n    \"\"\"\n    if not tags_metadata:\n        raise ValueError(\"Missing value for tags_metadata\")\n\n    if not update_metadata:\n        raise ValueError(\"Missing value for update_metadata\")\n\n    if isinstance(update_metadata, list):\n        ## List of dicts was passed\n\n        # print(f\"[DEBUG] Detected list of new tags: {update_metadata}\")\n\n        tags_metadata = tags_metadata + update_metadata\n\n        return_obj = tags_metadata\n\n    elif isinstance(update_metadata, dict):\n        ## Single tag dict was passed\n\n        # print(f\"[DEBUG] Detected single dict for new tag: {update_metadata}\")\n\n        tags_metadata.append(update_metadata)\n\n        return_obj = tags_metadata\n\n    else:\n        raise ValueError(\n            \"Type of update_metadata must be one of list[dict[str,str]] or dict[str,str]\"\n        )\n\n    return return_obj\n</code></pre>"},{"location":"reference/red_utils/ext/fastapi_utils/tag_definitions/","title":"tag_definitions","text":"<p>Add metadata to tags assigned throughout the app.</p> <p>If a router/endpoint's tags match any of these, the description and other metadata will be applied on the docs page.</p> <p>This tags_metadata can be imported and extended with tags_metadata.append(new_tags_dict).</p> <p>You can also create a new list of tags ([{\"name\": ..., \"description\": ...}, ...]) and join them with tags_metadata = tags_metadata + new_tags_list</p> <p>How to add new tags:</p> <ul> <li>Create a tag dict</li> <li>ex_tag = {\"name\": \"example\", \"description\": \"An example tag\"}</li> <li>Append to existing metadata object</li> <li>tags_metadata.append(garlic_metadata)</li> </ul> <p>Do this operation early, preferable before even creating the FastAPI app object. Otherwise, tags render really weird.</p> <p>Do not declare tags on a submodule, like an APIRouter module for example. Appending tags once the server is already running makes them unusable in the /docs site.</p>"},{"location":"reference/red_utils/ext/fastapi_utils/uvicorn_override/","title":"uvicorn_override","text":""},{"location":"reference/red_utils/ext/fastapi_utils/validators/","title":"validators","text":""},{"location":"reference/red_utils/ext/httpx_utils/__init__/","title":"httpx_utils","text":""},{"location":"reference/red_utils/ext/httpx_utils/__init__/#red_utils.ext.httpx_utils.HTTPXController","title":"<code>HTTPXController</code>","text":"<p>               Bases: <code>AbstractContextManager</code></p> <p>Handler for HTTPX client.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str | None</code> <p>Scope the httpx client to a URL.</p> <code>None</code> <code>base_url</code> <code>str | None</code> <p>A base URL will be prefixed to each request. I.e. if <code>base_url=\"https://example.com\", and you want to request \"https://example.com/endpoint,\" you can set the base URL and then request</code>/endpoint`.</p> <code>None</code> <code>proxy</code> <code>str | None</code> <p> <code>None</code> <code>proxies</code> <code>str | None</code> <p> <code>None</code> <code>mounts</code> <code>dict[str, HTTPTransport] | None</code> <p>A dict of <code>httpx.HTTPTransport</code> objects.</p> <code>{}</code> <code>cookies</code> <code>dict[str, Any]</code> <p> <code>{}</code> <code>auth</code> <code>Auth | None</code> <p> <code>None</code> <code>headers</code> <code>dict[str, str] | None</code> <p>Optional request headers to apply to all requests handled by controller instance.</p> <code>{}</code> <code>params</code> <code>dict[str, Any] | None</code> <p>Optional request params to apply to all requests handled by controller instance.</p> <code>{}</code> <code>follow_redirects</code> <code>bool</code> <p>[Default: False] Follow HTTP 302 redirects.</p> <code>False</code> <code>max_redirects</code> <code>int | None</code> <p>[Default: 20] Maximum number of HTTP 302 redirects to follow.</p> <code>20</code> <code>retries</code> <code>int | None</code> <p>Number of times to retry on request failure.</p> <code>None</code> <code>timeout</code> <code>int | float | None</code> <p>Timeout (in seconds) until client gives up on request.</p> <code>60</code> <code>limits</code> <code>Limits | None</code> <p> <code>None</code> <code>transport</code> <code>HTTPTransport | CacheTransport | None</code> <p>A transport to pass to class's <code>httpx.Client</code> object.</p> <code>None</code> <code>default_encoding</code> <code>str</code> <p>[Default: utf-8] Set default encoding for all requests.</p> <code>autodetect_charset</code> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>class HTTPXController(AbstractContextManager):\n    \"\"\"Handler for HTTPX client.\n\n    Params:\n        url (str|None): Scope the httpx client to a URL.\n        base_url (str|None): A base URL will be prefixed to each request. I.e. if `base_url=\"https://example.com\",\n            and you want to request \"https://example.com/endpoint,\" you can set the base URL and then request `/endpoint`.\n        proxy (str|None): &lt;Not yet documented&gt;\n        proxies (str|None): &lt;Not yet documented&gt;\n        mounts (dict[str, httpx.HTTPTransport]|None): A dict of `httpx.HTTPTransport` objects.\n        cookies (dict[str, Any]): &lt;Not yet documented&gt;\n        auth (httpx.Auth | None): &lt;Not yet documented&gt;\n        headers (dict[str, str]|None): Optional request headers to apply to all requests handled by controller instance.\n        params (dict[str, Any]|None): Optional request params to apply to all requests handled by controller instance.\n        follow_redirects (bool): [Default: False] Follow HTTP 302 redirects.\n        max_redirects (int|None): [Default: 20] Maximum number of HTTP 302 redirects to follow.\n        retries (int|None): Number of times to retry on request failure.\n        timeout (int|float|None): Timeout (in seconds) until client gives up on request.\n        limits (httpx.Limits | None): &lt;Not yet documented&gt;\n        transport (httpx.HTTPTransport|hishel.CacheTransport|None): A transport to pass to class's `httpx.Client` object.\n        default_encoding (str): [Default: utf-8] Set default encoding for all requests.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        url: str | None = None,\n        base_url: str | None = None,\n        proxy: str | None = None,\n        proxies: dict[str, str] | None = None,\n        mounts: dict[str, httpx.HTTPTransport] | None = {},\n        cookies: dict[str, t.Any] | None = {},\n        auth: httpx.Auth | None = None,\n        headers: dict[str, str] | None = {},\n        params: dict[str, t.Any] | None = {},\n        follow_redirects: bool = False,\n        max_redirects: int | None = 20,\n        retries: int | None = None,\n        timeout: t.Union[int, float] | None = 60,\n        limits: httpx.Limits | None = None,\n        transport: t.Union[httpx.HTTPTransport, hishel.CacheTransport] | None = None,\n        default_encoding: str = autodetect_charset,\n    ) -&gt; None:\n        self.url: httpx.URL | None = httpx.URL(url) if url else None\n        self.base_url: httpx.URL | None = httpx.URL(base_url) if base_url else None\n        self.proxy: str | None = proxy\n        self.proxies: dict[str, str] | None = proxies\n        self.mounts: dict[str, httpx.HTTPTransport] | None = mounts\n        self.auth: httpx.Auth | None = auth\n        self.headers: dict[str, str] | None = headers\n        self.cookies: dict[str, t.Any] | None = cookies\n        self.params: dict[str, str] | None = params\n        self.follow_redirects: bool = follow_redirects\n        self.max_redirects: int | None = max_redirects\n        self.retries: int | None = retries\n        self.timeout: t.Union[int, float] | None = timeout\n        self.limits: httpx.Limits | None = limits\n        self.transport: t.Union[httpx.HTTPTransport, hishel.CacheTransport] | None = (\n            transport\n        )\n        self.default_encoding: str = default_encoding\n\n        ## Placeholder for initialized httpx.Client\n        self.client: httpx.Client | None = None\n\n    def __enter__(self) -&gt; t.Self:\n        \"\"\"Execute when handler is called in a `with` statement.\n\n        Description:\n            Creates an `httpx.Client` object, using class parameters as options.\n        \"\"\"\n        try:\n            _client: httpx.Client = httpx.Client(\n                auth=self.auth,\n                params=self.params,\n                headers=self.headers,\n                cookies=self.cookies,\n                proxy=self.proxy,\n                proxies=self.proxies,\n                mounts=self.mounts,\n                timeout=self.timeout,\n                follow_redirects=self.follow_redirects,\n                max_redirects=self.max_redirects,\n                # base_url=self.base_url,\n                transport=self.transport,\n                default_encoding=self.default_encoding,\n            )\n\n            ## If base_url is None, an exception occurs. Set self.base_url\n            #  only if base_url is not None.\n            if self.base_url:\n                _client.base_url = self.base_url\n\n            self.client = _client\n\n            return self\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception initializing httpx Client. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        \"\"\"Execute  when `with` statement ends.\n\n        Description:\n            Show any exceptions/tracebacks. Close `self.client` on exit.\n\n        \"\"\"\n        if exc_type:\n            log.error(f\"({exc_type}): {exc_value}\")\n\n        if traceback:\n            log.error(f\"TRACE: {traceback}\")\n\n        ## Close httpx client\n        if self.client:\n            self.client.close()\n\n    def new_request(\n        self,\n        method: str = \"GET\",\n        url: str | httpx.URL = None,\n        files: list | None = None,\n        _json: t.Any | None = None,\n        params: dict | None = None,\n        headers: dict | None = {},\n        cookies: dict | None = None,\n        timeout: int | float | None = None,\n    ) -&gt; httpx.Request:\n        \"\"\"Assemble a new httpx.Request object from parts.\n\n        Params:\n            method (str): [Default: \"GET\"] HTTP method for request.\n            url (str|httpx.URL): URL to send request.\n            files (list|None): List of files to send with request. Only works with certain HTTP methods,\n                list `POST`.\n            _json (t.Any | None): JSON to append to request.\n            params (dict | None): Params to append to request.\n            headers (dict|None): Request headers.\n            cookies (dict): &lt;Not yet documented&gt;\n            timeout (int|float): Timeout (in seconds) before cancelling request.\n\n        Returns:\n            (httpx.Request): An initialized `httpx.Request` object.\n\n        \"\"\"\n        assert method, ValueError(\"Missing a request method\")\n        assert isinstance(method, str), TypeError(\n            f\"method should be a string. Got type: ({type(method)})\"\n        )\n\n        ## Ensure method is uppercase, i.e. 'get' -&gt; 'GET'\n        method: str = method.upper()\n\n        assert url, ValueError(\"Missing a URL\")\n        assert isinstance(url, str) or isinstance(url, httpx.URL), TypeError(\n            f\"URL must be a string or httpx.URL. Got type: ({type(url)})\"\n        )\n        if isinstance(url, str):\n            ## Convert URL from string into httpx.URL object\n            url: httpx.URL = httpx.URL(url=url)\n\n        if timeout:\n            assert (\n                isinstance(timeout, int) or isinstance(timeout, float)\n            ) and timeout &gt; 0, TypeError(\n                f\"timeout must be a non-zero positive int or float. Got type: ({type(timeout)})\"\n            )\n\n        ## Build httpx.Request object\n        try:\n            _req: httpx.Request = self.client.build_request(\n                method=method,\n                url=url,\n                files=files,\n                json=_json,\n                params=params,\n                headers=headers,\n                cookies=cookies,\n                timeout=timeout,\n            )\n\n            return _req\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception creaeting httpx.Request object. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def send_request(\n        self,\n        request: httpx.Request = None,\n        stream: bool = False,\n        auth: httpx.Auth = None,\n        debug_response: bool = False,\n    ) -&gt; httpx.Response:\n        \"\"\"Send httpx.Request using self.Client (and optional cache transport).\n\n        Params:\n            request (httpx.Request): An initialized `httpx.Request` object.\n            stream (bool): When `True`, response bytes will be streamed. This can be useful for large file downloads.\n            auth (httpx.Auth): &lt;Not yet documented&gt;\n\n        Returns:\n            (httpx.Response): An `httpx.Response` from the request.\n\n        \"\"\"\n        assert request, ValueError(\"Missing an httpx.Request object\")\n        assert isinstance(request, httpx.Request), TypeError(\n            f\"Expected request to be an httpx.Request object. Got type: ({type(request)})\"\n        )\n\n        ## Send request using class's httpx.Client\n        try:\n            res: httpx.Response = self.client.send(\n                request=request,\n                stream=stream,\n                auth=auth,\n                follow_redirects=self.follow_redirects,\n            )\n\n            if debug_response:\n                log.debug(\n                    f\"URL: {request.url}, Response: [{res.status_code}: {res.reason_phrase}]\"\n                )\n\n            return res\n\n        except httpx.ConnectError as conn_err:\n            ## Error connecting to remote\n            msg = Exception(\n                f\"ConnectError while requesting URL {request.url}. Details: {conn_err}\"\n            )\n            log.error(msg)\n\n            return\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception sending request. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n    def decode_res_content(self, res: httpx.Response = None) -&gt; dict:\n        \"\"\"Use multiple methods to attempt to decode an `httpx.Response.content` bytestring.\n\n        Params:\n            res (httpx.Response): An `httpx.Response` object, with `.content` to be decoded.\n\n        Returns:\n            (dict): A `dict` from the `httpx.Response`'s `.content` param.\n\n        \"\"\"\n        assert res, ValueError(\"Missing httpx Response object\")\n        assert isinstance(res, httpx.Response), TypeError(\n            f\"res must be of type httpx.Response. Got type: ({type(res)})\"\n        )\n\n        _content: bytes = res.content\n        assert _content, ValueError(\"Response content is empty\")\n        assert isinstance(_content, bytes), TypeError(\n            f\"Expected response.content to be a bytestring. Got type: ({type(_content)})\"\n        )\n\n        ## Get content's encoding, or default to 'utf-8'\n        try:\n            decode_charset: str = autodetect_charset(content=_content)\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception detecting response content's encoding. Details: {exc}\"\n            )\n            log.error(msg)\n            log.warning(\"Defaulting to 'utf-8'\")\n\n            decode_charset: str = \"utf-8\"\n\n        ## Decode content\n        try:\n            _decode: str = res.content.decode(decode_charset)\n\n        except Exception as exc:\n            ## Decoding failed, retry with different encodings\n            msg = Exception(\n                f\"[Attempt 1/2] Unhandled exception decoding response content. Details: {exc}\"\n            )\n            log.warning(msg)\n\n            if not res.encoding == \"utf-8\":\n                ## Try decoding again, using response's .encoding param\n                log.warning(\n                    f\"Retrying response content decode with encoding '{res.encoding}'\"\n                )\n                try:\n                    _decode = res.content.decode(res.encoding)\n                except Exception as exc:\n                    inner_msg = Exception(\n                        f\"[Attempt 2/2] Unhandled exception decoding response content. Details: {exc}\"\n                    )\n                    log.error(inner_msg)\n\n                    raise inner_msg\n\n            else:\n                ## Decoding with utf-8 failed, attempt with ISO-8859-1\n                #  https://en.wikipedia.org/wiki/ISO/IEC_8859-1\n                log.warning(\n                    \"Detected UTF-8 encoding, but decoding as UTF-8 failed. Retrying with encoding ISO-8859-1.\"\n                )\n                try:\n                    _decode = res.content.decode(\"ISO-8859-1\")\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Failure attempting to decode content as UTF-8 and ISO-8859-1. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n        ## Load decoded content into dict\n        try:\n            _json: dict = json.loads(_decode)\n\n            return _json\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception loading decoded response content to dict. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/__init__/#red_utils.ext.httpx_utils.HTTPXController.decode_res_content","title":"<code>decode_res_content(res=None)</code>","text":"<p>Use multiple methods to attempt to decode an <code>httpx.Response.content</code> bytestring.</p> <p>Parameters:</p> Name Type Description Default <code>res</code> <code>Response</code> <p>An <code>httpx.Response</code> object, with <code>.content</code> to be decoded.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A <code>dict</code> from the <code>httpx.Response</code>'s <code>.content</code> param.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>def decode_res_content(self, res: httpx.Response = None) -&gt; dict:\n    \"\"\"Use multiple methods to attempt to decode an `httpx.Response.content` bytestring.\n\n    Params:\n        res (httpx.Response): An `httpx.Response` object, with `.content` to be decoded.\n\n    Returns:\n        (dict): A `dict` from the `httpx.Response`'s `.content` param.\n\n    \"\"\"\n    assert res, ValueError(\"Missing httpx Response object\")\n    assert isinstance(res, httpx.Response), TypeError(\n        f\"res must be of type httpx.Response. Got type: ({type(res)})\"\n    )\n\n    _content: bytes = res.content\n    assert _content, ValueError(\"Response content is empty\")\n    assert isinstance(_content, bytes), TypeError(\n        f\"Expected response.content to be a bytestring. Got type: ({type(_content)})\"\n    )\n\n    ## Get content's encoding, or default to 'utf-8'\n    try:\n        decode_charset: str = autodetect_charset(content=_content)\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception detecting response content's encoding. Details: {exc}\"\n        )\n        log.error(msg)\n        log.warning(\"Defaulting to 'utf-8'\")\n\n        decode_charset: str = \"utf-8\"\n\n    ## Decode content\n    try:\n        _decode: str = res.content.decode(decode_charset)\n\n    except Exception as exc:\n        ## Decoding failed, retry with different encodings\n        msg = Exception(\n            f\"[Attempt 1/2] Unhandled exception decoding response content. Details: {exc}\"\n        )\n        log.warning(msg)\n\n        if not res.encoding == \"utf-8\":\n            ## Try decoding again, using response's .encoding param\n            log.warning(\n                f\"Retrying response content decode with encoding '{res.encoding}'\"\n            )\n            try:\n                _decode = res.content.decode(res.encoding)\n            except Exception as exc:\n                inner_msg = Exception(\n                    f\"[Attempt 2/2] Unhandled exception decoding response content. Details: {exc}\"\n                )\n                log.error(inner_msg)\n\n                raise inner_msg\n\n        else:\n            ## Decoding with utf-8 failed, attempt with ISO-8859-1\n            #  https://en.wikipedia.org/wiki/ISO/IEC_8859-1\n            log.warning(\n                \"Detected UTF-8 encoding, but decoding as UTF-8 failed. Retrying with encoding ISO-8859-1.\"\n            )\n            try:\n                _decode = res.content.decode(\"ISO-8859-1\")\n            except Exception as exc:\n                msg = Exception(\n                    f\"Failure attempting to decode content as UTF-8 and ISO-8859-1. Details: {exc}\"\n                )\n                log.error(msg)\n\n                raise exc\n\n    ## Load decoded content into dict\n    try:\n        _json: dict = json.loads(_decode)\n\n        return _json\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception loading decoded response content to dict. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/__init__/#red_utils.ext.httpx_utils.HTTPXController.new_request","title":"<code>new_request(method='GET', url=None, files=None, _json=None, params=None, headers={}, cookies=None, timeout=None)</code>","text":"<p>Assemble a new httpx.Request object from parts.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>[Default: \"GET\"] HTTP method for request.</p> <code>'GET'</code> <code>url</code> <code>str | URL</code> <p>URL to send request.</p> <code>None</code> <code>files</code> <code>list | None</code> <p>List of files to send with request. Only works with certain HTTP methods, list <code>POST</code>.</p> <code>None</code> <code>_json</code> <code>Any | None</code> <p>JSON to append to request.</p> <code>None</code> <code>params</code> <code>dict | None</code> <p>Params to append to request.</p> <code>None</code> <code>headers</code> <code>dict | None</code> <p>Request headers.</p> <code>{}</code> <code>cookies</code> <code>dict</code> <p> <code>None</code> <code>timeout</code> <code>int | float</code> <p>Timeout (in seconds) before cancelling request.</p> <code>None</code> <p>Returns:</p> Type Description <code>Request</code> <p>An initialized <code>httpx.Request</code> object.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>def new_request(\n    self,\n    method: str = \"GET\",\n    url: str | httpx.URL = None,\n    files: list | None = None,\n    _json: t.Any | None = None,\n    params: dict | None = None,\n    headers: dict | None = {},\n    cookies: dict | None = None,\n    timeout: int | float | None = None,\n) -&gt; httpx.Request:\n    \"\"\"Assemble a new httpx.Request object from parts.\n\n    Params:\n        method (str): [Default: \"GET\"] HTTP method for request.\n        url (str|httpx.URL): URL to send request.\n        files (list|None): List of files to send with request. Only works with certain HTTP methods,\n            list `POST`.\n        _json (t.Any | None): JSON to append to request.\n        params (dict | None): Params to append to request.\n        headers (dict|None): Request headers.\n        cookies (dict): &lt;Not yet documented&gt;\n        timeout (int|float): Timeout (in seconds) before cancelling request.\n\n    Returns:\n        (httpx.Request): An initialized `httpx.Request` object.\n\n    \"\"\"\n    assert method, ValueError(\"Missing a request method\")\n    assert isinstance(method, str), TypeError(\n        f\"method should be a string. Got type: ({type(method)})\"\n    )\n\n    ## Ensure method is uppercase, i.e. 'get' -&gt; 'GET'\n    method: str = method.upper()\n\n    assert url, ValueError(\"Missing a URL\")\n    assert isinstance(url, str) or isinstance(url, httpx.URL), TypeError(\n        f\"URL must be a string or httpx.URL. Got type: ({type(url)})\"\n    )\n    if isinstance(url, str):\n        ## Convert URL from string into httpx.URL object\n        url: httpx.URL = httpx.URL(url=url)\n\n    if timeout:\n        assert (\n            isinstance(timeout, int) or isinstance(timeout, float)\n        ) and timeout &gt; 0, TypeError(\n            f\"timeout must be a non-zero positive int or float. Got type: ({type(timeout)})\"\n        )\n\n    ## Build httpx.Request object\n    try:\n        _req: httpx.Request = self.client.build_request(\n            method=method,\n            url=url,\n            files=files,\n            json=_json,\n            params=params,\n            headers=headers,\n            cookies=cookies,\n            timeout=timeout,\n        )\n\n        return _req\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception creaeting httpx.Request object. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/__init__/#red_utils.ext.httpx_utils.HTTPXController.send_request","title":"<code>send_request(request=None, stream=False, auth=None, debug_response=False)</code>","text":"<p>Send httpx.Request using self.Client (and optional cache transport).</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>An initialized <code>httpx.Request</code> object.</p> <code>None</code> <code>stream</code> <code>bool</code> <p>When <code>True</code>, response bytes will be streamed. This can be useful for large file downloads.</p> <code>False</code> <code>auth</code> <code>Auth</code> <p> <code>None</code> <p>Returns:</p> Type Description <code>Response</code> <p>An <code>httpx.Response</code> from the request.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>def send_request(\n    self,\n    request: httpx.Request = None,\n    stream: bool = False,\n    auth: httpx.Auth = None,\n    debug_response: bool = False,\n) -&gt; httpx.Response:\n    \"\"\"Send httpx.Request using self.Client (and optional cache transport).\n\n    Params:\n        request (httpx.Request): An initialized `httpx.Request` object.\n        stream (bool): When `True`, response bytes will be streamed. This can be useful for large file downloads.\n        auth (httpx.Auth): &lt;Not yet documented&gt;\n\n    Returns:\n        (httpx.Response): An `httpx.Response` from the request.\n\n    \"\"\"\n    assert request, ValueError(\"Missing an httpx.Request object\")\n    assert isinstance(request, httpx.Request), TypeError(\n        f\"Expected request to be an httpx.Request object. Got type: ({type(request)})\"\n    )\n\n    ## Send request using class's httpx.Client\n    try:\n        res: httpx.Response = self.client.send(\n            request=request,\n            stream=stream,\n            auth=auth,\n            follow_redirects=self.follow_redirects,\n        )\n\n        if debug_response:\n            log.debug(\n                f\"URL: {request.url}, Response: [{res.status_code}: {res.reason_phrase}]\"\n            )\n\n        return res\n\n    except httpx.ConnectError as conn_err:\n        ## Error connecting to remote\n        msg = Exception(\n            f\"ConnectError while requesting URL {request.url}. Details: {conn_err}\"\n        )\n        log.error(msg)\n\n        return\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception sending request. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/__init__/#red_utils.ext.httpx_utils.HishelCacheClientController","title":"<code>HishelCacheClientController</code>","text":"<p>               Bases: <code>AbstractContextManager</code></p> <p>Handler for a hishel.CacheClient client.</p> <p>Parameters:</p> Name Type Description Default <code>cacheable_methods</code> <code>list[str]</code> <p>...</p> <code>['GET', 'POST']</code> <code>cacheable_status_codes</code> <code>list[int]</code> <p>...</p> <code>[200, 301, 308]</code> <code>allow_heuristics</code> <code>bool</code> <p>...</p> <code>False</code> <code>allow_stale</code> <code>bool</code> <p>...</p> <code>False</code> <code>always_revalidate</code> <code>bool</code> <p>...</p> <code>False</code> <code>force_cache</code> <code>bool</code> <p>...</p> <code>False</code> <code>storage</code> <code>FileStorage | RedisStorage | SQLiteStorage | S3Storage | InMemoryStorage</code> <p>...</p> <code>None</code> <code>follow_redirects</code> <code>bool</code> <p>...</p> <code>False</code> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>class HishelCacheClientController(AbstractContextManager):\n    \"\"\"Handler for a hishel.CacheClient client.\n\n    Params:\n        cacheable_methods (list[str]): ...\n        cacheable_status_codes (list[int]): ...\n        allow_heuristics (bool): ...\n        allow_stale (bool): ...\n        always_revalidate (bool): ...\n        force_cache (bool): ...\n        storage (hishel.FileStorage | hishel.RedisStorage | hishel.SQLiteStorage | hishel.S3Storage | hishel.InMemoryStorage): ...\n        follow_redirects (bool): ...\n    \"\"\"\n\n    def __init__(\n        self,\n        cacheable_methods: list[str] | None = [\"GET\", \"POST\"],\n        cacheable_status_codes: list[int] | None = [200, 301, 308],\n        allow_heuristics: bool = False,\n        allow_stale: bool = False,\n        always_revalidate: bool = False,\n        force_cache: bool = False,\n        storage: hishel_storage_type = None,\n        follow_redirects: bool = False,\n    ):\n        self.cacheable_methods = cacheable_methods\n        self.cacheable_status_codes = cacheable_status_codes\n        self.allow_heuristics = allow_heuristics\n        self.allow_stale = allow_stale\n        self.always_revalidate = always_revalidate\n        self.force_cache = force_cache\n        self.storage = storage\n        self.follow_redirects = follow_redirects\n\n        ## Placeholder for initialized hishel.Controller\n        self.controller: hishel.Controller = None\n        ## Placeholder for initialized hishel.CacheClient\n        self.client: hishel.CacheClient = None\n\n    def __enter__(self) -&gt; t.Self:\n        try:\n            _controller: hishel.Controller = hishel.Controller(\n                cacheable_methods=self.cacheable_methods,\n                cacheable_status_codes=self.cacheable_status_codes,\n                allow_heuristics=self.allow_heuristics,\n                allow_stale=self.allow_stale,\n                always_revalidate=self.always_revalidate,\n                force_cache=self.force_cache,\n            )\n            self.controller = _controller\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception initializing hishel.Controller. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n        try:\n            _client: hishel.CacheClient = hishel.CacheClient(\n                controller=self.controller, storage=self.storage\n            )\n            self.client = _client\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception initializing hishel.CacheClient. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        if exc_type:\n            log.error(f\"({exc_type}): {exc_value}\")\n        if traceback:\n            log.error(traceback)\n        if self.client:\n            self.client.close()\n\n    def new_request(\n        self,\n        method: str = \"GET\",\n        url: str = None,\n        files: list | None = None,\n        _json: t.Any | None = None,\n        params: dict | None = None,\n        headers: dict | None = None,\n        cookies: dict | None = None,\n        timeout: int | float | None = None,\n    ) -&gt; httpx.Request:\n        \"\"\"Assemble a new httpx.Request object from parts.\n\n        Params:\n            method (str): [Default: \"GET\"] HTTP method for request.\n            url (str|httpx.URL): URL to send request.\n            files (list|None): List of files to send with request. Only works with certain HTTP methods,\n                list `POST`.\n            _json (t.Any | None): JSON to append to request.\n            params (dict | None): Params to append to request.\n            headers (dict|None): Request headers.\n            cookies (dict): &lt;Not yet documented&gt;\n            timeout (int|float): Timeout (in seconds) before cancelling request.\n\n        Returns:\n            (httpx.Request): An initialized `httpx.Request` object.\n\n        \"\"\"\n        assert method, ValueError(\"Missing a request method\")\n        assert isinstance(method, str), TypeError(\n            f\"method should be a string. Got type: ({type(method)})\"\n        )\n\n        ## Ensure method is uppercase, i.e. 'get' -&gt; 'GET'\n        method: str = method.upper()\n\n        assert url, ValueError(\"Missing a URL\")\n        assert isinstance(url, str) or isinstance(url, httpx.URL), TypeError(\n            f\"URL must be a string or httpx.URL. Got type: ({type(url)})\"\n        )\n        if isinstance(url, str):\n            ## Convert URL from string into httpx.URL object\n            url: httpx.URL = httpx.URL(url=url)\n\n        if timeout:\n            assert (\n                isinstance(timeout, int) or isinstance(timeout, float)\n            ) and timeout &gt; 0, TypeError(\n                f\"timeout must be a non-zero positive int or float. Got type: ({type(timeout)})\"\n            )\n\n        ## Build httpx.Request object\n        try:\n            _req: httpx.Request = self.client.build_request(\n                method=method,\n                url=url,\n                files=files,\n                json=_json,\n                params=params,\n                headers=headers,\n                cookies=cookies,\n                timeout=timeout,\n            )\n\n            return _req\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception creaeting httpx.Request object. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def send_request(\n        self,\n        request: httpx.Request = None,\n        stream: bool = False,\n        auth: httpx.Auth = None,\n        debug_response: bool = False,\n    ) -&gt; httpx.Response:\n        \"\"\"Send httpx.Request using self.Client (and optional cache transport).\n\n        Params:\n            request (httpx.Request): An initialized `httpx.Request` object.\n            stream (bool): When `True`, response bytes will be streamed. This can be useful for large file downloads.\n            auth (httpx.Auth): &lt;Not yet documented&gt;\n\n        Returns:\n            (httpx.Response): An `httpx.Response` from the request.\n\n        \"\"\"\n        assert request, ValueError(\"Missing an httpx.Request object\")\n        assert isinstance(request, httpx.Request), TypeError(\n            f\"Expected request to be an httpx.Request object. Got type: ({type(request)})\"\n        )\n\n        ## Send request using class's httpx.Client\n        try:\n            res: httpx.Response = self.client.send(\n                request=request,\n                stream=stream,\n                auth=auth,\n                follow_redirects=self.follow_redirects,\n            )\n            if debug_response:\n                log.debug(\n                    f\"Response: [{res.status_code}: {res.reason_phrase}] {request.url}\"\n                )\n\n            return res\n\n        except httpx.ConnectError as conn_err:\n            ## Error connecting to remote\n            msg = Exception(\n                f\"ConnectError while requesting URL {request.url}. Details: {conn_err}\"\n            )\n            log.error(msg)\n\n            return\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception sending request. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n    def decode_res_content(self, res: httpx.Response = None) -&gt; dict:\n        \"\"\"Use multiple methods to attempt to decode an `httpx.Response.content` bytestring.\n\n        Params:\n            res (httpx.Response): An `httpx.Response` object, with `.content` to be decoded.\n\n        Returns:\n            (dict): A `dict` from the `httpx.Response`'s `.content` param.\n\n        \"\"\"\n        assert res, ValueError(\"Missing httpx Response object\")\n        assert isinstance(res, httpx.Response), TypeError(\n            f\"res must be of type httpx.Response. Got type: ({type(res)})\"\n        )\n\n        _content: bytes = res.content\n        assert _content, ValueError(\"Response content is empty\")\n        assert isinstance(_content, bytes), TypeError(\n            f\"Expected response.content to be a bytestring. Got type: ({type(_content)})\"\n        )\n\n        ## Get content's encoding, or default to 'utf-8'\n        try:\n            decode_charset: str = autodetect_charset(content=_content)\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception detecting response content's encoding. Details: {exc}\"\n            )\n            log.error(msg)\n            log.warning(\"Defaulting to 'utf-8'\")\n\n            decode_charset: str = \"utf-8\"\n\n        ## Decode content\n        try:\n            _decode: str = res.content.decode(decode_charset)\n\n        except Exception as exc:\n            ## Decoding failed, retry with different encodings\n            msg = Exception(\n                f\"[Attempt 1/2] Unhandled exception decoding response content. Details: {exc}\"\n            )\n            log.warning(msg)\n\n            if not res.encoding == \"utf-8\":\n                ## Try decoding again, using response's .encoding param\n                log.warning(\n                    f\"Retrying response content decode with encoding '{res.encoding}'\"\n                )\n                try:\n                    _decode = res.content.decode(res.encoding)\n                except Exception as exc:\n                    inner_msg = Exception(\n                        f\"[Attempt 2/2] Unhandled exception decoding response content. Details: {exc}\"\n                    )\n                    log.error(inner_msg)\n\n                    raise inner_msg\n\n            else:\n                ## Decoding with utf-8 failed, attempt with ISO-8859-1\n                #  https://en.wikipedia.org/wiki/ISO/IEC_8859-1\n                log.warning(\n                    \"Detected UTF-8 encoding, but decoding as UTF-8 failed. Retrying with encoding ISO-8859-1.\"\n                )\n                try:\n                    _decode = res.content.decode(\"ISO-8859-1\")\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Failure attempting to decode content as UTF-8 and ISO-8859-1. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n        ## Load decoded content into dict\n        try:\n            _json: dict = json.loads(_decode)\n\n            return _json\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception loading decoded response content to dict. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/__init__/#red_utils.ext.httpx_utils.HishelCacheClientController.decode_res_content","title":"<code>decode_res_content(res=None)</code>","text":"<p>Use multiple methods to attempt to decode an <code>httpx.Response.content</code> bytestring.</p> <p>Parameters:</p> Name Type Description Default <code>res</code> <code>Response</code> <p>An <code>httpx.Response</code> object, with <code>.content</code> to be decoded.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A <code>dict</code> from the <code>httpx.Response</code>'s <code>.content</code> param.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>def decode_res_content(self, res: httpx.Response = None) -&gt; dict:\n    \"\"\"Use multiple methods to attempt to decode an `httpx.Response.content` bytestring.\n\n    Params:\n        res (httpx.Response): An `httpx.Response` object, with `.content` to be decoded.\n\n    Returns:\n        (dict): A `dict` from the `httpx.Response`'s `.content` param.\n\n    \"\"\"\n    assert res, ValueError(\"Missing httpx Response object\")\n    assert isinstance(res, httpx.Response), TypeError(\n        f\"res must be of type httpx.Response. Got type: ({type(res)})\"\n    )\n\n    _content: bytes = res.content\n    assert _content, ValueError(\"Response content is empty\")\n    assert isinstance(_content, bytes), TypeError(\n        f\"Expected response.content to be a bytestring. Got type: ({type(_content)})\"\n    )\n\n    ## Get content's encoding, or default to 'utf-8'\n    try:\n        decode_charset: str = autodetect_charset(content=_content)\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception detecting response content's encoding. Details: {exc}\"\n        )\n        log.error(msg)\n        log.warning(\"Defaulting to 'utf-8'\")\n\n        decode_charset: str = \"utf-8\"\n\n    ## Decode content\n    try:\n        _decode: str = res.content.decode(decode_charset)\n\n    except Exception as exc:\n        ## Decoding failed, retry with different encodings\n        msg = Exception(\n            f\"[Attempt 1/2] Unhandled exception decoding response content. Details: {exc}\"\n        )\n        log.warning(msg)\n\n        if not res.encoding == \"utf-8\":\n            ## Try decoding again, using response's .encoding param\n            log.warning(\n                f\"Retrying response content decode with encoding '{res.encoding}'\"\n            )\n            try:\n                _decode = res.content.decode(res.encoding)\n            except Exception as exc:\n                inner_msg = Exception(\n                    f\"[Attempt 2/2] Unhandled exception decoding response content. Details: {exc}\"\n                )\n                log.error(inner_msg)\n\n                raise inner_msg\n\n        else:\n            ## Decoding with utf-8 failed, attempt with ISO-8859-1\n            #  https://en.wikipedia.org/wiki/ISO/IEC_8859-1\n            log.warning(\n                \"Detected UTF-8 encoding, but decoding as UTF-8 failed. Retrying with encoding ISO-8859-1.\"\n            )\n            try:\n                _decode = res.content.decode(\"ISO-8859-1\")\n            except Exception as exc:\n                msg = Exception(\n                    f\"Failure attempting to decode content as UTF-8 and ISO-8859-1. Details: {exc}\"\n                )\n                log.error(msg)\n\n                raise exc\n\n    ## Load decoded content into dict\n    try:\n        _json: dict = json.loads(_decode)\n\n        return _json\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception loading decoded response content to dict. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/__init__/#red_utils.ext.httpx_utils.HishelCacheClientController.new_request","title":"<code>new_request(method='GET', url=None, files=None, _json=None, params=None, headers=None, cookies=None, timeout=None)</code>","text":"<p>Assemble a new httpx.Request object from parts.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>[Default: \"GET\"] HTTP method for request.</p> <code>'GET'</code> <code>url</code> <code>str | URL</code> <p>URL to send request.</p> <code>None</code> <code>files</code> <code>list | None</code> <p>List of files to send with request. Only works with certain HTTP methods, list <code>POST</code>.</p> <code>None</code> <code>_json</code> <code>Any | None</code> <p>JSON to append to request.</p> <code>None</code> <code>params</code> <code>dict | None</code> <p>Params to append to request.</p> <code>None</code> <code>headers</code> <code>dict | None</code> <p>Request headers.</p> <code>None</code> <code>cookies</code> <code>dict</code> <p> <code>None</code> <code>timeout</code> <code>int | float</code> <p>Timeout (in seconds) before cancelling request.</p> <code>None</code> <p>Returns:</p> Type Description <code>Request</code> <p>An initialized <code>httpx.Request</code> object.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>def new_request(\n    self,\n    method: str = \"GET\",\n    url: str = None,\n    files: list | None = None,\n    _json: t.Any | None = None,\n    params: dict | None = None,\n    headers: dict | None = None,\n    cookies: dict | None = None,\n    timeout: int | float | None = None,\n) -&gt; httpx.Request:\n    \"\"\"Assemble a new httpx.Request object from parts.\n\n    Params:\n        method (str): [Default: \"GET\"] HTTP method for request.\n        url (str|httpx.URL): URL to send request.\n        files (list|None): List of files to send with request. Only works with certain HTTP methods,\n            list `POST`.\n        _json (t.Any | None): JSON to append to request.\n        params (dict | None): Params to append to request.\n        headers (dict|None): Request headers.\n        cookies (dict): &lt;Not yet documented&gt;\n        timeout (int|float): Timeout (in seconds) before cancelling request.\n\n    Returns:\n        (httpx.Request): An initialized `httpx.Request` object.\n\n    \"\"\"\n    assert method, ValueError(\"Missing a request method\")\n    assert isinstance(method, str), TypeError(\n        f\"method should be a string. Got type: ({type(method)})\"\n    )\n\n    ## Ensure method is uppercase, i.e. 'get' -&gt; 'GET'\n    method: str = method.upper()\n\n    assert url, ValueError(\"Missing a URL\")\n    assert isinstance(url, str) or isinstance(url, httpx.URL), TypeError(\n        f\"URL must be a string or httpx.URL. Got type: ({type(url)})\"\n    )\n    if isinstance(url, str):\n        ## Convert URL from string into httpx.URL object\n        url: httpx.URL = httpx.URL(url=url)\n\n    if timeout:\n        assert (\n            isinstance(timeout, int) or isinstance(timeout, float)\n        ) and timeout &gt; 0, TypeError(\n            f\"timeout must be a non-zero positive int or float. Got type: ({type(timeout)})\"\n        )\n\n    ## Build httpx.Request object\n    try:\n        _req: httpx.Request = self.client.build_request(\n            method=method,\n            url=url,\n            files=files,\n            json=_json,\n            params=params,\n            headers=headers,\n            cookies=cookies,\n            timeout=timeout,\n        )\n\n        return _req\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception creaeting httpx.Request object. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/__init__/#red_utils.ext.httpx_utils.HishelCacheClientController.send_request","title":"<code>send_request(request=None, stream=False, auth=None, debug_response=False)</code>","text":"<p>Send httpx.Request using self.Client (and optional cache transport).</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>An initialized <code>httpx.Request</code> object.</p> <code>None</code> <code>stream</code> <code>bool</code> <p>When <code>True</code>, response bytes will be streamed. This can be useful for large file downloads.</p> <code>False</code> <code>auth</code> <code>Auth</code> <p> <code>None</code> <p>Returns:</p> Type Description <code>Response</code> <p>An <code>httpx.Response</code> from the request.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>def send_request(\n    self,\n    request: httpx.Request = None,\n    stream: bool = False,\n    auth: httpx.Auth = None,\n    debug_response: bool = False,\n) -&gt; httpx.Response:\n    \"\"\"Send httpx.Request using self.Client (and optional cache transport).\n\n    Params:\n        request (httpx.Request): An initialized `httpx.Request` object.\n        stream (bool): When `True`, response bytes will be streamed. This can be useful for large file downloads.\n        auth (httpx.Auth): &lt;Not yet documented&gt;\n\n    Returns:\n        (httpx.Response): An `httpx.Response` from the request.\n\n    \"\"\"\n    assert request, ValueError(\"Missing an httpx.Request object\")\n    assert isinstance(request, httpx.Request), TypeError(\n        f\"Expected request to be an httpx.Request object. Got type: ({type(request)})\"\n    )\n\n    ## Send request using class's httpx.Client\n    try:\n        res: httpx.Response = self.client.send(\n            request=request,\n            stream=stream,\n            auth=auth,\n            follow_redirects=self.follow_redirects,\n        )\n        if debug_response:\n            log.debug(\n                f\"Response: [{res.status_code}: {res.reason_phrase}] {request.url}\"\n            )\n\n        return res\n\n    except httpx.ConnectError as conn_err:\n        ## Error connecting to remote\n        msg = Exception(\n            f\"ConnectError while requesting URL {request.url}. Details: {conn_err}\"\n        )\n        log.error(msg)\n\n        return\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception sending request. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/__init__/#red_utils.ext.httpx_utils.build_request","title":"<code>build_request(method='GET', url=None, params=None, headers=None, cookies=None, content=None, data=None, files=None, json=None, stream=None, extensions=None)</code>","text":"<p>Build an <code>httpx.Request()</code> object from inputs.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>(default=\"GET\") The HTTP method for the request.</p> <code>'GET'</code> <code>url</code> <code>str</code> <p>The URL to send request to.</p> <code>None</code> <code>files</code> <code>list</code> <p>List of files to send with request.</p> <code>None</code> <code>data</code> <code>Any</code> <p> <code>None</code> <code>contents</code> <code>bytes</code> <p>Byte-encoded request content.</p> required <code>params</code> <code>dict</code> <p>URL params for request. Pass each param as a key/value pair, like: <code>{\"api_key\": api_key, \"days\": 15, \"page\": 2}</code></p> <code>None</code> <code>headers</code> <code>dict</code> <p>Headers for request.</p> <code>None</code> <code>cookies</code> <code>dict</code> <p>Cookies for request.</p> <code>None</code> <code>extensions</code> <code>dict</code> <p>Extensions for request. Example: <code>{\"timeout\": {\"connect\": 5.0}}</code>.</p> <code>None</code> <code>stream</code> <code>SyncByteStream | AsyncByteSTream</code> <p> <code>None</code> Source code in <code>src\\red_utils\\ext\\httpx_utils\\operations.py</code> <pre><code>def build_request(\n    method: str = \"GET\",\n    url: t.Union[URL, str] = None,\n    params: QueryParamTypes | None = None,\n    headers: HeaderTypes | None = None,\n    cookies: CookieTypes | None = None,\n    content: RequestContent | None = None,\n    data: RequestData | None = None,\n    files: RequestFiles | None = None,\n    json: t.Any | None = None,\n    stream: t.Union[SyncByteStream, AsyncByteStream] | None = None,\n    extensions: RequestExtensions | None = None,\n) -&gt; httpx.Request:\n    \"\"\"Build an `httpx.Request()` object from inputs.\n\n    Params:\n        method (str): (default=\"GET\") The HTTP method for the request.\n        url (str): The URL to send request to.\n        files (list): List of files to send with request.\n        data (Any): &lt;UNDOCUMENTED&gt;\n        contents (bytes): Byte-encoded request content.\n        params (dict): URL params for request. Pass each param as a key/value pair, like:\n            `{\"api_key\": api_key, \"days\": 15, \"page\": 2}`\n        headers (dict): Headers for request.\n        cookies (dict): Cookies for request.\n        extensions (dict): Extensions for request. Example: `{\"timeout\": {\"connect\": 5.0}}`.\n        stream (httpx.SyncByteStream | httpx.AsyncByteSTream): &lt;UNDOCUMENTED&gt;\n    \"\"\"\n    method: str = method.upper()\n    method = validate_method(method=method)\n\n    try:\n        _request: httpx.Request = httpx.Request(\n            method=method,\n            url=url,\n            params=params,\n            headers=headers,\n            cookies=cookies,\n            content=content,\n            data=data,\n            files=files,\n            json=json,\n            extensions=extensions,\n            stream=stream,\n        )\n        return _request\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception building httpx.Request object. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/__init__/#red_utils.ext.httpx_utils.get_cache_transport","title":"<code>get_cache_transport(cache_dir='.cache/hishel', ttl=None, verify=True, retries=0, cert=None)</code>","text":"<p>Return an initialized hishel.CacheTransport.</p> <p>Parameters:</p> Name Type Description Default <code>cache_dir</code> <code>str</code> <p>[default: .cache/hishel] Directory where cache files will be stored.</p> <code>'.cache/hishel'</code> <code>ttl</code> <code>int | None</code> <p>[default: None] Limit ttl on requests sent with this transport.</p> <code>None</code> <code>verify</code> <code>bool</code> <p>[default: True] Verify SSL certificates on requests sent with this transport.</p> <code>True</code> <code>retries</code> <code>int</code> <p>[default: 0] Number of times to retry requests sent with this transport.</p> <code>0</code> <code>cert</code> <code>valid HTTPX Cert</code> <p>An optional SSL certificate to send with requests.</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\httpx_utils\\transports\\_transports.py</code> <pre><code>def get_cache_transport(\n    cache_dir: str = \".cache/hishel\",\n    ttl: int | None = None,\n    verify: bool = True,\n    retries: int = 0,\n    cert: t.Union[\n        str, tuple[str, str | None], tuple[str, str | None, str | None]\n    ] = None,\n) -&gt; hishel.CacheTransport:\n    \"\"\"Return an initialized hishel.CacheTransport.\n\n    Params:\n        cache_dir (str): [default: .cache/hishel] Directory where cache files will be stored.\n        ttl (int|None): [default: None] Limit ttl on requests sent with this transport.\n        verify (bool): [default: True] Verify SSL certificates on requests sent with this transport.\n        retries (int): [default: 0] Number of times to retry requests sent with this transport.\n        cert (valid HTTPX Cert): An optional SSL certificate to send with requests.\n\n    \"\"\"\n    # Create a cache instance with hishel\n    cache_storage = hishel.FileStorage(base_path=cache_dir, ttl=ttl)\n    cache_transport = httpx.HTTPTransport(verify=verify, cert=cert, retries=retries)\n\n    try:\n        # Create an HTTP cache transport\n        cache_transport = hishel.CacheTransport(\n            transport=cache_transport, storage=cache_storage\n        )\n\n        return cache_transport\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception returning cache transport. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/__init__/#red_utils.ext.httpx_utils.get_req_client","title":"<code>get_req_client(auth=None, params=None, headers=None, cookies=None, verify=True, cert=None, http1=True, http2=False, proxy=None, proxies=None, mounts=None, timeout=5.0, follow_redirects=False, limits={'max_connections': 100, 'max_keepalive_connections': 20}, max_redirects=20, event_hooks=None, base_url='', transport=None, app=None, trust_env=True, default_encoding='utf-8')</code>","text":"<p>Build an HTTPX Client from input parameters.</p> <p>Parameters:</p> Name Type Description Default <code>auth</code> <code>AuthTypes | None</code> <code>None</code> <code>params</code> <code>Union[QueryParamTypes, dict] | None</code> <code>None</code> <code>headers</code> <code>Union[HeaderTypes, dict] | None</code> <code>None</code> <code>cookies</code> <code>CookieTypes | None</code> <code>None</code> <code>verify</code> <code>VerifyTypes</code> <code>True</code> <code>cert</code> <code>CertTypes | None</code> <code>None</code> <code>http1</code> <code>bool</code> <code>True</code> <code>http2</code> <code>bool</code> <code>False</code> <code>proxy</code> <code>ProxyTypes | None</code> <code>None</code> <code>proxies</code> <code>ProxiesTypes | None</code> <code>None</code> <code>mounts</code> <code>Mapping[str, BaseTransport | None] | None</code> <code>None</code> <code>timeout</code> <code>Union[int, float, TimeoutTypes] | None</code> <code>5.0</code> <code>follow_redirects</code> <code>bool</code> <code>False</code> <code>limits</code> <code>Union[dict, Limits]</code> <code>{'max_connections': 100, 'max_keepalive_connections': 20}</code> <code>event_hooks</code> <code>Mapping[str, list[EventHook]] | None</code> <code>None</code> <code>base_url</code> <code>URLTypes</code> <code>''</code> <code>transport</code> <code>BaseTransport | None</code> <code>None</code> <code>app</code> <code>Callable[..., Any] | None</code> <code>None</code> <code>trust_env</code> <code>bool</code> <code>True</code> <code>default_encoding</code> <code>str | bytes</code> <code>'utf-8'</code> <p>Returns:</p> Type Description <code>Client</code> <p>An initialized HTTPX client.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\operations.py</code> <pre><code>def get_req_client(\n    auth: AuthTypes | None = None,\n    params: t.Union[QueryParamTypes, dict] | None = None,\n    headers: t.Union[HeaderTypes, dict] | None = None,\n    cookies: CookieTypes | None = None,\n    verify: VerifyTypes = True,\n    cert: CertTypes | None = None,\n    http1: bool = True,\n    http2: bool = False,\n    proxy: ProxyTypes | None = None,\n    proxies: ProxiesTypes | None = None,\n    mounts: t.Mapping[str, BaseTransport | None] | None = None,\n    timeout: t.Union[int, float, TimeoutTypes] | None = 5.0,\n    follow_redirects: bool = False,\n    limits: t.Union[dict, Limits] = {\n        \"max_connections\": 100,\n        \"max_keepalive_connections\": 20,\n    },\n    max_redirects: int | None = 20,\n    event_hooks: t.Mapping[str, list[EventHook]] | None = None,\n    base_url: URLTypes = \"\",\n    transport: BaseTransport | None = None,\n    app: t.Callable[..., t.Any] | None = None,\n    trust_env: bool = True,\n    default_encoding: str | bytes = \"utf-8\",\n) -&gt; httpx.Client:\n    \"\"\"Build an HTTPX Client from input parameters.\n\n    Params:\n        auth (AuthTypes | None):\n        params (t.Union[QueryParamTypes, dict] | None):\n        headers (t.Union[HeaderTypes, dict] | None):\n        cookies (CookieTypes | None):\n        verify (VerifyTypes):\n        cert (CertTypes | None):\n        http1 (bool):\n        http2 (bool):\n        proxy (ProxyTypes | None):\n        proxies (ProxiesTypes | None):\n        mounts (t.Mapping[str, BaseTransport | None] | None):\n        timeout (t.Union[int, float, TimeoutTypes] | None):\n        follow_redirects (bool):\n        limits (t.Union[dict, Limits]):\n        event_hooks (t.Mapping[str, list[EventHook]] | None):\n        base_url (URLTypes):\n        transport (BaseTransport | None):\n        app (t.Callable[..., t.Any] | None):\n        trust_env (bool):\n        default_encoding (str | bytes):\n\n    Returns:\n        (httpx.Client): An initialized HTTPX client.\n\n    \"\"\"\n    timeout: httpx.Timeout = httpx.Timeout(timeout)\n    if isinstance(limits, dict):\n        limits: Limits = Limits(**limits)\n\n    try:\n        _client: Client = Client(\n            headers=headers,\n            timeout=timeout,\n            auth=auth,\n            params=params,\n            cookies=cookies,\n            verify=verify,\n            cert=cert,\n            http1=http1,\n            http2=http2,\n            proxy=proxy,\n            proxies=proxies,\n            mounts=mounts,\n            follow_redirects=follow_redirects,\n            max_redirects=max_redirects,\n            event_hooks=event_hooks,\n            base_url=base_url,\n            transport=transport,\n            app=app,\n            trust_env=trust_env,\n            default_encoding=default_encoding,\n        )\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception building HTTPX RequestClient. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n\n    validate_client(_client)\n\n    return _client\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/__init__/#red_utils.ext.httpx_utils.make_request","title":"<code>make_request(client=None, url=None, method='GET', headers=None, timeout=None, data=None)</code>","text":"<p>Make a request with HTTPX.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\operations.py</code> <pre><code>def make_request(\n    client: Client = None,\n    url: str = None,\n    method: str = \"GET\",\n    headers: dict = None,\n    timeout: int | None = None,\n    data: dict | None = None,\n) -&gt; httpx.Response:\n    \"\"\"Make a request with HTTPX.\"\"\"\n    validate_method(method)\n\n    if not client:\n        log.warning(\n            \"No request client passed to make_request() function. Getting default client.\"\n        )\n\n        client = get_req_client(headers=headers, timeout=timeout, data=data)\n\n    validate_client(client=client)\n\n    if not isinstance(client, Client):\n        raise TypeError(\n            f\"Invalid type for client: {type(client)}. Must be of type {type(Client)}\"\n        )\n\n    if not url:\n        raise ValueError(\"Missing request URL\")\n\n    if not isinstance(url, str):\n        raise TypeError(f\"Invalid type for request URL: {type(url)}\")\n\n    if timeout:\n        if not isinstance(timeout, int):\n            raise TypeError(f\"Invalid type for timeout: {type(timeout)}\")\n\n    try:\n        ## Determine type of request to make\n        match method:\n            case \"GET\":\n                client = get_req_client(headers=headers, timeout=timeout)\n\n                res = client.get(url=url)\n\n            case _:\n                raise ValueError(f\"Invalid method: {method}\")\n\n        return res\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception creating request client. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/__init__/#red_utils.ext.httpx_utils.merge_headers","title":"<code>merge_headers(original_headers=default_headers, update_vals=None)</code>","text":"<p>Merge header dicts into new headers dict.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\operations.py</code> <pre><code>def merge_headers(\n    original_headers: dict[str, str] = default_headers,\n    update_vals: dict[str, str] = None,\n) -&gt; dict[str, str]:\n    \"\"\"Merge header dicts into new headers dict.\"\"\"\n    validate_headers(original_headers)\n    validate_headers(update_vals)\n\n    try:\n        _headers: dict = {**update_vals, **original_headers}\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception merging header dicts. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n\n    return _headers\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/__init__/#red_utils.ext.httpx_utils.validate_client","title":"<code>validate_client(client=None)</code>","text":"<p>Validate HTTPX Client/AsyncClient object.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\validators.py</code> <pre><code>def validate_client(\n    client: Union[Client, AsyncClient] = None\n) -&gt; Union[Client, AsyncClient]:\n    \"\"\"Validate HTTPX Client/AsyncClient object.\"\"\"\n    if not client:\n        raise ValueError(\"Missing client to evaluate\")\n\n    if not isinstance(client, Client) and not isinstance(client, AsyncClient):\n        raise TypeError(\n            f\"Invalid type for client: {type(client)}. Must be one of [{Client}, {AsyncClient}]\"\n        )\n\n    return client\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/__init__/#red_utils.ext.httpx_utils.validate_method","title":"<code>validate_method(method=None)</code>","text":"<p>Validate an HTTPX request method.</p> <p>Params: - method (str): The method to validate.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\validators.py</code> <pre><code>def validate_method(method: str = None) -&gt; str:\n    \"\"\"Validate an HTTPX request method.\n\n    Params:\n    - method (str): The method to validate.\n    \"\"\"\n    if method is None:\n        raise ValueError(\"Missing a method to validate\")\n    if not isinstance(method, str):\n        try:\n            method: str = str(method).upper()\n        except Exception as exc:\n            raise Exception(\n                f\"Unable to coerce method value to string: ({type(method)}) - {method}. Details: {exc}\"\n            )\n    else:\n        method: str = method.upper()\n\n    if method not in valid_methods:\n        raise ValueError(f\"Invalid method: {method}. Must be one of {valid_methods}\")\n\n    return method\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/classes/","title":"classes","text":""},{"location":"reference/red_utils/ext/httpx_utils/classes/#red_utils.ext.httpx_utils.classes.DictMixin","title":"<code>DictMixin</code>  <code>dataclass</code>","text":"<p>Mixin class to add \"as_dict()\" method to classes. Equivalent to .dict.</p> <p>Adds a <code>.as_dict()</code> method to classes that inherit from this mixin. For example, to add <code>.as_dict()</code> method to a parent class, where all children inherit the .as_dict() function, declare parent as:</p> <pre><code>@dataclass\nclass Parent(DictMixin):\n    ...\n</code></pre> <p>and call like:</p> <pre><code>p = Parent()\np_dict = p.as_dict()\n</code></pre> Source code in <code>src\\red_utils\\core\\dataclass_utils\\mixins\\mixin_classes.py</code> <pre><code>@dataclass\nclass DictMixin:\n    \"\"\"Mixin class to add \"as_dict()\" method to classes. Equivalent to .__dict__.\n\n    Adds a `.as_dict()` method to classes that inherit from this mixin. For example,\n    to add `.as_dict()` method to a parent class, where all children inherit the .as_dict()\n    function, declare parent as:\n\n    ``` py linenums=\"1\"\n    @dataclass\n    class Parent(DictMixin):\n        ...\n    ```\n\n    and call like:\n\n    ``` py linenums=\"1\"\n    p = Parent()\n    p_dict = p.as_dict()\n    ```\n    \"\"\"\n\n    def as_dict(self: Generic[T]):\n        \"\"\"Return dict representation of a dataclass instance.\n\n        Description:\n            Any class that inherits from `DictMixin` will automatically have a method `.as_dict()`.\n                There are no extra params.\n\n        Returns:\n            (dict): A Python `dict` representation of a Python `dataclass` class.\n\n        \"\"\"\n        try:\n            return self.__dict__.copy()\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception converting class instance to dict. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/classes/#red_utils.ext.httpx_utils.classes.DictMixin.as_dict","title":"<code>as_dict()</code>","text":"<p>Return dict representation of a dataclass instance.</p> Description <p>Any class that inherits from <code>DictMixin</code> will automatically have a method <code>.as_dict()</code>.     There are no extra params.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A Python <code>dict</code> representation of a Python <code>dataclass</code> class.</p> Source code in <code>src\\red_utils\\core\\dataclass_utils\\mixins\\mixin_classes.py</code> <pre><code>def as_dict(self: Generic[T]):\n    \"\"\"Return dict representation of a dataclass instance.\n\n    Description:\n        Any class that inherits from `DictMixin` will automatically have a method `.as_dict()`.\n            There are no extra params.\n\n    Returns:\n        (dict): A Python `dict` representation of a Python `dataclass` class.\n\n    \"\"\"\n    try:\n        return self.__dict__.copy()\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception converting class instance to dict. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/classes/#red_utils.ext.httpx_utils.classes.validate_client","title":"<code>validate_client(client=None)</code>","text":"<p>Validate HTTPX Client/AsyncClient object.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\validators.py</code> <pre><code>def validate_client(\n    client: Union[Client, AsyncClient] = None\n) -&gt; Union[Client, AsyncClient]:\n    \"\"\"Validate HTTPX Client/AsyncClient object.\"\"\"\n    if not client:\n        raise ValueError(\"Missing client to evaluate\")\n\n    if not isinstance(client, Client) and not isinstance(client, AsyncClient):\n        raise TypeError(\n            f\"Invalid type for client: {type(client)}. Must be one of [{Client}, {AsyncClient}]\"\n        )\n\n    return client\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/classes/#red_utils.ext.httpx_utils.classes.validate_method","title":"<code>validate_method(method=None)</code>","text":"<p>Validate an HTTPX request method.</p> <p>Params: - method (str): The method to validate.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\validators.py</code> <pre><code>def validate_method(method: str = None) -&gt; str:\n    \"\"\"Validate an HTTPX request method.\n\n    Params:\n    - method (str): The method to validate.\n    \"\"\"\n    if method is None:\n        raise ValueError(\"Missing a method to validate\")\n    if not isinstance(method, str):\n        try:\n            method: str = str(method).upper()\n        except Exception as exc:\n            raise Exception(\n                f\"Unable to coerce method value to string: ({type(method)}) - {method}. Details: {exc}\"\n            )\n    else:\n        method: str = method.upper()\n\n    if method not in valid_methods:\n        raise ValueError(f\"Invalid method: {method}. Must be one of {valid_methods}\")\n\n    return method\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/constants/","title":"constants","text":""},{"location":"reference/red_utils/ext/httpx_utils/operations/","title":"operations","text":""},{"location":"reference/red_utils/ext/httpx_utils/operations/#red_utils.ext.httpx_utils.operations.build_request","title":"<code>build_request(method='GET', url=None, params=None, headers=None, cookies=None, content=None, data=None, files=None, json=None, stream=None, extensions=None)</code>","text":"<p>Build an <code>httpx.Request()</code> object from inputs.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>(default=\"GET\") The HTTP method for the request.</p> <code>'GET'</code> <code>url</code> <code>str</code> <p>The URL to send request to.</p> <code>None</code> <code>files</code> <code>list</code> <p>List of files to send with request.</p> <code>None</code> <code>data</code> <code>Any</code> <p> <code>None</code> <code>contents</code> <code>bytes</code> <p>Byte-encoded request content.</p> required <code>params</code> <code>dict</code> <p>URL params for request. Pass each param as a key/value pair, like: <code>{\"api_key\": api_key, \"days\": 15, \"page\": 2}</code></p> <code>None</code> <code>headers</code> <code>dict</code> <p>Headers for request.</p> <code>None</code> <code>cookies</code> <code>dict</code> <p>Cookies for request.</p> <code>None</code> <code>extensions</code> <code>dict</code> <p>Extensions for request. Example: <code>{\"timeout\": {\"connect\": 5.0}}</code>.</p> <code>None</code> <code>stream</code> <code>SyncByteStream | AsyncByteSTream</code> <p> <code>None</code> Source code in <code>src\\red_utils\\ext\\httpx_utils\\operations.py</code> <pre><code>def build_request(\n    method: str = \"GET\",\n    url: t.Union[URL, str] = None,\n    params: QueryParamTypes | None = None,\n    headers: HeaderTypes | None = None,\n    cookies: CookieTypes | None = None,\n    content: RequestContent | None = None,\n    data: RequestData | None = None,\n    files: RequestFiles | None = None,\n    json: t.Any | None = None,\n    stream: t.Union[SyncByteStream, AsyncByteStream] | None = None,\n    extensions: RequestExtensions | None = None,\n) -&gt; httpx.Request:\n    \"\"\"Build an `httpx.Request()` object from inputs.\n\n    Params:\n        method (str): (default=\"GET\") The HTTP method for the request.\n        url (str): The URL to send request to.\n        files (list): List of files to send with request.\n        data (Any): &lt;UNDOCUMENTED&gt;\n        contents (bytes): Byte-encoded request content.\n        params (dict): URL params for request. Pass each param as a key/value pair, like:\n            `{\"api_key\": api_key, \"days\": 15, \"page\": 2}`\n        headers (dict): Headers for request.\n        cookies (dict): Cookies for request.\n        extensions (dict): Extensions for request. Example: `{\"timeout\": {\"connect\": 5.0}}`.\n        stream (httpx.SyncByteStream | httpx.AsyncByteSTream): &lt;UNDOCUMENTED&gt;\n    \"\"\"\n    method: str = method.upper()\n    method = validate_method(method=method)\n\n    try:\n        _request: httpx.Request = httpx.Request(\n            method=method,\n            url=url,\n            params=params,\n            headers=headers,\n            cookies=cookies,\n            content=content,\n            data=data,\n            files=files,\n            json=json,\n            extensions=extensions,\n            stream=stream,\n        )\n        return _request\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception building httpx.Request object. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/operations/#red_utils.ext.httpx_utils.operations.get_req_client","title":"<code>get_req_client(auth=None, params=None, headers=None, cookies=None, verify=True, cert=None, http1=True, http2=False, proxy=None, proxies=None, mounts=None, timeout=5.0, follow_redirects=False, limits={'max_connections': 100, 'max_keepalive_connections': 20}, max_redirects=20, event_hooks=None, base_url='', transport=None, app=None, trust_env=True, default_encoding='utf-8')</code>","text":"<p>Build an HTTPX Client from input parameters.</p> <p>Parameters:</p> Name Type Description Default <code>auth</code> <code>AuthTypes | None</code> <code>None</code> <code>params</code> <code>Union[QueryParamTypes, dict] | None</code> <code>None</code> <code>headers</code> <code>Union[HeaderTypes, dict] | None</code> <code>None</code> <code>cookies</code> <code>CookieTypes | None</code> <code>None</code> <code>verify</code> <code>VerifyTypes</code> <code>True</code> <code>cert</code> <code>CertTypes | None</code> <code>None</code> <code>http1</code> <code>bool</code> <code>True</code> <code>http2</code> <code>bool</code> <code>False</code> <code>proxy</code> <code>ProxyTypes | None</code> <code>None</code> <code>proxies</code> <code>ProxiesTypes | None</code> <code>None</code> <code>mounts</code> <code>Mapping[str, BaseTransport | None] | None</code> <code>None</code> <code>timeout</code> <code>Union[int, float, TimeoutTypes] | None</code> <code>5.0</code> <code>follow_redirects</code> <code>bool</code> <code>False</code> <code>limits</code> <code>Union[dict, Limits]</code> <code>{'max_connections': 100, 'max_keepalive_connections': 20}</code> <code>event_hooks</code> <code>Mapping[str, list[EventHook]] | None</code> <code>None</code> <code>base_url</code> <code>URLTypes</code> <code>''</code> <code>transport</code> <code>BaseTransport | None</code> <code>None</code> <code>app</code> <code>Callable[..., Any] | None</code> <code>None</code> <code>trust_env</code> <code>bool</code> <code>True</code> <code>default_encoding</code> <code>str | bytes</code> <code>'utf-8'</code> <p>Returns:</p> Type Description <code>Client</code> <p>An initialized HTTPX client.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\operations.py</code> <pre><code>def get_req_client(\n    auth: AuthTypes | None = None,\n    params: t.Union[QueryParamTypes, dict] | None = None,\n    headers: t.Union[HeaderTypes, dict] | None = None,\n    cookies: CookieTypes | None = None,\n    verify: VerifyTypes = True,\n    cert: CertTypes | None = None,\n    http1: bool = True,\n    http2: bool = False,\n    proxy: ProxyTypes | None = None,\n    proxies: ProxiesTypes | None = None,\n    mounts: t.Mapping[str, BaseTransport | None] | None = None,\n    timeout: t.Union[int, float, TimeoutTypes] | None = 5.0,\n    follow_redirects: bool = False,\n    limits: t.Union[dict, Limits] = {\n        \"max_connections\": 100,\n        \"max_keepalive_connections\": 20,\n    },\n    max_redirects: int | None = 20,\n    event_hooks: t.Mapping[str, list[EventHook]] | None = None,\n    base_url: URLTypes = \"\",\n    transport: BaseTransport | None = None,\n    app: t.Callable[..., t.Any] | None = None,\n    trust_env: bool = True,\n    default_encoding: str | bytes = \"utf-8\",\n) -&gt; httpx.Client:\n    \"\"\"Build an HTTPX Client from input parameters.\n\n    Params:\n        auth (AuthTypes | None):\n        params (t.Union[QueryParamTypes, dict] | None):\n        headers (t.Union[HeaderTypes, dict] | None):\n        cookies (CookieTypes | None):\n        verify (VerifyTypes):\n        cert (CertTypes | None):\n        http1 (bool):\n        http2 (bool):\n        proxy (ProxyTypes | None):\n        proxies (ProxiesTypes | None):\n        mounts (t.Mapping[str, BaseTransport | None] | None):\n        timeout (t.Union[int, float, TimeoutTypes] | None):\n        follow_redirects (bool):\n        limits (t.Union[dict, Limits]):\n        event_hooks (t.Mapping[str, list[EventHook]] | None):\n        base_url (URLTypes):\n        transport (BaseTransport | None):\n        app (t.Callable[..., t.Any] | None):\n        trust_env (bool):\n        default_encoding (str | bytes):\n\n    Returns:\n        (httpx.Client): An initialized HTTPX client.\n\n    \"\"\"\n    timeout: httpx.Timeout = httpx.Timeout(timeout)\n    if isinstance(limits, dict):\n        limits: Limits = Limits(**limits)\n\n    try:\n        _client: Client = Client(\n            headers=headers,\n            timeout=timeout,\n            auth=auth,\n            params=params,\n            cookies=cookies,\n            verify=verify,\n            cert=cert,\n            http1=http1,\n            http2=http2,\n            proxy=proxy,\n            proxies=proxies,\n            mounts=mounts,\n            follow_redirects=follow_redirects,\n            max_redirects=max_redirects,\n            event_hooks=event_hooks,\n            base_url=base_url,\n            transport=transport,\n            app=app,\n            trust_env=trust_env,\n            default_encoding=default_encoding,\n        )\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception building HTTPX RequestClient. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n\n    validate_client(_client)\n\n    return _client\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/operations/#red_utils.ext.httpx_utils.operations.make_request","title":"<code>make_request(client=None, url=None, method='GET', headers=None, timeout=None, data=None)</code>","text":"<p>Make a request with HTTPX.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\operations.py</code> <pre><code>def make_request(\n    client: Client = None,\n    url: str = None,\n    method: str = \"GET\",\n    headers: dict = None,\n    timeout: int | None = None,\n    data: dict | None = None,\n) -&gt; httpx.Response:\n    \"\"\"Make a request with HTTPX.\"\"\"\n    validate_method(method)\n\n    if not client:\n        log.warning(\n            \"No request client passed to make_request() function. Getting default client.\"\n        )\n\n        client = get_req_client(headers=headers, timeout=timeout, data=data)\n\n    validate_client(client=client)\n\n    if not isinstance(client, Client):\n        raise TypeError(\n            f\"Invalid type for client: {type(client)}. Must be of type {type(Client)}\"\n        )\n\n    if not url:\n        raise ValueError(\"Missing request URL\")\n\n    if not isinstance(url, str):\n        raise TypeError(f\"Invalid type for request URL: {type(url)}\")\n\n    if timeout:\n        if not isinstance(timeout, int):\n            raise TypeError(f\"Invalid type for timeout: {type(timeout)}\")\n\n    try:\n        ## Determine type of request to make\n        match method:\n            case \"GET\":\n                client = get_req_client(headers=headers, timeout=timeout)\n\n                res = client.get(url=url)\n\n            case _:\n                raise ValueError(f\"Invalid method: {method}\")\n\n        return res\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception creating request client. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/operations/#red_utils.ext.httpx_utils.operations.merge_headers","title":"<code>merge_headers(original_headers=default_headers, update_vals=None)</code>","text":"<p>Merge header dicts into new headers dict.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\operations.py</code> <pre><code>def merge_headers(\n    original_headers: dict[str, str] = default_headers,\n    update_vals: dict[str, str] = None,\n) -&gt; dict[str, str]:\n    \"\"\"Merge header dicts into new headers dict.\"\"\"\n    validate_headers(original_headers)\n    validate_headers(update_vals)\n\n    try:\n        _headers: dict = {**update_vals, **original_headers}\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception merging header dicts. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n\n    return _headers\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/operations/#red_utils.ext.httpx_utils.operations.validate_client","title":"<code>validate_client(client=None)</code>","text":"<p>Validate HTTPX Client/AsyncClient object.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\validators.py</code> <pre><code>def validate_client(\n    client: Union[Client, AsyncClient] = None\n) -&gt; Union[Client, AsyncClient]:\n    \"\"\"Validate HTTPX Client/AsyncClient object.\"\"\"\n    if not client:\n        raise ValueError(\"Missing client to evaluate\")\n\n    if not isinstance(client, Client) and not isinstance(client, AsyncClient):\n        raise TypeError(\n            f\"Invalid type for client: {type(client)}. Must be one of [{Client}, {AsyncClient}]\"\n        )\n\n    return client\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/operations/#red_utils.ext.httpx_utils.operations.validate_method","title":"<code>validate_method(method=None)</code>","text":"<p>Validate an HTTPX request method.</p> <p>Params: - method (str): The method to validate.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\validators.py</code> <pre><code>def validate_method(method: str = None) -&gt; str:\n    \"\"\"Validate an HTTPX request method.\n\n    Params:\n    - method (str): The method to validate.\n    \"\"\"\n    if method is None:\n        raise ValueError(\"Missing a method to validate\")\n    if not isinstance(method, str):\n        try:\n            method: str = str(method).upper()\n        except Exception as exc:\n            raise Exception(\n                f\"Unable to coerce method value to string: ({type(method)}) - {method}. Details: {exc}\"\n            )\n    else:\n        method: str = method.upper()\n\n    if method not in valid_methods:\n        raise ValueError(f\"Invalid method: {method}. Must be one of {valid_methods}\")\n\n    return method\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/validators/","title":"validators","text":""},{"location":"reference/red_utils/ext/httpx_utils/validators/#red_utils.ext.httpx_utils.validators.validate_client","title":"<code>validate_client(client=None)</code>","text":"<p>Validate HTTPX Client/AsyncClient object.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\validators.py</code> <pre><code>def validate_client(\n    client: Union[Client, AsyncClient] = None\n) -&gt; Union[Client, AsyncClient]:\n    \"\"\"Validate HTTPX Client/AsyncClient object.\"\"\"\n    if not client:\n        raise ValueError(\"Missing client to evaluate\")\n\n    if not isinstance(client, Client) and not isinstance(client, AsyncClient):\n        raise TypeError(\n            f\"Invalid type for client: {type(client)}. Must be one of [{Client}, {AsyncClient}]\"\n        )\n\n    return client\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/validators/#red_utils.ext.httpx_utils.validators.validate_method","title":"<code>validate_method(method=None)</code>","text":"<p>Validate an HTTPX request method.</p> <p>Params: - method (str): The method to validate.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\validators.py</code> <pre><code>def validate_method(method: str = None) -&gt; str:\n    \"\"\"Validate an HTTPX request method.\n\n    Params:\n    - method (str): The method to validate.\n    \"\"\"\n    if method is None:\n        raise ValueError(\"Missing a method to validate\")\n    if not isinstance(method, str):\n        try:\n            method: str = str(method).upper()\n        except Exception as exc:\n            raise Exception(\n                f\"Unable to coerce method value to string: ({type(method)}) - {method}. Details: {exc}\"\n            )\n    else:\n        method: str = method.upper()\n\n    if method not in valid_methods:\n        raise ValueError(f\"Invalid method: {method}. Must be one of {valid_methods}\")\n\n    return method\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/cache_storages/__init__/","title":"cache_storages","text":""},{"location":"reference/red_utils/ext/httpx_utils/cache_storages/_storages/","title":"_storages","text":""},{"location":"reference/red_utils/ext/httpx_utils/controllers/__init__/","title":"controllers","text":""},{"location":"reference/red_utils/ext/httpx_utils/controllers/__init__/#red_utils.ext.httpx_utils.controllers.HTTPXController","title":"<code>HTTPXController</code>","text":"<p>               Bases: <code>AbstractContextManager</code></p> <p>Handler for HTTPX client.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str | None</code> <p>Scope the httpx client to a URL.</p> <code>None</code> <code>base_url</code> <code>str | None</code> <p>A base URL will be prefixed to each request. I.e. if <code>base_url=\"https://example.com\", and you want to request \"https://example.com/endpoint,\" you can set the base URL and then request</code>/endpoint`.</p> <code>None</code> <code>proxy</code> <code>str | None</code> <p> <code>None</code> <code>proxies</code> <code>str | None</code> <p> <code>None</code> <code>mounts</code> <code>dict[str, HTTPTransport] | None</code> <p>A dict of <code>httpx.HTTPTransport</code> objects.</p> <code>{}</code> <code>cookies</code> <code>dict[str, Any]</code> <p> <code>{}</code> <code>auth</code> <code>Auth | None</code> <p> <code>None</code> <code>headers</code> <code>dict[str, str] | None</code> <p>Optional request headers to apply to all requests handled by controller instance.</p> <code>{}</code> <code>params</code> <code>dict[str, Any] | None</code> <p>Optional request params to apply to all requests handled by controller instance.</p> <code>{}</code> <code>follow_redirects</code> <code>bool</code> <p>[Default: False] Follow HTTP 302 redirects.</p> <code>False</code> <code>max_redirects</code> <code>int | None</code> <p>[Default: 20] Maximum number of HTTP 302 redirects to follow.</p> <code>20</code> <code>retries</code> <code>int | None</code> <p>Number of times to retry on request failure.</p> <code>None</code> <code>timeout</code> <code>int | float | None</code> <p>Timeout (in seconds) until client gives up on request.</p> <code>60</code> <code>limits</code> <code>Limits | None</code> <p> <code>None</code> <code>transport</code> <code>HTTPTransport | CacheTransport | None</code> <p>A transport to pass to class's <code>httpx.Client</code> object.</p> <code>None</code> <code>default_encoding</code> <code>str</code> <p>[Default: utf-8] Set default encoding for all requests.</p> <code>autodetect_charset</code> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>class HTTPXController(AbstractContextManager):\n    \"\"\"Handler for HTTPX client.\n\n    Params:\n        url (str|None): Scope the httpx client to a URL.\n        base_url (str|None): A base URL will be prefixed to each request. I.e. if `base_url=\"https://example.com\",\n            and you want to request \"https://example.com/endpoint,\" you can set the base URL and then request `/endpoint`.\n        proxy (str|None): &lt;Not yet documented&gt;\n        proxies (str|None): &lt;Not yet documented&gt;\n        mounts (dict[str, httpx.HTTPTransport]|None): A dict of `httpx.HTTPTransport` objects.\n        cookies (dict[str, Any]): &lt;Not yet documented&gt;\n        auth (httpx.Auth | None): &lt;Not yet documented&gt;\n        headers (dict[str, str]|None): Optional request headers to apply to all requests handled by controller instance.\n        params (dict[str, Any]|None): Optional request params to apply to all requests handled by controller instance.\n        follow_redirects (bool): [Default: False] Follow HTTP 302 redirects.\n        max_redirects (int|None): [Default: 20] Maximum number of HTTP 302 redirects to follow.\n        retries (int|None): Number of times to retry on request failure.\n        timeout (int|float|None): Timeout (in seconds) until client gives up on request.\n        limits (httpx.Limits | None): &lt;Not yet documented&gt;\n        transport (httpx.HTTPTransport|hishel.CacheTransport|None): A transport to pass to class's `httpx.Client` object.\n        default_encoding (str): [Default: utf-8] Set default encoding for all requests.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        url: str | None = None,\n        base_url: str | None = None,\n        proxy: str | None = None,\n        proxies: dict[str, str] | None = None,\n        mounts: dict[str, httpx.HTTPTransport] | None = {},\n        cookies: dict[str, t.Any] | None = {},\n        auth: httpx.Auth | None = None,\n        headers: dict[str, str] | None = {},\n        params: dict[str, t.Any] | None = {},\n        follow_redirects: bool = False,\n        max_redirects: int | None = 20,\n        retries: int | None = None,\n        timeout: t.Union[int, float] | None = 60,\n        limits: httpx.Limits | None = None,\n        transport: t.Union[httpx.HTTPTransport, hishel.CacheTransport] | None = None,\n        default_encoding: str = autodetect_charset,\n    ) -&gt; None:\n        self.url: httpx.URL | None = httpx.URL(url) if url else None\n        self.base_url: httpx.URL | None = httpx.URL(base_url) if base_url else None\n        self.proxy: str | None = proxy\n        self.proxies: dict[str, str] | None = proxies\n        self.mounts: dict[str, httpx.HTTPTransport] | None = mounts\n        self.auth: httpx.Auth | None = auth\n        self.headers: dict[str, str] | None = headers\n        self.cookies: dict[str, t.Any] | None = cookies\n        self.params: dict[str, str] | None = params\n        self.follow_redirects: bool = follow_redirects\n        self.max_redirects: int | None = max_redirects\n        self.retries: int | None = retries\n        self.timeout: t.Union[int, float] | None = timeout\n        self.limits: httpx.Limits | None = limits\n        self.transport: t.Union[httpx.HTTPTransport, hishel.CacheTransport] | None = (\n            transport\n        )\n        self.default_encoding: str = default_encoding\n\n        ## Placeholder for initialized httpx.Client\n        self.client: httpx.Client | None = None\n\n    def __enter__(self) -&gt; t.Self:\n        \"\"\"Execute when handler is called in a `with` statement.\n\n        Description:\n            Creates an `httpx.Client` object, using class parameters as options.\n        \"\"\"\n        try:\n            _client: httpx.Client = httpx.Client(\n                auth=self.auth,\n                params=self.params,\n                headers=self.headers,\n                cookies=self.cookies,\n                proxy=self.proxy,\n                proxies=self.proxies,\n                mounts=self.mounts,\n                timeout=self.timeout,\n                follow_redirects=self.follow_redirects,\n                max_redirects=self.max_redirects,\n                # base_url=self.base_url,\n                transport=self.transport,\n                default_encoding=self.default_encoding,\n            )\n\n            ## If base_url is None, an exception occurs. Set self.base_url\n            #  only if base_url is not None.\n            if self.base_url:\n                _client.base_url = self.base_url\n\n            self.client = _client\n\n            return self\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception initializing httpx Client. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        \"\"\"Execute  when `with` statement ends.\n\n        Description:\n            Show any exceptions/tracebacks. Close `self.client` on exit.\n\n        \"\"\"\n        if exc_type:\n            log.error(f\"({exc_type}): {exc_value}\")\n\n        if traceback:\n            log.error(f\"TRACE: {traceback}\")\n\n        ## Close httpx client\n        if self.client:\n            self.client.close()\n\n    def new_request(\n        self,\n        method: str = \"GET\",\n        url: str | httpx.URL = None,\n        files: list | None = None,\n        _json: t.Any | None = None,\n        params: dict | None = None,\n        headers: dict | None = {},\n        cookies: dict | None = None,\n        timeout: int | float | None = None,\n    ) -&gt; httpx.Request:\n        \"\"\"Assemble a new httpx.Request object from parts.\n\n        Params:\n            method (str): [Default: \"GET\"] HTTP method for request.\n            url (str|httpx.URL): URL to send request.\n            files (list|None): List of files to send with request. Only works with certain HTTP methods,\n                list `POST`.\n            _json (t.Any | None): JSON to append to request.\n            params (dict | None): Params to append to request.\n            headers (dict|None): Request headers.\n            cookies (dict): &lt;Not yet documented&gt;\n            timeout (int|float): Timeout (in seconds) before cancelling request.\n\n        Returns:\n            (httpx.Request): An initialized `httpx.Request` object.\n\n        \"\"\"\n        assert method, ValueError(\"Missing a request method\")\n        assert isinstance(method, str), TypeError(\n            f\"method should be a string. Got type: ({type(method)})\"\n        )\n\n        ## Ensure method is uppercase, i.e. 'get' -&gt; 'GET'\n        method: str = method.upper()\n\n        assert url, ValueError(\"Missing a URL\")\n        assert isinstance(url, str) or isinstance(url, httpx.URL), TypeError(\n            f\"URL must be a string or httpx.URL. Got type: ({type(url)})\"\n        )\n        if isinstance(url, str):\n            ## Convert URL from string into httpx.URL object\n            url: httpx.URL = httpx.URL(url=url)\n\n        if timeout:\n            assert (\n                isinstance(timeout, int) or isinstance(timeout, float)\n            ) and timeout &gt; 0, TypeError(\n                f\"timeout must be a non-zero positive int or float. Got type: ({type(timeout)})\"\n            )\n\n        ## Build httpx.Request object\n        try:\n            _req: httpx.Request = self.client.build_request(\n                method=method,\n                url=url,\n                files=files,\n                json=_json,\n                params=params,\n                headers=headers,\n                cookies=cookies,\n                timeout=timeout,\n            )\n\n            return _req\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception creaeting httpx.Request object. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def send_request(\n        self,\n        request: httpx.Request = None,\n        stream: bool = False,\n        auth: httpx.Auth = None,\n        debug_response: bool = False,\n    ) -&gt; httpx.Response:\n        \"\"\"Send httpx.Request using self.Client (and optional cache transport).\n\n        Params:\n            request (httpx.Request): An initialized `httpx.Request` object.\n            stream (bool): When `True`, response bytes will be streamed. This can be useful for large file downloads.\n            auth (httpx.Auth): &lt;Not yet documented&gt;\n\n        Returns:\n            (httpx.Response): An `httpx.Response` from the request.\n\n        \"\"\"\n        assert request, ValueError(\"Missing an httpx.Request object\")\n        assert isinstance(request, httpx.Request), TypeError(\n            f\"Expected request to be an httpx.Request object. Got type: ({type(request)})\"\n        )\n\n        ## Send request using class's httpx.Client\n        try:\n            res: httpx.Response = self.client.send(\n                request=request,\n                stream=stream,\n                auth=auth,\n                follow_redirects=self.follow_redirects,\n            )\n\n            if debug_response:\n                log.debug(\n                    f\"URL: {request.url}, Response: [{res.status_code}: {res.reason_phrase}]\"\n                )\n\n            return res\n\n        except httpx.ConnectError as conn_err:\n            ## Error connecting to remote\n            msg = Exception(\n                f\"ConnectError while requesting URL {request.url}. Details: {conn_err}\"\n            )\n            log.error(msg)\n\n            return\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception sending request. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n    def decode_res_content(self, res: httpx.Response = None) -&gt; dict:\n        \"\"\"Use multiple methods to attempt to decode an `httpx.Response.content` bytestring.\n\n        Params:\n            res (httpx.Response): An `httpx.Response` object, with `.content` to be decoded.\n\n        Returns:\n            (dict): A `dict` from the `httpx.Response`'s `.content` param.\n\n        \"\"\"\n        assert res, ValueError(\"Missing httpx Response object\")\n        assert isinstance(res, httpx.Response), TypeError(\n            f\"res must be of type httpx.Response. Got type: ({type(res)})\"\n        )\n\n        _content: bytes = res.content\n        assert _content, ValueError(\"Response content is empty\")\n        assert isinstance(_content, bytes), TypeError(\n            f\"Expected response.content to be a bytestring. Got type: ({type(_content)})\"\n        )\n\n        ## Get content's encoding, or default to 'utf-8'\n        try:\n            decode_charset: str = autodetect_charset(content=_content)\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception detecting response content's encoding. Details: {exc}\"\n            )\n            log.error(msg)\n            log.warning(\"Defaulting to 'utf-8'\")\n\n            decode_charset: str = \"utf-8\"\n\n        ## Decode content\n        try:\n            _decode: str = res.content.decode(decode_charset)\n\n        except Exception as exc:\n            ## Decoding failed, retry with different encodings\n            msg = Exception(\n                f\"[Attempt 1/2] Unhandled exception decoding response content. Details: {exc}\"\n            )\n            log.warning(msg)\n\n            if not res.encoding == \"utf-8\":\n                ## Try decoding again, using response's .encoding param\n                log.warning(\n                    f\"Retrying response content decode with encoding '{res.encoding}'\"\n                )\n                try:\n                    _decode = res.content.decode(res.encoding)\n                except Exception as exc:\n                    inner_msg = Exception(\n                        f\"[Attempt 2/2] Unhandled exception decoding response content. Details: {exc}\"\n                    )\n                    log.error(inner_msg)\n\n                    raise inner_msg\n\n            else:\n                ## Decoding with utf-8 failed, attempt with ISO-8859-1\n                #  https://en.wikipedia.org/wiki/ISO/IEC_8859-1\n                log.warning(\n                    \"Detected UTF-8 encoding, but decoding as UTF-8 failed. Retrying with encoding ISO-8859-1.\"\n                )\n                try:\n                    _decode = res.content.decode(\"ISO-8859-1\")\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Failure attempting to decode content as UTF-8 and ISO-8859-1. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n        ## Load decoded content into dict\n        try:\n            _json: dict = json.loads(_decode)\n\n            return _json\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception loading decoded response content to dict. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/controllers/__init__/#red_utils.ext.httpx_utils.controllers.HTTPXController.decode_res_content","title":"<code>decode_res_content(res=None)</code>","text":"<p>Use multiple methods to attempt to decode an <code>httpx.Response.content</code> bytestring.</p> <p>Parameters:</p> Name Type Description Default <code>res</code> <code>Response</code> <p>An <code>httpx.Response</code> object, with <code>.content</code> to be decoded.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A <code>dict</code> from the <code>httpx.Response</code>'s <code>.content</code> param.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>def decode_res_content(self, res: httpx.Response = None) -&gt; dict:\n    \"\"\"Use multiple methods to attempt to decode an `httpx.Response.content` bytestring.\n\n    Params:\n        res (httpx.Response): An `httpx.Response` object, with `.content` to be decoded.\n\n    Returns:\n        (dict): A `dict` from the `httpx.Response`'s `.content` param.\n\n    \"\"\"\n    assert res, ValueError(\"Missing httpx Response object\")\n    assert isinstance(res, httpx.Response), TypeError(\n        f\"res must be of type httpx.Response. Got type: ({type(res)})\"\n    )\n\n    _content: bytes = res.content\n    assert _content, ValueError(\"Response content is empty\")\n    assert isinstance(_content, bytes), TypeError(\n        f\"Expected response.content to be a bytestring. Got type: ({type(_content)})\"\n    )\n\n    ## Get content's encoding, or default to 'utf-8'\n    try:\n        decode_charset: str = autodetect_charset(content=_content)\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception detecting response content's encoding. Details: {exc}\"\n        )\n        log.error(msg)\n        log.warning(\"Defaulting to 'utf-8'\")\n\n        decode_charset: str = \"utf-8\"\n\n    ## Decode content\n    try:\n        _decode: str = res.content.decode(decode_charset)\n\n    except Exception as exc:\n        ## Decoding failed, retry with different encodings\n        msg = Exception(\n            f\"[Attempt 1/2] Unhandled exception decoding response content. Details: {exc}\"\n        )\n        log.warning(msg)\n\n        if not res.encoding == \"utf-8\":\n            ## Try decoding again, using response's .encoding param\n            log.warning(\n                f\"Retrying response content decode with encoding '{res.encoding}'\"\n            )\n            try:\n                _decode = res.content.decode(res.encoding)\n            except Exception as exc:\n                inner_msg = Exception(\n                    f\"[Attempt 2/2] Unhandled exception decoding response content. Details: {exc}\"\n                )\n                log.error(inner_msg)\n\n                raise inner_msg\n\n        else:\n            ## Decoding with utf-8 failed, attempt with ISO-8859-1\n            #  https://en.wikipedia.org/wiki/ISO/IEC_8859-1\n            log.warning(\n                \"Detected UTF-8 encoding, but decoding as UTF-8 failed. Retrying with encoding ISO-8859-1.\"\n            )\n            try:\n                _decode = res.content.decode(\"ISO-8859-1\")\n            except Exception as exc:\n                msg = Exception(\n                    f\"Failure attempting to decode content as UTF-8 and ISO-8859-1. Details: {exc}\"\n                )\n                log.error(msg)\n\n                raise exc\n\n    ## Load decoded content into dict\n    try:\n        _json: dict = json.loads(_decode)\n\n        return _json\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception loading decoded response content to dict. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/controllers/__init__/#red_utils.ext.httpx_utils.controllers.HTTPXController.new_request","title":"<code>new_request(method='GET', url=None, files=None, _json=None, params=None, headers={}, cookies=None, timeout=None)</code>","text":"<p>Assemble a new httpx.Request object from parts.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>[Default: \"GET\"] HTTP method for request.</p> <code>'GET'</code> <code>url</code> <code>str | URL</code> <p>URL to send request.</p> <code>None</code> <code>files</code> <code>list | None</code> <p>List of files to send with request. Only works with certain HTTP methods, list <code>POST</code>.</p> <code>None</code> <code>_json</code> <code>Any | None</code> <p>JSON to append to request.</p> <code>None</code> <code>params</code> <code>dict | None</code> <p>Params to append to request.</p> <code>None</code> <code>headers</code> <code>dict | None</code> <p>Request headers.</p> <code>{}</code> <code>cookies</code> <code>dict</code> <p> <code>None</code> <code>timeout</code> <code>int | float</code> <p>Timeout (in seconds) before cancelling request.</p> <code>None</code> <p>Returns:</p> Type Description <code>Request</code> <p>An initialized <code>httpx.Request</code> object.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>def new_request(\n    self,\n    method: str = \"GET\",\n    url: str | httpx.URL = None,\n    files: list | None = None,\n    _json: t.Any | None = None,\n    params: dict | None = None,\n    headers: dict | None = {},\n    cookies: dict | None = None,\n    timeout: int | float | None = None,\n) -&gt; httpx.Request:\n    \"\"\"Assemble a new httpx.Request object from parts.\n\n    Params:\n        method (str): [Default: \"GET\"] HTTP method for request.\n        url (str|httpx.URL): URL to send request.\n        files (list|None): List of files to send with request. Only works with certain HTTP methods,\n            list `POST`.\n        _json (t.Any | None): JSON to append to request.\n        params (dict | None): Params to append to request.\n        headers (dict|None): Request headers.\n        cookies (dict): &lt;Not yet documented&gt;\n        timeout (int|float): Timeout (in seconds) before cancelling request.\n\n    Returns:\n        (httpx.Request): An initialized `httpx.Request` object.\n\n    \"\"\"\n    assert method, ValueError(\"Missing a request method\")\n    assert isinstance(method, str), TypeError(\n        f\"method should be a string. Got type: ({type(method)})\"\n    )\n\n    ## Ensure method is uppercase, i.e. 'get' -&gt; 'GET'\n    method: str = method.upper()\n\n    assert url, ValueError(\"Missing a URL\")\n    assert isinstance(url, str) or isinstance(url, httpx.URL), TypeError(\n        f\"URL must be a string or httpx.URL. Got type: ({type(url)})\"\n    )\n    if isinstance(url, str):\n        ## Convert URL from string into httpx.URL object\n        url: httpx.URL = httpx.URL(url=url)\n\n    if timeout:\n        assert (\n            isinstance(timeout, int) or isinstance(timeout, float)\n        ) and timeout &gt; 0, TypeError(\n            f\"timeout must be a non-zero positive int or float. Got type: ({type(timeout)})\"\n        )\n\n    ## Build httpx.Request object\n    try:\n        _req: httpx.Request = self.client.build_request(\n            method=method,\n            url=url,\n            files=files,\n            json=_json,\n            params=params,\n            headers=headers,\n            cookies=cookies,\n            timeout=timeout,\n        )\n\n        return _req\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception creaeting httpx.Request object. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/controllers/__init__/#red_utils.ext.httpx_utils.controllers.HTTPXController.send_request","title":"<code>send_request(request=None, stream=False, auth=None, debug_response=False)</code>","text":"<p>Send httpx.Request using self.Client (and optional cache transport).</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>An initialized <code>httpx.Request</code> object.</p> <code>None</code> <code>stream</code> <code>bool</code> <p>When <code>True</code>, response bytes will be streamed. This can be useful for large file downloads.</p> <code>False</code> <code>auth</code> <code>Auth</code> <p> <code>None</code> <p>Returns:</p> Type Description <code>Response</code> <p>An <code>httpx.Response</code> from the request.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>def send_request(\n    self,\n    request: httpx.Request = None,\n    stream: bool = False,\n    auth: httpx.Auth = None,\n    debug_response: bool = False,\n) -&gt; httpx.Response:\n    \"\"\"Send httpx.Request using self.Client (and optional cache transport).\n\n    Params:\n        request (httpx.Request): An initialized `httpx.Request` object.\n        stream (bool): When `True`, response bytes will be streamed. This can be useful for large file downloads.\n        auth (httpx.Auth): &lt;Not yet documented&gt;\n\n    Returns:\n        (httpx.Response): An `httpx.Response` from the request.\n\n    \"\"\"\n    assert request, ValueError(\"Missing an httpx.Request object\")\n    assert isinstance(request, httpx.Request), TypeError(\n        f\"Expected request to be an httpx.Request object. Got type: ({type(request)})\"\n    )\n\n    ## Send request using class's httpx.Client\n    try:\n        res: httpx.Response = self.client.send(\n            request=request,\n            stream=stream,\n            auth=auth,\n            follow_redirects=self.follow_redirects,\n        )\n\n        if debug_response:\n            log.debug(\n                f\"URL: {request.url}, Response: [{res.status_code}: {res.reason_phrase}]\"\n            )\n\n        return res\n\n    except httpx.ConnectError as conn_err:\n        ## Error connecting to remote\n        msg = Exception(\n            f\"ConnectError while requesting URL {request.url}. Details: {conn_err}\"\n        )\n        log.error(msg)\n\n        return\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception sending request. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/controllers/__init__/#red_utils.ext.httpx_utils.controllers.HishelCacheClientController","title":"<code>HishelCacheClientController</code>","text":"<p>               Bases: <code>AbstractContextManager</code></p> <p>Handler for a hishel.CacheClient client.</p> <p>Parameters:</p> Name Type Description Default <code>cacheable_methods</code> <code>list[str]</code> <p>...</p> <code>['GET', 'POST']</code> <code>cacheable_status_codes</code> <code>list[int]</code> <p>...</p> <code>[200, 301, 308]</code> <code>allow_heuristics</code> <code>bool</code> <p>...</p> <code>False</code> <code>allow_stale</code> <code>bool</code> <p>...</p> <code>False</code> <code>always_revalidate</code> <code>bool</code> <p>...</p> <code>False</code> <code>force_cache</code> <code>bool</code> <p>...</p> <code>False</code> <code>storage</code> <code>FileStorage | RedisStorage | SQLiteStorage | S3Storage | InMemoryStorage</code> <p>...</p> <code>None</code> <code>follow_redirects</code> <code>bool</code> <p>...</p> <code>False</code> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>class HishelCacheClientController(AbstractContextManager):\n    \"\"\"Handler for a hishel.CacheClient client.\n\n    Params:\n        cacheable_methods (list[str]): ...\n        cacheable_status_codes (list[int]): ...\n        allow_heuristics (bool): ...\n        allow_stale (bool): ...\n        always_revalidate (bool): ...\n        force_cache (bool): ...\n        storage (hishel.FileStorage | hishel.RedisStorage | hishel.SQLiteStorage | hishel.S3Storage | hishel.InMemoryStorage): ...\n        follow_redirects (bool): ...\n    \"\"\"\n\n    def __init__(\n        self,\n        cacheable_methods: list[str] | None = [\"GET\", \"POST\"],\n        cacheable_status_codes: list[int] | None = [200, 301, 308],\n        allow_heuristics: bool = False,\n        allow_stale: bool = False,\n        always_revalidate: bool = False,\n        force_cache: bool = False,\n        storage: hishel_storage_type = None,\n        follow_redirects: bool = False,\n    ):\n        self.cacheable_methods = cacheable_methods\n        self.cacheable_status_codes = cacheable_status_codes\n        self.allow_heuristics = allow_heuristics\n        self.allow_stale = allow_stale\n        self.always_revalidate = always_revalidate\n        self.force_cache = force_cache\n        self.storage = storage\n        self.follow_redirects = follow_redirects\n\n        ## Placeholder for initialized hishel.Controller\n        self.controller: hishel.Controller = None\n        ## Placeholder for initialized hishel.CacheClient\n        self.client: hishel.CacheClient = None\n\n    def __enter__(self) -&gt; t.Self:\n        try:\n            _controller: hishel.Controller = hishel.Controller(\n                cacheable_methods=self.cacheable_methods,\n                cacheable_status_codes=self.cacheable_status_codes,\n                allow_heuristics=self.allow_heuristics,\n                allow_stale=self.allow_stale,\n                always_revalidate=self.always_revalidate,\n                force_cache=self.force_cache,\n            )\n            self.controller = _controller\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception initializing hishel.Controller. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n        try:\n            _client: hishel.CacheClient = hishel.CacheClient(\n                controller=self.controller, storage=self.storage\n            )\n            self.client = _client\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception initializing hishel.CacheClient. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        if exc_type:\n            log.error(f\"({exc_type}): {exc_value}\")\n        if traceback:\n            log.error(traceback)\n        if self.client:\n            self.client.close()\n\n    def new_request(\n        self,\n        method: str = \"GET\",\n        url: str = None,\n        files: list | None = None,\n        _json: t.Any | None = None,\n        params: dict | None = None,\n        headers: dict | None = None,\n        cookies: dict | None = None,\n        timeout: int | float | None = None,\n    ) -&gt; httpx.Request:\n        \"\"\"Assemble a new httpx.Request object from parts.\n\n        Params:\n            method (str): [Default: \"GET\"] HTTP method for request.\n            url (str|httpx.URL): URL to send request.\n            files (list|None): List of files to send with request. Only works with certain HTTP methods,\n                list `POST`.\n            _json (t.Any | None): JSON to append to request.\n            params (dict | None): Params to append to request.\n            headers (dict|None): Request headers.\n            cookies (dict): &lt;Not yet documented&gt;\n            timeout (int|float): Timeout (in seconds) before cancelling request.\n\n        Returns:\n            (httpx.Request): An initialized `httpx.Request` object.\n\n        \"\"\"\n        assert method, ValueError(\"Missing a request method\")\n        assert isinstance(method, str), TypeError(\n            f\"method should be a string. Got type: ({type(method)})\"\n        )\n\n        ## Ensure method is uppercase, i.e. 'get' -&gt; 'GET'\n        method: str = method.upper()\n\n        assert url, ValueError(\"Missing a URL\")\n        assert isinstance(url, str) or isinstance(url, httpx.URL), TypeError(\n            f\"URL must be a string or httpx.URL. Got type: ({type(url)})\"\n        )\n        if isinstance(url, str):\n            ## Convert URL from string into httpx.URL object\n            url: httpx.URL = httpx.URL(url=url)\n\n        if timeout:\n            assert (\n                isinstance(timeout, int) or isinstance(timeout, float)\n            ) and timeout &gt; 0, TypeError(\n                f\"timeout must be a non-zero positive int or float. Got type: ({type(timeout)})\"\n            )\n\n        ## Build httpx.Request object\n        try:\n            _req: httpx.Request = self.client.build_request(\n                method=method,\n                url=url,\n                files=files,\n                json=_json,\n                params=params,\n                headers=headers,\n                cookies=cookies,\n                timeout=timeout,\n            )\n\n            return _req\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception creaeting httpx.Request object. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def send_request(\n        self,\n        request: httpx.Request = None,\n        stream: bool = False,\n        auth: httpx.Auth = None,\n        debug_response: bool = False,\n    ) -&gt; httpx.Response:\n        \"\"\"Send httpx.Request using self.Client (and optional cache transport).\n\n        Params:\n            request (httpx.Request): An initialized `httpx.Request` object.\n            stream (bool): When `True`, response bytes will be streamed. This can be useful for large file downloads.\n            auth (httpx.Auth): &lt;Not yet documented&gt;\n\n        Returns:\n            (httpx.Response): An `httpx.Response` from the request.\n\n        \"\"\"\n        assert request, ValueError(\"Missing an httpx.Request object\")\n        assert isinstance(request, httpx.Request), TypeError(\n            f\"Expected request to be an httpx.Request object. Got type: ({type(request)})\"\n        )\n\n        ## Send request using class's httpx.Client\n        try:\n            res: httpx.Response = self.client.send(\n                request=request,\n                stream=stream,\n                auth=auth,\n                follow_redirects=self.follow_redirects,\n            )\n            if debug_response:\n                log.debug(\n                    f\"Response: [{res.status_code}: {res.reason_phrase}] {request.url}\"\n                )\n\n            return res\n\n        except httpx.ConnectError as conn_err:\n            ## Error connecting to remote\n            msg = Exception(\n                f\"ConnectError while requesting URL {request.url}. Details: {conn_err}\"\n            )\n            log.error(msg)\n\n            return\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception sending request. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n    def decode_res_content(self, res: httpx.Response = None) -&gt; dict:\n        \"\"\"Use multiple methods to attempt to decode an `httpx.Response.content` bytestring.\n\n        Params:\n            res (httpx.Response): An `httpx.Response` object, with `.content` to be decoded.\n\n        Returns:\n            (dict): A `dict` from the `httpx.Response`'s `.content` param.\n\n        \"\"\"\n        assert res, ValueError(\"Missing httpx Response object\")\n        assert isinstance(res, httpx.Response), TypeError(\n            f\"res must be of type httpx.Response. Got type: ({type(res)})\"\n        )\n\n        _content: bytes = res.content\n        assert _content, ValueError(\"Response content is empty\")\n        assert isinstance(_content, bytes), TypeError(\n            f\"Expected response.content to be a bytestring. Got type: ({type(_content)})\"\n        )\n\n        ## Get content's encoding, or default to 'utf-8'\n        try:\n            decode_charset: str = autodetect_charset(content=_content)\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception detecting response content's encoding. Details: {exc}\"\n            )\n            log.error(msg)\n            log.warning(\"Defaulting to 'utf-8'\")\n\n            decode_charset: str = \"utf-8\"\n\n        ## Decode content\n        try:\n            _decode: str = res.content.decode(decode_charset)\n\n        except Exception as exc:\n            ## Decoding failed, retry with different encodings\n            msg = Exception(\n                f\"[Attempt 1/2] Unhandled exception decoding response content. Details: {exc}\"\n            )\n            log.warning(msg)\n\n            if not res.encoding == \"utf-8\":\n                ## Try decoding again, using response's .encoding param\n                log.warning(\n                    f\"Retrying response content decode with encoding '{res.encoding}'\"\n                )\n                try:\n                    _decode = res.content.decode(res.encoding)\n                except Exception as exc:\n                    inner_msg = Exception(\n                        f\"[Attempt 2/2] Unhandled exception decoding response content. Details: {exc}\"\n                    )\n                    log.error(inner_msg)\n\n                    raise inner_msg\n\n            else:\n                ## Decoding with utf-8 failed, attempt with ISO-8859-1\n                #  https://en.wikipedia.org/wiki/ISO/IEC_8859-1\n                log.warning(\n                    \"Detected UTF-8 encoding, but decoding as UTF-8 failed. Retrying with encoding ISO-8859-1.\"\n                )\n                try:\n                    _decode = res.content.decode(\"ISO-8859-1\")\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Failure attempting to decode content as UTF-8 and ISO-8859-1. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n        ## Load decoded content into dict\n        try:\n            _json: dict = json.loads(_decode)\n\n            return _json\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception loading decoded response content to dict. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/controllers/__init__/#red_utils.ext.httpx_utils.controllers.HishelCacheClientController.decode_res_content","title":"<code>decode_res_content(res=None)</code>","text":"<p>Use multiple methods to attempt to decode an <code>httpx.Response.content</code> bytestring.</p> <p>Parameters:</p> Name Type Description Default <code>res</code> <code>Response</code> <p>An <code>httpx.Response</code> object, with <code>.content</code> to be decoded.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A <code>dict</code> from the <code>httpx.Response</code>'s <code>.content</code> param.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>def decode_res_content(self, res: httpx.Response = None) -&gt; dict:\n    \"\"\"Use multiple methods to attempt to decode an `httpx.Response.content` bytestring.\n\n    Params:\n        res (httpx.Response): An `httpx.Response` object, with `.content` to be decoded.\n\n    Returns:\n        (dict): A `dict` from the `httpx.Response`'s `.content` param.\n\n    \"\"\"\n    assert res, ValueError(\"Missing httpx Response object\")\n    assert isinstance(res, httpx.Response), TypeError(\n        f\"res must be of type httpx.Response. Got type: ({type(res)})\"\n    )\n\n    _content: bytes = res.content\n    assert _content, ValueError(\"Response content is empty\")\n    assert isinstance(_content, bytes), TypeError(\n        f\"Expected response.content to be a bytestring. Got type: ({type(_content)})\"\n    )\n\n    ## Get content's encoding, or default to 'utf-8'\n    try:\n        decode_charset: str = autodetect_charset(content=_content)\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception detecting response content's encoding. Details: {exc}\"\n        )\n        log.error(msg)\n        log.warning(\"Defaulting to 'utf-8'\")\n\n        decode_charset: str = \"utf-8\"\n\n    ## Decode content\n    try:\n        _decode: str = res.content.decode(decode_charset)\n\n    except Exception as exc:\n        ## Decoding failed, retry with different encodings\n        msg = Exception(\n            f\"[Attempt 1/2] Unhandled exception decoding response content. Details: {exc}\"\n        )\n        log.warning(msg)\n\n        if not res.encoding == \"utf-8\":\n            ## Try decoding again, using response's .encoding param\n            log.warning(\n                f\"Retrying response content decode with encoding '{res.encoding}'\"\n            )\n            try:\n                _decode = res.content.decode(res.encoding)\n            except Exception as exc:\n                inner_msg = Exception(\n                    f\"[Attempt 2/2] Unhandled exception decoding response content. Details: {exc}\"\n                )\n                log.error(inner_msg)\n\n                raise inner_msg\n\n        else:\n            ## Decoding with utf-8 failed, attempt with ISO-8859-1\n            #  https://en.wikipedia.org/wiki/ISO/IEC_8859-1\n            log.warning(\n                \"Detected UTF-8 encoding, but decoding as UTF-8 failed. Retrying with encoding ISO-8859-1.\"\n            )\n            try:\n                _decode = res.content.decode(\"ISO-8859-1\")\n            except Exception as exc:\n                msg = Exception(\n                    f\"Failure attempting to decode content as UTF-8 and ISO-8859-1. Details: {exc}\"\n                )\n                log.error(msg)\n\n                raise exc\n\n    ## Load decoded content into dict\n    try:\n        _json: dict = json.loads(_decode)\n\n        return _json\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception loading decoded response content to dict. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/controllers/__init__/#red_utils.ext.httpx_utils.controllers.HishelCacheClientController.new_request","title":"<code>new_request(method='GET', url=None, files=None, _json=None, params=None, headers=None, cookies=None, timeout=None)</code>","text":"<p>Assemble a new httpx.Request object from parts.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>[Default: \"GET\"] HTTP method for request.</p> <code>'GET'</code> <code>url</code> <code>str | URL</code> <p>URL to send request.</p> <code>None</code> <code>files</code> <code>list | None</code> <p>List of files to send with request. Only works with certain HTTP methods, list <code>POST</code>.</p> <code>None</code> <code>_json</code> <code>Any | None</code> <p>JSON to append to request.</p> <code>None</code> <code>params</code> <code>dict | None</code> <p>Params to append to request.</p> <code>None</code> <code>headers</code> <code>dict | None</code> <p>Request headers.</p> <code>None</code> <code>cookies</code> <code>dict</code> <p> <code>None</code> <code>timeout</code> <code>int | float</code> <p>Timeout (in seconds) before cancelling request.</p> <code>None</code> <p>Returns:</p> Type Description <code>Request</code> <p>An initialized <code>httpx.Request</code> object.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>def new_request(\n    self,\n    method: str = \"GET\",\n    url: str = None,\n    files: list | None = None,\n    _json: t.Any | None = None,\n    params: dict | None = None,\n    headers: dict | None = None,\n    cookies: dict | None = None,\n    timeout: int | float | None = None,\n) -&gt; httpx.Request:\n    \"\"\"Assemble a new httpx.Request object from parts.\n\n    Params:\n        method (str): [Default: \"GET\"] HTTP method for request.\n        url (str|httpx.URL): URL to send request.\n        files (list|None): List of files to send with request. Only works with certain HTTP methods,\n            list `POST`.\n        _json (t.Any | None): JSON to append to request.\n        params (dict | None): Params to append to request.\n        headers (dict|None): Request headers.\n        cookies (dict): &lt;Not yet documented&gt;\n        timeout (int|float): Timeout (in seconds) before cancelling request.\n\n    Returns:\n        (httpx.Request): An initialized `httpx.Request` object.\n\n    \"\"\"\n    assert method, ValueError(\"Missing a request method\")\n    assert isinstance(method, str), TypeError(\n        f\"method should be a string. Got type: ({type(method)})\"\n    )\n\n    ## Ensure method is uppercase, i.e. 'get' -&gt; 'GET'\n    method: str = method.upper()\n\n    assert url, ValueError(\"Missing a URL\")\n    assert isinstance(url, str) or isinstance(url, httpx.URL), TypeError(\n        f\"URL must be a string or httpx.URL. Got type: ({type(url)})\"\n    )\n    if isinstance(url, str):\n        ## Convert URL from string into httpx.URL object\n        url: httpx.URL = httpx.URL(url=url)\n\n    if timeout:\n        assert (\n            isinstance(timeout, int) or isinstance(timeout, float)\n        ) and timeout &gt; 0, TypeError(\n            f\"timeout must be a non-zero positive int or float. Got type: ({type(timeout)})\"\n        )\n\n    ## Build httpx.Request object\n    try:\n        _req: httpx.Request = self.client.build_request(\n            method=method,\n            url=url,\n            files=files,\n            json=_json,\n            params=params,\n            headers=headers,\n            cookies=cookies,\n            timeout=timeout,\n        )\n\n        return _req\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception creaeting httpx.Request object. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/controllers/__init__/#red_utils.ext.httpx_utils.controllers.HishelCacheClientController.send_request","title":"<code>send_request(request=None, stream=False, auth=None, debug_response=False)</code>","text":"<p>Send httpx.Request using self.Client (and optional cache transport).</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>An initialized <code>httpx.Request</code> object.</p> <code>None</code> <code>stream</code> <code>bool</code> <p>When <code>True</code>, response bytes will be streamed. This can be useful for large file downloads.</p> <code>False</code> <code>auth</code> <code>Auth</code> <p> <code>None</code> <p>Returns:</p> Type Description <code>Response</code> <p>An <code>httpx.Response</code> from the request.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>def send_request(\n    self,\n    request: httpx.Request = None,\n    stream: bool = False,\n    auth: httpx.Auth = None,\n    debug_response: bool = False,\n) -&gt; httpx.Response:\n    \"\"\"Send httpx.Request using self.Client (and optional cache transport).\n\n    Params:\n        request (httpx.Request): An initialized `httpx.Request` object.\n        stream (bool): When `True`, response bytes will be streamed. This can be useful for large file downloads.\n        auth (httpx.Auth): &lt;Not yet documented&gt;\n\n    Returns:\n        (httpx.Response): An `httpx.Response` from the request.\n\n    \"\"\"\n    assert request, ValueError(\"Missing an httpx.Request object\")\n    assert isinstance(request, httpx.Request), TypeError(\n        f\"Expected request to be an httpx.Request object. Got type: ({type(request)})\"\n    )\n\n    ## Send request using class's httpx.Client\n    try:\n        res: httpx.Response = self.client.send(\n            request=request,\n            stream=stream,\n            auth=auth,\n            follow_redirects=self.follow_redirects,\n        )\n        if debug_response:\n            log.debug(\n                f\"Response: [{res.status_code}: {res.reason_phrase}] {request.url}\"\n            )\n\n        return res\n\n    except httpx.ConnectError as conn_err:\n        ## Error connecting to remote\n        msg = Exception(\n            f\"ConnectError while requesting URL {request.url}. Details: {conn_err}\"\n        )\n        log.error(msg)\n\n        return\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception sending request. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/controllers/_controllers/","title":"_controllers","text":""},{"location":"reference/red_utils/ext/httpx_utils/controllers/_controllers/#red_utils.ext.httpx_utils.controllers._controllers.HTTPXController","title":"<code>HTTPXController</code>","text":"<p>               Bases: <code>AbstractContextManager</code></p> <p>Handler for HTTPX client.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str | None</code> <p>Scope the httpx client to a URL.</p> <code>None</code> <code>base_url</code> <code>str | None</code> <p>A base URL will be prefixed to each request. I.e. if <code>base_url=\"https://example.com\", and you want to request \"https://example.com/endpoint,\" you can set the base URL and then request</code>/endpoint`.</p> <code>None</code> <code>proxy</code> <code>str | None</code> <p> <code>None</code> <code>proxies</code> <code>str | None</code> <p> <code>None</code> <code>mounts</code> <code>dict[str, HTTPTransport] | None</code> <p>A dict of <code>httpx.HTTPTransport</code> objects.</p> <code>{}</code> <code>cookies</code> <code>dict[str, Any]</code> <p> <code>{}</code> <code>auth</code> <code>Auth | None</code> <p> <code>None</code> <code>headers</code> <code>dict[str, str] | None</code> <p>Optional request headers to apply to all requests handled by controller instance.</p> <code>{}</code> <code>params</code> <code>dict[str, Any] | None</code> <p>Optional request params to apply to all requests handled by controller instance.</p> <code>{}</code> <code>follow_redirects</code> <code>bool</code> <p>[Default: False] Follow HTTP 302 redirects.</p> <code>False</code> <code>max_redirects</code> <code>int | None</code> <p>[Default: 20] Maximum number of HTTP 302 redirects to follow.</p> <code>20</code> <code>retries</code> <code>int | None</code> <p>Number of times to retry on request failure.</p> <code>None</code> <code>timeout</code> <code>int | float | None</code> <p>Timeout (in seconds) until client gives up on request.</p> <code>60</code> <code>limits</code> <code>Limits | None</code> <p> <code>None</code> <code>transport</code> <code>HTTPTransport | CacheTransport | None</code> <p>A transport to pass to class's <code>httpx.Client</code> object.</p> <code>None</code> <code>default_encoding</code> <code>str</code> <p>[Default: utf-8] Set default encoding for all requests.</p> <code>autodetect_charset</code> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>class HTTPXController(AbstractContextManager):\n    \"\"\"Handler for HTTPX client.\n\n    Params:\n        url (str|None): Scope the httpx client to a URL.\n        base_url (str|None): A base URL will be prefixed to each request. I.e. if `base_url=\"https://example.com\",\n            and you want to request \"https://example.com/endpoint,\" you can set the base URL and then request `/endpoint`.\n        proxy (str|None): &lt;Not yet documented&gt;\n        proxies (str|None): &lt;Not yet documented&gt;\n        mounts (dict[str, httpx.HTTPTransport]|None): A dict of `httpx.HTTPTransport` objects.\n        cookies (dict[str, Any]): &lt;Not yet documented&gt;\n        auth (httpx.Auth | None): &lt;Not yet documented&gt;\n        headers (dict[str, str]|None): Optional request headers to apply to all requests handled by controller instance.\n        params (dict[str, Any]|None): Optional request params to apply to all requests handled by controller instance.\n        follow_redirects (bool): [Default: False] Follow HTTP 302 redirects.\n        max_redirects (int|None): [Default: 20] Maximum number of HTTP 302 redirects to follow.\n        retries (int|None): Number of times to retry on request failure.\n        timeout (int|float|None): Timeout (in seconds) until client gives up on request.\n        limits (httpx.Limits | None): &lt;Not yet documented&gt;\n        transport (httpx.HTTPTransport|hishel.CacheTransport|None): A transport to pass to class's `httpx.Client` object.\n        default_encoding (str): [Default: utf-8] Set default encoding for all requests.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        url: str | None = None,\n        base_url: str | None = None,\n        proxy: str | None = None,\n        proxies: dict[str, str] | None = None,\n        mounts: dict[str, httpx.HTTPTransport] | None = {},\n        cookies: dict[str, t.Any] | None = {},\n        auth: httpx.Auth | None = None,\n        headers: dict[str, str] | None = {},\n        params: dict[str, t.Any] | None = {},\n        follow_redirects: bool = False,\n        max_redirects: int | None = 20,\n        retries: int | None = None,\n        timeout: t.Union[int, float] | None = 60,\n        limits: httpx.Limits | None = None,\n        transport: t.Union[httpx.HTTPTransport, hishel.CacheTransport] | None = None,\n        default_encoding: str = autodetect_charset,\n    ) -&gt; None:\n        self.url: httpx.URL | None = httpx.URL(url) if url else None\n        self.base_url: httpx.URL | None = httpx.URL(base_url) if base_url else None\n        self.proxy: str | None = proxy\n        self.proxies: dict[str, str] | None = proxies\n        self.mounts: dict[str, httpx.HTTPTransport] | None = mounts\n        self.auth: httpx.Auth | None = auth\n        self.headers: dict[str, str] | None = headers\n        self.cookies: dict[str, t.Any] | None = cookies\n        self.params: dict[str, str] | None = params\n        self.follow_redirects: bool = follow_redirects\n        self.max_redirects: int | None = max_redirects\n        self.retries: int | None = retries\n        self.timeout: t.Union[int, float] | None = timeout\n        self.limits: httpx.Limits | None = limits\n        self.transport: t.Union[httpx.HTTPTransport, hishel.CacheTransport] | None = (\n            transport\n        )\n        self.default_encoding: str = default_encoding\n\n        ## Placeholder for initialized httpx.Client\n        self.client: httpx.Client | None = None\n\n    def __enter__(self) -&gt; t.Self:\n        \"\"\"Execute when handler is called in a `with` statement.\n\n        Description:\n            Creates an `httpx.Client` object, using class parameters as options.\n        \"\"\"\n        try:\n            _client: httpx.Client = httpx.Client(\n                auth=self.auth,\n                params=self.params,\n                headers=self.headers,\n                cookies=self.cookies,\n                proxy=self.proxy,\n                proxies=self.proxies,\n                mounts=self.mounts,\n                timeout=self.timeout,\n                follow_redirects=self.follow_redirects,\n                max_redirects=self.max_redirects,\n                # base_url=self.base_url,\n                transport=self.transport,\n                default_encoding=self.default_encoding,\n            )\n\n            ## If base_url is None, an exception occurs. Set self.base_url\n            #  only if base_url is not None.\n            if self.base_url:\n                _client.base_url = self.base_url\n\n            self.client = _client\n\n            return self\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception initializing httpx Client. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        \"\"\"Execute  when `with` statement ends.\n\n        Description:\n            Show any exceptions/tracebacks. Close `self.client` on exit.\n\n        \"\"\"\n        if exc_type:\n            log.error(f\"({exc_type}): {exc_value}\")\n\n        if traceback:\n            log.error(f\"TRACE: {traceback}\")\n\n        ## Close httpx client\n        if self.client:\n            self.client.close()\n\n    def new_request(\n        self,\n        method: str = \"GET\",\n        url: str | httpx.URL = None,\n        files: list | None = None,\n        _json: t.Any | None = None,\n        params: dict | None = None,\n        headers: dict | None = {},\n        cookies: dict | None = None,\n        timeout: int | float | None = None,\n    ) -&gt; httpx.Request:\n        \"\"\"Assemble a new httpx.Request object from parts.\n\n        Params:\n            method (str): [Default: \"GET\"] HTTP method for request.\n            url (str|httpx.URL): URL to send request.\n            files (list|None): List of files to send with request. Only works with certain HTTP methods,\n                list `POST`.\n            _json (t.Any | None): JSON to append to request.\n            params (dict | None): Params to append to request.\n            headers (dict|None): Request headers.\n            cookies (dict): &lt;Not yet documented&gt;\n            timeout (int|float): Timeout (in seconds) before cancelling request.\n\n        Returns:\n            (httpx.Request): An initialized `httpx.Request` object.\n\n        \"\"\"\n        assert method, ValueError(\"Missing a request method\")\n        assert isinstance(method, str), TypeError(\n            f\"method should be a string. Got type: ({type(method)})\"\n        )\n\n        ## Ensure method is uppercase, i.e. 'get' -&gt; 'GET'\n        method: str = method.upper()\n\n        assert url, ValueError(\"Missing a URL\")\n        assert isinstance(url, str) or isinstance(url, httpx.URL), TypeError(\n            f\"URL must be a string or httpx.URL. Got type: ({type(url)})\"\n        )\n        if isinstance(url, str):\n            ## Convert URL from string into httpx.URL object\n            url: httpx.URL = httpx.URL(url=url)\n\n        if timeout:\n            assert (\n                isinstance(timeout, int) or isinstance(timeout, float)\n            ) and timeout &gt; 0, TypeError(\n                f\"timeout must be a non-zero positive int or float. Got type: ({type(timeout)})\"\n            )\n\n        ## Build httpx.Request object\n        try:\n            _req: httpx.Request = self.client.build_request(\n                method=method,\n                url=url,\n                files=files,\n                json=_json,\n                params=params,\n                headers=headers,\n                cookies=cookies,\n                timeout=timeout,\n            )\n\n            return _req\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception creaeting httpx.Request object. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def send_request(\n        self,\n        request: httpx.Request = None,\n        stream: bool = False,\n        auth: httpx.Auth = None,\n        debug_response: bool = False,\n    ) -&gt; httpx.Response:\n        \"\"\"Send httpx.Request using self.Client (and optional cache transport).\n\n        Params:\n            request (httpx.Request): An initialized `httpx.Request` object.\n            stream (bool): When `True`, response bytes will be streamed. This can be useful for large file downloads.\n            auth (httpx.Auth): &lt;Not yet documented&gt;\n\n        Returns:\n            (httpx.Response): An `httpx.Response` from the request.\n\n        \"\"\"\n        assert request, ValueError(\"Missing an httpx.Request object\")\n        assert isinstance(request, httpx.Request), TypeError(\n            f\"Expected request to be an httpx.Request object. Got type: ({type(request)})\"\n        )\n\n        ## Send request using class's httpx.Client\n        try:\n            res: httpx.Response = self.client.send(\n                request=request,\n                stream=stream,\n                auth=auth,\n                follow_redirects=self.follow_redirects,\n            )\n\n            if debug_response:\n                log.debug(\n                    f\"URL: {request.url}, Response: [{res.status_code}: {res.reason_phrase}]\"\n                )\n\n            return res\n\n        except httpx.ConnectError as conn_err:\n            ## Error connecting to remote\n            msg = Exception(\n                f\"ConnectError while requesting URL {request.url}. Details: {conn_err}\"\n            )\n            log.error(msg)\n\n            return\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception sending request. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n    def decode_res_content(self, res: httpx.Response = None) -&gt; dict:\n        \"\"\"Use multiple methods to attempt to decode an `httpx.Response.content` bytestring.\n\n        Params:\n            res (httpx.Response): An `httpx.Response` object, with `.content` to be decoded.\n\n        Returns:\n            (dict): A `dict` from the `httpx.Response`'s `.content` param.\n\n        \"\"\"\n        assert res, ValueError(\"Missing httpx Response object\")\n        assert isinstance(res, httpx.Response), TypeError(\n            f\"res must be of type httpx.Response. Got type: ({type(res)})\"\n        )\n\n        _content: bytes = res.content\n        assert _content, ValueError(\"Response content is empty\")\n        assert isinstance(_content, bytes), TypeError(\n            f\"Expected response.content to be a bytestring. Got type: ({type(_content)})\"\n        )\n\n        ## Get content's encoding, or default to 'utf-8'\n        try:\n            decode_charset: str = autodetect_charset(content=_content)\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception detecting response content's encoding. Details: {exc}\"\n            )\n            log.error(msg)\n            log.warning(\"Defaulting to 'utf-8'\")\n\n            decode_charset: str = \"utf-8\"\n\n        ## Decode content\n        try:\n            _decode: str = res.content.decode(decode_charset)\n\n        except Exception as exc:\n            ## Decoding failed, retry with different encodings\n            msg = Exception(\n                f\"[Attempt 1/2] Unhandled exception decoding response content. Details: {exc}\"\n            )\n            log.warning(msg)\n\n            if not res.encoding == \"utf-8\":\n                ## Try decoding again, using response's .encoding param\n                log.warning(\n                    f\"Retrying response content decode with encoding '{res.encoding}'\"\n                )\n                try:\n                    _decode = res.content.decode(res.encoding)\n                except Exception as exc:\n                    inner_msg = Exception(\n                        f\"[Attempt 2/2] Unhandled exception decoding response content. Details: {exc}\"\n                    )\n                    log.error(inner_msg)\n\n                    raise inner_msg\n\n            else:\n                ## Decoding with utf-8 failed, attempt with ISO-8859-1\n                #  https://en.wikipedia.org/wiki/ISO/IEC_8859-1\n                log.warning(\n                    \"Detected UTF-8 encoding, but decoding as UTF-8 failed. Retrying with encoding ISO-8859-1.\"\n                )\n                try:\n                    _decode = res.content.decode(\"ISO-8859-1\")\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Failure attempting to decode content as UTF-8 and ISO-8859-1. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n        ## Load decoded content into dict\n        try:\n            _json: dict = json.loads(_decode)\n\n            return _json\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception loading decoded response content to dict. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/controllers/_controllers/#red_utils.ext.httpx_utils.controllers._controllers.HTTPXController.decode_res_content","title":"<code>decode_res_content(res=None)</code>","text":"<p>Use multiple methods to attempt to decode an <code>httpx.Response.content</code> bytestring.</p> <p>Parameters:</p> Name Type Description Default <code>res</code> <code>Response</code> <p>An <code>httpx.Response</code> object, with <code>.content</code> to be decoded.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A <code>dict</code> from the <code>httpx.Response</code>'s <code>.content</code> param.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>def decode_res_content(self, res: httpx.Response = None) -&gt; dict:\n    \"\"\"Use multiple methods to attempt to decode an `httpx.Response.content` bytestring.\n\n    Params:\n        res (httpx.Response): An `httpx.Response` object, with `.content` to be decoded.\n\n    Returns:\n        (dict): A `dict` from the `httpx.Response`'s `.content` param.\n\n    \"\"\"\n    assert res, ValueError(\"Missing httpx Response object\")\n    assert isinstance(res, httpx.Response), TypeError(\n        f\"res must be of type httpx.Response. Got type: ({type(res)})\"\n    )\n\n    _content: bytes = res.content\n    assert _content, ValueError(\"Response content is empty\")\n    assert isinstance(_content, bytes), TypeError(\n        f\"Expected response.content to be a bytestring. Got type: ({type(_content)})\"\n    )\n\n    ## Get content's encoding, or default to 'utf-8'\n    try:\n        decode_charset: str = autodetect_charset(content=_content)\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception detecting response content's encoding. Details: {exc}\"\n        )\n        log.error(msg)\n        log.warning(\"Defaulting to 'utf-8'\")\n\n        decode_charset: str = \"utf-8\"\n\n    ## Decode content\n    try:\n        _decode: str = res.content.decode(decode_charset)\n\n    except Exception as exc:\n        ## Decoding failed, retry with different encodings\n        msg = Exception(\n            f\"[Attempt 1/2] Unhandled exception decoding response content. Details: {exc}\"\n        )\n        log.warning(msg)\n\n        if not res.encoding == \"utf-8\":\n            ## Try decoding again, using response's .encoding param\n            log.warning(\n                f\"Retrying response content decode with encoding '{res.encoding}'\"\n            )\n            try:\n                _decode = res.content.decode(res.encoding)\n            except Exception as exc:\n                inner_msg = Exception(\n                    f\"[Attempt 2/2] Unhandled exception decoding response content. Details: {exc}\"\n                )\n                log.error(inner_msg)\n\n                raise inner_msg\n\n        else:\n            ## Decoding with utf-8 failed, attempt with ISO-8859-1\n            #  https://en.wikipedia.org/wiki/ISO/IEC_8859-1\n            log.warning(\n                \"Detected UTF-8 encoding, but decoding as UTF-8 failed. Retrying with encoding ISO-8859-1.\"\n            )\n            try:\n                _decode = res.content.decode(\"ISO-8859-1\")\n            except Exception as exc:\n                msg = Exception(\n                    f\"Failure attempting to decode content as UTF-8 and ISO-8859-1. Details: {exc}\"\n                )\n                log.error(msg)\n\n                raise exc\n\n    ## Load decoded content into dict\n    try:\n        _json: dict = json.loads(_decode)\n\n        return _json\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception loading decoded response content to dict. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/controllers/_controllers/#red_utils.ext.httpx_utils.controllers._controllers.HTTPXController.new_request","title":"<code>new_request(method='GET', url=None, files=None, _json=None, params=None, headers={}, cookies=None, timeout=None)</code>","text":"<p>Assemble a new httpx.Request object from parts.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>[Default: \"GET\"] HTTP method for request.</p> <code>'GET'</code> <code>url</code> <code>str | URL</code> <p>URL to send request.</p> <code>None</code> <code>files</code> <code>list | None</code> <p>List of files to send with request. Only works with certain HTTP methods, list <code>POST</code>.</p> <code>None</code> <code>_json</code> <code>Any | None</code> <p>JSON to append to request.</p> <code>None</code> <code>params</code> <code>dict | None</code> <p>Params to append to request.</p> <code>None</code> <code>headers</code> <code>dict | None</code> <p>Request headers.</p> <code>{}</code> <code>cookies</code> <code>dict</code> <p> <code>None</code> <code>timeout</code> <code>int | float</code> <p>Timeout (in seconds) before cancelling request.</p> <code>None</code> <p>Returns:</p> Type Description <code>Request</code> <p>An initialized <code>httpx.Request</code> object.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>def new_request(\n    self,\n    method: str = \"GET\",\n    url: str | httpx.URL = None,\n    files: list | None = None,\n    _json: t.Any | None = None,\n    params: dict | None = None,\n    headers: dict | None = {},\n    cookies: dict | None = None,\n    timeout: int | float | None = None,\n) -&gt; httpx.Request:\n    \"\"\"Assemble a new httpx.Request object from parts.\n\n    Params:\n        method (str): [Default: \"GET\"] HTTP method for request.\n        url (str|httpx.URL): URL to send request.\n        files (list|None): List of files to send with request. Only works with certain HTTP methods,\n            list `POST`.\n        _json (t.Any | None): JSON to append to request.\n        params (dict | None): Params to append to request.\n        headers (dict|None): Request headers.\n        cookies (dict): &lt;Not yet documented&gt;\n        timeout (int|float): Timeout (in seconds) before cancelling request.\n\n    Returns:\n        (httpx.Request): An initialized `httpx.Request` object.\n\n    \"\"\"\n    assert method, ValueError(\"Missing a request method\")\n    assert isinstance(method, str), TypeError(\n        f\"method should be a string. Got type: ({type(method)})\"\n    )\n\n    ## Ensure method is uppercase, i.e. 'get' -&gt; 'GET'\n    method: str = method.upper()\n\n    assert url, ValueError(\"Missing a URL\")\n    assert isinstance(url, str) or isinstance(url, httpx.URL), TypeError(\n        f\"URL must be a string or httpx.URL. Got type: ({type(url)})\"\n    )\n    if isinstance(url, str):\n        ## Convert URL from string into httpx.URL object\n        url: httpx.URL = httpx.URL(url=url)\n\n    if timeout:\n        assert (\n            isinstance(timeout, int) or isinstance(timeout, float)\n        ) and timeout &gt; 0, TypeError(\n            f\"timeout must be a non-zero positive int or float. Got type: ({type(timeout)})\"\n        )\n\n    ## Build httpx.Request object\n    try:\n        _req: httpx.Request = self.client.build_request(\n            method=method,\n            url=url,\n            files=files,\n            json=_json,\n            params=params,\n            headers=headers,\n            cookies=cookies,\n            timeout=timeout,\n        )\n\n        return _req\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception creaeting httpx.Request object. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/controllers/_controllers/#red_utils.ext.httpx_utils.controllers._controllers.HTTPXController.send_request","title":"<code>send_request(request=None, stream=False, auth=None, debug_response=False)</code>","text":"<p>Send httpx.Request using self.Client (and optional cache transport).</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>An initialized <code>httpx.Request</code> object.</p> <code>None</code> <code>stream</code> <code>bool</code> <p>When <code>True</code>, response bytes will be streamed. This can be useful for large file downloads.</p> <code>False</code> <code>auth</code> <code>Auth</code> <p> <code>None</code> <p>Returns:</p> Type Description <code>Response</code> <p>An <code>httpx.Response</code> from the request.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>def send_request(\n    self,\n    request: httpx.Request = None,\n    stream: bool = False,\n    auth: httpx.Auth = None,\n    debug_response: bool = False,\n) -&gt; httpx.Response:\n    \"\"\"Send httpx.Request using self.Client (and optional cache transport).\n\n    Params:\n        request (httpx.Request): An initialized `httpx.Request` object.\n        stream (bool): When `True`, response bytes will be streamed. This can be useful for large file downloads.\n        auth (httpx.Auth): &lt;Not yet documented&gt;\n\n    Returns:\n        (httpx.Response): An `httpx.Response` from the request.\n\n    \"\"\"\n    assert request, ValueError(\"Missing an httpx.Request object\")\n    assert isinstance(request, httpx.Request), TypeError(\n        f\"Expected request to be an httpx.Request object. Got type: ({type(request)})\"\n    )\n\n    ## Send request using class's httpx.Client\n    try:\n        res: httpx.Response = self.client.send(\n            request=request,\n            stream=stream,\n            auth=auth,\n            follow_redirects=self.follow_redirects,\n        )\n\n        if debug_response:\n            log.debug(\n                f\"URL: {request.url}, Response: [{res.status_code}: {res.reason_phrase}]\"\n            )\n\n        return res\n\n    except httpx.ConnectError as conn_err:\n        ## Error connecting to remote\n        msg = Exception(\n            f\"ConnectError while requesting URL {request.url}. Details: {conn_err}\"\n        )\n        log.error(msg)\n\n        return\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception sending request. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/controllers/_controllers/#red_utils.ext.httpx_utils.controllers._controllers.HishelCacheClientController","title":"<code>HishelCacheClientController</code>","text":"<p>               Bases: <code>AbstractContextManager</code></p> <p>Handler for a hishel.CacheClient client.</p> <p>Parameters:</p> Name Type Description Default <code>cacheable_methods</code> <code>list[str]</code> <p>...</p> <code>['GET', 'POST']</code> <code>cacheable_status_codes</code> <code>list[int]</code> <p>...</p> <code>[200, 301, 308]</code> <code>allow_heuristics</code> <code>bool</code> <p>...</p> <code>False</code> <code>allow_stale</code> <code>bool</code> <p>...</p> <code>False</code> <code>always_revalidate</code> <code>bool</code> <p>...</p> <code>False</code> <code>force_cache</code> <code>bool</code> <p>...</p> <code>False</code> <code>storage</code> <code>FileStorage | RedisStorage | SQLiteStorage | S3Storage | InMemoryStorage</code> <p>...</p> <code>None</code> <code>follow_redirects</code> <code>bool</code> <p>...</p> <code>False</code> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>class HishelCacheClientController(AbstractContextManager):\n    \"\"\"Handler for a hishel.CacheClient client.\n\n    Params:\n        cacheable_methods (list[str]): ...\n        cacheable_status_codes (list[int]): ...\n        allow_heuristics (bool): ...\n        allow_stale (bool): ...\n        always_revalidate (bool): ...\n        force_cache (bool): ...\n        storage (hishel.FileStorage | hishel.RedisStorage | hishel.SQLiteStorage | hishel.S3Storage | hishel.InMemoryStorage): ...\n        follow_redirects (bool): ...\n    \"\"\"\n\n    def __init__(\n        self,\n        cacheable_methods: list[str] | None = [\"GET\", \"POST\"],\n        cacheable_status_codes: list[int] | None = [200, 301, 308],\n        allow_heuristics: bool = False,\n        allow_stale: bool = False,\n        always_revalidate: bool = False,\n        force_cache: bool = False,\n        storage: hishel_storage_type = None,\n        follow_redirects: bool = False,\n    ):\n        self.cacheable_methods = cacheable_methods\n        self.cacheable_status_codes = cacheable_status_codes\n        self.allow_heuristics = allow_heuristics\n        self.allow_stale = allow_stale\n        self.always_revalidate = always_revalidate\n        self.force_cache = force_cache\n        self.storage = storage\n        self.follow_redirects = follow_redirects\n\n        ## Placeholder for initialized hishel.Controller\n        self.controller: hishel.Controller = None\n        ## Placeholder for initialized hishel.CacheClient\n        self.client: hishel.CacheClient = None\n\n    def __enter__(self) -&gt; t.Self:\n        try:\n            _controller: hishel.Controller = hishel.Controller(\n                cacheable_methods=self.cacheable_methods,\n                cacheable_status_codes=self.cacheable_status_codes,\n                allow_heuristics=self.allow_heuristics,\n                allow_stale=self.allow_stale,\n                always_revalidate=self.always_revalidate,\n                force_cache=self.force_cache,\n            )\n            self.controller = _controller\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception initializing hishel.Controller. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n        try:\n            _client: hishel.CacheClient = hishel.CacheClient(\n                controller=self.controller, storage=self.storage\n            )\n            self.client = _client\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception initializing hishel.CacheClient. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        if exc_type:\n            log.error(f\"({exc_type}): {exc_value}\")\n        if traceback:\n            log.error(traceback)\n        if self.client:\n            self.client.close()\n\n    def new_request(\n        self,\n        method: str = \"GET\",\n        url: str = None,\n        files: list | None = None,\n        _json: t.Any | None = None,\n        params: dict | None = None,\n        headers: dict | None = None,\n        cookies: dict | None = None,\n        timeout: int | float | None = None,\n    ) -&gt; httpx.Request:\n        \"\"\"Assemble a new httpx.Request object from parts.\n\n        Params:\n            method (str): [Default: \"GET\"] HTTP method for request.\n            url (str|httpx.URL): URL to send request.\n            files (list|None): List of files to send with request. Only works with certain HTTP methods,\n                list `POST`.\n            _json (t.Any | None): JSON to append to request.\n            params (dict | None): Params to append to request.\n            headers (dict|None): Request headers.\n            cookies (dict): &lt;Not yet documented&gt;\n            timeout (int|float): Timeout (in seconds) before cancelling request.\n\n        Returns:\n            (httpx.Request): An initialized `httpx.Request` object.\n\n        \"\"\"\n        assert method, ValueError(\"Missing a request method\")\n        assert isinstance(method, str), TypeError(\n            f\"method should be a string. Got type: ({type(method)})\"\n        )\n\n        ## Ensure method is uppercase, i.e. 'get' -&gt; 'GET'\n        method: str = method.upper()\n\n        assert url, ValueError(\"Missing a URL\")\n        assert isinstance(url, str) or isinstance(url, httpx.URL), TypeError(\n            f\"URL must be a string or httpx.URL. Got type: ({type(url)})\"\n        )\n        if isinstance(url, str):\n            ## Convert URL from string into httpx.URL object\n            url: httpx.URL = httpx.URL(url=url)\n\n        if timeout:\n            assert (\n                isinstance(timeout, int) or isinstance(timeout, float)\n            ) and timeout &gt; 0, TypeError(\n                f\"timeout must be a non-zero positive int or float. Got type: ({type(timeout)})\"\n            )\n\n        ## Build httpx.Request object\n        try:\n            _req: httpx.Request = self.client.build_request(\n                method=method,\n                url=url,\n                files=files,\n                json=_json,\n                params=params,\n                headers=headers,\n                cookies=cookies,\n                timeout=timeout,\n            )\n\n            return _req\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception creaeting httpx.Request object. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def send_request(\n        self,\n        request: httpx.Request = None,\n        stream: bool = False,\n        auth: httpx.Auth = None,\n        debug_response: bool = False,\n    ) -&gt; httpx.Response:\n        \"\"\"Send httpx.Request using self.Client (and optional cache transport).\n\n        Params:\n            request (httpx.Request): An initialized `httpx.Request` object.\n            stream (bool): When `True`, response bytes will be streamed. This can be useful for large file downloads.\n            auth (httpx.Auth): &lt;Not yet documented&gt;\n\n        Returns:\n            (httpx.Response): An `httpx.Response` from the request.\n\n        \"\"\"\n        assert request, ValueError(\"Missing an httpx.Request object\")\n        assert isinstance(request, httpx.Request), TypeError(\n            f\"Expected request to be an httpx.Request object. Got type: ({type(request)})\"\n        )\n\n        ## Send request using class's httpx.Client\n        try:\n            res: httpx.Response = self.client.send(\n                request=request,\n                stream=stream,\n                auth=auth,\n                follow_redirects=self.follow_redirects,\n            )\n            if debug_response:\n                log.debug(\n                    f\"Response: [{res.status_code}: {res.reason_phrase}] {request.url}\"\n                )\n\n            return res\n\n        except httpx.ConnectError as conn_err:\n            ## Error connecting to remote\n            msg = Exception(\n                f\"ConnectError while requesting URL {request.url}. Details: {conn_err}\"\n            )\n            log.error(msg)\n\n            return\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception sending request. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n    def decode_res_content(self, res: httpx.Response = None) -&gt; dict:\n        \"\"\"Use multiple methods to attempt to decode an `httpx.Response.content` bytestring.\n\n        Params:\n            res (httpx.Response): An `httpx.Response` object, with `.content` to be decoded.\n\n        Returns:\n            (dict): A `dict` from the `httpx.Response`'s `.content` param.\n\n        \"\"\"\n        assert res, ValueError(\"Missing httpx Response object\")\n        assert isinstance(res, httpx.Response), TypeError(\n            f\"res must be of type httpx.Response. Got type: ({type(res)})\"\n        )\n\n        _content: bytes = res.content\n        assert _content, ValueError(\"Response content is empty\")\n        assert isinstance(_content, bytes), TypeError(\n            f\"Expected response.content to be a bytestring. Got type: ({type(_content)})\"\n        )\n\n        ## Get content's encoding, or default to 'utf-8'\n        try:\n            decode_charset: str = autodetect_charset(content=_content)\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception detecting response content's encoding. Details: {exc}\"\n            )\n            log.error(msg)\n            log.warning(\"Defaulting to 'utf-8'\")\n\n            decode_charset: str = \"utf-8\"\n\n        ## Decode content\n        try:\n            _decode: str = res.content.decode(decode_charset)\n\n        except Exception as exc:\n            ## Decoding failed, retry with different encodings\n            msg = Exception(\n                f\"[Attempt 1/2] Unhandled exception decoding response content. Details: {exc}\"\n            )\n            log.warning(msg)\n\n            if not res.encoding == \"utf-8\":\n                ## Try decoding again, using response's .encoding param\n                log.warning(\n                    f\"Retrying response content decode with encoding '{res.encoding}'\"\n                )\n                try:\n                    _decode = res.content.decode(res.encoding)\n                except Exception as exc:\n                    inner_msg = Exception(\n                        f\"[Attempt 2/2] Unhandled exception decoding response content. Details: {exc}\"\n                    )\n                    log.error(inner_msg)\n\n                    raise inner_msg\n\n            else:\n                ## Decoding with utf-8 failed, attempt with ISO-8859-1\n                #  https://en.wikipedia.org/wiki/ISO/IEC_8859-1\n                log.warning(\n                    \"Detected UTF-8 encoding, but decoding as UTF-8 failed. Retrying with encoding ISO-8859-1.\"\n                )\n                try:\n                    _decode = res.content.decode(\"ISO-8859-1\")\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Failure attempting to decode content as UTF-8 and ISO-8859-1. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n        ## Load decoded content into dict\n        try:\n            _json: dict = json.loads(_decode)\n\n            return _json\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception loading decoded response content to dict. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/controllers/_controllers/#red_utils.ext.httpx_utils.controllers._controllers.HishelCacheClientController.decode_res_content","title":"<code>decode_res_content(res=None)</code>","text":"<p>Use multiple methods to attempt to decode an <code>httpx.Response.content</code> bytestring.</p> <p>Parameters:</p> Name Type Description Default <code>res</code> <code>Response</code> <p>An <code>httpx.Response</code> object, with <code>.content</code> to be decoded.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A <code>dict</code> from the <code>httpx.Response</code>'s <code>.content</code> param.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>def decode_res_content(self, res: httpx.Response = None) -&gt; dict:\n    \"\"\"Use multiple methods to attempt to decode an `httpx.Response.content` bytestring.\n\n    Params:\n        res (httpx.Response): An `httpx.Response` object, with `.content` to be decoded.\n\n    Returns:\n        (dict): A `dict` from the `httpx.Response`'s `.content` param.\n\n    \"\"\"\n    assert res, ValueError(\"Missing httpx Response object\")\n    assert isinstance(res, httpx.Response), TypeError(\n        f\"res must be of type httpx.Response. Got type: ({type(res)})\"\n    )\n\n    _content: bytes = res.content\n    assert _content, ValueError(\"Response content is empty\")\n    assert isinstance(_content, bytes), TypeError(\n        f\"Expected response.content to be a bytestring. Got type: ({type(_content)})\"\n    )\n\n    ## Get content's encoding, or default to 'utf-8'\n    try:\n        decode_charset: str = autodetect_charset(content=_content)\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception detecting response content's encoding. Details: {exc}\"\n        )\n        log.error(msg)\n        log.warning(\"Defaulting to 'utf-8'\")\n\n        decode_charset: str = \"utf-8\"\n\n    ## Decode content\n    try:\n        _decode: str = res.content.decode(decode_charset)\n\n    except Exception as exc:\n        ## Decoding failed, retry with different encodings\n        msg = Exception(\n            f\"[Attempt 1/2] Unhandled exception decoding response content. Details: {exc}\"\n        )\n        log.warning(msg)\n\n        if not res.encoding == \"utf-8\":\n            ## Try decoding again, using response's .encoding param\n            log.warning(\n                f\"Retrying response content decode with encoding '{res.encoding}'\"\n            )\n            try:\n                _decode = res.content.decode(res.encoding)\n            except Exception as exc:\n                inner_msg = Exception(\n                    f\"[Attempt 2/2] Unhandled exception decoding response content. Details: {exc}\"\n                )\n                log.error(inner_msg)\n\n                raise inner_msg\n\n        else:\n            ## Decoding with utf-8 failed, attempt with ISO-8859-1\n            #  https://en.wikipedia.org/wiki/ISO/IEC_8859-1\n            log.warning(\n                \"Detected UTF-8 encoding, but decoding as UTF-8 failed. Retrying with encoding ISO-8859-1.\"\n            )\n            try:\n                _decode = res.content.decode(\"ISO-8859-1\")\n            except Exception as exc:\n                msg = Exception(\n                    f\"Failure attempting to decode content as UTF-8 and ISO-8859-1. Details: {exc}\"\n                )\n                log.error(msg)\n\n                raise exc\n\n    ## Load decoded content into dict\n    try:\n        _json: dict = json.loads(_decode)\n\n        return _json\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception loading decoded response content to dict. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/controllers/_controllers/#red_utils.ext.httpx_utils.controllers._controllers.HishelCacheClientController.new_request","title":"<code>new_request(method='GET', url=None, files=None, _json=None, params=None, headers=None, cookies=None, timeout=None)</code>","text":"<p>Assemble a new httpx.Request object from parts.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>[Default: \"GET\"] HTTP method for request.</p> <code>'GET'</code> <code>url</code> <code>str | URL</code> <p>URL to send request.</p> <code>None</code> <code>files</code> <code>list | None</code> <p>List of files to send with request. Only works with certain HTTP methods, list <code>POST</code>.</p> <code>None</code> <code>_json</code> <code>Any | None</code> <p>JSON to append to request.</p> <code>None</code> <code>params</code> <code>dict | None</code> <p>Params to append to request.</p> <code>None</code> <code>headers</code> <code>dict | None</code> <p>Request headers.</p> <code>None</code> <code>cookies</code> <code>dict</code> <p> <code>None</code> <code>timeout</code> <code>int | float</code> <p>Timeout (in seconds) before cancelling request.</p> <code>None</code> <p>Returns:</p> Type Description <code>Request</code> <p>An initialized <code>httpx.Request</code> object.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>def new_request(\n    self,\n    method: str = \"GET\",\n    url: str = None,\n    files: list | None = None,\n    _json: t.Any | None = None,\n    params: dict | None = None,\n    headers: dict | None = None,\n    cookies: dict | None = None,\n    timeout: int | float | None = None,\n) -&gt; httpx.Request:\n    \"\"\"Assemble a new httpx.Request object from parts.\n\n    Params:\n        method (str): [Default: \"GET\"] HTTP method for request.\n        url (str|httpx.URL): URL to send request.\n        files (list|None): List of files to send with request. Only works with certain HTTP methods,\n            list `POST`.\n        _json (t.Any | None): JSON to append to request.\n        params (dict | None): Params to append to request.\n        headers (dict|None): Request headers.\n        cookies (dict): &lt;Not yet documented&gt;\n        timeout (int|float): Timeout (in seconds) before cancelling request.\n\n    Returns:\n        (httpx.Request): An initialized `httpx.Request` object.\n\n    \"\"\"\n    assert method, ValueError(\"Missing a request method\")\n    assert isinstance(method, str), TypeError(\n        f\"method should be a string. Got type: ({type(method)})\"\n    )\n\n    ## Ensure method is uppercase, i.e. 'get' -&gt; 'GET'\n    method: str = method.upper()\n\n    assert url, ValueError(\"Missing a URL\")\n    assert isinstance(url, str) or isinstance(url, httpx.URL), TypeError(\n        f\"URL must be a string or httpx.URL. Got type: ({type(url)})\"\n    )\n    if isinstance(url, str):\n        ## Convert URL from string into httpx.URL object\n        url: httpx.URL = httpx.URL(url=url)\n\n    if timeout:\n        assert (\n            isinstance(timeout, int) or isinstance(timeout, float)\n        ) and timeout &gt; 0, TypeError(\n            f\"timeout must be a non-zero positive int or float. Got type: ({type(timeout)})\"\n        )\n\n    ## Build httpx.Request object\n    try:\n        _req: httpx.Request = self.client.build_request(\n            method=method,\n            url=url,\n            files=files,\n            json=_json,\n            params=params,\n            headers=headers,\n            cookies=cookies,\n            timeout=timeout,\n        )\n\n        return _req\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception creaeting httpx.Request object. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/controllers/_controllers/#red_utils.ext.httpx_utils.controllers._controllers.HishelCacheClientController.send_request","title":"<code>send_request(request=None, stream=False, auth=None, debug_response=False)</code>","text":"<p>Send httpx.Request using self.Client (and optional cache transport).</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>An initialized <code>httpx.Request</code> object.</p> <code>None</code> <code>stream</code> <code>bool</code> <p>When <code>True</code>, response bytes will be streamed. This can be useful for large file downloads.</p> <code>False</code> <code>auth</code> <code>Auth</code> <p> <code>None</code> <p>Returns:</p> Type Description <code>Response</code> <p>An <code>httpx.Response</code> from the request.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>def send_request(\n    self,\n    request: httpx.Request = None,\n    stream: bool = False,\n    auth: httpx.Auth = None,\n    debug_response: bool = False,\n) -&gt; httpx.Response:\n    \"\"\"Send httpx.Request using self.Client (and optional cache transport).\n\n    Params:\n        request (httpx.Request): An initialized `httpx.Request` object.\n        stream (bool): When `True`, response bytes will be streamed. This can be useful for large file downloads.\n        auth (httpx.Auth): &lt;Not yet documented&gt;\n\n    Returns:\n        (httpx.Response): An `httpx.Response` from the request.\n\n    \"\"\"\n    assert request, ValueError(\"Missing an httpx.Request object\")\n    assert isinstance(request, httpx.Request), TypeError(\n        f\"Expected request to be an httpx.Request object. Got type: ({type(request)})\"\n    )\n\n    ## Send request using class's httpx.Client\n    try:\n        res: httpx.Response = self.client.send(\n            request=request,\n            stream=stream,\n            auth=auth,\n            follow_redirects=self.follow_redirects,\n        )\n        if debug_response:\n            log.debug(\n                f\"Response: [{res.status_code}: {res.reason_phrase}] {request.url}\"\n            )\n\n        return res\n\n    except httpx.ConnectError as conn_err:\n        ## Error connecting to remote\n        msg = Exception(\n            f\"ConnectError while requesting URL {request.url}. Details: {conn_err}\"\n        )\n        log.error(msg)\n\n        return\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception sending request. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/controllers/_controllers/#red_utils.ext.httpx_utils.controllers._controllers.autodetect_charset","title":"<code>autodetect_charset(content=None)</code>","text":"<p>Attempt to automatically detect encoding from input bytestring.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\controllers\\_controllers.py</code> <pre><code>def autodetect_charset(content: bytes = None):\n    \"\"\"Attempt to automatically detect encoding from input bytestring.\"\"\"\n    try:\n        ## Detect encoding from bytes\n        _encoding: str | None = chardet.detect(byte_str=content).get(\"encoding\")\n\n        if not _encoding:\n            ## Default to utf-8\n            _encoding = \"utf-8\"\n\n        return _encoding\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception auto-detecting character set for input bytestring. Details: {exc}\"\n        )\n        log.error(msg)\n        log.warning(\"Defaulting to utf-8\")\n\n        return \"utf-8\"\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/decoders/__init__/","title":"decoders","text":""},{"location":"reference/red_utils/ext/httpx_utils/decoders/__init__/#red_utils.ext.httpx_utils.decoders.autodetect_charset","title":"<code>autodetect_charset(content=None)</code>","text":"<p>Attempt to automatically detect encoding from input bytestring.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\decoders\\__response_decoders.py</code> <pre><code>def autodetect_charset(content: bytes = None):\n    \"\"\"Attempt to automatically detect encoding from input bytestring.\"\"\"\n    try:\n        ## Detect encoding from bytes\n        _encoding: str | None = chardet.detect(byte_str=content).get(\"encoding\")\n\n        if not _encoding:\n            ## Default to utf-8\n            _encoding = \"utf-8\"\n\n        return _encoding\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception auto-detecting character set for input bytestring. Details: {exc}\"\n        )\n        log.error(msg)\n        log.warning(\"Defaulting to utf-8\")\n\n        return \"utf-8\"\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/decoders/__init__/#red_utils.ext.httpx_utils.decoders.decode_res_content","title":"<code>decode_res_content(self, res=None)</code>","text":"<p>Use multiple methods to attempt to decode an <code>httpx.Response.content</code> bytestring.</p> <p>Parameters:</p> Name Type Description Default <code>res</code> <code>Response</code> <p>An <code>httpx.Response</code> object, with <code>.content</code> to be decoded.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A <code>dict</code> from the <code>httpx.Response</code>'s <code>.content</code> param.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\decoders\\__response_decoders.py</code> <pre><code>def decode_res_content(self, res: httpx.Response = None) -&gt; dict:\n    \"\"\"Use multiple methods to attempt to decode an `httpx.Response.content` bytestring.\n\n    Params:\n        res (httpx.Response): An `httpx.Response` object, with `.content` to be decoded.\n\n    Returns:\n        (dict): A `dict` from the `httpx.Response`'s `.content` param.\n\n    \"\"\"\n    assert res, ValueError(\"Missing httpx Response object\")\n    assert isinstance(res, httpx.Response), TypeError(\n        f\"res must be of type httpx.Response. Got type: ({type(res)})\"\n    )\n\n    _content: bytes = res.content\n    assert _content, ValueError(\"Response content is empty\")\n    assert isinstance(_content, bytes), TypeError(\n        f\"Expected response.content to be a bytestring. Got type: ({type(_content)})\"\n    )\n\n    ## Get content's encoding, or default to 'utf-8'\n    try:\n        decode_charset: str = autodetect_charset(content=_content)\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception detecting response content's encoding. Details: {exc}\"\n        )\n        log.error(msg)\n        log.trace(exc)\n        log.warning(f\"Defaulting to 'utf-8'\")\n\n        decode_charset: str = \"utf-8\"\n\n    ## Decode content\n    try:\n        _decode: str = res.content.decode(decode_charset)\n\n    except Exception as exc:\n        ## Decoding failed, retry with different encodings\n        msg = Exception(\n            f\"[Attempt 1/2] Unhandled exception decoding response content. Details: {exc}\"\n        )\n        log.warning(msg)\n\n        if not res.encoding == \"utf-8\":\n            ## Try decoding again, using response's .encoding param\n            log.warning(\n                f\"Retrying response content decode with encoding '{res.encoding}'\"\n            )\n            try:\n                _decode = res.content.decode(res.encoding)\n            except Exception as exc:\n                inner_msg = Exception(\n                    f\"[Attempt 2/2] Unhandled exception decoding response content. Details: {exc}\"\n                )\n                log.error(inner_msg)\n\n                raise inner_msg\n\n        else:\n            ## Decoding with utf-8 failed, attempt with ISO-8859-1\n            #  https://en.wikipedia.org/wiki/ISO/IEC_8859-1\n            log.warning(\n                f\"Detected UTF-8 encoding, but decoding as UTF-8 failed. Retrying with encoding ISO-8859-1.\"\n            )\n            try:\n                _decode = res.content.decode(\"ISO-8859-1\")\n            except Exception as exc:\n                msg = Exception(\n                    f\"Failure attempting to decode content as UTF-8 and ISO-8859-1. Details: {exc}\"\n                )\n\n                raise msg\n\n    ## Load decoded content into dict\n    try:\n        _json: dict = json.loads(_decode)\n\n        return _json\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception loading decoded response content to dict. Details: {exc}\"\n        )\n\n        raise msg\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/decoders/__response_decoders/","title":"__response_decoders","text":""},{"location":"reference/red_utils/ext/httpx_utils/decoders/__response_decoders/#red_utils.ext.httpx_utils.decoders.__response_decoders.autodetect_charset","title":"<code>autodetect_charset(content=None)</code>","text":"<p>Attempt to automatically detect encoding from input bytestring.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\decoders\\__response_decoders.py</code> <pre><code>def autodetect_charset(content: bytes = None):\n    \"\"\"Attempt to automatically detect encoding from input bytestring.\"\"\"\n    try:\n        ## Detect encoding from bytes\n        _encoding: str | None = chardet.detect(byte_str=content).get(\"encoding\")\n\n        if not _encoding:\n            ## Default to utf-8\n            _encoding = \"utf-8\"\n\n        return _encoding\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception auto-detecting character set for input bytestring. Details: {exc}\"\n        )\n        log.error(msg)\n        log.warning(\"Defaulting to utf-8\")\n\n        return \"utf-8\"\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/decoders/__response_decoders/#red_utils.ext.httpx_utils.decoders.__response_decoders.decode_res_content","title":"<code>decode_res_content(self, res=None)</code>","text":"<p>Use multiple methods to attempt to decode an <code>httpx.Response.content</code> bytestring.</p> <p>Parameters:</p> Name Type Description Default <code>res</code> <code>Response</code> <p>An <code>httpx.Response</code> object, with <code>.content</code> to be decoded.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A <code>dict</code> from the <code>httpx.Response</code>'s <code>.content</code> param.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\decoders\\__response_decoders.py</code> <pre><code>def decode_res_content(self, res: httpx.Response = None) -&gt; dict:\n    \"\"\"Use multiple methods to attempt to decode an `httpx.Response.content` bytestring.\n\n    Params:\n        res (httpx.Response): An `httpx.Response` object, with `.content` to be decoded.\n\n    Returns:\n        (dict): A `dict` from the `httpx.Response`'s `.content` param.\n\n    \"\"\"\n    assert res, ValueError(\"Missing httpx Response object\")\n    assert isinstance(res, httpx.Response), TypeError(\n        f\"res must be of type httpx.Response. Got type: ({type(res)})\"\n    )\n\n    _content: bytes = res.content\n    assert _content, ValueError(\"Response content is empty\")\n    assert isinstance(_content, bytes), TypeError(\n        f\"Expected response.content to be a bytestring. Got type: ({type(_content)})\"\n    )\n\n    ## Get content's encoding, or default to 'utf-8'\n    try:\n        decode_charset: str = autodetect_charset(content=_content)\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception detecting response content's encoding. Details: {exc}\"\n        )\n        log.error(msg)\n        log.trace(exc)\n        log.warning(f\"Defaulting to 'utf-8'\")\n\n        decode_charset: str = \"utf-8\"\n\n    ## Decode content\n    try:\n        _decode: str = res.content.decode(decode_charset)\n\n    except Exception as exc:\n        ## Decoding failed, retry with different encodings\n        msg = Exception(\n            f\"[Attempt 1/2] Unhandled exception decoding response content. Details: {exc}\"\n        )\n        log.warning(msg)\n\n        if not res.encoding == \"utf-8\":\n            ## Try decoding again, using response's .encoding param\n            log.warning(\n                f\"Retrying response content decode with encoding '{res.encoding}'\"\n            )\n            try:\n                _decode = res.content.decode(res.encoding)\n            except Exception as exc:\n                inner_msg = Exception(\n                    f\"[Attempt 2/2] Unhandled exception decoding response content. Details: {exc}\"\n                )\n                log.error(inner_msg)\n\n                raise inner_msg\n\n        else:\n            ## Decoding with utf-8 failed, attempt with ISO-8859-1\n            #  https://en.wikipedia.org/wiki/ISO/IEC_8859-1\n            log.warning(\n                f\"Detected UTF-8 encoding, but decoding as UTF-8 failed. Retrying with encoding ISO-8859-1.\"\n            )\n            try:\n                _decode = res.content.decode(\"ISO-8859-1\")\n            except Exception as exc:\n                msg = Exception(\n                    f\"Failure attempting to decode content as UTF-8 and ISO-8859-1. Details: {exc}\"\n                )\n\n                raise msg\n\n    ## Load decoded content into dict\n    try:\n        _json: dict = json.loads(_decode)\n\n        return _json\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception loading decoded response content to dict. Details: {exc}\"\n        )\n\n        raise msg\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/encoders/__init__/","title":"encoders","text":"<p>Encoding/decoding helpers.</p>"},{"location":"reference/red_utils/ext/httpx_utils/encoders/__init__/#red_utils.ext.httpx_utils.encoders.DateTimeEncoder","title":"<code>DateTimeEncoder</code>","text":"<p>               Bases: <code>JSONEncoder</code></p> <p>Handle encoding a <code>datetime.datetime</code> or <code>pendulum.DateTime</code> as an ISO-formatted string.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\encoders\\json_encoders\\_encoders.py</code> <pre><code>class DateTimeEncoder(json.JSONEncoder):\n    \"\"\"Handle encoding a `datetime.datetime` or `pendulum.DateTime` as an ISO-formatted string.\"\"\"\n\n    def default(self, o) -&gt; str | json.Any:\n        if isinstance(o, datetime):\n            return o.isoformat()\n        elif isinstance(o, pendulum.DateTime):\n            return o.isoformat()\n\n        try:\n            _encoded = json.JSONEncoder.default(self=self, o=o)\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception encoding DateTime. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n        return _encoded\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/encoders/json_encoders/__init__/","title":"json_encoders","text":"<p>JSON encoder/decoder helpers.</p>"},{"location":"reference/red_utils/ext/httpx_utils/encoders/json_encoders/__init__/#red_utils.ext.httpx_utils.encoders.json_encoders.DateTimeEncoder","title":"<code>DateTimeEncoder</code>","text":"<p>               Bases: <code>JSONEncoder</code></p> <p>Handle encoding a <code>datetime.datetime</code> or <code>pendulum.DateTime</code> as an ISO-formatted string.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\encoders\\json_encoders\\_encoders.py</code> <pre><code>class DateTimeEncoder(json.JSONEncoder):\n    \"\"\"Handle encoding a `datetime.datetime` or `pendulum.DateTime` as an ISO-formatted string.\"\"\"\n\n    def default(self, o) -&gt; str | json.Any:\n        if isinstance(o, datetime):\n            return o.isoformat()\n        elif isinstance(o, pendulum.DateTime):\n            return o.isoformat()\n\n        try:\n            _encoded = json.JSONEncoder.default(self=self, o=o)\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception encoding DateTime. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n        return _encoded\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/encoders/json_encoders/_encoders/","title":"_encoders","text":""},{"location":"reference/red_utils/ext/httpx_utils/encoders/json_encoders/_encoders/#red_utils.ext.httpx_utils.encoders.json_encoders._encoders.DateTimeEncoder","title":"<code>DateTimeEncoder</code>","text":"<p>               Bases: <code>JSONEncoder</code></p> <p>Handle encoding a <code>datetime.datetime</code> or <code>pendulum.DateTime</code> as an ISO-formatted string.</p> Source code in <code>src\\red_utils\\ext\\httpx_utils\\encoders\\json_encoders\\_encoders.py</code> <pre><code>class DateTimeEncoder(json.JSONEncoder):\n    \"\"\"Handle encoding a `datetime.datetime` or `pendulum.DateTime` as an ISO-formatted string.\"\"\"\n\n    def default(self, o) -&gt; str | json.Any:\n        if isinstance(o, datetime):\n            return o.isoformat()\n        elif isinstance(o, pendulum.DateTime):\n            return o.isoformat()\n\n        try:\n            _encoded = json.JSONEncoder.default(self=self, o=o)\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception encoding DateTime. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n        return _encoded\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/transports/__init__/","title":"transports","text":""},{"location":"reference/red_utils/ext/httpx_utils/transports/__init__/#red_utils.ext.httpx_utils.transports.get_cache_transport","title":"<code>get_cache_transport(cache_dir='.cache/hishel', ttl=None, verify=True, retries=0, cert=None)</code>","text":"<p>Return an initialized hishel.CacheTransport.</p> <p>Parameters:</p> Name Type Description Default <code>cache_dir</code> <code>str</code> <p>[default: .cache/hishel] Directory where cache files will be stored.</p> <code>'.cache/hishel'</code> <code>ttl</code> <code>int | None</code> <p>[default: None] Limit ttl on requests sent with this transport.</p> <code>None</code> <code>verify</code> <code>bool</code> <p>[default: True] Verify SSL certificates on requests sent with this transport.</p> <code>True</code> <code>retries</code> <code>int</code> <p>[default: 0] Number of times to retry requests sent with this transport.</p> <code>0</code> <code>cert</code> <code>valid HTTPX Cert</code> <p>An optional SSL certificate to send with requests.</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\httpx_utils\\transports\\_transports.py</code> <pre><code>def get_cache_transport(\n    cache_dir: str = \".cache/hishel\",\n    ttl: int | None = None,\n    verify: bool = True,\n    retries: int = 0,\n    cert: t.Union[\n        str, tuple[str, str | None], tuple[str, str | None, str | None]\n    ] = None,\n) -&gt; hishel.CacheTransport:\n    \"\"\"Return an initialized hishel.CacheTransport.\n\n    Params:\n        cache_dir (str): [default: .cache/hishel] Directory where cache files will be stored.\n        ttl (int|None): [default: None] Limit ttl on requests sent with this transport.\n        verify (bool): [default: True] Verify SSL certificates on requests sent with this transport.\n        retries (int): [default: 0] Number of times to retry requests sent with this transport.\n        cert (valid HTTPX Cert): An optional SSL certificate to send with requests.\n\n    \"\"\"\n    # Create a cache instance with hishel\n    cache_storage = hishel.FileStorage(base_path=cache_dir, ttl=ttl)\n    cache_transport = httpx.HTTPTransport(verify=verify, cert=cert, retries=retries)\n\n    try:\n        # Create an HTTP cache transport\n        cache_transport = hishel.CacheTransport(\n            transport=cache_transport, storage=cache_storage\n        )\n\n        return cache_transport\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception returning cache transport. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/httpx_utils/transports/_transports/","title":"_transports","text":""},{"location":"reference/red_utils/ext/httpx_utils/transports/_transports/#red_utils.ext.httpx_utils.transports._transports.get_cache_transport","title":"<code>get_cache_transport(cache_dir='.cache/hishel', ttl=None, verify=True, retries=0, cert=None)</code>","text":"<p>Return an initialized hishel.CacheTransport.</p> <p>Parameters:</p> Name Type Description Default <code>cache_dir</code> <code>str</code> <p>[default: .cache/hishel] Directory where cache files will be stored.</p> <code>'.cache/hishel'</code> <code>ttl</code> <code>int | None</code> <p>[default: None] Limit ttl on requests sent with this transport.</p> <code>None</code> <code>verify</code> <code>bool</code> <p>[default: True] Verify SSL certificates on requests sent with this transport.</p> <code>True</code> <code>retries</code> <code>int</code> <p>[default: 0] Number of times to retry requests sent with this transport.</p> <code>0</code> <code>cert</code> <code>valid HTTPX Cert</code> <p>An optional SSL certificate to send with requests.</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\httpx_utils\\transports\\_transports.py</code> <pre><code>def get_cache_transport(\n    cache_dir: str = \".cache/hishel\",\n    ttl: int | None = None,\n    verify: bool = True,\n    retries: int = 0,\n    cert: t.Union[\n        str, tuple[str, str | None], tuple[str, str | None, str | None]\n    ] = None,\n) -&gt; hishel.CacheTransport:\n    \"\"\"Return an initialized hishel.CacheTransport.\n\n    Params:\n        cache_dir (str): [default: .cache/hishel] Directory where cache files will be stored.\n        ttl (int|None): [default: None] Limit ttl on requests sent with this transport.\n        verify (bool): [default: True] Verify SSL certificates on requests sent with this transport.\n        retries (int): [default: 0] Number of times to retry requests sent with this transport.\n        cert (valid HTTPX Cert): An optional SSL certificate to send with requests.\n\n    \"\"\"\n    # Create a cache instance with hishel\n    cache_storage = hishel.FileStorage(base_path=cache_dir, ttl=ttl)\n    cache_transport = httpx.HTTPTransport(verify=verify, cert=cert, retries=retries)\n\n    try:\n        # Create an HTTP cache transport\n        cache_transport = hishel.CacheTransport(\n            transport=cache_transport, storage=cache_storage\n        )\n\n        return cache_transport\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception returning cache transport. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/__init__/","title":"loguru_utils","text":"<p>Utilities, classes, functions, constants, &amp; more for the <code>loguru</code> library.</p> <p>When using the <code>init_logger()</code> function, make sure to run it as soon as possible. If possible, start your script like:</p> <pre><code>...\n\n## List of Loguru sink dicts\nloguru_sinks = [LoguruSinkStdOut(level=\"DEBUG\").as_dict(), LoguruSinkErrFile().as_dict()]\n\nif __name__ == \"__main__\":\n    init_logger(sinks=loguru_sinks)\n\n    ...\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/__init__/#red_utils.ext.loguru_utils.DefaultSinks","title":"<code>DefaultSinks</code>  <code>dataclass</code>","text":"<p>               Bases: <code>LoguruSinkBase</code></p> <p>Return initialized defaults for Loguru sink classes.</p> <p>Access initialized sinks as class parameters. For example, to get an STDOUT logger, initialized with the default LoguruSinkStdOut settings: <code>DefaultSinks().stdout</code></p> <p>To get a list of initialized default sinks (an <code>app.log</code>, <code>err.log</code>, and <code>STDOUT</code> logger), choose from <code>.color</code> (for loggers initialized with colorize; excludes file loggers), or <code>.nocolor</code> (no colorize initialized):</p> <p><code>DefaultSinks().stdout.color</code></p> Source code in <code>src\\red_utils\\ext\\loguru_utils\\sinks.py</code> <pre><code>class DefaultSinks(LoguruSinkBase):\n    \"\"\"Return initialized defaults for Loguru sink classes.\n\n    Access initialized sinks as class parameters. For example, to get an STDOUT logger,\n    initialized with the default LoguruSinkStdOut settings: `DefaultSinks().stdout`\n\n    To get a list of initialized default sinks (an `app.log`, `err.log`, and `STDOUT` logger), choose\n    from `.color` (for loggers initialized with colorize; excludes file loggers), or `.nocolor` (no colorize initialized):\n\n    `DefaultSinks().stdout.color`\n    \"\"\"\n\n    stdout: LoguruSinkStdOut | None = default_stdout_sink\n    stderr: LoguruSinkStdErr | None = default_stderr_sink\n    log_file: LoguruSinkAppFile | None = default_app_log_file_sink\n    error_log_file: LoguruSinkErrFile | None = default_error_log_file_sink\n    trace_log_file: LoguruSinkTraceFile | None = default_trace_log_file_sink\n\n    @property\n    def color(\n        self,\n    ) -&gt; list[dict]:\n        \"\"\"List of initialized Loguru loggers.\n\n        Returns:\n            (list[dict]): List of Loguru sink dicts with `colorize=True`.\n\n        \"\"\"\n        sink_list = [\n            self.stdout,\n            self.log_file,\n            self.error_log_file,\n            self.trace_log_file,\n        ]\n\n        return sink_list\n\n    @property\n    def no_color(\n        self,\n    ) -&gt; list[dict]:\n        \"\"\"List of initialized Loguru loggers.\n\n        Returns:\n            (list[dict]): List of Loguru sink dicts with `colorize=False`.\n\n        \"\"\"\n        sink_list = [\n            default_stdout_no_color_sink,\n            self.log_file,\n            self.error_log_file,\n            self.trace_log_file,\n        ]\n\n        return sink_list\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/__init__/#red_utils.ext.loguru_utils.DefaultSinks.color","title":"<code>color: list[dict]</code>  <code>property</code>","text":"<p>List of initialized Loguru loggers.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>List of Loguru sink dicts with <code>colorize=True</code>.</p>"},{"location":"reference/red_utils/ext/loguru_utils/__init__/#red_utils.ext.loguru_utils.DefaultSinks.no_color","title":"<code>no_color: list[dict]</code>  <code>property</code>","text":"<p>List of initialized Loguru loggers.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>List of Loguru sink dicts with <code>colorize=False</code>.</p>"},{"location":"reference/red_utils/ext/loguru_utils/__init__/#red_utils.ext.loguru_utils.LogLevel","title":"<code>LogLevel</code>  <code>dataclass</code>","text":"<p>Class representing a <code>loguru</code> log level.</p> Source code in <code>src\\red_utils\\ext\\loguru_utils\\constants.py</code> <pre><code>@dataclass\nclass LogLevel:\n    \"\"\"Class representing a `loguru` log level.\"\"\"\n\n    name: str = field(default=None)\n    level_name: str = field(default=None)\n    severity: int = field(default=None)\n    method: Callable = field(default=None)\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/__init__/#red_utils.ext.loguru_utils.LoguruSinkAppFile","title":"<code>LoguruSinkAppFile</code>  <code>dataclass</code>","text":"<p>               Bases: <code>LoguruSinkFileBase</code>, <code>DictMixin</code></p> <p>Sink class for app.log file.</p> <p>Parameters:</p> Name Type Description Default <code>sink</code> <code>(str, TextIO)</code> <p>the Loguru sink definition</p> <code>f'{LOG_DIR}/app.log'</code> <code>colorize</code> <code>bool</code> <p>If <code>True</code>, log messages will be colorized</p> <code>True</code> <code>retention</code> <code>str | int</code> <p>Amount of time to retain log files</p> <code>3</code> <code>rotation</code> <code>str</code> <p>Size limit when a log file will be rotated</p> <code>'5 MB'</code> <code>format</code> <code>str</code> <p>A formatted string for log messages</p> <code>default_fmt</code> <code>level</code> <code>str</code> <p>Level of logs to log to file, i.e. <code>\"INFO\"</code>, <code>\"DEBUG\"</code>, etc</p> <code>'DEBUG'</code> <code>enqueue</code> <code>bool</code> <p>Set to <code>True</code> if app is asynchronous in order to avoid IO collisions</p> <code>True</code> Source code in <code>src\\red_utils\\ext\\loguru_utils\\sinks.py</code> <pre><code>@dataclass\nclass LoguruSinkAppFile(LoguruSinkFileBase, DictMixin):\n    \"\"\"Sink class for app.log file.\n\n    Params:\n        sink (str, TextIO): the Loguru sink definition\n        colorize (bool): If `True`, log messages will be colorized\n        retention (str|int): Amount of time to retain log files\n        rotation (str): Size limit when a log file will be rotated\n        format (str): A formatted string for log messages\n        level (str): Level of logs to log to file, i.e. `\"INFO\"`, `\"DEBUG\"`, etc\n        enqueue (bool): Set to `True` if app is asynchronous in order to avoid IO\n            collisions\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/__init__/#red_utils.ext.loguru_utils.LoguruSinkDefault","title":"<code>LoguruSinkDefault</code>  <code>dataclass</code>","text":"<p>               Bases: <code>LoguruSinkBase</code></p> <p>Default Loguru sink. Defaults to colorized, formatted stdout, level=INFO.</p> <p>Use this class as a starting point to create customized Loguru sinks. Create a new class by inheriting from this one:</p> <pre><code>my_loguru_sink = LoguruSinkDefault(sink=...,level=..., colorize=True)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>sink</code> <code>str | TextIO</code> <p>A Loguru sink. Can be a string (i.e. \"app.log\" for a file at ./app.log) or a Python callable (i.e. sys.stdout). Loguru Docs: sinks</p> <code>stdout</code> <code>format</code> <code>str</code> <p>A string describing the format for the Loguru logger. Loguru Docs: time formatting. Loguru Docs: color markup formatting.</p> <code>default_fmt</code> <code>level</code> <code>str</code> <p>A severity level string for the logger. Controls which messages will be outputted. Value will be forced uppercase. Loguru Docs: Severity levels</p> <code>'INFO'</code> <code>colorize</code> <code>bool</code> <p>Control whether logger outputs are colorized.</p> <code>False</code> Source code in <code>src\\red_utils\\ext\\loguru_utils\\sinks.py</code> <pre><code>@dataclass\nclass LoguruSinkDefault(LoguruSinkBase):\n    \"\"\"Default Loguru sink. Defaults to colorized, formatted stdout, level=INFO.\n\n    Use this class as a starting point to create customized Loguru sinks. Create a new class\n    by inheriting from this one:\n\n    ``` py linenums=\"1\"\n    my_loguru_sink = LoguruSinkDefault(sink=...,level=..., colorize=True)\n    ```\n\n    Params:\n        sink (str|TextIO): A Loguru sink. Can be a string (i.e. \"app.log\" for a file at ./app.log) or a Python callable (i.e. sys.stdout).\n            [Loguru Docs: sinks](https://loguru.readthedocs.io/en/stable/api/logger.html#sink)\n        format (str): A string describing the format for the Loguru logger.\n            [Loguru Docs: time formatting](https://loguru.readthedocs.io/en/stable/api/logger.html#time).\n            [Loguru Docs: color markup formatting](https://loguru.readthedocs.io/en/stable/api/logger.html#color).\n        level (str): A severity level string for the logger. Controls which messages will be outputted. Value will be forced uppercase.\n            [Loguru Docs: Severity levels](https://loguru.readthedocs.io/en/stable/api/logger.html#levels)\n        colorize (bool): Control whether logger outputs are colorized.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/__init__/#red_utils.ext.loguru_utils.LoguruSinkErrFile","title":"<code>LoguruSinkErrFile</code>  <code>dataclass</code>","text":"<p>               Bases: <code>LoguruSinkFileBase</code></p> <p>Sink class for error.log file.</p> <p>Parameters:</p> Name Type Description Default <code>sink</code> <code>(str, TextIO)</code> <p>the Loguru sink definition</p> <code>f'{LOG_DIR}/error.log'</code> <code>colorize</code> <code>bool</code> <p>If <code>True</code>, log messages will be colorized</p> <code>True</code> <code>retention</code> <code>str | int</code> <p>Amount of time to retain log files</p> <code>3</code> <code>rotation</code> <code>str</code> <p>Size limit when a log file will be rotated</p> <code>'5 MB'</code> <code>format</code> <code>str</code> <p>A formatted string for log messages</p> <code>default_fmt</code> <code>level</code> <code>str</code> <p>Level of logs to log to file, i.e. <code>\"INFO\"</code>, <code>\"DEBUG\"</code>, etc</p> <code>'ERROR'</code> <code>enqueue</code> <code>bool</code> <p>Set to <code>True</code> if app is asynchronous in order to avoid IO collisions</p> <code>True</code> Source code in <code>src\\red_utils\\ext\\loguru_utils\\sinks.py</code> <pre><code>@dataclass\nclass LoguruSinkErrFile(LoguruSinkFileBase):\n    \"\"\"Sink class for error.log file.\n\n    Params:\n        sink (str, TextIO): the Loguru sink definition\n        colorize (bool): If `True`, log messages will be colorized\n        retention (str|int): Amount of time to retain log files\n        rotation (str): Size limit when a log file will be rotated\n        format (str): A formatted string for log messages\n        level (str): Level of logs to log to file, i.e. `\"INFO\"`, `\"DEBUG\"`, etc\n        enqueue (bool): Set to `True` if app is asynchronous in order to avoid IO\n            collisions\n    \"\"\"\n\n    sink: Union[str, TextIO] = field(default=f\"{LOG_DIR}/error.log\")\n    level: str = field(default=\"ERROR\")\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/__init__/#red_utils.ext.loguru_utils.LoguruSinkFileDefault","title":"<code>LoguruSinkFileDefault</code>  <code>dataclass</code>","text":"<p>               Bases: <code>LoguruSinkFileBase</code></p> <p>Default Loguru file sink. Defaults to file <code>app.log</code>, <code>level=DEBUG</code>.</p> <p>Use this class as a starting point to create customized Loguru file sinks. Create a new class by inheriting from this one:</p> <pre><code>my_loguru_file_sink = LoguruSinkFileDefault(sink=...,level=..., colorize=True)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>sink</code> <code>(str, TextIO)</code> <p>the Loguru sink definition</p> <code>f'{LOG_DIR}/app.log'</code> <code>colorize</code> <code>bool</code> <p>If <code>True</code>, log messages will be colorized</p> <code>True</code> <code>retention</code> <code>str | int</code> <p>Amount of time to retain log files</p> <code>3</code> <code>rotation</code> <code>str</code> <p>Size limit when a log file will be rotated</p> <code>'5 MB'</code> <code>format</code> <code>str</code> <p>A formatted string for log messages</p> <code>default_fmt</code> <code>level</code> <code>str</code> <p>Level of logs to log to file, i.e. <code>\"INFO\"</code>, <code>\"DEBUG\"</code>, etc</p> <code>'DEBUG'</code> <code>enqueue</code> <code>bool</code> <p>Set to <code>True</code> if app is asynchronous in order to avoid IO collisions</p> <code>True</code> Source code in <code>src\\red_utils\\ext\\loguru_utils\\sinks.py</code> <pre><code>@dataclass\nclass LoguruSinkFileDefault(LoguruSinkFileBase):\n    \"\"\"Default Loguru file sink. Defaults to file `app.log`, `level=DEBUG`.\n\n    Use this class as a starting point to create customized Loguru file sinks. Create a new class\n    by inheriting from this one:\n\n    ``` py linenums=\"1\"\n    my_loguru_file_sink = LoguruSinkFileDefault(sink=...,level=..., colorize=True)\n    ```\n\n    Params:\n        sink (str, TextIO): the Loguru sink definition\n        colorize (bool): If `True`, log messages will be colorized\n        retention (str|int): Amount of time to retain log files\n        rotation (str): Size limit when a log file will be rotated\n        format (str): A formatted string for log messages\n        level (str): Level of logs to log to file, i.e. `\"INFO\"`, `\"DEBUG\"`, etc\n        enqueue (bool): Set to `True` if app is asynchronous in order to avoid IO\n            collisions\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/__init__/#red_utils.ext.loguru_utils.LoguruSinkStdErr","title":"<code>LoguruSinkStdErr</code>  <code>dataclass</code>","text":"<p>               Bases: <code>LoguruSinkBase</code></p> <p>Console STDERR sink.</p> <p>Parameters:</p> Name Type Description Default <code>sink</code> <code>(str, TextIO)</code> <p>the Loguru sink definition</p> <code>stderr</code> <code>format</code> <code>str</code> <p>A formatted string for log messages</p> <code>default_color_fmt</code> <code>colorize</code> <code>bool</code> <p>If <code>True</code>, log messages will be colorized</p> <code>True</code> Source code in <code>src\\red_utils\\ext\\loguru_utils\\sinks.py</code> <pre><code>@dataclass\nclass LoguruSinkStdErr(LoguruSinkBase):\n    \"\"\"Console STDERR sink.\n\n    Params:\n        sink (str, TextIO): the Loguru sink definition\n        format (str): A formatted string for log messages\n        colorize (bool): If `True`, log messages will be colorized\n    \"\"\"\n\n    sink: Union[str, TextIO] = field(default=sys.stderr)\n    format: str = field(default=default_color_fmt)\n    colorize: bool = field(default=True)\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/__init__/#red_utils.ext.loguru_utils.LoguruSinkStdOut","title":"<code>LoguruSinkStdOut</code>  <code>dataclass</code>","text":"<p>               Bases: <code>LoguruSinkBase</code>, <code>DictMixin</code></p> <p>Console STDOUT sink.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>A formatted string for log messages</p> <code>default_color_fmt</code> <code>colorize</code> <code>bool</code> <p>If <code>True</code>, log messages will be colorized</p> <code>True</code> Source code in <code>src\\red_utils\\ext\\loguru_utils\\sinks.py</code> <pre><code>@dataclass\nclass LoguruSinkStdOut(LoguruSinkBase, DictMixin):\n    \"\"\"Console STDOUT sink.\n\n    Params:\n        format (str): A formatted string for log messages\n        colorize (bool): If `True`, log messages will be colorized\n    \"\"\"\n\n    format: str = field(default=default_color_fmt)\n    colorize: bool = field(default=True)\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/__init__/#red_utils.ext.loguru_utils.LoguruSinkTraceFile","title":"<code>LoguruSinkTraceFile</code>  <code>dataclass</code>","text":"<p>               Bases: <code>LoguruSinkFileBase</code></p> <p>Sink class for trace.log file.</p> <p>Parameters:</p> Name Type Description Default <code>sink</code> <code>(str, TextIO)</code> <p>the Loguru sink definition</p> <code>f'{LOG_DIR}/trace.log'</code> <code>colorize</code> <code>bool</code> <p>If <code>True</code>, log messages will be colorized</p> <code>True</code> <code>retention</code> <code>str | int</code> <p>Amount of time to retain log files</p> <code>3</code> <code>rotation</code> <code>str</code> <p>Size limit when a log file will be rotated</p> <code>'5 MB'</code> <code>format</code> <code>str</code> <p>A formatted string for log messages</p> <code>default_fmt</code> <code>level</code> <code>str</code> <p>Level of logs to log to file, i.e. <code>\"INFO\"</code>, <code>\"DEBUG\"</code>, etc</p> <code>'TRACE'</code> <code>enqueue</code> <code>bool</code> <p>Set to <code>True</code> if app is asynchronous in order to avoid IO collisions</p> <code>True</code> Source code in <code>src\\red_utils\\ext\\loguru_utils\\sinks.py</code> <pre><code>@dataclass\nclass LoguruSinkTraceFile(LoguruSinkFileBase):\n    \"\"\"Sink class for trace.log file.\n\n    Params:\n        sink (str, TextIO): the Loguru sink definition\n        colorize (bool): If `True`, log messages will be colorized\n        retention (str|int): Amount of time to retain log files\n        rotation (str): Size limit when a log file will be rotated\n        format (str): A formatted string for log messages\n        level (str): Level of logs to log to file, i.e. `\"INFO\"`, `\"DEBUG\"`, etc\n        enqueue (bool): Set to `True` if app is asynchronous in order to avoid IO\n            collisions\n    \"\"\"\n\n    sink: Union[str, TextIO] = field(default=f\"{LOG_DIR}/trace.log\")\n    level: str = field(default=\"TRACE\")\n    filter: str = field(default=\"TRACE\")\n    backtrace: bool = field(default=True)\n    diagnose: bool = field(default=True)\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/__init__/#red_utils.ext.loguru_utils.add_sink","title":"<code>add_sink(_logger=None, sink=None, level='INFO', format=default_fmt, color_format=default_color_fmt, filter=None, colorize=False, serialize=False, backtrace=False, diagnose=False, enqueue=False, catch=False, rotation=None, retention=None, compression=None)</code>","text":"<p>Add a sink to a Loguru logger.</p> <p>Helper function for adding a sink to a Loguru logger. Can be called without arguments to use a default instance.</p> <p>Parameters:</p> Name Type Description Default <code>_logger</code> <code>logger</code> <p>An instance of <code>loguru.logger</code> to add a sink to</p> <code>None</code> <code>sink</code> <code>str | Path | TextIOWrapper | Handler | Callable | Coroutine</code> <p>A Loguru-compatible logger sink. If the value is a <code>str</code> or <code>Path</code>, the sink will be a file. Read the Loguru sinks docs for more info, or the Loguru file sink config docs.</p> <code>None</code> <code>level</code> <code>str</code> <p>The all-caps log level for the sink, i.e. <code>\"INFO\"</code>, <code>\"DEBUG\"</code>, etc</p> <code>'INFO'</code> <code>format</code> <code>str | Callable</code> <p>The formatting for a log message</p> <code>default_fmt</code> <code>color_format</code> <code>str | Callable</code> <p>The formatting for a colored log message</p> <code>default_color_fmt</code> <code>filter</code> <code>(str | Callable, dict)</code> <p>A filter to control messages logged by Loguru</p> <code>None</code> <code>colorize</code> <code>bool</code> <p>If <code>True</code>, log messages will be colored using the <code>color_format</code></p> <code>False</code> <code>serialize</code> <code>bool</code> <p>If <code>True</code>, log messages will be formatted as json strings</p> <code>False</code> <code>backtrace</code> <code>bool</code> <p>If <code>True</code>, errors/traces will print the preceding stack trace that lead to a crash</p> <code>False</code> <code>diagnose</code> <code>bool</code> <p>If <code>True</code>, exception trace will display variable values for debugging. Warning: This should be set to <code>False</code> in production to avoid leaking sensitive data.</p> <code>False</code> <code>enqueue</code> <code>bool</code> <p>If using Loguru in an async context, <code>enqueue</code> should be set to <code>True</code> to avoid IO collisions when logging to a file.</p> <code>False</code> <code>catch</code> <code>bool</code> <p>If <code>True</code>, errors occurring while sink handles logs messages will be automatically caught, and an exception message will be displayed in <code>sys.stderr</code>. With this option, the exception is not propagated to the caller, preventing your app from crashing.</p> <code>False</code> <code>rotation</code> <code>int | time | timedelta | str | Callable</code> <p>Define log rotation rules for file logging</p> <code>None</code> <code>retention</code> <code>int | timedelta | str | Callable</code> <p>Define how long log files should be retained during rotation</p> <code>None</code> <code>compression</code> <code>str | Callable</code> <code>None</code> Source code in <code>src\\red_utils\\ext\\loguru_utils\\operations.py</code> <pre><code>def add_sink(\n    _logger: logger = None,\n    sink: Union[str, Path, io.TextIOWrapper, Handler, Callable, Coroutine] = None,\n    level: Union[int, str] | None = \"INFO\",\n    format: Union[str, Callable] = default_fmt,\n    color_format: Union[str, Callable] = default_color_fmt,\n    filter: Union[str, Callable, dict] = None,\n    colorize: bool | None = False,\n    serialize: bool | None = False,\n    backtrace: bool | None = False,\n    diagnose: bool | None = False,\n    enqueue: bool | None = False,\n    catch: bool | None = False,\n    rotation: Union[int, datetime.time, datetime.timedelta, str, Callable] = None,\n    retention: Union[int, datetime.timedelta, str, Callable] = None,\n    compression: Union[str, Callable] = None,\n) -&gt; logger:\n    \"\"\"Add a sink to a Loguru logger.\n\n    Helper function for adding a sink to a Loguru logger.\n    Can be called without arguments to use a default instance.\n\n    Params:\n        _logger (loguru.logger): An instance of `loguru.logger` to add a sink to\n        sink (str|Path|io.TextIOWrapper|Handler|Callable|Coroutine): A Loguru-compatible logger sink.\n            If the value is a `str` or `Path`, the sink will be a file. Read the\n            [Loguru sinks docs](https://loguru.readthedocs.io/en/stable/api/logger.html#sink) for more info,\n            or the [Loguru file sink config](https://loguru.readthedocs.io/en/stable/api/logger.html#file) docs.\n        level (str): The all-caps log level for the sink, i.e. `\"INFO\"`, `\"DEBUG\"`, etc\n        format (str|Callable): The formatting for a log message\n        color_format (str|Callable): The formatting for a colored log message\n        filter (str|Callable, dict): A filter to control messages logged by Loguru\n        colorize (bool): If `True`, log messages will be colored using the `color_format`\n        serialize (bool): If `True`, log messages will be formatted as json strings\n        backtrace (bool): If `True`, errors/traces will print the preceding stack trace that lead to a crash\n        diagnose (bool): If `True`, exception trace will display variable values for debugging.\n            **Warning**: This should be set to `False` in production to avoid leaking sensitive data.\n        enqueue (bool): If using Loguru in an async context, `enqueue` should be set to `True` to avoid IO collisions\n            when logging to a file.\n        catch (bool): If `True`, errors occurring while sink handles logs messages will be automatically caught, and an\n            exception message will be displayed in `sys.stderr`. With this option, the exception is not propagated to\n            the caller, preventing your app from crashing.\n        rotation (int|datetime.time|datetime.timedelta|str|Callable): Define log rotation rules for file logging\n        retention (int|datetime.timedelta|str|Callable): Define how long log files should be retained during rotation\n        compression (str|Callable):\n    \"\"\"\n    ## Validate inputs\n    validate_logger(_logger)\n    validate_compression_str(compression, none_ok=True)\n    validate_level(level=level)\n\n    if not sink:\n        sink: io.TextIOWrapper = sys.stderr\n\n    match colorize:\n        case True:\n            fmt = color_format\n        case False:\n            fmt = format\n\n    _logger.add(\n        sink=sink,\n        level=level,\n        format=fmt,\n        filter=filter,\n        colorize=colorize,\n        serialize=serialize,\n        backtrace=backtrace,\n        diagnose=diagnose,\n        enqueue=enqueue,\n        catch=catch,\n    )\n\n    return _logger\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/__init__/#red_utils.ext.loguru_utils.init_logger","title":"<code>init_logger(sinks=[default_stderr_sink, default_app_log_file_sink, default_error_log_file_sink, default_trace_log_file_sink])</code>","text":"<p>Initialize a Loguru logger using sink dicts.</p> <p>Call this script very early in program execution, ideally as the very first thing to happen. To ease with sink configuration, you can import sinks from <code>red_utils.ext.loguru_utils.sinks</code>, like <code>LoguruSinkStdOut</code> which defines a default, colorized <code>sys.stdout</code> sink.</p> <p>Note</p> <p>If using a custom <code>red_utils</code> sink, when adding it to the list of sinks, use the <code>.as_dict()</code> function to convert the sink to a dict.</p> Example <pre><code>stdout_sink = LoguruSinkStdOut(level=\"DEBUG\")\ninit_logger(sinks=[stdout_sink.as_dict()])\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>sinks</code> <code>list[dict]</code> <p>A list of dicts defining Loguru sinks</p> <code>[default_stderr_sink, default_app_log_file_sink, default_error_log_file_sink, default_trace_log_file_sink]</code> Source code in <code>src\\red_utils\\ext\\loguru_utils\\operations.py</code> <pre><code>def init_logger(\n    sinks: list[dict] = [\n        default_stderr_sink,\n        default_app_log_file_sink,\n        default_error_log_file_sink,\n        default_trace_log_file_sink,\n    ]\n):\n    \"\"\"Initialize a Loguru logger using sink dicts.\n\n    Call this script very early in program execution, ideally as the very first thing to happen.\n    To ease with sink configuration, you can import sinks from `red_utils.ext.loguru_utils.sinks`,\n    like `LoguruSinkStdOut` which defines a default, colorized `sys.stdout` sink.\n\n    !!! note\n\n        If using a custom `red_utils` sink, when adding it to the list of sinks, use the `.as_dict()`\n        function to convert the sink to a dict.\n\n    Example:\n        ``` py linenums=\"1\"\n        stdout_sink = LoguruSinkStdOut(level=\"DEBUG\")\n        init_logger(sinks=[stdout_sink.as_dict()])\n        ```\n\n    Params:\n        sinks (list[dict]): A list of dicts defining Loguru sinks\n\n    \"\"\"\n    logger.remove()\n\n    for sink in sinks:\n        logger.add(**sink)\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/__init__/#red_utils.ext.loguru_utils.validate_compression_str","title":"<code>validate_compression_str(string=None, none_ok=True)</code>","text":"<p>Validate a Loguru compression string value.</p> <p>Parameters:</p> Name Type Description Default <code>string</code> <code>str</code> <p>The compression string to validate</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>If <code>True</code>, allows null values</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>A validated compression string</p> Source code in <code>src\\red_utils\\ext\\loguru_utils\\validators.py</code> <pre><code>def validate_compression_str(string: str = None, none_ok: bool = True) -&gt; str:\n    \"\"\"Validate a Loguru compression string value.\n\n    Params:\n        string (str): The compression string to validate\n        none_ok (bool): If `True`, allows null values\n\n    Returns:\n        (str): A validated compression string\n\n    \"\"\"\n    if none_ok:\n        return string\n    elif not string:\n        raise ValueError(\"Missing a compression string to validate\")\n\n    if not isinstance(string, str):\n        raise TypeError(f\"Invalid type for string: ({type(string)}). Must be type(str)\")\n\n    if string not in valid_compression_strs:\n        raise ValueError(\n            f\"Invalid compression type: [{type(string)}]. Must be one of {valid_compression_strs}\"\n        )\n\n    return string\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/__init__/#red_utils.ext.loguru_utils.validate_level","title":"<code>validate_level(level=None, none_ok=False)</code>","text":"<p>Validate a Loguru compression string value.</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <code>str</code> <p>A log level string</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>If <code>True</code>, allows null values</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>A validated log level string</p> Source code in <code>src\\red_utils\\ext\\loguru_utils\\validators.py</code> <pre><code>def validate_level(level: str = None, none_ok: bool = False) -&gt; str:\n    \"\"\"Validate a Loguru compression string value.\n\n    Params:\n        level (str): A log level string\n        none_ok (bool): If `True`, allows null values\n\n    Returns:\n        (str): A validated log level string\n\n    \"\"\"\n    if none_ok:\n        return level\n    elif not level:\n        raise ValueError(\"Missing a log level string to evaluate.\")\n\n    if not isinstance(level, str):\n        raise TypeError(f\"Invalid level type: [{type(level)}]\")\n\n    try:\n        for _level in log_levels:\n            if not level == _level.name or not level == _level.level_name:\n                pass\n            else:\n                return _level\n\n    except ValueError as exc:\n        msg = ValueError(f\"Unhandled exception validating log level. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/__init__/#red_utils.ext.loguru_utils.validate_logger","title":"<code>validate_logger(_logger=None, none_ok=False)</code>","text":"<p>Validate a loguru.Logger object.</p> <p>Parameters:</p> Name Type Description Default <code>_logger</code> <code>logger</code> <p>A Loguru <code>logger</code></p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>If <code>True</code>, allows null values</p> <code>False</code> <p>Returns:</p> Type Description <code>logger</code> <p>A validated <code>loguru.logger</code></p> Source code in <code>src\\red_utils\\ext\\loguru_utils\\validators.py</code> <pre><code>def validate_logger(_logger: logger = None, none_ok: bool = False) -&gt; logger:\n    \"\"\"Validate a loguru.Logger object.\n\n    Params:\n        _logger (loguru.logger): A Loguru `logger`\n        none_ok (bool): If `True`, allows null values\n\n    Returns:\n        (loguru.logger): A validated `loguru.logger`\n\n    \"\"\"\n    if none_ok:\n        return _logger\n    elif not _logger:\n        raise ValueError(\"Missing loguru Logger object to validate\")\n\n    if not isinstance(_logger, type(logger)):\n        raise TypeError(\n            f\"Invalid type for logger: {type(_logger)}. Must be type(Logger)\"\n        )\n\n    return _logger\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/constants/","title":"constants","text":"<p>Constant values for use throughout the app, or to be imported from <code>red_utils</code> into other applications</p> <p>Warning</p> <p>The list below is a preview, check the source code for <code>red_utils.ext.loguru_utils.constants.py</code> to see all constants defined. <pre><code>_ts: str = \"[{time:YYYY-MM-DD_HH:mm:ss}]\"\n_level: str = \"[{level}]\"\n_module: str = \"[{module}]\"\n_function: str = \"[{function}]\"\n_name: str = \"[{name}]\"\n_line: str = \"[{line}]\"\n_name_line: str = \"[{name}:{line}]\"\n_module_line: str = \"[{module}:{line}]\"\n_msg: str = \"{message}\"\n\ndefault_fmt: str = f\"{_ts} {_level} &gt; {_name_line}: {_msg}\"\ndefault_color_fmt: str = f\"&lt;green&gt;{_ts}&lt;/green&gt; &lt;level&gt;{_level}&lt;/level&gt; &gt; &lt;level&gt;{_name_line}&lt;/level&gt;: {_msg}\"\n\nvalid_compression_strs: list[str] = [\n    \"gz\",\n    \"bz2\",\n    \"xz\",\n    \"lzma\",\n    \"tar\",\n    \"tar.gz\",\n    \"tar.bz2\",\n    \"tar.xz\",\n    \"zip\",\n]\n</code></pre></p>"},{"location":"reference/red_utils/ext/loguru_utils/constants/#red_utils.ext.loguru_utils.constants.LogLevel","title":"<code>LogLevel</code>  <code>dataclass</code>","text":"<p>Class representing a <code>loguru</code> log level.</p> Source code in <code>src\\red_utils\\ext\\loguru_utils\\constants.py</code> <pre><code>@dataclass\nclass LogLevel:\n    \"\"\"Class representing a `loguru` log level.\"\"\"\n\n    name: str = field(default=None)\n    level_name: str = field(default=None)\n    severity: int = field(default=None)\n    method: Callable = field(default=None)\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/enums/","title":"enums","text":"<p>Enum values for <code>loguru</code> utilities.</p> <p>Warning</p> <p>Code below is not the complete code of <code>red_utils.ext.loguru_utils.enums</code>. Check the source code for all options.</p> <pre><code>class EnumLogLevels(Enum):\n    TRACE: str = \"TRACE\"\n    DEBUG: str = \"DEBUG\"\n    INFO: str = \"INFO\"\n    SUCCESS: str = \"SUCCESS\"\n    WARNING: str = \"WARNING\"\n    ERROR: str = \"ERROR\"\n    CRITICAL: str = \"CRITICAL\"\n\n\nclass EnumDefaultSinks(Enum):\n    STDOUT: TextIO = sys.stdout\n    STDERR: TextIO = sys.stderr\n    APP_FILE: str = \"logs/app.log\"\n    ERROR_FILE: str = \"logs/err.log\"\n    TRACE_FILE: str = \"logs/trace.log\"\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/operations/","title":"operations","text":"<p>Functions that can be imported and used to manage <code>loguru</code>.</p>"},{"location":"reference/red_utils/ext/loguru_utils/operations/#red_utils.ext.loguru_utils.operations.add_sink","title":"<code>add_sink(_logger=None, sink=None, level='INFO', format=default_fmt, color_format=default_color_fmt, filter=None, colorize=False, serialize=False, backtrace=False, diagnose=False, enqueue=False, catch=False, rotation=None, retention=None, compression=None)</code>","text":"<p>Add a sink to a Loguru logger.</p> <p>Helper function for adding a sink to a Loguru logger. Can be called without arguments to use a default instance.</p> <p>Parameters:</p> Name Type Description Default <code>_logger</code> <code>logger</code> <p>An instance of <code>loguru.logger</code> to add a sink to</p> <code>None</code> <code>sink</code> <code>str | Path | TextIOWrapper | Handler | Callable | Coroutine</code> <p>A Loguru-compatible logger sink. If the value is a <code>str</code> or <code>Path</code>, the sink will be a file. Read the Loguru sinks docs for more info, or the Loguru file sink config docs.</p> <code>None</code> <code>level</code> <code>str</code> <p>The all-caps log level for the sink, i.e. <code>\"INFO\"</code>, <code>\"DEBUG\"</code>, etc</p> <code>'INFO'</code> <code>format</code> <code>str | Callable</code> <p>The formatting for a log message</p> <code>default_fmt</code> <code>color_format</code> <code>str | Callable</code> <p>The formatting for a colored log message</p> <code>default_color_fmt</code> <code>filter</code> <code>(str | Callable, dict)</code> <p>A filter to control messages logged by Loguru</p> <code>None</code> <code>colorize</code> <code>bool</code> <p>If <code>True</code>, log messages will be colored using the <code>color_format</code></p> <code>False</code> <code>serialize</code> <code>bool</code> <p>If <code>True</code>, log messages will be formatted as json strings</p> <code>False</code> <code>backtrace</code> <code>bool</code> <p>If <code>True</code>, errors/traces will print the preceding stack trace that lead to a crash</p> <code>False</code> <code>diagnose</code> <code>bool</code> <p>If <code>True</code>, exception trace will display variable values for debugging. Warning: This should be set to <code>False</code> in production to avoid leaking sensitive data.</p> <code>False</code> <code>enqueue</code> <code>bool</code> <p>If using Loguru in an async context, <code>enqueue</code> should be set to <code>True</code> to avoid IO collisions when logging to a file.</p> <code>False</code> <code>catch</code> <code>bool</code> <p>If <code>True</code>, errors occurring while sink handles logs messages will be automatically caught, and an exception message will be displayed in <code>sys.stderr</code>. With this option, the exception is not propagated to the caller, preventing your app from crashing.</p> <code>False</code> <code>rotation</code> <code>int | time | timedelta | str | Callable</code> <p>Define log rotation rules for file logging</p> <code>None</code> <code>retention</code> <code>int | timedelta | str | Callable</code> <p>Define how long log files should be retained during rotation</p> <code>None</code> <code>compression</code> <code>str | Callable</code> <code>None</code> Source code in <code>src\\red_utils\\ext\\loguru_utils\\operations.py</code> <pre><code>def add_sink(\n    _logger: logger = None,\n    sink: Union[str, Path, io.TextIOWrapper, Handler, Callable, Coroutine] = None,\n    level: Union[int, str] | None = \"INFO\",\n    format: Union[str, Callable] = default_fmt,\n    color_format: Union[str, Callable] = default_color_fmt,\n    filter: Union[str, Callable, dict] = None,\n    colorize: bool | None = False,\n    serialize: bool | None = False,\n    backtrace: bool | None = False,\n    diagnose: bool | None = False,\n    enqueue: bool | None = False,\n    catch: bool | None = False,\n    rotation: Union[int, datetime.time, datetime.timedelta, str, Callable] = None,\n    retention: Union[int, datetime.timedelta, str, Callable] = None,\n    compression: Union[str, Callable] = None,\n) -&gt; logger:\n    \"\"\"Add a sink to a Loguru logger.\n\n    Helper function for adding a sink to a Loguru logger.\n    Can be called without arguments to use a default instance.\n\n    Params:\n        _logger (loguru.logger): An instance of `loguru.logger` to add a sink to\n        sink (str|Path|io.TextIOWrapper|Handler|Callable|Coroutine): A Loguru-compatible logger sink.\n            If the value is a `str` or `Path`, the sink will be a file. Read the\n            [Loguru sinks docs](https://loguru.readthedocs.io/en/stable/api/logger.html#sink) for more info,\n            or the [Loguru file sink config](https://loguru.readthedocs.io/en/stable/api/logger.html#file) docs.\n        level (str): The all-caps log level for the sink, i.e. `\"INFO\"`, `\"DEBUG\"`, etc\n        format (str|Callable): The formatting for a log message\n        color_format (str|Callable): The formatting for a colored log message\n        filter (str|Callable, dict): A filter to control messages logged by Loguru\n        colorize (bool): If `True`, log messages will be colored using the `color_format`\n        serialize (bool): If `True`, log messages will be formatted as json strings\n        backtrace (bool): If `True`, errors/traces will print the preceding stack trace that lead to a crash\n        diagnose (bool): If `True`, exception trace will display variable values for debugging.\n            **Warning**: This should be set to `False` in production to avoid leaking sensitive data.\n        enqueue (bool): If using Loguru in an async context, `enqueue` should be set to `True` to avoid IO collisions\n            when logging to a file.\n        catch (bool): If `True`, errors occurring while sink handles logs messages will be automatically caught, and an\n            exception message will be displayed in `sys.stderr`. With this option, the exception is not propagated to\n            the caller, preventing your app from crashing.\n        rotation (int|datetime.time|datetime.timedelta|str|Callable): Define log rotation rules for file logging\n        retention (int|datetime.timedelta|str|Callable): Define how long log files should be retained during rotation\n        compression (str|Callable):\n    \"\"\"\n    ## Validate inputs\n    validate_logger(_logger)\n    validate_compression_str(compression, none_ok=True)\n    validate_level(level=level)\n\n    if not sink:\n        sink: io.TextIOWrapper = sys.stderr\n\n    match colorize:\n        case True:\n            fmt = color_format\n        case False:\n            fmt = format\n\n    _logger.add(\n        sink=sink,\n        level=level,\n        format=fmt,\n        filter=filter,\n        colorize=colorize,\n        serialize=serialize,\n        backtrace=backtrace,\n        diagnose=diagnose,\n        enqueue=enqueue,\n        catch=catch,\n    )\n\n    return _logger\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/operations/#red_utils.ext.loguru_utils.operations.init_logger","title":"<code>init_logger(sinks=[default_stderr_sink, default_app_log_file_sink, default_error_log_file_sink, default_trace_log_file_sink])</code>","text":"<p>Initialize a Loguru logger using sink dicts.</p> <p>Call this script very early in program execution, ideally as the very first thing to happen. To ease with sink configuration, you can import sinks from <code>red_utils.ext.loguru_utils.sinks</code>, like <code>LoguruSinkStdOut</code> which defines a default, colorized <code>sys.stdout</code> sink.</p> <p>Note</p> <p>If using a custom <code>red_utils</code> sink, when adding it to the list of sinks, use the <code>.as_dict()</code> function to convert the sink to a dict.</p> Example <pre><code>stdout_sink = LoguruSinkStdOut(level=\"DEBUG\")\ninit_logger(sinks=[stdout_sink.as_dict()])\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>sinks</code> <code>list[dict]</code> <p>A list of dicts defining Loguru sinks</p> <code>[default_stderr_sink, default_app_log_file_sink, default_error_log_file_sink, default_trace_log_file_sink]</code> Source code in <code>src\\red_utils\\ext\\loguru_utils\\operations.py</code> <pre><code>def init_logger(\n    sinks: list[dict] = [\n        default_stderr_sink,\n        default_app_log_file_sink,\n        default_error_log_file_sink,\n        default_trace_log_file_sink,\n    ]\n):\n    \"\"\"Initialize a Loguru logger using sink dicts.\n\n    Call this script very early in program execution, ideally as the very first thing to happen.\n    To ease with sink configuration, you can import sinks from `red_utils.ext.loguru_utils.sinks`,\n    like `LoguruSinkStdOut` which defines a default, colorized `sys.stdout` sink.\n\n    !!! note\n\n        If using a custom `red_utils` sink, when adding it to the list of sinks, use the `.as_dict()`\n        function to convert the sink to a dict.\n\n    Example:\n        ``` py linenums=\"1\"\n        stdout_sink = LoguruSinkStdOut(level=\"DEBUG\")\n        init_logger(sinks=[stdout_sink.as_dict()])\n        ```\n\n    Params:\n        sinks (list[dict]): A list of dicts defining Loguru sinks\n\n    \"\"\"\n    logger.remove()\n\n    for sink in sinks:\n        logger.add(**sink)\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/operations/#red_utils.ext.loguru_utils.operations.validate_compression_str","title":"<code>validate_compression_str(string=None, none_ok=True)</code>","text":"<p>Validate a Loguru compression string value.</p> <p>Parameters:</p> Name Type Description Default <code>string</code> <code>str</code> <p>The compression string to validate</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>If <code>True</code>, allows null values</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>A validated compression string</p> Source code in <code>src\\red_utils\\ext\\loguru_utils\\validators.py</code> <pre><code>def validate_compression_str(string: str = None, none_ok: bool = True) -&gt; str:\n    \"\"\"Validate a Loguru compression string value.\n\n    Params:\n        string (str): The compression string to validate\n        none_ok (bool): If `True`, allows null values\n\n    Returns:\n        (str): A validated compression string\n\n    \"\"\"\n    if none_ok:\n        return string\n    elif not string:\n        raise ValueError(\"Missing a compression string to validate\")\n\n    if not isinstance(string, str):\n        raise TypeError(f\"Invalid type for string: ({type(string)}). Must be type(str)\")\n\n    if string not in valid_compression_strs:\n        raise ValueError(\n            f\"Invalid compression type: [{type(string)}]. Must be one of {valid_compression_strs}\"\n        )\n\n    return string\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/operations/#red_utils.ext.loguru_utils.operations.validate_level","title":"<code>validate_level(level=None, none_ok=False)</code>","text":"<p>Validate a Loguru compression string value.</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <code>str</code> <p>A log level string</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>If <code>True</code>, allows null values</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>A validated log level string</p> Source code in <code>src\\red_utils\\ext\\loguru_utils\\validators.py</code> <pre><code>def validate_level(level: str = None, none_ok: bool = False) -&gt; str:\n    \"\"\"Validate a Loguru compression string value.\n\n    Params:\n        level (str): A log level string\n        none_ok (bool): If `True`, allows null values\n\n    Returns:\n        (str): A validated log level string\n\n    \"\"\"\n    if none_ok:\n        return level\n    elif not level:\n        raise ValueError(\"Missing a log level string to evaluate.\")\n\n    if not isinstance(level, str):\n        raise TypeError(f\"Invalid level type: [{type(level)}]\")\n\n    try:\n        for _level in log_levels:\n            if not level == _level.name or not level == _level.level_name:\n                pass\n            else:\n                return _level\n\n    except ValueError as exc:\n        msg = ValueError(f\"Unhandled exception validating log level. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/operations/#red_utils.ext.loguru_utils.operations.validate_logger","title":"<code>validate_logger(_logger=None, none_ok=False)</code>","text":"<p>Validate a loguru.Logger object.</p> <p>Parameters:</p> Name Type Description Default <code>_logger</code> <code>logger</code> <p>A Loguru <code>logger</code></p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>If <code>True</code>, allows null values</p> <code>False</code> <p>Returns:</p> Type Description <code>logger</code> <p>A validated <code>loguru.logger</code></p> Source code in <code>src\\red_utils\\ext\\loguru_utils\\validators.py</code> <pre><code>def validate_logger(_logger: logger = None, none_ok: bool = False) -&gt; logger:\n    \"\"\"Validate a loguru.Logger object.\n\n    Params:\n        _logger (loguru.logger): A Loguru `logger`\n        none_ok (bool): If `True`, allows null values\n\n    Returns:\n        (loguru.logger): A validated `loguru.logger`\n\n    \"\"\"\n    if none_ok:\n        return _logger\n    elif not _logger:\n        raise ValueError(\"Missing loguru Logger object to validate\")\n\n    if not isinstance(_logger, type(logger)):\n        raise TypeError(\n            f\"Invalid type for logger: {type(_logger)}. Must be type(Logger)\"\n        )\n\n    return _logger\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/sinks/","title":"sinks","text":""},{"location":"reference/red_utils/ext/loguru_utils/sinks/#red_utils.ext.loguru_utils.sinks.DefaultSinks","title":"<code>DefaultSinks</code>  <code>dataclass</code>","text":"<p>               Bases: <code>LoguruSinkBase</code></p> <p>Return initialized defaults for Loguru sink classes.</p> <p>Access initialized sinks as class parameters. For example, to get an STDOUT logger, initialized with the default LoguruSinkStdOut settings: <code>DefaultSinks().stdout</code></p> <p>To get a list of initialized default sinks (an <code>app.log</code>, <code>err.log</code>, and <code>STDOUT</code> logger), choose from <code>.color</code> (for loggers initialized with colorize; excludes file loggers), or <code>.nocolor</code> (no colorize initialized):</p> <p><code>DefaultSinks().stdout.color</code></p> Source code in <code>src\\red_utils\\ext\\loguru_utils\\sinks.py</code> <pre><code>class DefaultSinks(LoguruSinkBase):\n    \"\"\"Return initialized defaults for Loguru sink classes.\n\n    Access initialized sinks as class parameters. For example, to get an STDOUT logger,\n    initialized with the default LoguruSinkStdOut settings: `DefaultSinks().stdout`\n\n    To get a list of initialized default sinks (an `app.log`, `err.log`, and `STDOUT` logger), choose\n    from `.color` (for loggers initialized with colorize; excludes file loggers), or `.nocolor` (no colorize initialized):\n\n    `DefaultSinks().stdout.color`\n    \"\"\"\n\n    stdout: LoguruSinkStdOut | None = default_stdout_sink\n    stderr: LoguruSinkStdErr | None = default_stderr_sink\n    log_file: LoguruSinkAppFile | None = default_app_log_file_sink\n    error_log_file: LoguruSinkErrFile | None = default_error_log_file_sink\n    trace_log_file: LoguruSinkTraceFile | None = default_trace_log_file_sink\n\n    @property\n    def color(\n        self,\n    ) -&gt; list[dict]:\n        \"\"\"List of initialized Loguru loggers.\n\n        Returns:\n            (list[dict]): List of Loguru sink dicts with `colorize=True`.\n\n        \"\"\"\n        sink_list = [\n            self.stdout,\n            self.log_file,\n            self.error_log_file,\n            self.trace_log_file,\n        ]\n\n        return sink_list\n\n    @property\n    def no_color(\n        self,\n    ) -&gt; list[dict]:\n        \"\"\"List of initialized Loguru loggers.\n\n        Returns:\n            (list[dict]): List of Loguru sink dicts with `colorize=False`.\n\n        \"\"\"\n        sink_list = [\n            default_stdout_no_color_sink,\n            self.log_file,\n            self.error_log_file,\n            self.trace_log_file,\n        ]\n\n        return sink_list\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/sinks/#red_utils.ext.loguru_utils.sinks.DefaultSinks.color","title":"<code>color: list[dict]</code>  <code>property</code>","text":"<p>List of initialized Loguru loggers.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>List of Loguru sink dicts with <code>colorize=True</code>.</p>"},{"location":"reference/red_utils/ext/loguru_utils/sinks/#red_utils.ext.loguru_utils.sinks.DefaultSinks.no_color","title":"<code>no_color: list[dict]</code>  <code>property</code>","text":"<p>List of initialized Loguru loggers.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>List of Loguru sink dicts with <code>colorize=False</code>.</p>"},{"location":"reference/red_utils/ext/loguru_utils/sinks/#red_utils.ext.loguru_utils.sinks.DictMixin","title":"<code>DictMixin</code>  <code>dataclass</code>","text":"<p>Mixin class to add \"as_dict()\" method to classes. Equivalent to .dict.</p> <p>Adds a <code>.as_dict()</code> method to classes that inherit from this mixin. For example, to add <code>.as_dict()</code> method to a parent class, where all children inherit the .as_dict() function, declare parent as:</p> <pre><code>@dataclass\nclass Parent(DictMixin):\n    ...\n</code></pre> <p>and call like:</p> <pre><code>p = Parent()\np_dict = p.as_dict()\n</code></pre> Source code in <code>src\\red_utils\\core\\dataclass_utils\\mixins\\mixin_classes.py</code> <pre><code>@dataclass\nclass DictMixin:\n    \"\"\"Mixin class to add \"as_dict()\" method to classes. Equivalent to .__dict__.\n\n    Adds a `.as_dict()` method to classes that inherit from this mixin. For example,\n    to add `.as_dict()` method to a parent class, where all children inherit the .as_dict()\n    function, declare parent as:\n\n    ``` py linenums=\"1\"\n    @dataclass\n    class Parent(DictMixin):\n        ...\n    ```\n\n    and call like:\n\n    ``` py linenums=\"1\"\n    p = Parent()\n    p_dict = p.as_dict()\n    ```\n    \"\"\"\n\n    def as_dict(self: Generic[T]):\n        \"\"\"Return dict representation of a dataclass instance.\n\n        Description:\n            Any class that inherits from `DictMixin` will automatically have a method `.as_dict()`.\n                There are no extra params.\n\n        Returns:\n            (dict): A Python `dict` representation of a Python `dataclass` class.\n\n        \"\"\"\n        try:\n            return self.__dict__.copy()\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception converting class instance to dict. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/sinks/#red_utils.ext.loguru_utils.sinks.DictMixin.as_dict","title":"<code>as_dict()</code>","text":"<p>Return dict representation of a dataclass instance.</p> Description <p>Any class that inherits from <code>DictMixin</code> will automatically have a method <code>.as_dict()</code>.     There are no extra params.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A Python <code>dict</code> representation of a Python <code>dataclass</code> class.</p> Source code in <code>src\\red_utils\\core\\dataclass_utils\\mixins\\mixin_classes.py</code> <pre><code>def as_dict(self: Generic[T]):\n    \"\"\"Return dict representation of a dataclass instance.\n\n    Description:\n        Any class that inherits from `DictMixin` will automatically have a method `.as_dict()`.\n            There are no extra params.\n\n    Returns:\n        (dict): A Python `dict` representation of a Python `dataclass` class.\n\n    \"\"\"\n    try:\n        return self.__dict__.copy()\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception converting class instance to dict. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/sinks/#red_utils.ext.loguru_utils.sinks.LoguruSinkAppFile","title":"<code>LoguruSinkAppFile</code>  <code>dataclass</code>","text":"<p>               Bases: <code>LoguruSinkFileBase</code>, <code>DictMixin</code></p> <p>Sink class for app.log file.</p> <p>Parameters:</p> Name Type Description Default <code>sink</code> <code>(str, TextIO)</code> <p>the Loguru sink definition</p> <code>f'{LOG_DIR}/app.log'</code> <code>colorize</code> <code>bool</code> <p>If <code>True</code>, log messages will be colorized</p> <code>True</code> <code>retention</code> <code>str | int</code> <p>Amount of time to retain log files</p> <code>3</code> <code>rotation</code> <code>str</code> <p>Size limit when a log file will be rotated</p> <code>'5 MB'</code> <code>format</code> <code>str</code> <p>A formatted string for log messages</p> <code>default_fmt</code> <code>level</code> <code>str</code> <p>Level of logs to log to file, i.e. <code>\"INFO\"</code>, <code>\"DEBUG\"</code>, etc</p> <code>'DEBUG'</code> <code>enqueue</code> <code>bool</code> <p>Set to <code>True</code> if app is asynchronous in order to avoid IO collisions</p> <code>True</code> Source code in <code>src\\red_utils\\ext\\loguru_utils\\sinks.py</code> <pre><code>@dataclass\nclass LoguruSinkAppFile(LoguruSinkFileBase, DictMixin):\n    \"\"\"Sink class for app.log file.\n\n    Params:\n        sink (str, TextIO): the Loguru sink definition\n        colorize (bool): If `True`, log messages will be colorized\n        retention (str|int): Amount of time to retain log files\n        rotation (str): Size limit when a log file will be rotated\n        format (str): A formatted string for log messages\n        level (str): Level of logs to log to file, i.e. `\"INFO\"`, `\"DEBUG\"`, etc\n        enqueue (bool): Set to `True` if app is asynchronous in order to avoid IO\n            collisions\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/sinks/#red_utils.ext.loguru_utils.sinks.LoguruSinkBase","title":"<code>LoguruSinkBase</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DictMixin</code></p> <p>Base Loguru sink class.</p> <p>Define common options for children to inherit from.</p> <p>Parameters:</p> Name Type Description Default <code>sink</code> <code>str | TextIO</code> <p>A Loguru sink. Can be a string (i.e. \"app.log\" for a file at ./app.log) or a Python callable (i.e. sys.stdout). Loguru Docs: sinks</p> <code>stdout</code> <code>format</code> <code>str</code> <p>A string describing the format for the Loguru logger. Loguru Docs: time formatting. Loguru Docs: color markup formatting.</p> <code>default_fmt</code> <code>level</code> <code>str</code> <p>A severity level string for the logger. Controls which messages will be outputted. Value will be forced uppercase. Loguru Docs: Severity levels</p> <code>'INFO'</code> <code>colorize</code> <code>bool</code> <p>Control whether logger outputs are colorized.</p> <code>False</code> Source code in <code>src\\red_utils\\ext\\loguru_utils\\sinks.py</code> <pre><code>@dataclass\nclass LoguruSinkBase(DictMixin):\n    \"\"\"Base Loguru sink class.\n\n    Define common options for children to inherit from.\n\n    Params:\n        sink (str|TextIO): A Loguru sink. Can be a string (i.e. \"app.log\" for a file at ./app.log) or a Python callable (i.e. sys.stdout).\n            [Loguru Docs: sinks](https://loguru.readthedocs.io/en/stable/api/logger.html#sink)\n        format (str): A string describing the format for the Loguru logger.\n            [Loguru Docs: time formatting](https://loguru.readthedocs.io/en/stable/api/logger.html#time).\n            [Loguru Docs: color markup formatting](https://loguru.readthedocs.io/en/stable/api/logger.html#color).\n        level (str): A severity level string for the logger. Controls which messages will be outputted. Value will be forced uppercase.\n            [Loguru Docs: Severity levels](https://loguru.readthedocs.io/en/stable/api/logger.html#levels)\n        colorize (bool): Control whether logger outputs are colorized.\n    \"\"\"\n\n    sink: Union[str, TextIO] = field(default=sys.stdout)\n    format: str = field(default=default_fmt)\n    level: str = field(default=\"INFO\")\n    colorize: bool = field(default=False)\n\n    def __post_init__(self):\n        self.level = self.level.upper()\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/sinks/#red_utils.ext.loguru_utils.sinks.LoguruSinkDefault","title":"<code>LoguruSinkDefault</code>  <code>dataclass</code>","text":"<p>               Bases: <code>LoguruSinkBase</code></p> <p>Default Loguru sink. Defaults to colorized, formatted stdout, level=INFO.</p> <p>Use this class as a starting point to create customized Loguru sinks. Create a new class by inheriting from this one:</p> <pre><code>my_loguru_sink = LoguruSinkDefault(sink=...,level=..., colorize=True)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>sink</code> <code>str | TextIO</code> <p>A Loguru sink. Can be a string (i.e. \"app.log\" for a file at ./app.log) or a Python callable (i.e. sys.stdout). Loguru Docs: sinks</p> <code>stdout</code> <code>format</code> <code>str</code> <p>A string describing the format for the Loguru logger. Loguru Docs: time formatting. Loguru Docs: color markup formatting.</p> <code>default_fmt</code> <code>level</code> <code>str</code> <p>A severity level string for the logger. Controls which messages will be outputted. Value will be forced uppercase. Loguru Docs: Severity levels</p> <code>'INFO'</code> <code>colorize</code> <code>bool</code> <p>Control whether logger outputs are colorized.</p> <code>False</code> Source code in <code>src\\red_utils\\ext\\loguru_utils\\sinks.py</code> <pre><code>@dataclass\nclass LoguruSinkDefault(LoguruSinkBase):\n    \"\"\"Default Loguru sink. Defaults to colorized, formatted stdout, level=INFO.\n\n    Use this class as a starting point to create customized Loguru sinks. Create a new class\n    by inheriting from this one:\n\n    ``` py linenums=\"1\"\n    my_loguru_sink = LoguruSinkDefault(sink=...,level=..., colorize=True)\n    ```\n\n    Params:\n        sink (str|TextIO): A Loguru sink. Can be a string (i.e. \"app.log\" for a file at ./app.log) or a Python callable (i.e. sys.stdout).\n            [Loguru Docs: sinks](https://loguru.readthedocs.io/en/stable/api/logger.html#sink)\n        format (str): A string describing the format for the Loguru logger.\n            [Loguru Docs: time formatting](https://loguru.readthedocs.io/en/stable/api/logger.html#time).\n            [Loguru Docs: color markup formatting](https://loguru.readthedocs.io/en/stable/api/logger.html#color).\n        level (str): A severity level string for the logger. Controls which messages will be outputted. Value will be forced uppercase.\n            [Loguru Docs: Severity levels](https://loguru.readthedocs.io/en/stable/api/logger.html#levels)\n        colorize (bool): Control whether logger outputs are colorized.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/sinks/#red_utils.ext.loguru_utils.sinks.LoguruSinkErrFile","title":"<code>LoguruSinkErrFile</code>  <code>dataclass</code>","text":"<p>               Bases: <code>LoguruSinkFileBase</code></p> <p>Sink class for error.log file.</p> <p>Parameters:</p> Name Type Description Default <code>sink</code> <code>(str, TextIO)</code> <p>the Loguru sink definition</p> <code>f'{LOG_DIR}/error.log'</code> <code>colorize</code> <code>bool</code> <p>If <code>True</code>, log messages will be colorized</p> <code>True</code> <code>retention</code> <code>str | int</code> <p>Amount of time to retain log files</p> <code>3</code> <code>rotation</code> <code>str</code> <p>Size limit when a log file will be rotated</p> <code>'5 MB'</code> <code>format</code> <code>str</code> <p>A formatted string for log messages</p> <code>default_fmt</code> <code>level</code> <code>str</code> <p>Level of logs to log to file, i.e. <code>\"INFO\"</code>, <code>\"DEBUG\"</code>, etc</p> <code>'ERROR'</code> <code>enqueue</code> <code>bool</code> <p>Set to <code>True</code> if app is asynchronous in order to avoid IO collisions</p> <code>True</code> Source code in <code>src\\red_utils\\ext\\loguru_utils\\sinks.py</code> <pre><code>@dataclass\nclass LoguruSinkErrFile(LoguruSinkFileBase):\n    \"\"\"Sink class for error.log file.\n\n    Params:\n        sink (str, TextIO): the Loguru sink definition\n        colorize (bool): If `True`, log messages will be colorized\n        retention (str|int): Amount of time to retain log files\n        rotation (str): Size limit when a log file will be rotated\n        format (str): A formatted string for log messages\n        level (str): Level of logs to log to file, i.e. `\"INFO\"`, `\"DEBUG\"`, etc\n        enqueue (bool): Set to `True` if app is asynchronous in order to avoid IO\n            collisions\n    \"\"\"\n\n    sink: Union[str, TextIO] = field(default=f\"{LOG_DIR}/error.log\")\n    level: str = field(default=\"ERROR\")\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/sinks/#red_utils.ext.loguru_utils.sinks.LoguruSinkFileBase","title":"<code>LoguruSinkFileBase</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DictMixin</code></p> <p>Base class for file sinks.</p> <p>Parameters:</p> Name Type Description Default <code>sink</code> <code>(str, TextIO)</code> <p>the Loguru sink definition</p> <code>f'{LOG_DIR}/app.log'</code> <code>colorize</code> <code>bool</code> <p>If <code>True</code>, log messages will be colorized</p> <code>True</code> <code>retention</code> <code>str | int</code> <p>Amount of time to retain log files</p> <code>3</code> <code>rotation</code> <code>str</code> <p>Size limit when a log file will be rotated</p> <code>'5 MB'</code> <code>format</code> <code>str</code> <p>A formatted string for log messages</p> <code>default_fmt</code> <code>level</code> <code>str</code> <p>Level of logs to log to file, i.e. <code>\"INFO\"</code>, <code>\"DEBUG\"</code>, etc</p> <code>'DEBUG'</code> <code>enqueue</code> <code>bool</code> <p>Set to <code>True</code> if app is asynchronous in order to avoid IO collisions</p> <code>True</code> Source code in <code>src\\red_utils\\ext\\loguru_utils\\sinks.py</code> <pre><code>@dataclass\nclass LoguruSinkFileBase(DictMixin):\n    \"\"\"Base class for file sinks.\n\n    Params:\n        sink (str, TextIO): the Loguru sink definition\n        colorize (bool): If `True`, log messages will be colorized\n        retention (str|int): Amount of time to retain log files\n        rotation (str): Size limit when a log file will be rotated\n        format (str): A formatted string for log messages\n        level (str): Level of logs to log to file, i.e. `\"INFO\"`, `\"DEBUG\"`, etc\n        enqueue (bool): Set to `True` if app is asynchronous in order to avoid IO\n            collisions\n    \"\"\"\n\n    sink: Union[str, TextIO] = field(default=f\"{LOG_DIR}/app.log\")\n    colorize: bool = field(default=True)\n    retention: Union[str, int] = field(default=3)\n    rotation: str = field(default=\"5 MB\")\n    format: str = field(default=default_fmt)\n    level: str = field(default=\"DEBUG\")\n    enqueue: bool = field(default=True)\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/sinks/#red_utils.ext.loguru_utils.sinks.LoguruSinkFileDefault","title":"<code>LoguruSinkFileDefault</code>  <code>dataclass</code>","text":"<p>               Bases: <code>LoguruSinkFileBase</code></p> <p>Default Loguru file sink. Defaults to file <code>app.log</code>, <code>level=DEBUG</code>.</p> <p>Use this class as a starting point to create customized Loguru file sinks. Create a new class by inheriting from this one:</p> <pre><code>my_loguru_file_sink = LoguruSinkFileDefault(sink=...,level=..., colorize=True)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>sink</code> <code>(str, TextIO)</code> <p>the Loguru sink definition</p> <code>f'{LOG_DIR}/app.log'</code> <code>colorize</code> <code>bool</code> <p>If <code>True</code>, log messages will be colorized</p> <code>True</code> <code>retention</code> <code>str | int</code> <p>Amount of time to retain log files</p> <code>3</code> <code>rotation</code> <code>str</code> <p>Size limit when a log file will be rotated</p> <code>'5 MB'</code> <code>format</code> <code>str</code> <p>A formatted string for log messages</p> <code>default_fmt</code> <code>level</code> <code>str</code> <p>Level of logs to log to file, i.e. <code>\"INFO\"</code>, <code>\"DEBUG\"</code>, etc</p> <code>'DEBUG'</code> <code>enqueue</code> <code>bool</code> <p>Set to <code>True</code> if app is asynchronous in order to avoid IO collisions</p> <code>True</code> Source code in <code>src\\red_utils\\ext\\loguru_utils\\sinks.py</code> <pre><code>@dataclass\nclass LoguruSinkFileDefault(LoguruSinkFileBase):\n    \"\"\"Default Loguru file sink. Defaults to file `app.log`, `level=DEBUG`.\n\n    Use this class as a starting point to create customized Loguru file sinks. Create a new class\n    by inheriting from this one:\n\n    ``` py linenums=\"1\"\n    my_loguru_file_sink = LoguruSinkFileDefault(sink=...,level=..., colorize=True)\n    ```\n\n    Params:\n        sink (str, TextIO): the Loguru sink definition\n        colorize (bool): If `True`, log messages will be colorized\n        retention (str|int): Amount of time to retain log files\n        rotation (str): Size limit when a log file will be rotated\n        format (str): A formatted string for log messages\n        level (str): Level of logs to log to file, i.e. `\"INFO\"`, `\"DEBUG\"`, etc\n        enqueue (bool): Set to `True` if app is asynchronous in order to avoid IO\n            collisions\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/sinks/#red_utils.ext.loguru_utils.sinks.LoguruSinkStdErr","title":"<code>LoguruSinkStdErr</code>  <code>dataclass</code>","text":"<p>               Bases: <code>LoguruSinkBase</code></p> <p>Console STDERR sink.</p> <p>Parameters:</p> Name Type Description Default <code>sink</code> <code>(str, TextIO)</code> <p>the Loguru sink definition</p> <code>stderr</code> <code>format</code> <code>str</code> <p>A formatted string for log messages</p> <code>default_color_fmt</code> <code>colorize</code> <code>bool</code> <p>If <code>True</code>, log messages will be colorized</p> <code>True</code> Source code in <code>src\\red_utils\\ext\\loguru_utils\\sinks.py</code> <pre><code>@dataclass\nclass LoguruSinkStdErr(LoguruSinkBase):\n    \"\"\"Console STDERR sink.\n\n    Params:\n        sink (str, TextIO): the Loguru sink definition\n        format (str): A formatted string for log messages\n        colorize (bool): If `True`, log messages will be colorized\n    \"\"\"\n\n    sink: Union[str, TextIO] = field(default=sys.stderr)\n    format: str = field(default=default_color_fmt)\n    colorize: bool = field(default=True)\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/sinks/#red_utils.ext.loguru_utils.sinks.LoguruSinkStdOut","title":"<code>LoguruSinkStdOut</code>  <code>dataclass</code>","text":"<p>               Bases: <code>LoguruSinkBase</code>, <code>DictMixin</code></p> <p>Console STDOUT sink.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>A formatted string for log messages</p> <code>default_color_fmt</code> <code>colorize</code> <code>bool</code> <p>If <code>True</code>, log messages will be colorized</p> <code>True</code> Source code in <code>src\\red_utils\\ext\\loguru_utils\\sinks.py</code> <pre><code>@dataclass\nclass LoguruSinkStdOut(LoguruSinkBase, DictMixin):\n    \"\"\"Console STDOUT sink.\n\n    Params:\n        format (str): A formatted string for log messages\n        colorize (bool): If `True`, log messages will be colorized\n    \"\"\"\n\n    format: str = field(default=default_color_fmt)\n    colorize: bool = field(default=True)\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/sinks/#red_utils.ext.loguru_utils.sinks.LoguruSinkTraceFile","title":"<code>LoguruSinkTraceFile</code>  <code>dataclass</code>","text":"<p>               Bases: <code>LoguruSinkFileBase</code></p> <p>Sink class for trace.log file.</p> <p>Parameters:</p> Name Type Description Default <code>sink</code> <code>(str, TextIO)</code> <p>the Loguru sink definition</p> <code>f'{LOG_DIR}/trace.log'</code> <code>colorize</code> <code>bool</code> <p>If <code>True</code>, log messages will be colorized</p> <code>True</code> <code>retention</code> <code>str | int</code> <p>Amount of time to retain log files</p> <code>3</code> <code>rotation</code> <code>str</code> <p>Size limit when a log file will be rotated</p> <code>'5 MB'</code> <code>format</code> <code>str</code> <p>A formatted string for log messages</p> <code>default_fmt</code> <code>level</code> <code>str</code> <p>Level of logs to log to file, i.e. <code>\"INFO\"</code>, <code>\"DEBUG\"</code>, etc</p> <code>'TRACE'</code> <code>enqueue</code> <code>bool</code> <p>Set to <code>True</code> if app is asynchronous in order to avoid IO collisions</p> <code>True</code> Source code in <code>src\\red_utils\\ext\\loguru_utils\\sinks.py</code> <pre><code>@dataclass\nclass LoguruSinkTraceFile(LoguruSinkFileBase):\n    \"\"\"Sink class for trace.log file.\n\n    Params:\n        sink (str, TextIO): the Loguru sink definition\n        colorize (bool): If `True`, log messages will be colorized\n        retention (str|int): Amount of time to retain log files\n        rotation (str): Size limit when a log file will be rotated\n        format (str): A formatted string for log messages\n        level (str): Level of logs to log to file, i.e. `\"INFO\"`, `\"DEBUG\"`, etc\n        enqueue (bool): Set to `True` if app is asynchronous in order to avoid IO\n            collisions\n    \"\"\"\n\n    sink: Union[str, TextIO] = field(default=f\"{LOG_DIR}/trace.log\")\n    level: str = field(default=\"TRACE\")\n    filter: str = field(default=\"TRACE\")\n    backtrace: bool = field(default=True)\n    diagnose: bool = field(default=True)\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/validators/","title":"validators","text":"<p>Loguru validators.</p> <p>Pass objects, strings, bools, etc for evaluation.</p> <p>Each validator checks for existence (unless <code>none_ok=True</code>), then type, then value (if a list of allowed values is passed).</p>"},{"location":"reference/red_utils/ext/loguru_utils/validators/#red_utils.ext.loguru_utils.validators.validate_compression_str","title":"<code>validate_compression_str(string=None, none_ok=True)</code>","text":"<p>Validate a Loguru compression string value.</p> <p>Parameters:</p> Name Type Description Default <code>string</code> <code>str</code> <p>The compression string to validate</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>If <code>True</code>, allows null values</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>A validated compression string</p> Source code in <code>src\\red_utils\\ext\\loguru_utils\\validators.py</code> <pre><code>def validate_compression_str(string: str = None, none_ok: bool = True) -&gt; str:\n    \"\"\"Validate a Loguru compression string value.\n\n    Params:\n        string (str): The compression string to validate\n        none_ok (bool): If `True`, allows null values\n\n    Returns:\n        (str): A validated compression string\n\n    \"\"\"\n    if none_ok:\n        return string\n    elif not string:\n        raise ValueError(\"Missing a compression string to validate\")\n\n    if not isinstance(string, str):\n        raise TypeError(f\"Invalid type for string: ({type(string)}). Must be type(str)\")\n\n    if string not in valid_compression_strs:\n        raise ValueError(\n            f\"Invalid compression type: [{type(string)}]. Must be one of {valid_compression_strs}\"\n        )\n\n    return string\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/validators/#red_utils.ext.loguru_utils.validators.validate_level","title":"<code>validate_level(level=None, none_ok=False)</code>","text":"<p>Validate a Loguru compression string value.</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <code>str</code> <p>A log level string</p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>If <code>True</code>, allows null values</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>A validated log level string</p> Source code in <code>src\\red_utils\\ext\\loguru_utils\\validators.py</code> <pre><code>def validate_level(level: str = None, none_ok: bool = False) -&gt; str:\n    \"\"\"Validate a Loguru compression string value.\n\n    Params:\n        level (str): A log level string\n        none_ok (bool): If `True`, allows null values\n\n    Returns:\n        (str): A validated log level string\n\n    \"\"\"\n    if none_ok:\n        return level\n    elif not level:\n        raise ValueError(\"Missing a log level string to evaluate.\")\n\n    if not isinstance(level, str):\n        raise TypeError(f\"Invalid level type: [{type(level)}]\")\n\n    try:\n        for _level in log_levels:\n            if not level == _level.name or not level == _level.level_name:\n                pass\n            else:\n                return _level\n\n    except ValueError as exc:\n        msg = ValueError(f\"Unhandled exception validating log level. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/loguru_utils/validators/#red_utils.ext.loguru_utils.validators.validate_logger","title":"<code>validate_logger(_logger=None, none_ok=False)</code>","text":"<p>Validate a loguru.Logger object.</p> <p>Parameters:</p> Name Type Description Default <code>_logger</code> <code>logger</code> <p>A Loguru <code>logger</code></p> <code>None</code> <code>none_ok</code> <code>bool</code> <p>If <code>True</code>, allows null values</p> <code>False</code> <p>Returns:</p> Type Description <code>logger</code> <p>A validated <code>loguru.logger</code></p> Source code in <code>src\\red_utils\\ext\\loguru_utils\\validators.py</code> <pre><code>def validate_logger(_logger: logger = None, none_ok: bool = False) -&gt; logger:\n    \"\"\"Validate a loguru.Logger object.\n\n    Params:\n        _logger (loguru.logger): A Loguru `logger`\n        none_ok (bool): If `True`, allows null values\n\n    Returns:\n        (loguru.logger): A validated `loguru.logger`\n\n    \"\"\"\n    if none_ok:\n        return _logger\n    elif not _logger:\n        raise ValueError(\"Missing loguru Logger object to validate\")\n\n    if not isinstance(_logger, type(logger)):\n        raise TypeError(\n            f\"Invalid type for logger: {type(_logger)}. Must be type(Logger)\"\n        )\n\n    return _logger\n</code></pre>"},{"location":"reference/red_utils/ext/msgpack_utils/__init__/","title":"msgpack_utils","text":"<p>Utilities for the <code>msgpack</code> serialization library.</p>"},{"location":"reference/red_utils/ext/msgpack_utils/__init__/#red_utils.ext.msgpack_utils.SerialFunctionResponse","title":"<code>SerialFunctionResponse</code>  <code>dataclass</code>","text":"<p>               Bases: <code>SerialFunctionResponseBase</code></p> <p>A <code>dataclass</code> for passing <code>msgpack</code> serialization responses.</p> <p>Parameters:</p> Name Type Description Default <code>success</code> <code>bool</code> <p><code>True</code> if operation success, <code>False</code> if operation failure</p> <code>False</code> <code>detail</code> <code>Any</code> <p>Append additional details to a response</p> <code>None</code> <code>operation</code> <code>str</code> <p>The operation that produced this response. Can be serialize/deserialize, or serialize/deserialize file.</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\msgpack_utils\\classes.py</code> <pre><code>@dataclass\nclass SerialFunctionResponse(SerialFunctionResponseBase):\n    \"\"\"A `dataclass` for passing `msgpack` serialization responses.\n\n    Params:\n        success (bool): `True` if operation success, `False` if operation failure\n        detail (Any): Append additional details to a response\n        operation (str): The operation that produced this response.\n            Can be serialize/deserialize, or serialize/deserialize file.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/red_utils/ext/msgpack_utils/__init__/#red_utils.ext.msgpack_utils.ensure_path","title":"<code>ensure_path(dir=None)</code>","text":"<p>Ensure a directory path exists.</p> <p>Parameters:</p> Name Type Description Default <code>dir</code> <code>str | Path</code> <p>The directory path to ensure existence of</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if Path exists/was created</p> <code>bool</code> <p><code>False</code> if an error was encountered</p> Source code in <code>src\\red_utils\\ext\\msgpack_utils\\operations.py</code> <pre><code>def ensure_path(dir: Union[str, Path] = None) -&gt; bool:\n    \"\"\"Ensure a directory path exists.\n\n    Params:\n        dir (str|Path): The directory path to ensure existence of\n\n    Returns:\n        (bool): `True` if Path exists/was created\n        (bool): `False` if an error was encountered\n\n    \"\"\"\n    if not dir:\n        raise ValueError(\"Missing input directory to validate\")\n\n    if not isinstance(dir, Path) and not isinstance(dir, str):\n        raise TypeError(\n            f\"Invalid type for property [dir]: ({type(dir)}). Must be of type str or Path\"\n        )\n\n    if isinstance(dir, str):\n        dir = Path(dir)\n\n    if not dir.exists():\n        try:\n            dir.mkdir(parents=True, exist_ok=True)\n        except FileExistsError as f_exc:\n            log.warning(f_exc)\n\n            return True\n        except PermissionError as perm_exc:\n            log.error(perm_exc)\n\n            return False\n        except Exception as exc:\n            msg = Exception(\n                {\n                    \"success\": False,\n                    \"error\": f\"Unhandled exception creating dir: [{dir}].\",\n                    \"details\": exc,\n                }\n            )\n            log.error(msg)\n\n            return False\n\n    else:\n        return True\n</code></pre>"},{"location":"reference/red_utils/ext/msgpack_utils/__init__/#red_utils.ext.msgpack_utils.msgpack_deserialize","title":"<code>msgpack_deserialize(packed_str=None)</code>","text":"<p>Load serialized msgpack string.</p> <p>Parameters:</p> Name Type Description Default <code>packed_str</code> <code>bytes</code> <p>A <code>msgpack</code> serialized <code>bytestring</code> to be deserialized</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>False</code> if deserialization fails</p> <code>str</code> <p>String value from serialized <code>packed_str</code></p> <code>dict</code> <p>A dict with 2 keys, <code>'success'</code> and <code>'detail'</code>. <code>success</code> is a <code>bool</code> indicator of deserialize operation success status. <code>detail</code> contains the <code>'message'</code> key with the <code>bytestring</code>, as well as other     optional details to be returned.</p> Source code in <code>src\\red_utils\\ext\\msgpack_utils\\operations.py</code> <pre><code>def msgpack_deserialize(\n    packed_str: bytes = None,\n) -&gt; dict[str, Union[bool, str, dict[str, Union[str, dict]]]]:\n    \"\"\"Load serialized msgpack string.\n\n    Params:\n        packed_str (bytes): A `msgpack` serialized `bytestring` to be deserialized\n\n    Returns:\n        (bool): `False` if deserialization fails\n        (str): String value from serialized `packed_str`\n        (dict): A dict with 2 keys, `'success'` and `'detail'`.\n            `success` is a `bool` indicator of deserialize operation success status.\n            `detail` contains the `'message'` key with the `bytestring`, as well as other\n                optional details to be returned.\n\n    \"\"\"\n    if not packed_str:\n        raise ValueError(\"Must pass a bytestring to deserialize\")\n\n    if not isinstance(packed_str, bytes):\n        raise TypeError(\n            f\"Invalid type for [packed_str]: ({type(packed_str)}). Must be of type bytestring\"\n        )\n\n    try:\n        unpacked = msgpack.unpackb(packed_str)\n\n        return_obj = {\n            \"success\": True,\n            \"detail\": {\n                \"message\": unpacked,\n            },\n        }\n\n    except Exception as exc:\n        # log.error({\"exception\": \"Unhandled exception reading msgpack.\"}, exc_info=True)\n        log.error(exc)\n        return_obj = {\"success\": False, \"detail\": {\"message\": f\"{exc}\"}}\n\n    return return_obj\n</code></pre>"},{"location":"reference/red_utils/ext/msgpack_utils/__init__/#red_utils.ext.msgpack_utils.msgpack_deserialize_file","title":"<code>msgpack_deserialize_file(filename=None)</code>","text":"<p>Load serialized msgpack string from a file and return.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The path to a file with serialized data to load</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dict with 2 keys, <code>'success'</code> and <code>'detail'</code>. <code>success</code> is a <code>bool</code> indicator of deserialize operation success status. <code>detail</code> contains the <code>'message'</code> key with the <code>bytestring</code>, as well as other     optional details to be returned.</p> Source code in <code>src\\red_utils\\ext\\msgpack_utils\\operations.py</code> <pre><code>def msgpack_deserialize_file(\n    filename: str = None,\n) -&gt; (\n    SerialFunctionResponse\n):  ## dict[str, Union[bool, str, dict[str, Union[str, dict]]]]:\n    \"\"\"Load serialized msgpack string from a file and return.\n\n    Params:\n        filename (str): The path to a file with serialized data to load\n\n    Returns:\n        (dict): A dict with 2 keys, `'success'` and `'detail'`.\n            `success` is a `bool` indicator of deserialize operation success status.\n            `detail` contains the `'message'` key with the `bytestring`, as well as other\n                optional details to be returned.\n\n    \"\"\"\n    if not filename:\n        raise ValueError(\"Must pass a file name/path to deserialize\")\n\n    if not Path(filename).exists():\n        raise FileNotFoundError(f\"Could not find file: {filename}\")\n\n    try:\n        with open(f\"{filename}\", \"rb\") as infile:\n            in_bytes = infile.read()\n            unpacked = msgpack.unpackb(in_bytes)\n\n        return_obj = {\n            \"success\": True,\n            \"detail\": {\n                \"message\": f\"Data deserialized from file {filename}\",\n                \"unpacked\": unpacked,\n            },\n        }\n\n        return_obj = SerialFunctionResponse(success=True, detail=unpacked)\n\n    except Exception as exc:\n        # log.error({\"exception\": \"Unhandled exception reading msgpack.\"}, exc_info=True)\n\n        # return_obj = {\"success\": False, \"detail\": {\"message\": f\"{exc}\"}}\n        log.error(exc)\n        return_obj = SerialFunctionResponse(success=False, detail=exc)\n\n    return return_obj\n</code></pre>"},{"location":"reference/red_utils/ext/msgpack_utils/__init__/#red_utils.ext.msgpack_utils.msgpack_serialize","title":"<code>msgpack_serialize(_json=None)</code>","text":"<p>Serialize a Python dict to a msgpack string.</p> <p>Parameters:</p> Name Type Description Default <code>_json</code> <code>dict</code> <p>A Python <code>dict</code> to serialize</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dict with 2 keys, <code>'success'</code> and <code>'detail'</code>. <code>success</code> is a <code>bool</code> indicator of serialize operation success status. <code>detail</code> contains the <code>'message'</code> key with the <code>bytestring</code>, as well as other     optional details to be returned.</p> Source code in <code>src\\red_utils\\ext\\msgpack_utils\\operations.py</code> <pre><code>def msgpack_serialize(\n    _json: dict = None,\n) -&gt; SerialFunctionResponse:  # -&gt; dict[str, Union[bool, str, bytes, None]]:\n    \"\"\"Serialize a Python dict to a msgpack string.\n\n    Params:\n        _json (dict): A Python `dict` to serialize\n\n    Returns:\n        (dict): A dict with 2 keys, `'success'` and `'detail'`.\n            `success` is a `bool` indicator of serialize operation success status.\n            `detail` contains the `'message'` key with the `bytestring`, as well as other\n                optional details to be returned.\n\n    \"\"\"\n    if not _json:\n        raise ValueError(\"Missing Python dict data to serialize\")\n\n    try:\n        packed = msgpack.packb(_json)\n\n        # return_obj = {\"success\": True, \"detail\": {\"message\": packed}}\n        return_obj: SerialFunctionResponse = SerialFunctionResponse(\n            success=True, detail=packed, operation=\"serialize\"\n        )\n\n    except Exception as exc:\n        log.error(exc)\n        # return_obj = {\"success\": False, \"detail\": {\"message\": f\"{exc}\"}}\n        return_obj: SerialFunctionResponse = SerialFunctionResponse(\n            success=False, detail=exc, operation=\"serialize\"\n        )\n\n    return return_obj\n</code></pre>"},{"location":"reference/red_utils/ext/msgpack_utils/__init__/#red_utils.ext.msgpack_utils.msgpack_serialize_file","title":"<code>msgpack_serialize_file(_json=None, output_dir=SERIALIZE_DIR, filename=None)</code>","text":"<p>Serialize a Python dict to a msgpack file.</p> <p>Parameters:</p> Name Type Description Default <code>_json</code> <code>dict</code> <p>A Python <code>dict</code> to serialize</p> <code>None</code> <code>output_dir</code> <code>str</code> <p>Output path where file should be saved</p> <code>SERIALIZE_DIR</code> <code>filename</code> <code>str</code> <p>Name of the serialized file</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dict with 2 keys, <code>'success'</code> and <code>'detail'</code>. <code>success</code> is a <code>bool</code> indicator of serialize operation success status. <code>detail</code> contains the <code>'message'</code> key with the <code>bytestring</code>, as well as other     optional details to be returned.</p> Source code in <code>src\\red_utils\\ext\\msgpack_utils\\operations.py</code> <pre><code>def msgpack_serialize_file(\n    _json: dict = None, output_dir: str = SERIALIZE_DIR, filename: str = None\n) -&gt; (\n    SerialFunctionResponse\n):  ## dict[str, Union[bool, str, dict[str, Union[str, dict]]]]:\n    \"\"\"Serialize a Python dict to a msgpack file.\n\n    Params:\n        _json (dict): A Python `dict` to serialize\n        output_dir (str): Output path where file should be saved\n        filename (str): Name of the serialized file\n\n    Returns:\n        (dict): A dict with 2 keys, `'success'` and `'detail'`.\n            `success` is a `bool` indicator of serialize operation success status.\n            `detail` contains the `'message'` key with the `bytestring`, as well as other\n                optional details to be returned.\n\n    \"\"\"\n    if not _json:\n        raise ValueError(\"Missing Python dict data to serialize\")\n\n    if not filename:\n        # log.debug(f\"Missing filename. Generating a random filename.\")\n\n        filename = str(uuid4())\n\n    if filename.endswith(\".msgpack\"):\n        filename.replace(\".msgpack\", \"\")\n    else:\n        filename = f\"{filename}.msgpack\"\n\n    dir_exist = ensure_path(output_dir)\n\n    filename = f\"{output_dir}/{filename}\"\n\n    if _json:\n        try:\n            with open(f\"{filename}\", \"wb\") as outfile:\n                packed = msgpack.packb(_json)\n                outfile.write(packed)\n\n            # return_obj = {\n            #     \"success\": True,\n            #     \"detail\": {\"message\": f\"Data serialized to file {filename}\"},\n            # }\n\n            return_obj = SerialFunctionResponse(success=True, detail=filename)\n\n        except Exception as exc:\n            # return_obj = {\"success\": False, \"detail\": {\"message\": f\"{exc}\"}}\n            log.error(exc)\n            return_obj = SerialFunctionResponse(success=False, detail=exc)\n\n    return return_obj\n</code></pre>"},{"location":"reference/red_utils/ext/msgpack_utils/classes/","title":"classes","text":""},{"location":"reference/red_utils/ext/msgpack_utils/classes/#red_utils.ext.msgpack_utils.classes.SerialFunctionResponse","title":"<code>SerialFunctionResponse</code>  <code>dataclass</code>","text":"<p>               Bases: <code>SerialFunctionResponseBase</code></p> <p>A <code>dataclass</code> for passing <code>msgpack</code> serialization responses.</p> <p>Parameters:</p> Name Type Description Default <code>success</code> <code>bool</code> <p><code>True</code> if operation success, <code>False</code> if operation failure</p> <code>False</code> <code>detail</code> <code>Any</code> <p>Append additional details to a response</p> <code>None</code> <code>operation</code> <code>str</code> <p>The operation that produced this response. Can be serialize/deserialize, or serialize/deserialize file.</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\msgpack_utils\\classes.py</code> <pre><code>@dataclass\nclass SerialFunctionResponse(SerialFunctionResponseBase):\n    \"\"\"A `dataclass` for passing `msgpack` serialization responses.\n\n    Params:\n        success (bool): `True` if operation success, `False` if operation failure\n        detail (Any): Append additional details to a response\n        operation (str): The operation that produced this response.\n            Can be serialize/deserialize, or serialize/deserialize file.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/red_utils/ext/msgpack_utils/constants/","title":"constants","text":""},{"location":"reference/red_utils/ext/msgpack_utils/operations/","title":"operations","text":""},{"location":"reference/red_utils/ext/msgpack_utils/operations/#red_utils.ext.msgpack_utils.operations.SerialFunctionResponse","title":"<code>SerialFunctionResponse</code>  <code>dataclass</code>","text":"<p>               Bases: <code>SerialFunctionResponseBase</code></p> <p>A <code>dataclass</code> for passing <code>msgpack</code> serialization responses.</p> <p>Parameters:</p> Name Type Description Default <code>success</code> <code>bool</code> <p><code>True</code> if operation success, <code>False</code> if operation failure</p> <code>False</code> <code>detail</code> <code>Any</code> <p>Append additional details to a response</p> <code>None</code> <code>operation</code> <code>str</code> <p>The operation that produced this response. Can be serialize/deserialize, or serialize/deserialize file.</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\msgpack_utils\\classes.py</code> <pre><code>@dataclass\nclass SerialFunctionResponse(SerialFunctionResponseBase):\n    \"\"\"A `dataclass` for passing `msgpack` serialization responses.\n\n    Params:\n        success (bool): `True` if operation success, `False` if operation failure\n        detail (Any): Append additional details to a response\n        operation (str): The operation that produced this response.\n            Can be serialize/deserialize, or serialize/deserialize file.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/red_utils/ext/msgpack_utils/operations/#red_utils.ext.msgpack_utils.operations.ensure_path","title":"<code>ensure_path(dir=None)</code>","text":"<p>Ensure a directory path exists.</p> <p>Parameters:</p> Name Type Description Default <code>dir</code> <code>str | Path</code> <p>The directory path to ensure existence of</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if Path exists/was created</p> <code>bool</code> <p><code>False</code> if an error was encountered</p> Source code in <code>src\\red_utils\\ext\\msgpack_utils\\operations.py</code> <pre><code>def ensure_path(dir: Union[str, Path] = None) -&gt; bool:\n    \"\"\"Ensure a directory path exists.\n\n    Params:\n        dir (str|Path): The directory path to ensure existence of\n\n    Returns:\n        (bool): `True` if Path exists/was created\n        (bool): `False` if an error was encountered\n\n    \"\"\"\n    if not dir:\n        raise ValueError(\"Missing input directory to validate\")\n\n    if not isinstance(dir, Path) and not isinstance(dir, str):\n        raise TypeError(\n            f\"Invalid type for property [dir]: ({type(dir)}). Must be of type str or Path\"\n        )\n\n    if isinstance(dir, str):\n        dir = Path(dir)\n\n    if not dir.exists():\n        try:\n            dir.mkdir(parents=True, exist_ok=True)\n        except FileExistsError as f_exc:\n            log.warning(f_exc)\n\n            return True\n        except PermissionError as perm_exc:\n            log.error(perm_exc)\n\n            return False\n        except Exception as exc:\n            msg = Exception(\n                {\n                    \"success\": False,\n                    \"error\": f\"Unhandled exception creating dir: [{dir}].\",\n                    \"details\": exc,\n                }\n            )\n            log.error(msg)\n\n            return False\n\n    else:\n        return True\n</code></pre>"},{"location":"reference/red_utils/ext/msgpack_utils/operations/#red_utils.ext.msgpack_utils.operations.msgpack_deserialize","title":"<code>msgpack_deserialize(packed_str=None)</code>","text":"<p>Load serialized msgpack string.</p> <p>Parameters:</p> Name Type Description Default <code>packed_str</code> <code>bytes</code> <p>A <code>msgpack</code> serialized <code>bytestring</code> to be deserialized</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>False</code> if deserialization fails</p> <code>str</code> <p>String value from serialized <code>packed_str</code></p> <code>dict</code> <p>A dict with 2 keys, <code>'success'</code> and <code>'detail'</code>. <code>success</code> is a <code>bool</code> indicator of deserialize operation success status. <code>detail</code> contains the <code>'message'</code> key with the <code>bytestring</code>, as well as other     optional details to be returned.</p> Source code in <code>src\\red_utils\\ext\\msgpack_utils\\operations.py</code> <pre><code>def msgpack_deserialize(\n    packed_str: bytes = None,\n) -&gt; dict[str, Union[bool, str, dict[str, Union[str, dict]]]]:\n    \"\"\"Load serialized msgpack string.\n\n    Params:\n        packed_str (bytes): A `msgpack` serialized `bytestring` to be deserialized\n\n    Returns:\n        (bool): `False` if deserialization fails\n        (str): String value from serialized `packed_str`\n        (dict): A dict with 2 keys, `'success'` and `'detail'`.\n            `success` is a `bool` indicator of deserialize operation success status.\n            `detail` contains the `'message'` key with the `bytestring`, as well as other\n                optional details to be returned.\n\n    \"\"\"\n    if not packed_str:\n        raise ValueError(\"Must pass a bytestring to deserialize\")\n\n    if not isinstance(packed_str, bytes):\n        raise TypeError(\n            f\"Invalid type for [packed_str]: ({type(packed_str)}). Must be of type bytestring\"\n        )\n\n    try:\n        unpacked = msgpack.unpackb(packed_str)\n\n        return_obj = {\n            \"success\": True,\n            \"detail\": {\n                \"message\": unpacked,\n            },\n        }\n\n    except Exception as exc:\n        # log.error({\"exception\": \"Unhandled exception reading msgpack.\"}, exc_info=True)\n        log.error(exc)\n        return_obj = {\"success\": False, \"detail\": {\"message\": f\"{exc}\"}}\n\n    return return_obj\n</code></pre>"},{"location":"reference/red_utils/ext/msgpack_utils/operations/#red_utils.ext.msgpack_utils.operations.msgpack_deserialize_file","title":"<code>msgpack_deserialize_file(filename=None)</code>","text":"<p>Load serialized msgpack string from a file and return.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The path to a file with serialized data to load</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dict with 2 keys, <code>'success'</code> and <code>'detail'</code>. <code>success</code> is a <code>bool</code> indicator of deserialize operation success status. <code>detail</code> contains the <code>'message'</code> key with the <code>bytestring</code>, as well as other     optional details to be returned.</p> Source code in <code>src\\red_utils\\ext\\msgpack_utils\\operations.py</code> <pre><code>def msgpack_deserialize_file(\n    filename: str = None,\n) -&gt; (\n    SerialFunctionResponse\n):  ## dict[str, Union[bool, str, dict[str, Union[str, dict]]]]:\n    \"\"\"Load serialized msgpack string from a file and return.\n\n    Params:\n        filename (str): The path to a file with serialized data to load\n\n    Returns:\n        (dict): A dict with 2 keys, `'success'` and `'detail'`.\n            `success` is a `bool` indicator of deserialize operation success status.\n            `detail` contains the `'message'` key with the `bytestring`, as well as other\n                optional details to be returned.\n\n    \"\"\"\n    if not filename:\n        raise ValueError(\"Must pass a file name/path to deserialize\")\n\n    if not Path(filename).exists():\n        raise FileNotFoundError(f\"Could not find file: {filename}\")\n\n    try:\n        with open(f\"{filename}\", \"rb\") as infile:\n            in_bytes = infile.read()\n            unpacked = msgpack.unpackb(in_bytes)\n\n        return_obj = {\n            \"success\": True,\n            \"detail\": {\n                \"message\": f\"Data deserialized from file {filename}\",\n                \"unpacked\": unpacked,\n            },\n        }\n\n        return_obj = SerialFunctionResponse(success=True, detail=unpacked)\n\n    except Exception as exc:\n        # log.error({\"exception\": \"Unhandled exception reading msgpack.\"}, exc_info=True)\n\n        # return_obj = {\"success\": False, \"detail\": {\"message\": f\"{exc}\"}}\n        log.error(exc)\n        return_obj = SerialFunctionResponse(success=False, detail=exc)\n\n    return return_obj\n</code></pre>"},{"location":"reference/red_utils/ext/msgpack_utils/operations/#red_utils.ext.msgpack_utils.operations.msgpack_serialize","title":"<code>msgpack_serialize(_json=None)</code>","text":"<p>Serialize a Python dict to a msgpack string.</p> <p>Parameters:</p> Name Type Description Default <code>_json</code> <code>dict</code> <p>A Python <code>dict</code> to serialize</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dict with 2 keys, <code>'success'</code> and <code>'detail'</code>. <code>success</code> is a <code>bool</code> indicator of serialize operation success status. <code>detail</code> contains the <code>'message'</code> key with the <code>bytestring</code>, as well as other     optional details to be returned.</p> Source code in <code>src\\red_utils\\ext\\msgpack_utils\\operations.py</code> <pre><code>def msgpack_serialize(\n    _json: dict = None,\n) -&gt; SerialFunctionResponse:  # -&gt; dict[str, Union[bool, str, bytes, None]]:\n    \"\"\"Serialize a Python dict to a msgpack string.\n\n    Params:\n        _json (dict): A Python `dict` to serialize\n\n    Returns:\n        (dict): A dict with 2 keys, `'success'` and `'detail'`.\n            `success` is a `bool` indicator of serialize operation success status.\n            `detail` contains the `'message'` key with the `bytestring`, as well as other\n                optional details to be returned.\n\n    \"\"\"\n    if not _json:\n        raise ValueError(\"Missing Python dict data to serialize\")\n\n    try:\n        packed = msgpack.packb(_json)\n\n        # return_obj = {\"success\": True, \"detail\": {\"message\": packed}}\n        return_obj: SerialFunctionResponse = SerialFunctionResponse(\n            success=True, detail=packed, operation=\"serialize\"\n        )\n\n    except Exception as exc:\n        log.error(exc)\n        # return_obj = {\"success\": False, \"detail\": {\"message\": f\"{exc}\"}}\n        return_obj: SerialFunctionResponse = SerialFunctionResponse(\n            success=False, detail=exc, operation=\"serialize\"\n        )\n\n    return return_obj\n</code></pre>"},{"location":"reference/red_utils/ext/msgpack_utils/operations/#red_utils.ext.msgpack_utils.operations.msgpack_serialize_file","title":"<code>msgpack_serialize_file(_json=None, output_dir=SERIALIZE_DIR, filename=None)</code>","text":"<p>Serialize a Python dict to a msgpack file.</p> <p>Parameters:</p> Name Type Description Default <code>_json</code> <code>dict</code> <p>A Python <code>dict</code> to serialize</p> <code>None</code> <code>output_dir</code> <code>str</code> <p>Output path where file should be saved</p> <code>SERIALIZE_DIR</code> <code>filename</code> <code>str</code> <p>Name of the serialized file</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dict with 2 keys, <code>'success'</code> and <code>'detail'</code>. <code>success</code> is a <code>bool</code> indicator of serialize operation success status. <code>detail</code> contains the <code>'message'</code> key with the <code>bytestring</code>, as well as other     optional details to be returned.</p> Source code in <code>src\\red_utils\\ext\\msgpack_utils\\operations.py</code> <pre><code>def msgpack_serialize_file(\n    _json: dict = None, output_dir: str = SERIALIZE_DIR, filename: str = None\n) -&gt; (\n    SerialFunctionResponse\n):  ## dict[str, Union[bool, str, dict[str, Union[str, dict]]]]:\n    \"\"\"Serialize a Python dict to a msgpack file.\n\n    Params:\n        _json (dict): A Python `dict` to serialize\n        output_dir (str): Output path where file should be saved\n        filename (str): Name of the serialized file\n\n    Returns:\n        (dict): A dict with 2 keys, `'success'` and `'detail'`.\n            `success` is a `bool` indicator of serialize operation success status.\n            `detail` contains the `'message'` key with the `bytestring`, as well as other\n                optional details to be returned.\n\n    \"\"\"\n    if not _json:\n        raise ValueError(\"Missing Python dict data to serialize\")\n\n    if not filename:\n        # log.debug(f\"Missing filename. Generating a random filename.\")\n\n        filename = str(uuid4())\n\n    if filename.endswith(\".msgpack\"):\n        filename.replace(\".msgpack\", \"\")\n    else:\n        filename = f\"{filename}.msgpack\"\n\n    dir_exist = ensure_path(output_dir)\n\n    filename = f\"{output_dir}/{filename}\"\n\n    if _json:\n        try:\n            with open(f\"{filename}\", \"wb\") as outfile:\n                packed = msgpack.packb(_json)\n                outfile.write(packed)\n\n            # return_obj = {\n            #     \"success\": True,\n            #     \"detail\": {\"message\": f\"Data serialized to file {filename}\"},\n            # }\n\n            return_obj = SerialFunctionResponse(success=True, detail=filename)\n\n        except Exception as exc:\n            # return_obj = {\"success\": False, \"detail\": {\"message\": f\"{exc}\"}}\n            log.error(exc)\n            return_obj = SerialFunctionResponse(success=False, detail=exc)\n\n    return return_obj\n</code></pre>"},{"location":"reference/red_utils/ext/msgpack_utils/validators/","title":"validators","text":"<p>Validators for <code>msgpack</code> utilities.</p> <pre><code>valid_operations: list[str] = [\n    \"serialize\",\n    \"deserialize\",\n    \"serialize_file\",\n    \"deserialize_file\",\n]\n</code></pre>"},{"location":"reference/red_utils/ext/pydantic_utils/__init__/","title":"pydantic_utils","text":"<p>Utilities for <code>pydantic</code></p>"},{"location":"reference/red_utils/ext/pydantic_utils/__init__/#red_utils.ext.pydantic_utils.parse_pydantic_schema","title":"<code>parse_pydantic_schema(schema)</code>","text":"<p>Iterate through pydantic schema and parses nested schemas to a dictionary containing SQLAlchemy models.</p> <p>Only works if nested schemas have specified the Meta.orm_model.</p> <p>Make sure to add this line to Pydantic schemas that have an ORM class:</p> <pre><code>class Meta:\n    orm_model = \"SQLAModelName\"\n</code></pre> Source code in <code>src\\red_utils\\ext\\pydantic_utils\\parsers.py</code> <pre><code>def parse_pydantic_schema(schema):\n    \"\"\"Iterate through pydantic schema and parses nested schemas to a dictionary containing SQLAlchemy models.\n\n    Only works if nested schemas have specified the Meta.orm_model.\n\n    Make sure to add this line to Pydantic schemas that have an ORM class:\n\n    ``` py linenums=\"1\"\n    class Meta:\n        orm_model = \"SQLAModelName\"\n    ```\n    \"\"\"\n    parsed_schema: dict = dict(schema)\n\n    for key, value in parsed_schema.items():\n        try:\n            if isinstance(value, list) and len(value):\n                if is_pydantic(value[0]):\n                    parsed_schema[key] = [\n                        schema.Meta.orm_model(**schema.dict()) for schema in value\n                    ]\n\n            else:\n                if is_pydantic(value):\n                    parsed_schema[key] = value.Meta.orm_model(**value.dict())\n\n        except AttributeError:\n            raise AttributeError(\n                \"Found nested Pydantic model but Meta.orm_model was not specified.\"\n            )\n\n    return parsed_schema\n</code></pre>"},{"location":"reference/red_utils/ext/pydantic_utils/parsers/","title":"parsers","text":"<p>Parse a Pydantic model so it is usable by SQLAlchemy.</p>"},{"location":"reference/red_utils/ext/pydantic_utils/parsers/#red_utils.ext.pydantic_utils.parsers.is_pydantic","title":"<code>is_pydantic(obj)</code>","text":"<p>Check whether an object is pydantic.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>object</code> <p>An arbitrary Python object to evaluate</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>obj</code> is of Pydantic type <code>ModelMetaClass</code></p> <code>bool</code> <p><code>False</code> if <code>obj</code> is not of Pydatic type <code>ModelMetaClass</code></p> Source code in <code>src\\red_utils\\ext\\pydantic_utils\\parsers.py</code> <pre><code>def is_pydantic(obj: object) -&gt; bool:\n    \"\"\"Check whether an object is pydantic.\n\n    Params:\n        obj (object): An arbitrary Python object to evaluate\n\n    Returns:\n        (bool): `True` if `obj` is of Pydantic type `ModelMetaClass`\n        (bool): `False` if `obj` is not of Pydatic type `ModelMetaClass`\n\n    \"\"\"\n    return type(obj).__class__.__name__ == \"ModelMetaclass\"\n</code></pre>"},{"location":"reference/red_utils/ext/pydantic_utils/parsers/#red_utils.ext.pydantic_utils.parsers.parse_pydantic_schema","title":"<code>parse_pydantic_schema(schema)</code>","text":"<p>Iterate through pydantic schema and parses nested schemas to a dictionary containing SQLAlchemy models.</p> <p>Only works if nested schemas have specified the Meta.orm_model.</p> <p>Make sure to add this line to Pydantic schemas that have an ORM class:</p> <pre><code>class Meta:\n    orm_model = \"SQLAModelName\"\n</code></pre> Source code in <code>src\\red_utils\\ext\\pydantic_utils\\parsers.py</code> <pre><code>def parse_pydantic_schema(schema):\n    \"\"\"Iterate through pydantic schema and parses nested schemas to a dictionary containing SQLAlchemy models.\n\n    Only works if nested schemas have specified the Meta.orm_model.\n\n    Make sure to add this line to Pydantic schemas that have an ORM class:\n\n    ``` py linenums=\"1\"\n    class Meta:\n        orm_model = \"SQLAModelName\"\n    ```\n    \"\"\"\n    parsed_schema: dict = dict(schema)\n\n    for key, value in parsed_schema.items():\n        try:\n            if isinstance(value, list) and len(value):\n                if is_pydantic(value[0]):\n                    parsed_schema[key] = [\n                        schema.Meta.orm_model(**schema.dict()) for schema in value\n                    ]\n\n            else:\n                if is_pydantic(value):\n                    parsed_schema[key] = value.Meta.orm_model(**value.dict())\n\n        except AttributeError:\n            raise AttributeError(\n                \"Found nested Pydantic model but Meta.orm_model was not specified.\"\n            )\n\n    return parsed_schema\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/","title":"sqlalchemy_utils","text":"<p>SQLAlchemy common database code.</p> <p>Contains SQLAlchemy setup code, engine, and session(s). Uses <code>dataclasses</code> to define database connection, and builds a default <code>Engine</code> &amp; <code>Session</code>. The use of <code>dataclasses</code> is to minimize depdencies for this common SQLAlchemy code so it can be easily re-used in other projects utilizing SQLAlchemy for database operations.</p> <p>The default <code>Engine</code> and <code>Session</code> are customizable using the <code>get_engine()</code> and <code>get_session()</code> functions. These functions can be imported &amp; called from another app, with customized values to control engine &amp; session behavior.</p> Currently supported databases <ul> <li>[x] SQLite</li> <li>[x] Postgres</li> <li>[ ] MySQL</li> <li>[x] MSSQL</li> <li>[ ] Azure Cosmos</li> </ul> <p>Be sure to import the <code>Base</code> object from this script and run <code>Base.metadata.create_all(bind=engine)</code> as early as possible. For example, import the <code>Base</code> object from this script into a <code>main.py</code> or equivalent entrypoint, create/import an <code>Engine</code>, and immediately run the metadata create function.</p>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.Base","title":"<code>Base</code>","text":"<p>               Bases: <code>DeclarativeBase</code></p> <p>Default/Base class for SQLAlchemy models.</p> <p>Description:</p> <p>Child classes inheriting from this Base object will be treated as SQLAlchemy models. Set child class tables with <code>__tablename__ = ....</code></p> <p>Global defaults can be set on this object (i.e. a SQLAlchemy registry), and will be inherited/accessible by all child classes.</p> <p>Note</p> <p>When this class is instantiated, it will not be of type sqlalchemy.orm.DeclarativeBase;     Because of the way this class is intialized, its type will be     sqlalchemy.orm.decl_api.DeclarativeAttributeIntercept</p> <p>Parameters:</p> Name Type Description Default <code>registry</code> <code>Registry</code> <p>A <code>registry</code> object for the <code>Base</code> class</p> required <code>metadata</code> <code>MetaData</code> <p>A <code>MetaData</code> object, with data about the <code>Base</code> class</p> required Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\base.py</code> <pre><code>class Base(so.DeclarativeBase):\n    \"\"\"Default/Base class for SQLAlchemy models.\n\n    Description:\n\n    Child classes inheriting from this Base object will be treated as SQLAlchemy\n    models. Set child class tables with `__tablename__ = ....`\n\n    Global defaults can be set on this object (i.e. a SQLAlchemy registry), and will\n    be inherited/accessible by all child classes.\n\n    !!! note\n\n        When this class is instantiated, it will not be of type sqlalchemy.orm.DeclarativeBase;\n            Because of the way this class is intialized, its type will be\n            sqlalchemy.orm.decl_api.DeclarativeAttributeIntercept\n\n    Params:\n        registry (sqlalchemy.Registry): A `registry` object for the `Base` class\n        metadata (sqlalchemy.MetaData): A `MetaData` object, with data about the `Base` class\n    \"\"\"\n\n    registry: so.registry = reg\n    metadata: sa.MetaData = metadata\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.CompatibleUUID","title":"<code>CompatibleUUID</code>","text":"<p>               Bases: <code>TypeDecorator</code></p> <p>Define a custom UUID, overriding SQLAlchemy's UUId type.</p> <p>The main purpose of this class is to instruct SQLAlchemy to store UUIDs as a binary, instead of as a UUID type. This is useful for cross-database support, i.e. for SQLite which does not support the UUID type.</p> <p>Note</p> <ul> <li>SQLAlchemy docs: backend agnostic GUID type</li> </ul> <p>Usage:</p> <p>When defining a table model, after declaring <code>__tablename_</code>_, set the <code>type_annotation_map</code>, i.e.:</p> <pre><code>class ExampleModel(Base):\n    __tablename__ = \"__sometable__\"\n\n    type_annotation_map = {uuid.UUID: CompatibleUUID}\n</code></pre> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\custom_types\\type_classes.py</code> <pre><code>class CompatibleUUID(TypeDecorator):\n    \"\"\"Define a custom UUID, overriding SQLAlchemy's UUId type.\n\n    The main purpose of this class is to instruct SQLAlchemy to\n    store UUIDs as a binary, instead of as a UUID type. This is\n    useful for cross-database support, i.e. for SQLite which does\n    not support the UUID type.\n\n    !!! note\n    - [SQLAlchemy docs: backend agnostic GUID type](https://docs.sqlalchemy.org/en/20/core/custom_types.html#backend-agnostic-guid-type)\n\n    Usage:\n\n    When defining a table model, after declaring `__tablename_`_, set the `type_annotation_map`, i.e.:\n\n    ``` py linenums=\"1\"\n    class ExampleModel(Base):\n        __tablename__ = \"__sometable__\"\n\n        type_annotation_map = {uuid.UUID: CompatibleUUID}\n    ```\n    \"\"\"\n\n    impl = sa.BINARY\n    cache_ok = True\n\n    def load_diaclect_impl(self, dialect):\n        if dialect.name == \"postgresql\":\n            return dialect.type_descriptor(UUID())\n        else:\n            return dialect.type_descriptor(CHAR(32))\n\n    def process_bind_param(self, value, dialect):\n        if value is None:\n            return value\n        elif dialect.name == \"postgresql\":\n            return str(value)\n        else:\n            if not isinstance(value, uuid.UUID):\n                return \"%.32x\" % uuid.UUID(value).int\n            else:\n                ## Return hexstring\n                return \"%.32x\" % value.int\n\n    def process_result_value(self, value: Any | None, dialect: Dialect) -&gt; Any | None:\n        if value is None:\n            return value\n        else:\n            if not isinstance(value, uuid.UUID):\n                value = uuid.UUID(value)\n            return value\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.DBSettings","title":"<code>DBSettings</code>  <code>dataclass</code>","text":"<p>Store configuration for a database.</p> <p>Parameters:</p> Name Type Description Default <code>drivername</code> <code>str</code> <p>The <code>sqlalchemy</code> driver name, i.e. <code>'sqlite+pysqlite'</code>.</p> <code>'sqlite+pysqlite'</code> <code>username</code> <code>str | None</code> <p>The database user's username.</p> <code>None</code> <code>password</code> <code>str | None</code> <p>The database user's password.</p> <code>None</code> <code>host</code> <code>str | None</code> <p>The database host address.</p> <code>None</code> <code>port</code> <code>str | int | None</code> <p>The database host's port.</p> <code>None</code> <code>database</code> <code>str</code> <p>The name of the database to connect to. For SQLite, use the path to the file, i.e. <code>db/app.sqlite</code>.</p> <code>'app.sqlite'</code> <code>echo</code> <code>bool</code> <p>If <code>True</code>, the SQLAlchemy <code>Engine</code> will echo SQL queries to the CLI, and will create tables that do not exist (if possible).</p> <code>False</code> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\db_config.py</code> <pre><code>@dataclass\nclass DBSettings:\n    \"\"\"Store configuration for a database.\n\n    Params:\n        drivername (str): The `sqlalchemy` driver name, i.e. `'sqlite+pysqlite'`.\n        username (str|None): The database user's username.\n        password (str|None): The database user's password.\n        host (str|None): The database host address.\n        port (str|int|None): The database host's port.\n        database (str): The name of the database to connect to. For SQLite, use the path to the file,\n            i.e. `db/app.sqlite`.\n        echo (bool): If `True`, the SQLAlchemy `Engine` will echo SQL queries to the CLI, and will create tables\n            that do not exist (if possible).\n\n    \"\"\"\n\n    drivername: str = field(default=\"sqlite+pysqlite\")\n    username: str | None = field(default=None)\n    password: str | None = field(default=None, repr=False)\n    host: str | None = field(default=None)\n    port: str | None = field(default=None)\n    database: str = field(default=\"app.sqlite\")\n    echo: bool = field(default=False)\n\n    def __post_init__(self):  # noqa: D105\n        assert self.drivername is not None, ValueError(\"drivername cannot be None\")\n        assert isinstance(self.drivername, str), TypeError(\n            f\"drivername must be of type str. Got type: ({type(self.drivername)})\"\n        )\n        assert isinstance(self.echo, bool), TypeError(\n            f\"echo must be a bool. Got type: ({type(self.echo)})\"\n        )\n        if self.username:\n            if self.username == \"\":\n                self.username = None\n            else:\n                assert isinstance(self.username, str), TypeError(\n                    f\"user must be of type str. Got type: ({type(self.username)})\"\n                )\n        if self.password:\n            if self.password == \"\":\n                self.password = None\n            else:\n                assert isinstance(self.password, str), TypeError(\n                    f\"password must be of type str. Got type: ({type(self.password)})\"\n                )\n        if self.host:\n            if self.host == \"\":\n                self.host = None\n            else:\n                assert isinstance(self.host, str), TypeError(\n                    f\"host must be of type str. Got type: ({type(self.host)})\"\n                )\n        if self.port:\n            if self.port == \"\":\n                self.port = None\n            else:\n                assert isinstance(self.port, int), TypeError(\n                    f\"port must be of type int. Got type: ({type(self.port)})\"\n                )\n                assert self.port &gt; 0 and self.port &lt;= 65535, ValueError(\n                    f\"port must be an integer between 1 and 65535\"\n                )\n        if self.database:\n            assert isinstance(self.database, Path) or isinstance(\n                self.database, str\n            ), TypeError(\n                f\"database must be of type str or Path. Got type: ({type(self.database)})\"\n            )\n            if isinstance(self.database, Path):\n                self.database: str = f\"{self.database}\"\n\n    def get_db_uri(self) -&gt; sa.URL:\n        \"\"\"Construct a SQLAlchemy `URL` from class params.\n\n        Returns:\n            (sqlalchemy.URL): An initialized database connection URL.\n\n        \"\"\"\n        try:\n            _uri: sa.URL = sa.URL.create(\n                drivername=self.drivername,\n                username=self.username,\n                password=self.password,\n                host=self.host,\n                port=self.port,\n                database=self.database,\n            )\n\n            return _uri\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception getting SQLAlchemy database URL. Details: {exc}\"\n            )\n            log.error(msg)\n            raise exc\n\n    def get_engine(self, echo_override: bool | None = None) -&gt; sa.Engine:\n        \"\"\"Build &amp; return a SQLAlchemy `Engine`.\n\n        Returns:\n            `sqlalchemy.Engine`: A SQLAlchemy `Engine` instance.\n\n        \"\"\"\n        assert self.get_db_uri() is not None, ValueError(\"db_uri is not None\")\n        assert isinstance(self.get_db_uri(), sa.URL), TypeError(\n            f\"db_uri must be of type sqlalchemy.URL. Got type: ({type(self.db_uri)})\"\n        )\n\n        if echo_override is not None:\n            _echo: bool = echo_override\n        else:\n            _echo: bool = self.echo\n\n        try:\n            engine: sa.Engine = sa.create_engine(\n                url=self.get_db_uri().render_as_string(hide_password=False),\n                echo=_echo,\n            )\n\n            return engine\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception getting database engine. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def get_session_pool(self) -&gt; so.sessionmaker[so.Session]:\n        \"\"\"Configure a session pool using class's SQLAlchemy `Engine`.\n\n        Returns:\n            (sqlalchemy.orm.sessionmaker): A SQLAlchemy `Session` pool for database connections.\n\n        \"\"\"\n        engine: sa.Engine = self.get_engine()\n        assert engine is not None, ValueError(\"engine cannot be None\")\n        assert isinstance(engine, sa.Engine), TypeError(\n            f\"engine must be of type sqlalchemy.Engine. Got type: ({type(engine)})\"\n        )\n\n        session_pool: so.sessionmaker[so.Session] = so.sessionmaker(bind=engine)\n\n        return session_pool\n\n    @contextmanager\n    def get_db(self) -&gt; t.Generator[so.Session, t.Any, None]:\n        \"\"\"Context manager class to handle a SQLAlchemy Session pool.\n\n        Usage:\n\n        ```py title=\"get_db() dependency usage\" linenums=\"1\"\n\n        ## Assumes `db_settings` is an initialized instance of `DBSettings`.\n        with db_settings.get_db() as session:\n            repo = someRepoClass(session)\n\n            all = repo.get_all()\n        ```\n        \"\"\"\n        db: so.Session = self.get_session_pool()\n\n        try:\n            yield db\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception yielding database session. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n        finally:\n            db.close()\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.DBSettings.get_db","title":"<code>get_db()</code>","text":"<p>Context manager class to handle a SQLAlchemy Session pool.</p> <p>Usage:</p> get_db() dependency usage<pre><code>## Assumes `db_settings` is an initialized instance of `DBSettings`.\nwith db_settings.get_db() as session:\n    repo = someRepoClass(session)\n\n    all = repo.get_all()\n</code></pre> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\db_config.py</code> <pre><code>@contextmanager\ndef get_db(self) -&gt; t.Generator[so.Session, t.Any, None]:\n    \"\"\"Context manager class to handle a SQLAlchemy Session pool.\n\n    Usage:\n\n    ```py title=\"get_db() dependency usage\" linenums=\"1\"\n\n    ## Assumes `db_settings` is an initialized instance of `DBSettings`.\n    with db_settings.get_db() as session:\n        repo = someRepoClass(session)\n\n        all = repo.get_all()\n    ```\n    \"\"\"\n    db: so.Session = self.get_session_pool()\n\n    try:\n        yield db\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception yielding database session. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n    finally:\n        db.close()\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.DBSettings.get_db_uri","title":"<code>get_db_uri()</code>","text":"<p>Construct a SQLAlchemy <code>URL</code> from class params.</p> <p>Returns:</p> Type Description <code>URL</code> <p>An initialized database connection URL.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\db_config.py</code> <pre><code>def get_db_uri(self) -&gt; sa.URL:\n    \"\"\"Construct a SQLAlchemy `URL` from class params.\n\n    Returns:\n        (sqlalchemy.URL): An initialized database connection URL.\n\n    \"\"\"\n    try:\n        _uri: sa.URL = sa.URL.create(\n            drivername=self.drivername,\n            username=self.username,\n            password=self.password,\n            host=self.host,\n            port=self.port,\n            database=self.database,\n        )\n\n        return _uri\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting SQLAlchemy database URL. Details: {exc}\"\n        )\n        log.error(msg)\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.DBSettings.get_engine","title":"<code>get_engine(echo_override=None)</code>","text":"<p>Build &amp; return a SQLAlchemy <code>Engine</code>.</p> <p>Returns:</p> Type Description <code>Engine</code> <p><code>sqlalchemy.Engine</code>: A SQLAlchemy <code>Engine</code> instance.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\db_config.py</code> <pre><code>def get_engine(self, echo_override: bool | None = None) -&gt; sa.Engine:\n    \"\"\"Build &amp; return a SQLAlchemy `Engine`.\n\n    Returns:\n        `sqlalchemy.Engine`: A SQLAlchemy `Engine` instance.\n\n    \"\"\"\n    assert self.get_db_uri() is not None, ValueError(\"db_uri is not None\")\n    assert isinstance(self.get_db_uri(), sa.URL), TypeError(\n        f\"db_uri must be of type sqlalchemy.URL. Got type: ({type(self.db_uri)})\"\n    )\n\n    if echo_override is not None:\n        _echo: bool = echo_override\n    else:\n        _echo: bool = self.echo\n\n    try:\n        engine: sa.Engine = sa.create_engine(\n            url=self.get_db_uri().render_as_string(hide_password=False),\n            echo=_echo,\n        )\n\n        return engine\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting database engine. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.DBSettings.get_session_pool","title":"<code>get_session_pool()</code>","text":"<p>Configure a session pool using class's SQLAlchemy <code>Engine</code>.</p> <p>Returns:</p> Type Description <code>sessionmaker</code> <p>A SQLAlchemy <code>Session</code> pool for database connections.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\db_config.py</code> <pre><code>def get_session_pool(self) -&gt; so.sessionmaker[so.Session]:\n    \"\"\"Configure a session pool using class's SQLAlchemy `Engine`.\n\n    Returns:\n        (sqlalchemy.orm.sessionmaker): A SQLAlchemy `Session` pool for database connections.\n\n    \"\"\"\n    engine: sa.Engine = self.get_engine()\n    assert engine is not None, ValueError(\"engine cannot be None\")\n    assert isinstance(engine, sa.Engine), TypeError(\n        f\"engine must be of type sqlalchemy.Engine. Got type: ({type(engine)})\"\n    )\n\n    session_pool: so.sessionmaker[so.Session] = so.sessionmaker(bind=engine)\n\n    return session_pool\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.MissingDependencyException","title":"<code>MissingDependencyException</code>  <code>dataclass</code>","text":"<p>               Bases: <code>CustomException</code></p> <p>Exception to raise when an import is called but a dependency is missing.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>A message to display with the exception.</p> <code>'Custom exception called'</code> <code>errors</code> <code>Any</code> <p>Property to store arbitrary data. Meant to be used for errors associated with the exception.</p> <code>None</code> <code>extra</code> <code>Any</code> <p>Property to store arbitrary data. Data stored in this property can be a Python object (i.e. a class instance, dict, str, or other), a list of objects/strings, etc.</p> <code>None</code> Usage <pre><code>try:\n    ...\nexcept CustomException as exc:\n    raise CustomException(msg=\"Custom exception occurred\", errors=exc)\n</code></pre> Source code in <code>src\\red_utils\\exc\\import_exc\\_import.py</code> <pre><code>@dataclass\nclass MissingDependencyException(CustomException):\n    \"\"\"Exception to raise when an import is called but a dependency is missing.\n\n    Params:\n        msg (str): A message to display with the exception.\n        errors (Any): Property to store arbitrary data. Meant to be used for errors associated with the exception.\n        extra (Any): Property to store arbitrary data.\n            Data stored in this property can be a Python object (i.e. a class\n            instance, dict, str, or other), a list of objects/strings, etc.\n\n    Usage:\n        ``` py\n        try:\n            ...\n        except CustomException as exc:\n            raise CustomException(msg=\"Custom exception occurred\", errors=exc)\n        ```\n    \"\"\"\n\n    errors: Any | None = field(default=None)\n    extra: Any | None = field(default=None)\n    missing_dependencies: list[str] | None = field(default_factory=list())\n\n    def __repr__(self):\n        repr_str: str = f\"{self.msg!r}\"\n\n        if self.errors is not None:\n            repr_str: str = f\"{repr_str}\\nErrors: {self.errors!r}\"\n        if self.extra is not None:\n            repr_str: str = f\"{repr_str}\\nExtra: {self.extra!r}\"\n\n        return repr_str\n\n    def __str__(self):\n        return repr(self)\n\n    @property\n    def exc_msg(self):\n        msg = CustomModuleNotFoundError(\n            msg=self.msg, missing_dependencies=self.missing_dependencies\n        )\n\n        return msg\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.RepositoryBase","title":"<code>RepositoryBase</code>","text":"<p>               Bases: <code>Generic[T]</code></p> <p>A generic SQLAlchemy repository class base.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\repository\\_repository.py</code> <pre><code>class RepositoryBase(t.Generic[T], metaclass=abc.ABCMeta):\n    \"\"\"A generic SQLAlchemy repository class base.\"\"\"\n\n    @abc.abstractmethod\n    def add(self, entity: T):\n        \"\"\"Add new entity to database.\"\"\"\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def update(self, entity: T):\n        \"\"\"Update existing entity.\"\"\"\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def remove(self, entity: T):\n        \"\"\"Remove existing entity from database.\"\"\"\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def get_by_id(self, entity_id) -&gt; T:\n        \"\"\"Retrieve entity from database by its ID.\"\"\"\n        raise NotImplementedError()\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.RepositoryBase.add","title":"<code>add(entity)</code>  <code>abstractmethod</code>","text":"<p>Add new entity to database.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\repository\\_repository.py</code> <pre><code>@abc.abstractmethod\ndef add(self, entity: T):\n    \"\"\"Add new entity to database.\"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.RepositoryBase.get_by_id","title":"<code>get_by_id(entity_id)</code>  <code>abstractmethod</code>","text":"<p>Retrieve entity from database by its ID.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\repository\\_repository.py</code> <pre><code>@abc.abstractmethod\ndef get_by_id(self, entity_id) -&gt; T:\n    \"\"\"Retrieve entity from database by its ID.\"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.RepositoryBase.remove","title":"<code>remove(entity)</code>  <code>abstractmethod</code>","text":"<p>Remove existing entity from database.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\repository\\_repository.py</code> <pre><code>@abc.abstractmethod\ndef remove(self, entity: T):\n    \"\"\"Remove existing entity from database.\"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.RepositoryBase.update","title":"<code>update(entity)</code>  <code>abstractmethod</code>","text":"<p>Update existing entity.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\repository\\_repository.py</code> <pre><code>@abc.abstractmethod\ndef update(self, entity: T):\n    \"\"\"Update existing entity.\"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.TableNameMixin","title":"<code>TableNameMixin</code>","text":"<p>Mixin to automatically name tables based on class name.</p> <p>Generates a <code>__tablename__</code> for classes inheriting from this mixin.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\mixins\\table_mixins.py</code> <pre><code>class TableNameMixin:\n    \"\"\"Mixin to automatically name tables based on class name.\n\n    Generates a `__tablename__` for classes inheriting from this mixin.\n    \"\"\"\n\n    @so.declared_attr.directive\n    def __tablename__(cls) -&gt; str:  # noqa: D105\n        return cls.__name__.lower() + \"s\"\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.TimestampMixin","title":"<code>TimestampMixin</code>","text":"<p>Add a created_at &amp; updated_at column to records.</p> <p>Add to class declaration to automatically create these columns on records.</p> <p>Usage:</p> <p>``` py linenums=1 class Record(Base, TimestampMixin):     tablename = ...</p> <pre><code>...\n</code></pre> <p>```</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\mixins\\table_mixins.py</code> <pre><code>class TimestampMixin:\n    \"\"\"Add a created_at &amp; updated_at column to records.\n\n    Add to class declaration to automatically create these columns on\n    records.\n\n    Usage:\n\n    ``` py linenums=1\n    class Record(Base, TimestampMixin):\n        __tablename__ = ...\n\n        ...\n    ```\n    \"\"\"\n\n    created_at: so.Mapped[datetime] = so.mapped_column(\n        sa.TIMESTAMP, server_default=sa.func.now()\n    )\n    updated_at: so.Mapped[datetime] = so.mapped_column(\n        sa.TIMESTAMP, server_default=sa.func.now(), onupdate=sa.func.now()\n    )\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.saConnectionGeneric","title":"<code>saConnectionGeneric</code>  <code>dataclass</code>","text":"<p>               Bases: <code>saConnectionBase</code></p> <p>Generic SQLAlchemy connection class.</p> <p>Inherits settings &amp; properties from the base class, and can be extended if none of the other saConnection* models meet needs.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\connection_models.py</code> <pre><code>class saConnectionGeneric(saConnectionBase):\n    \"\"\"Generic SQLAlchemy connection class.\n\n    Inherits settings &amp; properties from the base class, and can be\n    extended if none of the other saConnection* models meet needs.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.saMSSQLConnection","title":"<code>saMSSQLConnection</code>  <code>dataclass</code>","text":"<p>               Bases: <code>saConnectionBase</code></p> <p>Default Microsoft SQL Server connection.</p> <p>Parameters:</p> Name Type Description Default <code>drivername</code> <code>str</code> <p>The SQLAlchemy drivername string</p> <code>'mssql+pyodbc'</code> <code>host</code> <code>str</code> <p>The PostgreSQL database server address/hostname</p> <code>'127.0.0.1'</code> <code>port</code> <code>int</code> <p>The PostgreSQL database connection port</p> <code>1433</code> <code>username</code> <code>str</code> <p>The PostgreSQL user to authenticate as</p> <code>'SA'</code> <code>password</code> <code>str</code> <p>The PostgreSQL password associated with <code>username</code> to authenticate with</p> <code>'1Secure*Password1'</code> <code>database</code> <code>str</code> <p>The name of the database to connect to</p> <code>'master'</code> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\connection_models.py</code> <pre><code>@dataclass\nclass saMSSQLConnection(saConnectionBase):\n    \"\"\"Default Microsoft SQL Server connection.\n\n    Params:\n        drivername (str): The SQLAlchemy drivername string\n        host (str): The PostgreSQL database server address/hostname\n        port (int): The PostgreSQL database connection port\n        username (str): The PostgreSQL user to authenticate as\n        password (str): The PostgreSQL password associated with `username` to authenticate with\n        database (str): The name of the database to connect to\n    \"\"\"\n\n    drivername: str = field(default=\"mssql+pyodbc\")\n    host: str = field(default=\"127.0.0.1\")\n    # instance: str = field(default=\"\\\\SQLEXPRESS\")\n    port: int = field(default=1433)\n    username: str = field(default=\"SA\")\n    ## Hide password from __repr__\n    password: str = field(default=\"1Secure*Password1\", repr=False)\n    database: str = field(default=\"master\")\n\n    @property\n    def connection_string(self) -&gt; sa.engine.url.URL:\n        \"\"\"Return a formatted SQLAlchemy `Engine` connection URI string.\"\"\"\n        _string: sa.engine.url.URL = sa.engine.url.URL.create(\n            drivername=self.drivername,\n            host=self.host,\n            username=self.username,\n            password=self.password,\n            port=self.port,\n            database=self.database,\n            query=dict(driver=\"ODBC Driver 17 for SQL Server\"),\n        )\n\n        return _string\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.saMSSQLConnection.connection_string","title":"<code>connection_string: sa.engine.url.URL</code>  <code>property</code>","text":"<p>Return a formatted SQLAlchemy <code>Engine</code> connection URI string.</p>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.saPGConnection","title":"<code>saPGConnection</code>  <code>dataclass</code>","text":"<p>               Bases: <code>saConnectionBase</code></p> <p>Default Postgres connection. Useful for local testing.</p> <p>For Postgres databases, the database you specify must exist before creating the initial connection/engine.</p> <p>Parameters:</p> Name Type Description Default <code>drivername</code> <code>str</code> <p>The SQLAlchemy drivername string</p> <code>'postgresql+psycopg2'</code> <code>host</code> <code>str</code> <p>The PostgreSQL database server address/hostname</p> <code>'127.0.0.1'</code> <code>port</code> <code>int</code> <p>The PostgreSQL database connection port</p> <code>5432</code> <code>username</code> <code>str</code> <p>The PostgreSQL user to authenticate as</p> <code>'postgres'</code> <code>password</code> <code>str</code> <p>The PostgreSQL password associated with <code>username</code> to authenticate with</p> <code>'postgres'</code> <code>database</code> <code>str</code> <p>The name of the database to connect to</p> <code>'postgres'</code> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\connection_models.py</code> <pre><code>@dataclass\nclass saPGConnection(saConnectionBase):\n    \"\"\"Default Postgres connection. Useful for local testing.\n\n    For Postgres databases, the database you specify must exist before\n    creating the initial connection/engine.\n\n    Params:\n        drivername (str): The SQLAlchemy drivername string\n        host (str): The PostgreSQL database server address/hostname\n        port (int): The PostgreSQL database connection port\n        username (str): The PostgreSQL user to authenticate as\n        password (str): The PostgreSQL password associated with `username` to authenticate with\n        database (str): The name of the database to connect to\n    \"\"\"\n\n    drivername: str = field(default=\"postgresql+psycopg2\")\n    host: str = field(default=\"127.0.0.1\")\n    port: int = field(default=5432)\n    username: str = field(default=\"postgres\")\n    ## Hide password from __repr__\n    password: str = field(default=\"postgres\", repr=False)\n    database: str = field(default=\"postgres\")\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.saSQLiteConnection","title":"<code>saSQLiteConnection</code>  <code>dataclass</code>","text":"<p>               Bases: <code>saConnectionBase</code></p> <p>Default SQLite connection. Useful for local testing.</p> <p>Parameters:</p> Name Type Description Default <code>drivername</code> <code>str</code> <p>The SQLAlchemy driver string for the database</p> <code>'sqlite+pysqlite'</code> <code>database</code> <code>str</code> <p>The name/path to the SQLite database. It is recommended to use .sqlite for the file extension, although .db or any other should work fine as well.</p> <code>'.db/default_unnamed.sqlite'</code> <p>Pass a value for <code>database</code> to change the name of the SQLite database file. If you use a path (i.e. <code>db/test.sqlite</code>), you need to create the Path manually.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\connection_models.py</code> <pre><code>@dataclass\nclass saSQLiteConnection(saConnectionBase):\n    \"\"\"Default SQLite connection. Useful for local testing.\n\n    Params:\n        drivername (str): The SQLAlchemy driver string for the database\n        database (str): The name/path to the SQLite database.\n            It is recommended to use .sqlite for the file extension,\n            although .db or any other should work fine as well.\n\n    Pass a value for `database` to change the name of the SQLite database file.\n    If you use a path (i.e. `db/test.sqlite`), you need to create the Path\n    manually.\n    \"\"\"\n\n    drivername: str = field(default=\"sqlite+pysqlite\")\n    database: str = field(default=\".db/default_unnamed.sqlite\")\n\n    def ensure_path(self) -&gt; None:\n        \"\"\"Ensure path to self.database exists.\n\n        Use `Path()` to split the directory path\n        from the filename, and ensure directores in path\n        exist.\n        \"\"\"\n        ## Get absolute path to immediate parent directory without filename.\n        _path = Path(self.database).parent.absolute()\n\n        ## Create directories along path if they do not exist\n        if not _path.exists():\n            try:\n                _path.mkdir(parents=True, exist_ok=True)\n            except PermissionError as perm_exc:\n                msg = Exception(\n                    f\"Permission error trying to open {str(_path)}. Details: {perm_exc}\"\n                )\n                log.error(msg)\n\n                raise exc\n            except Exception as exc:\n                msg = Exception(\n                    f\"Unhandled exception creating directories in path: {str(_path)}. Details: {exc}\"\n                )\n                log.error(msg)\n\n                raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.saSQLiteConnection.ensure_path","title":"<code>ensure_path()</code>","text":"<p>Ensure path to self.database exists.</p> <p>Use <code>Path()</code> to split the directory path from the filename, and ensure directores in path exist.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\connection_models.py</code> <pre><code>def ensure_path(self) -&gt; None:\n    \"\"\"Ensure path to self.database exists.\n\n    Use `Path()` to split the directory path\n    from the filename, and ensure directores in path\n    exist.\n    \"\"\"\n    ## Get absolute path to immediate parent directory without filename.\n    _path = Path(self.database).parent.absolute()\n\n    ## Create directories along path if they do not exist\n    if not _path.exists():\n        try:\n            _path.mkdir(parents=True, exist_ok=True)\n        except PermissionError as perm_exc:\n            msg = Exception(\n                f\"Permission error trying to open {str(_path)}. Details: {perm_exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception creating directories in path: {str(_path)}. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.create_base_metadata","title":"<code>create_base_metadata(base_obj=None, engine=None)</code>","text":"<p>Create <code>Base</code> object's metadata.</p> Description <p>Import this function early in your app/script (i.e. <code>main.py</code>) and run as soon as possible, i.e. after imports.</p> <p>This function accepts a SQLAlchemy <code>DeclarativeBase</code> object, and creates the table metadata from that object using the <code>Engine</code> passed.</p> <p>This function will only ever return <code>True</code> if successful. It does not return <code>False</code>, as an <code>Exception</code> is raised if metadata creation fails and the program is halted.</p> <p>Parameters:</p> Name Type Description Default <code>base_obj</code> <code>DeclarativeBase</code> <p>A SQLAlchemy <code>DeclarativeBase</code> object to extract metadata from</p> <code>None</code> <code>engine</code> <code>Engine</code> <p>The <code>Engine</code> to use for the database connection.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if creating <code>Base</code> metadata is successful</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When input values are invalid</p> <code>OperationalError</code> <p>When SQLAlchemy runs into an error with the database, usually starting on the database (not in SQLAlchemy)</p> <code>DBAPIERROR</code> <p>When SQLAlchemy runs into an issue, generally in the way you've coded a SQLAlchemy statement or operation</p> <code>Exception</code> <p>When an uncaught/unhandled exception occurs</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\utils.py</code> <pre><code>def create_base_metadata(\n    base_obj: so.DeclarativeBase = None, engine: sa.Engine = None\n) -&gt; bool:\n    \"\"\"Create `Base` object's metadata.\n\n    Description:\n        Import this function early in your app/script (i.e. `main.py`) and run as soon as\n        possible, i.e. after imports.\n\n        This function accepts a SQLAlchemy `DeclarativeBase` object, and creates the table\n        metadata from that object using the `Engine` passed.\n\n        This function will only ever return `True` if successful. It does not return `False`,\n        as an `Exception` is raised if metadata creation fails and the program is halted.\n\n    Params:\n        base_obj (sqlalchemy.DeclarativeBase): A SQLAlchemy `DeclarativeBase` object to extract metadata from\n        engine (sqlalchemy.Engine): The `Engine` to use for the database connection.\n\n    Returns:\n        (bool): `True` if creating `Base` metadata is successful\n\n    Raises:\n        ValueError: When input values are invalid\n        OperationalError: When SQLAlchemy runs into an error with the database, usually starting\n            on the database (not in SQLAlchemy)\n        DBAPIERROR: When SQLAlchemy runs into an issue, generally in the way you've coded a SQLAlchemy\n            statement or operation\n        Exception: When an uncaught/unhandled exception occurs\n\n    \"\"\"\n    try:\n        base_obj.metadata.create_all(bind=engine)\n\n        return True\n    except OperationalError as op_exc:\n        raise op_exc\n    except DBAPIError as dbapi_exc:\n        raise dbapi_exc\n    except Exception as exc:\n        raise Exception(f\"Unhandled exception creating Base metadata. Details: {exc}\")\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.debug_metadata_obj","title":"<code>debug_metadata_obj(metadata_obj=None)</code>","text":"<p>Debug-print a SQLAlchemy MetaData object.</p> <p>Loop over tables and print names.</p> <p>Parameters:</p> Name Type Description Default <code>metadata_obj</code> <code>MetaData</code> <p>A SQLAlchemy <code>MetaData</code> object to debug</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\utils.py</code> <pre><code>def debug_metadata_obj(metadata_obj: sa.MetaData = None) -&gt; None:\n    \"\"\"Debug-print a SQLAlchemy MetaData object.\n\n    Loop over tables and print names.\n\n    Params:\n        metadata_obj (sqlalchemy.MetaData): A SQLAlchemy `MetaData` object to debug\n    \"\"\"\n    if not metadata_obj:\n        raise ValueError(\"Missing a SQLAlchemy metadata object.\")\n\n    if not isinstance(metadata_obj, sa.MetaData):\n        raise ValueError(\n            f\"Expected a MetaData obj, not object of type '{type(metadata_obj).__name__}'\"\n        )\n\n    for _table in metadata_obj.sorted_tables:\n        print(f\"Table name: {_table.name}\")\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.generate_metadata","title":"<code>generate_metadata(metadata_obj=None, engine=None)</code>","text":"<p>Create SQLAlchemy table metadata.</p> <p>Accept a SQLalchemy MetaData object, run .create_all(engine) to create table metadata.</p> <p>Parameters:</p> Name Type Description Default <code>metadata_obj</code> <code>MetaData</code> <p>A SQLAlchemy <code>MetaData</code> object to use for generating in the database</p> <code>None</code> <code>engine</code> <code>Engine</code> <p>The SQLAlchemy <code>Engine</code> to use for the database connection</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>When input values are invalid</p> <code>OperationalError</code> <p>When SQLAlchemy runs into an error with the database, usually starting on the database (not in SQLAlchemy)</p> <code>DBAPIERROR</code> <p>When SQLAlchemy runs into an issue, generally in the way you've coded a SQLAlchemy statement or operation</p> <code>Exception</code> <p>When an uncaught/unhandled exception occurs</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\utils.py</code> <pre><code>def generate_metadata(\n    metadata_obj: sa.MetaData = None, engine: sa.Engine = None\n) -&gt; None:\n    \"\"\"Create SQLAlchemy table metadata.\n\n    Accept a SQLalchemy MetaData object, run .create_all(engine) to create\n    table metadata.\n\n    Params:\n        metadata_obj (sqlalchemy.MetaData): A SQLAlchemy `MetaData` object to use for generating in the database\n        engine (sqlalchemy.Engine): The SQLAlchemy `Engine` to use for the database connection\n\n    Raises:\n        ValueError: When input values are invalid\n        OperationalError: When SQLAlchemy runs into an error with the database, usually starting\n            on the database (not in SQLAlchemy)\n        DBAPIERROR: When SQLAlchemy runs into an issue, generally in the way you've coded a SQLAlchemy\n            statement or operation\n        Exception: When an uncaught/unhandled exception occurs\n\n    \"\"\"\n    if not metadata_obj:\n        raise ValueError(\"Missing a SQLAlchemy MetaData object.\")\n\n    if not isinstance(metadata_obj, sa.MetaData):\n        raise ValueError(\n            f\"Expected a MetaData obj, not object of type '{type(metadata_obj).__name__}'\"\n        )\n\n    if not engine:\n        raise ValueError(\"Missing a SQLAlchemy engine object.\")\n\n    if not isinstance(engine, sa.Engine):\n        raise ValueError(\n            f\"Expected a SQLAlchemy engine obj, not object of type '{type(engine).__name__}\"\n        )\n\n    try:\n        metadata_obj.create_all(engine)\n\n        return True\n    except OperationalError as op_exc:\n        raise op_exc\n    except DBAPIError as dbapi_exc:\n        raise dbapi_exc\n    except Exception as exc:\n        raise Exception(f\"Unhandled exception creating Base metadata. Details: {exc}\")\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.get_db","title":"<code>get_db(db_settings=None)</code>","text":"<p>Dependency to yield a SQLAlchemy Session pool.</p> <p>Usage:</p> get_db() dependency usage<pre><code>from core.dependencies import get_db\n\nwith get_db() as session:\n    repo = someRepoClass(session)\n\n    all = repo.get_all()\n</code></pre> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\_depends.py</code> <pre><code>@contextmanager\ndef get_db(db_settings: DBSettings = None) -&gt; t.Generator[so.Session, t.Any, None]:\n    \"\"\"Dependency to yield a SQLAlchemy Session pool.\n\n    Usage:\n\n    ```py title=\"get_db() dependency usage\" linenums=\"1\"\n\n    from core.dependencies import get_db\n\n    with get_db() as session:\n        repo = someRepoClass(session)\n\n        all = repo.get_all()\n    ```\n    \"\"\"\n    assert db_settings, ValueError(\"Missing DBSettings object.\")\n\n    SESSION_POOL: so.sessionmaker[so.Session] = db_settings.get_session_pool()\n\n    db: so.Session = SESSION_POOL()\n\n    try:\n        yield db\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception yielding database session. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n    finally:\n        db.close()\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.get_engine","title":"<code>get_engine(connection=None, db_type='sqlite', echo=False, pool_pre_ping=False)</code>","text":"<p>Return a SQLAlchemy Engine object.</p> <p>SQLAlchemy docs: Engine</p> <p>To use a database other than SQLite, i.e. Postgres or MySQL, pass the lowercase string name of the database.</p> Currently supported databases <ul> <li>[x] SQLite</li> <li>[x] Postgres</li> <li>[ ] MySQL</li> <li>[x] MSSQL</li> <li>[ ] Azure Cosmos</li> </ul> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>(saSQLiteConnection, saPGConnection)</code> <p>Instantiated instance of a custom database connection class</p> <code>None</code> <code>db_type</code> <code>str</code> <p>The string name (lowercase) of a database type</p> <code>'sqlite'</code> <code>echo</code> <code>bool</code> <p>If <code>True</code>, the SQL the <code>Engine</code> runs will be echoed to the CLI</p> <code>False</code> <code>pool_pre_ping</code> <code>bool</code> <p>Test connection pool before starting operations</p> <code>False</code> <p>Returns:</p> Type Description <code>Engine</code> <p>An initialized SQLAlchemy <code>Engine</code> object</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\utils.py</code> <pre><code>def get_engine(\n    connection: Union[saSQLiteConnection, saPGConnection, str] = None,\n    db_type: str = \"sqlite\",\n    echo: bool = False,\n    pool_pre_ping: bool = False,\n) -&gt; sa.Engine:\n    \"\"\"Return a SQLAlchemy Engine object.\n\n    [SQLAlchemy docs: Engine](https://docs.sqlalchemy.org/en/20/tutorial/engine.html)\n\n    To use a database other than SQLite, i.e. Postgres or MySQL, pass\n    the lowercase string name of the database.\n\n    Currently supported databases:\n        - [x] SQLite\n        - [x] Postgres\n        - [ ] MySQL\n        - [x] MSSQL\n        - [ ] Azure Cosmos\n\n    Params:\n        connection (saSQLiteConnection, saPGConnection): Instantiated instance of a custom database connection class\n        db_type (str): The string name (lowercase) of a database type\n        echo (bool): If `True`, the SQL the `Engine` runs will be echoed to the CLI\n        pool_pre_ping (bool): Test connection pool before starting operations\n\n    Returns:\n        (sqlalchemy.Engine): An initialized SQLAlchemy `Engine` object\n\n    \"\"\"\n    if not connection:\n        raise ValueError(\"Missing connection object/string.\")\n\n    if isinstance(connection, str):\n        if db_type == \"sqlite\":\n            connection: saSQLiteConnection = saSQLiteConnection(database=connection)\n\n    ## Validate db_type input\n    if db_type:\n        _valid: bool = validate_db_type(db_type)\n\n        if not _valid:\n            raise ValueError(\n                f\"Invalid db_type: {db_type}. Must be one of: {valid_db_types}\"\n            )\n\n    else:\n        ## Default to sqlite if no db_type is passed\n        db_type = \"sqlite\"\n\n    if db_type == \"sqlite\":\n        ## Ensure path to database file exists\n        connection.ensure_path()\n\n    if db_type == \"postgres\":\n        pass\n\n    if db_type == \"mssql\":\n        pass\n\n    try:\n        engine = sa.create_engine(\n            connection.connection_string, echo=echo, pool_pre_ping=pool_pre_ping\n        )\n\n        return engine\n\n    except OperationalError as op_exc:\n        raise OperationalError(\n            f\"SQLAlchemy OperationalError exception occurred connecting to database {connection.database}. Details: {op_exc}\"\n        )\n\n    except Exception as exc:\n        raise Exception(f\"Unhandled exception creating database engine. Details: {exc}\")\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.get_session_pool","title":"<code>get_session_pool(engine=None, autoflush=False, expire_on_commit=False, class_=so.Session)</code>","text":"<p>Define a factory for creating SQLAlchemy sessions.</p> <p>Returns a <code>sqlalchemy.orm.sessionmaker</code> <code>Session</code> instance. Import this function in scripts that interact with the database, and create a <code>SessionLocal</code> object with <code>SessionLocal = get_session(**args)</code></p> <p>Parameters:</p> Name Type Description Default <code>engine</code> <code>Engine</code> <p>A SQLAlchemy <code>Engine</code> object to use for connections</p> <code>None</code> <code>autoflush</code> <code>bool</code> <p>Automatically run <code>flush</code> operation on commits</p> <code>False</code> <code>expire_on_commit</code> <code>bool</code> <p>If <code>True</code>, connection expires once it's closed</p> <code>False</code> <code>class_</code> <p>You can specify a class which should be returned instead of <code>sqlalchemy.orm.Session</code>. SQLAlchemy: sessionmaker class_ docs</p> <code>Session</code> <p>Returns:</p> Type Description <code>sessionmaker[Session]</code> <p>An initialized <code>Session</code> instance</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\utils.py</code> <pre><code>def get_session_pool(\n    engine: sa.Engine = None,\n    autoflush: bool = False,\n    expire_on_commit: bool = False,\n    class_=so.Session,\n) -&gt; so.sessionmaker[so.Session]:\n    \"\"\"Define a factory for creating SQLAlchemy sessions.\n\n    Returns a `sqlalchemy.orm.sessionmaker` `Session` instance. Import this\n    function in scripts that interact with the database, and create a\n    `SessionLocal` object with `SessionLocal = get_session(**args)`\n\n    Params:\n        engine (sqlalchemy.Engine): A SQLAlchemy `Engine` object to use for connections\n        autoflush (bool): Automatically run `flush` operation on commits\n        expire_on_commit (bool): If `True`, connection expires once it's closed\n        class_: You can specify a class which should be returned instead of `sqlalchemy.orm.Session`.\n            [SQLAlchemy: sessionmaker class_ docs](https://docs.sqlalchemy.org/en/20/orm/session_api.html#sqlalchemy.orm.Session.params.class_)\n\n    Returns:\n        (sessionmaker[Session]): An initialized `Session` instance\n\n    \"\"\"\n    try:\n        session_pool: so.sessionmaker[so.Session] = so.sessionmaker(\n            bind=engine,\n            autoflush=autoflush,\n            expire_on_commit=expire_on_commit,\n            class_=class_,\n        )\n\n        return session_pool\n\n    except Exception as exc:\n        raise Exception(\n            f\"Unhandled exception creating a sessionmaker Session. Details: {exc}\"\n        )\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/__init__/#red_utils.ext.sqlalchemy_utils.validate_db_type","title":"<code>validate_db_type(in_str=None)</code>","text":"<p>Validate <code>db_type</code> string in functions that utilize <code>db_type</code>.</p> <p>Parameters:</p> Name Type Description Default <code>in_str</code> <code>str</code> <p>A <code>db_type</code> string to validate</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>in_str</code> is valid</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the <code>in_str</code> is not valid</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\utils.py</code> <pre><code>def validate_db_type(in_str: str = None) -&gt; bool:\n    \"\"\"Validate `db_type` string in functions that utilize `db_type`.\n\n    Params:\n        in_str (str): A `db_type` string to validate\n\n    Returns:\n        (bool): `True` if `in_str` is valid\n\n    Raises:\n        ValueError: If the `in_str` is not valid\n\n    \"\"\"\n    if not in_str:\n        raise ValueError(\"Missing input string to validate\")\n\n    if in_str not in valid_db_types:\n        return False\n\n    return True\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/_depends/","title":"_depends","text":"<p>Dependencies for database.</p> <p>Includes functions like <code>get_db()</code>, which is a context manager that yields a database session.</p>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/_depends/#red_utils.ext.sqlalchemy_utils._depends.DBSettings","title":"<code>DBSettings</code>  <code>dataclass</code>","text":"<p>Store configuration for a database.</p> <p>Parameters:</p> Name Type Description Default <code>drivername</code> <code>str</code> <p>The <code>sqlalchemy</code> driver name, i.e. <code>'sqlite+pysqlite'</code>.</p> <code>'sqlite+pysqlite'</code> <code>username</code> <code>str | None</code> <p>The database user's username.</p> <code>None</code> <code>password</code> <code>str | None</code> <p>The database user's password.</p> <code>None</code> <code>host</code> <code>str | None</code> <p>The database host address.</p> <code>None</code> <code>port</code> <code>str | int | None</code> <p>The database host's port.</p> <code>None</code> <code>database</code> <code>str</code> <p>The name of the database to connect to. For SQLite, use the path to the file, i.e. <code>db/app.sqlite</code>.</p> <code>'app.sqlite'</code> <code>echo</code> <code>bool</code> <p>If <code>True</code>, the SQLAlchemy <code>Engine</code> will echo SQL queries to the CLI, and will create tables that do not exist (if possible).</p> <code>False</code> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\db_config.py</code> <pre><code>@dataclass\nclass DBSettings:\n    \"\"\"Store configuration for a database.\n\n    Params:\n        drivername (str): The `sqlalchemy` driver name, i.e. `'sqlite+pysqlite'`.\n        username (str|None): The database user's username.\n        password (str|None): The database user's password.\n        host (str|None): The database host address.\n        port (str|int|None): The database host's port.\n        database (str): The name of the database to connect to. For SQLite, use the path to the file,\n            i.e. `db/app.sqlite`.\n        echo (bool): If `True`, the SQLAlchemy `Engine` will echo SQL queries to the CLI, and will create tables\n            that do not exist (if possible).\n\n    \"\"\"\n\n    drivername: str = field(default=\"sqlite+pysqlite\")\n    username: str | None = field(default=None)\n    password: str | None = field(default=None, repr=False)\n    host: str | None = field(default=None)\n    port: str | None = field(default=None)\n    database: str = field(default=\"app.sqlite\")\n    echo: bool = field(default=False)\n\n    def __post_init__(self):  # noqa: D105\n        assert self.drivername is not None, ValueError(\"drivername cannot be None\")\n        assert isinstance(self.drivername, str), TypeError(\n            f\"drivername must be of type str. Got type: ({type(self.drivername)})\"\n        )\n        assert isinstance(self.echo, bool), TypeError(\n            f\"echo must be a bool. Got type: ({type(self.echo)})\"\n        )\n        if self.username:\n            if self.username == \"\":\n                self.username = None\n            else:\n                assert isinstance(self.username, str), TypeError(\n                    f\"user must be of type str. Got type: ({type(self.username)})\"\n                )\n        if self.password:\n            if self.password == \"\":\n                self.password = None\n            else:\n                assert isinstance(self.password, str), TypeError(\n                    f\"password must be of type str. Got type: ({type(self.password)})\"\n                )\n        if self.host:\n            if self.host == \"\":\n                self.host = None\n            else:\n                assert isinstance(self.host, str), TypeError(\n                    f\"host must be of type str. Got type: ({type(self.host)})\"\n                )\n        if self.port:\n            if self.port == \"\":\n                self.port = None\n            else:\n                assert isinstance(self.port, int), TypeError(\n                    f\"port must be of type int. Got type: ({type(self.port)})\"\n                )\n                assert self.port &gt; 0 and self.port &lt;= 65535, ValueError(\n                    f\"port must be an integer between 1 and 65535\"\n                )\n        if self.database:\n            assert isinstance(self.database, Path) or isinstance(\n                self.database, str\n            ), TypeError(\n                f\"database must be of type str or Path. Got type: ({type(self.database)})\"\n            )\n            if isinstance(self.database, Path):\n                self.database: str = f\"{self.database}\"\n\n    def get_db_uri(self) -&gt; sa.URL:\n        \"\"\"Construct a SQLAlchemy `URL` from class params.\n\n        Returns:\n            (sqlalchemy.URL): An initialized database connection URL.\n\n        \"\"\"\n        try:\n            _uri: sa.URL = sa.URL.create(\n                drivername=self.drivername,\n                username=self.username,\n                password=self.password,\n                host=self.host,\n                port=self.port,\n                database=self.database,\n            )\n\n            return _uri\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception getting SQLAlchemy database URL. Details: {exc}\"\n            )\n            log.error(msg)\n            raise exc\n\n    def get_engine(self, echo_override: bool | None = None) -&gt; sa.Engine:\n        \"\"\"Build &amp; return a SQLAlchemy `Engine`.\n\n        Returns:\n            `sqlalchemy.Engine`: A SQLAlchemy `Engine` instance.\n\n        \"\"\"\n        assert self.get_db_uri() is not None, ValueError(\"db_uri is not None\")\n        assert isinstance(self.get_db_uri(), sa.URL), TypeError(\n            f\"db_uri must be of type sqlalchemy.URL. Got type: ({type(self.db_uri)})\"\n        )\n\n        if echo_override is not None:\n            _echo: bool = echo_override\n        else:\n            _echo: bool = self.echo\n\n        try:\n            engine: sa.Engine = sa.create_engine(\n                url=self.get_db_uri().render_as_string(hide_password=False),\n                echo=_echo,\n            )\n\n            return engine\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception getting database engine. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def get_session_pool(self) -&gt; so.sessionmaker[so.Session]:\n        \"\"\"Configure a session pool using class's SQLAlchemy `Engine`.\n\n        Returns:\n            (sqlalchemy.orm.sessionmaker): A SQLAlchemy `Session` pool for database connections.\n\n        \"\"\"\n        engine: sa.Engine = self.get_engine()\n        assert engine is not None, ValueError(\"engine cannot be None\")\n        assert isinstance(engine, sa.Engine), TypeError(\n            f\"engine must be of type sqlalchemy.Engine. Got type: ({type(engine)})\"\n        )\n\n        session_pool: so.sessionmaker[so.Session] = so.sessionmaker(bind=engine)\n\n        return session_pool\n\n    @contextmanager\n    def get_db(self) -&gt; t.Generator[so.Session, t.Any, None]:\n        \"\"\"Context manager class to handle a SQLAlchemy Session pool.\n\n        Usage:\n\n        ```py title=\"get_db() dependency usage\" linenums=\"1\"\n\n        ## Assumes `db_settings` is an initialized instance of `DBSettings`.\n        with db_settings.get_db() as session:\n            repo = someRepoClass(session)\n\n            all = repo.get_all()\n        ```\n        \"\"\"\n        db: so.Session = self.get_session_pool()\n\n        try:\n            yield db\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception yielding database session. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n        finally:\n            db.close()\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/_depends/#red_utils.ext.sqlalchemy_utils._depends.DBSettings.get_db","title":"<code>get_db()</code>","text":"<p>Context manager class to handle a SQLAlchemy Session pool.</p> <p>Usage:</p> get_db() dependency usage<pre><code>## Assumes `db_settings` is an initialized instance of `DBSettings`.\nwith db_settings.get_db() as session:\n    repo = someRepoClass(session)\n\n    all = repo.get_all()\n</code></pre> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\db_config.py</code> <pre><code>@contextmanager\ndef get_db(self) -&gt; t.Generator[so.Session, t.Any, None]:\n    \"\"\"Context manager class to handle a SQLAlchemy Session pool.\n\n    Usage:\n\n    ```py title=\"get_db() dependency usage\" linenums=\"1\"\n\n    ## Assumes `db_settings` is an initialized instance of `DBSettings`.\n    with db_settings.get_db() as session:\n        repo = someRepoClass(session)\n\n        all = repo.get_all()\n    ```\n    \"\"\"\n    db: so.Session = self.get_session_pool()\n\n    try:\n        yield db\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception yielding database session. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n    finally:\n        db.close()\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/_depends/#red_utils.ext.sqlalchemy_utils._depends.DBSettings.get_db_uri","title":"<code>get_db_uri()</code>","text":"<p>Construct a SQLAlchemy <code>URL</code> from class params.</p> <p>Returns:</p> Type Description <code>URL</code> <p>An initialized database connection URL.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\db_config.py</code> <pre><code>def get_db_uri(self) -&gt; sa.URL:\n    \"\"\"Construct a SQLAlchemy `URL` from class params.\n\n    Returns:\n        (sqlalchemy.URL): An initialized database connection URL.\n\n    \"\"\"\n    try:\n        _uri: sa.URL = sa.URL.create(\n            drivername=self.drivername,\n            username=self.username,\n            password=self.password,\n            host=self.host,\n            port=self.port,\n            database=self.database,\n        )\n\n        return _uri\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting SQLAlchemy database URL. Details: {exc}\"\n        )\n        log.error(msg)\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/_depends/#red_utils.ext.sqlalchemy_utils._depends.DBSettings.get_engine","title":"<code>get_engine(echo_override=None)</code>","text":"<p>Build &amp; return a SQLAlchemy <code>Engine</code>.</p> <p>Returns:</p> Type Description <code>Engine</code> <p><code>sqlalchemy.Engine</code>: A SQLAlchemy <code>Engine</code> instance.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\db_config.py</code> <pre><code>def get_engine(self, echo_override: bool | None = None) -&gt; sa.Engine:\n    \"\"\"Build &amp; return a SQLAlchemy `Engine`.\n\n    Returns:\n        `sqlalchemy.Engine`: A SQLAlchemy `Engine` instance.\n\n    \"\"\"\n    assert self.get_db_uri() is not None, ValueError(\"db_uri is not None\")\n    assert isinstance(self.get_db_uri(), sa.URL), TypeError(\n        f\"db_uri must be of type sqlalchemy.URL. Got type: ({type(self.db_uri)})\"\n    )\n\n    if echo_override is not None:\n        _echo: bool = echo_override\n    else:\n        _echo: bool = self.echo\n\n    try:\n        engine: sa.Engine = sa.create_engine(\n            url=self.get_db_uri().render_as_string(hide_password=False),\n            echo=_echo,\n        )\n\n        return engine\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting database engine. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/_depends/#red_utils.ext.sqlalchemy_utils._depends.DBSettings.get_session_pool","title":"<code>get_session_pool()</code>","text":"<p>Configure a session pool using class's SQLAlchemy <code>Engine</code>.</p> <p>Returns:</p> Type Description <code>sessionmaker</code> <p>A SQLAlchemy <code>Session</code> pool for database connections.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\db_config.py</code> <pre><code>def get_session_pool(self) -&gt; so.sessionmaker[so.Session]:\n    \"\"\"Configure a session pool using class's SQLAlchemy `Engine`.\n\n    Returns:\n        (sqlalchemy.orm.sessionmaker): A SQLAlchemy `Session` pool for database connections.\n\n    \"\"\"\n    engine: sa.Engine = self.get_engine()\n    assert engine is not None, ValueError(\"engine cannot be None\")\n    assert isinstance(engine, sa.Engine), TypeError(\n        f\"engine must be of type sqlalchemy.Engine. Got type: ({type(engine)})\"\n    )\n\n    session_pool: so.sessionmaker[so.Session] = so.sessionmaker(bind=engine)\n\n    return session_pool\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/_depends/#red_utils.ext.sqlalchemy_utils._depends.get_db","title":"<code>get_db(db_settings=None)</code>","text":"<p>Dependency to yield a SQLAlchemy Session pool.</p> <p>Usage:</p> get_db() dependency usage<pre><code>from core.dependencies import get_db\n\nwith get_db() as session:\n    repo = someRepoClass(session)\n\n    all = repo.get_all()\n</code></pre> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\_depends.py</code> <pre><code>@contextmanager\ndef get_db(db_settings: DBSettings = None) -&gt; t.Generator[so.Session, t.Any, None]:\n    \"\"\"Dependency to yield a SQLAlchemy Session pool.\n\n    Usage:\n\n    ```py title=\"get_db() dependency usage\" linenums=\"1\"\n\n    from core.dependencies import get_db\n\n    with get_db() as session:\n        repo = someRepoClass(session)\n\n        all = repo.get_all()\n    ```\n    \"\"\"\n    assert db_settings, ValueError(\"Missing DBSettings object.\")\n\n    SESSION_POOL: so.sessionmaker[so.Session] = db_settings.get_session_pool()\n\n    db: so.Session = SESSION_POOL()\n\n    try:\n        yield db\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception yielding database session. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n    finally:\n        db.close()\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/base/","title":"base","text":"<p>SQLAlchemy <code>DeclarativeBase</code>, <code>MetaData</code>, and <code>registry</code> objects.</p> <p>Import this <code>Base</code> into SQLAlchemy model files and let classes inherit from the <code>DeclarativeBase</code> declared here.</p> <p>The <code>registry()</code> function sets the global SQLAlchemy <code>registry</code> for the <code>DeclarativeBase</code> object.</p> <p>Note</p> <p>Docs for <code>DeclarativeBase</code> and <code>registry()</code></p> <ul> <li>Using a DelcarativeBase base class</li> </ul> <p>Docs for MetaData object</p> <ul> <li>Unified tutorial</li> <li>MetaData Docs</li> <li>Impose a table naming scheme with MetaData object</li> </ul>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/base/#red_utils.ext.sqlalchemy_utils.base.Base","title":"<code>Base</code>","text":"<p>               Bases: <code>DeclarativeBase</code></p> <p>Default/Base class for SQLAlchemy models.</p> <p>Description:</p> <p>Child classes inheriting from this Base object will be treated as SQLAlchemy models. Set child class tables with <code>__tablename__ = ....</code></p> <p>Global defaults can be set on this object (i.e. a SQLAlchemy registry), and will be inherited/accessible by all child classes.</p> <p>Note</p> <p>When this class is instantiated, it will not be of type sqlalchemy.orm.DeclarativeBase;     Because of the way this class is intialized, its type will be     sqlalchemy.orm.decl_api.DeclarativeAttributeIntercept</p> <p>Parameters:</p> Name Type Description Default <code>registry</code> <code>Registry</code> <p>A <code>registry</code> object for the <code>Base</code> class</p> required <code>metadata</code> <code>MetaData</code> <p>A <code>MetaData</code> object, with data about the <code>Base</code> class</p> required Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\base.py</code> <pre><code>class Base(so.DeclarativeBase):\n    \"\"\"Default/Base class for SQLAlchemy models.\n\n    Description:\n\n    Child classes inheriting from this Base object will be treated as SQLAlchemy\n    models. Set child class tables with `__tablename__ = ....`\n\n    Global defaults can be set on this object (i.e. a SQLAlchemy registry), and will\n    be inherited/accessible by all child classes.\n\n    !!! note\n\n        When this class is instantiated, it will not be of type sqlalchemy.orm.DeclarativeBase;\n            Because of the way this class is intialized, its type will be\n            sqlalchemy.orm.decl_api.DeclarativeAttributeIntercept\n\n    Params:\n        registry (sqlalchemy.Registry): A `registry` object for the `Base` class\n        metadata (sqlalchemy.MetaData): A `MetaData` object, with data about the `Base` class\n    \"\"\"\n\n    registry: so.registry = reg\n    metadata: sa.MetaData = metadata\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/connection_models/","title":"connection_models","text":""},{"location":"reference/red_utils/ext/sqlalchemy_utils/connection_models/#red_utils.ext.sqlalchemy_utils.connection_models.DictMixin","title":"<code>DictMixin</code>  <code>dataclass</code>","text":"<p>Mixin class to add \"as_dict()\" method to classes. Equivalent to .dict.</p> <p>Adds a <code>.as_dict()</code> method to classes that inherit from this mixin. For example, to add <code>.as_dict()</code> method to a parent class, where all children inherit the .as_dict() function, declare parent as:</p> <pre><code>@dataclass\nclass Parent(DictMixin):\n    ...\n</code></pre> <p>and call like:</p> <pre><code>p = Parent()\np_dict = p.as_dict()\n</code></pre> Source code in <code>src\\red_utils\\core\\dataclass_utils\\mixins\\mixin_classes.py</code> <pre><code>@dataclass\nclass DictMixin:\n    \"\"\"Mixin class to add \"as_dict()\" method to classes. Equivalent to .__dict__.\n\n    Adds a `.as_dict()` method to classes that inherit from this mixin. For example,\n    to add `.as_dict()` method to a parent class, where all children inherit the .as_dict()\n    function, declare parent as:\n\n    ``` py linenums=\"1\"\n    @dataclass\n    class Parent(DictMixin):\n        ...\n    ```\n\n    and call like:\n\n    ``` py linenums=\"1\"\n    p = Parent()\n    p_dict = p.as_dict()\n    ```\n    \"\"\"\n\n    def as_dict(self: Generic[T]):\n        \"\"\"Return dict representation of a dataclass instance.\n\n        Description:\n            Any class that inherits from `DictMixin` will automatically have a method `.as_dict()`.\n                There are no extra params.\n\n        Returns:\n            (dict): A Python `dict` representation of a Python `dataclass` class.\n\n        \"\"\"\n        try:\n            return self.__dict__.copy()\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception converting class instance to dict. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/connection_models/#red_utils.ext.sqlalchemy_utils.connection_models.DictMixin.as_dict","title":"<code>as_dict()</code>","text":"<p>Return dict representation of a dataclass instance.</p> Description <p>Any class that inherits from <code>DictMixin</code> will automatically have a method <code>.as_dict()</code>.     There are no extra params.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A Python <code>dict</code> representation of a Python <code>dataclass</code> class.</p> Source code in <code>src\\red_utils\\core\\dataclass_utils\\mixins\\mixin_classes.py</code> <pre><code>def as_dict(self: Generic[T]):\n    \"\"\"Return dict representation of a dataclass instance.\n\n    Description:\n        Any class that inherits from `DictMixin` will automatically have a method `.as_dict()`.\n            There are no extra params.\n\n    Returns:\n        (dict): A Python `dict` representation of a Python `dataclass` class.\n\n    \"\"\"\n    try:\n        return self.__dict__.copy()\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception converting class instance to dict. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/connection_models/#red_utils.ext.sqlalchemy_utils.connection_models.saConnectionBase","title":"<code>saConnectionBase</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DictMixin</code></p> <p>Base class for SQLAlchemy connection models.</p> <p>Each model will inherit the connection_string propery, which outputs a URL conection object.</p> <p>Parameters:</p> Name Type Description Default <code>drivername</code> <code>str</code> <p>The SQLAlchemy drivername string</p> <code>None</code> <code>host</code> <code>str</code> <p>The database host name/address</p> <code>None</code> <code>port</code> <code>int</code> <p>The connection port for the database</p> <code>None</code> <code>username</code> <code>str</code> <p>The database username to authenticate as</p> <code>None</code> <code>password</code> <code>str</code> <p>The <code>username</code>'s password to authenticate with</p> <code>None</code> <code>database</code> <code>str</code> <p>The name of the database to connect to</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\connection_models.py</code> <pre><code>@dataclass\nclass saConnectionBase(DictMixin):\n    \"\"\"Base class for SQLAlchemy connection models.\n\n    Each model will inherit the connection_string propery,\n    which outputs a URL conection object.\n\n    Params:\n        drivername (str): The SQLAlchemy drivername string\n        host (str): The database host name/address\n        port (int): The connection port for the database\n        username (str): The database username to authenticate as\n        password (str): The `username`'s password to authenticate with\n        database (str): The name of the database to connect to\n    \"\"\"\n\n    drivername: str = field(default=None)\n    host: str = field(default=None)\n    port: int = field(default=None)\n    username: str = field(default=None)\n    ## Hide password from __repr__\n    password: str = field(default=None, repr=False)\n    database: str = field(default=None)\n\n    @property\n    def connection_string(self) -&gt; sa.engine.url.URL:\n        \"\"\"Return a formatted SQLAlchemy `Engine` connection URI string.\"\"\"\n        _string: sa.engine.url.URL = sa.engine.url.URL.create(\n            drivername=self.drivername,\n            host=self.host,\n            username=self.username,\n            password=self.password,\n            port=self.port,\n            database=self.database,\n        )\n\n        return _string\n\n    def __post_init__(self):\n        \"\"\"Dataclasses does not have inbuilt validation for class variables.\n\n        Define validator functions in `__post_init__()`. Classes that inherit from this\n        base class will pass their values through these validators as well.\n\n        !!! note\n\n        [SlingAcademy: How to validate data in dataclass](https://www.slingacademy.com/article/python-how-to-validate-data-in-dataclass/)\n        \"\"\"\n        if self.drivername and not isinstance(self.drivername, str):\n            raise TypeError(\n                f\"Drivername should be of type str, not {type(self.drivername).__name__}\"\n            )\n\n        if self.username and not isinstance(self.username, str):\n            raise TypeError(\n                f\"Username should be of type str, not {type(self.username).__name__}\"\n            )\n\n        if self.password and not isinstance(self.password, str):\n            raise TypeError(\n                f\"Password should be of type str, not {type(self.password).__name__}\"\n            )\n\n        if self.host and not isinstance(self.host, str):\n            raise TypeError(\n                f\"Host should be of type str, not {type(self.host).__name__}\"\n            )\n\n        if self.port and not isinstance(self.port, int):\n            raise TypeError(\n                f\"Port should be of type int, not {type(self.port).__name__}\"\n            )\n\n        if self.port and (self.port &lt;= 0 or self.port &gt; 65535):\n            raise ValueError(\"Port number must be between 1 and 65535\")\n\n        if self.database and not isinstance(self.database, str):\n            raise TypeError(\n                f\"Database should be of type str, not {type(self.database).__name__}\"\n            )\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/connection_models/#red_utils.ext.sqlalchemy_utils.connection_models.saConnectionBase.connection_string","title":"<code>connection_string: sa.engine.url.URL</code>  <code>property</code>","text":"<p>Return a formatted SQLAlchemy <code>Engine</code> connection URI string.</p>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/connection_models/#red_utils.ext.sqlalchemy_utils.connection_models.saConnectionGeneric","title":"<code>saConnectionGeneric</code>  <code>dataclass</code>","text":"<p>               Bases: <code>saConnectionBase</code></p> <p>Generic SQLAlchemy connection class.</p> <p>Inherits settings &amp; properties from the base class, and can be extended if none of the other saConnection* models meet needs.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\connection_models.py</code> <pre><code>class saConnectionGeneric(saConnectionBase):\n    \"\"\"Generic SQLAlchemy connection class.\n\n    Inherits settings &amp; properties from the base class, and can be\n    extended if none of the other saConnection* models meet needs.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/connection_models/#red_utils.ext.sqlalchemy_utils.connection_models.saMSSQLConnection","title":"<code>saMSSQLConnection</code>  <code>dataclass</code>","text":"<p>               Bases: <code>saConnectionBase</code></p> <p>Default Microsoft SQL Server connection.</p> <p>Parameters:</p> Name Type Description Default <code>drivername</code> <code>str</code> <p>The SQLAlchemy drivername string</p> <code>'mssql+pyodbc'</code> <code>host</code> <code>str</code> <p>The PostgreSQL database server address/hostname</p> <code>'127.0.0.1'</code> <code>port</code> <code>int</code> <p>The PostgreSQL database connection port</p> <code>1433</code> <code>username</code> <code>str</code> <p>The PostgreSQL user to authenticate as</p> <code>'SA'</code> <code>password</code> <code>str</code> <p>The PostgreSQL password associated with <code>username</code> to authenticate with</p> <code>'1Secure*Password1'</code> <code>database</code> <code>str</code> <p>The name of the database to connect to</p> <code>'master'</code> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\connection_models.py</code> <pre><code>@dataclass\nclass saMSSQLConnection(saConnectionBase):\n    \"\"\"Default Microsoft SQL Server connection.\n\n    Params:\n        drivername (str): The SQLAlchemy drivername string\n        host (str): The PostgreSQL database server address/hostname\n        port (int): The PostgreSQL database connection port\n        username (str): The PostgreSQL user to authenticate as\n        password (str): The PostgreSQL password associated with `username` to authenticate with\n        database (str): The name of the database to connect to\n    \"\"\"\n\n    drivername: str = field(default=\"mssql+pyodbc\")\n    host: str = field(default=\"127.0.0.1\")\n    # instance: str = field(default=\"\\\\SQLEXPRESS\")\n    port: int = field(default=1433)\n    username: str = field(default=\"SA\")\n    ## Hide password from __repr__\n    password: str = field(default=\"1Secure*Password1\", repr=False)\n    database: str = field(default=\"master\")\n\n    @property\n    def connection_string(self) -&gt; sa.engine.url.URL:\n        \"\"\"Return a formatted SQLAlchemy `Engine` connection URI string.\"\"\"\n        _string: sa.engine.url.URL = sa.engine.url.URL.create(\n            drivername=self.drivername,\n            host=self.host,\n            username=self.username,\n            password=self.password,\n            port=self.port,\n            database=self.database,\n            query=dict(driver=\"ODBC Driver 17 for SQL Server\"),\n        )\n\n        return _string\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/connection_models/#red_utils.ext.sqlalchemy_utils.connection_models.saMSSQLConnection.connection_string","title":"<code>connection_string: sa.engine.url.URL</code>  <code>property</code>","text":"<p>Return a formatted SQLAlchemy <code>Engine</code> connection URI string.</p>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/connection_models/#red_utils.ext.sqlalchemy_utils.connection_models.saPGConnection","title":"<code>saPGConnection</code>  <code>dataclass</code>","text":"<p>               Bases: <code>saConnectionBase</code></p> <p>Default Postgres connection. Useful for local testing.</p> <p>For Postgres databases, the database you specify must exist before creating the initial connection/engine.</p> <p>Parameters:</p> Name Type Description Default <code>drivername</code> <code>str</code> <p>The SQLAlchemy drivername string</p> <code>'postgresql+psycopg2'</code> <code>host</code> <code>str</code> <p>The PostgreSQL database server address/hostname</p> <code>'127.0.0.1'</code> <code>port</code> <code>int</code> <p>The PostgreSQL database connection port</p> <code>5432</code> <code>username</code> <code>str</code> <p>The PostgreSQL user to authenticate as</p> <code>'postgres'</code> <code>password</code> <code>str</code> <p>The PostgreSQL password associated with <code>username</code> to authenticate with</p> <code>'postgres'</code> <code>database</code> <code>str</code> <p>The name of the database to connect to</p> <code>'postgres'</code> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\connection_models.py</code> <pre><code>@dataclass\nclass saPGConnection(saConnectionBase):\n    \"\"\"Default Postgres connection. Useful for local testing.\n\n    For Postgres databases, the database you specify must exist before\n    creating the initial connection/engine.\n\n    Params:\n        drivername (str): The SQLAlchemy drivername string\n        host (str): The PostgreSQL database server address/hostname\n        port (int): The PostgreSQL database connection port\n        username (str): The PostgreSQL user to authenticate as\n        password (str): The PostgreSQL password associated with `username` to authenticate with\n        database (str): The name of the database to connect to\n    \"\"\"\n\n    drivername: str = field(default=\"postgresql+psycopg2\")\n    host: str = field(default=\"127.0.0.1\")\n    port: int = field(default=5432)\n    username: str = field(default=\"postgres\")\n    ## Hide password from __repr__\n    password: str = field(default=\"postgres\", repr=False)\n    database: str = field(default=\"postgres\")\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/connection_models/#red_utils.ext.sqlalchemy_utils.connection_models.saSQLiteConnection","title":"<code>saSQLiteConnection</code>  <code>dataclass</code>","text":"<p>               Bases: <code>saConnectionBase</code></p> <p>Default SQLite connection. Useful for local testing.</p> <p>Parameters:</p> Name Type Description Default <code>drivername</code> <code>str</code> <p>The SQLAlchemy driver string for the database</p> <code>'sqlite+pysqlite'</code> <code>database</code> <code>str</code> <p>The name/path to the SQLite database. It is recommended to use .sqlite for the file extension, although .db or any other should work fine as well.</p> <code>'.db/default_unnamed.sqlite'</code> <p>Pass a value for <code>database</code> to change the name of the SQLite database file. If you use a path (i.e. <code>db/test.sqlite</code>), you need to create the Path manually.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\connection_models.py</code> <pre><code>@dataclass\nclass saSQLiteConnection(saConnectionBase):\n    \"\"\"Default SQLite connection. Useful for local testing.\n\n    Params:\n        drivername (str): The SQLAlchemy driver string for the database\n        database (str): The name/path to the SQLite database.\n            It is recommended to use .sqlite for the file extension,\n            although .db or any other should work fine as well.\n\n    Pass a value for `database` to change the name of the SQLite database file.\n    If you use a path (i.e. `db/test.sqlite`), you need to create the Path\n    manually.\n    \"\"\"\n\n    drivername: str = field(default=\"sqlite+pysqlite\")\n    database: str = field(default=\".db/default_unnamed.sqlite\")\n\n    def ensure_path(self) -&gt; None:\n        \"\"\"Ensure path to self.database exists.\n\n        Use `Path()` to split the directory path\n        from the filename, and ensure directores in path\n        exist.\n        \"\"\"\n        ## Get absolute path to immediate parent directory without filename.\n        _path = Path(self.database).parent.absolute()\n\n        ## Create directories along path if they do not exist\n        if not _path.exists():\n            try:\n                _path.mkdir(parents=True, exist_ok=True)\n            except PermissionError as perm_exc:\n                msg = Exception(\n                    f\"Permission error trying to open {str(_path)}. Details: {perm_exc}\"\n                )\n                log.error(msg)\n\n                raise exc\n            except Exception as exc:\n                msg = Exception(\n                    f\"Unhandled exception creating directories in path: {str(_path)}. Details: {exc}\"\n                )\n                log.error(msg)\n\n                raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/connection_models/#red_utils.ext.sqlalchemy_utils.connection_models.saSQLiteConnection.ensure_path","title":"<code>ensure_path()</code>","text":"<p>Ensure path to self.database exists.</p> <p>Use <code>Path()</code> to split the directory path from the filename, and ensure directores in path exist.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\connection_models.py</code> <pre><code>def ensure_path(self) -&gt; None:\n    \"\"\"Ensure path to self.database exists.\n\n    Use `Path()` to split the directory path\n    from the filename, and ensure directores in path\n    exist.\n    \"\"\"\n    ## Get absolute path to immediate parent directory without filename.\n    _path = Path(self.database).parent.absolute()\n\n    ## Create directories along path if they do not exist\n    if not _path.exists():\n        try:\n            _path.mkdir(parents=True, exist_ok=True)\n        except PermissionError as perm_exc:\n            msg = Exception(\n                f\"Permission error trying to open {str(_path)}. Details: {perm_exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception creating directories in path: {str(_path)}. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/constants/","title":"constants","text":"<p>Validators for custom SQLAlchemy utilities.</p> <p><code>valid_db_types</code>: List of strings of supported database types.</p> <p>Supported: <code>[\"sqlite\", \"postgres\", \"mssql\"]</code></p>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/db_config/","title":"db_config","text":""},{"location":"reference/red_utils/ext/sqlalchemy_utils/db_config/#red_utils.ext.sqlalchemy_utils.db_config.DBSettings","title":"<code>DBSettings</code>  <code>dataclass</code>","text":"<p>Store configuration for a database.</p> <p>Parameters:</p> Name Type Description Default <code>drivername</code> <code>str</code> <p>The <code>sqlalchemy</code> driver name, i.e. <code>'sqlite+pysqlite'</code>.</p> <code>'sqlite+pysqlite'</code> <code>username</code> <code>str | None</code> <p>The database user's username.</p> <code>None</code> <code>password</code> <code>str | None</code> <p>The database user's password.</p> <code>None</code> <code>host</code> <code>str | None</code> <p>The database host address.</p> <code>None</code> <code>port</code> <code>str | int | None</code> <p>The database host's port.</p> <code>None</code> <code>database</code> <code>str</code> <p>The name of the database to connect to. For SQLite, use the path to the file, i.e. <code>db/app.sqlite</code>.</p> <code>'app.sqlite'</code> <code>echo</code> <code>bool</code> <p>If <code>True</code>, the SQLAlchemy <code>Engine</code> will echo SQL queries to the CLI, and will create tables that do not exist (if possible).</p> <code>False</code> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\db_config.py</code> <pre><code>@dataclass\nclass DBSettings:\n    \"\"\"Store configuration for a database.\n\n    Params:\n        drivername (str): The `sqlalchemy` driver name, i.e. `'sqlite+pysqlite'`.\n        username (str|None): The database user's username.\n        password (str|None): The database user's password.\n        host (str|None): The database host address.\n        port (str|int|None): The database host's port.\n        database (str): The name of the database to connect to. For SQLite, use the path to the file,\n            i.e. `db/app.sqlite`.\n        echo (bool): If `True`, the SQLAlchemy `Engine` will echo SQL queries to the CLI, and will create tables\n            that do not exist (if possible).\n\n    \"\"\"\n\n    drivername: str = field(default=\"sqlite+pysqlite\")\n    username: str | None = field(default=None)\n    password: str | None = field(default=None, repr=False)\n    host: str | None = field(default=None)\n    port: str | None = field(default=None)\n    database: str = field(default=\"app.sqlite\")\n    echo: bool = field(default=False)\n\n    def __post_init__(self):  # noqa: D105\n        assert self.drivername is not None, ValueError(\"drivername cannot be None\")\n        assert isinstance(self.drivername, str), TypeError(\n            f\"drivername must be of type str. Got type: ({type(self.drivername)})\"\n        )\n        assert isinstance(self.echo, bool), TypeError(\n            f\"echo must be a bool. Got type: ({type(self.echo)})\"\n        )\n        if self.username:\n            if self.username == \"\":\n                self.username = None\n            else:\n                assert isinstance(self.username, str), TypeError(\n                    f\"user must be of type str. Got type: ({type(self.username)})\"\n                )\n        if self.password:\n            if self.password == \"\":\n                self.password = None\n            else:\n                assert isinstance(self.password, str), TypeError(\n                    f\"password must be of type str. Got type: ({type(self.password)})\"\n                )\n        if self.host:\n            if self.host == \"\":\n                self.host = None\n            else:\n                assert isinstance(self.host, str), TypeError(\n                    f\"host must be of type str. Got type: ({type(self.host)})\"\n                )\n        if self.port:\n            if self.port == \"\":\n                self.port = None\n            else:\n                assert isinstance(self.port, int), TypeError(\n                    f\"port must be of type int. Got type: ({type(self.port)})\"\n                )\n                assert self.port &gt; 0 and self.port &lt;= 65535, ValueError(\n                    f\"port must be an integer between 1 and 65535\"\n                )\n        if self.database:\n            assert isinstance(self.database, Path) or isinstance(\n                self.database, str\n            ), TypeError(\n                f\"database must be of type str or Path. Got type: ({type(self.database)})\"\n            )\n            if isinstance(self.database, Path):\n                self.database: str = f\"{self.database}\"\n\n    def get_db_uri(self) -&gt; sa.URL:\n        \"\"\"Construct a SQLAlchemy `URL` from class params.\n\n        Returns:\n            (sqlalchemy.URL): An initialized database connection URL.\n\n        \"\"\"\n        try:\n            _uri: sa.URL = sa.URL.create(\n                drivername=self.drivername,\n                username=self.username,\n                password=self.password,\n                host=self.host,\n                port=self.port,\n                database=self.database,\n            )\n\n            return _uri\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception getting SQLAlchemy database URL. Details: {exc}\"\n            )\n            log.error(msg)\n            raise exc\n\n    def get_engine(self, echo_override: bool | None = None) -&gt; sa.Engine:\n        \"\"\"Build &amp; return a SQLAlchemy `Engine`.\n\n        Returns:\n            `sqlalchemy.Engine`: A SQLAlchemy `Engine` instance.\n\n        \"\"\"\n        assert self.get_db_uri() is not None, ValueError(\"db_uri is not None\")\n        assert isinstance(self.get_db_uri(), sa.URL), TypeError(\n            f\"db_uri must be of type sqlalchemy.URL. Got type: ({type(self.db_uri)})\"\n        )\n\n        if echo_override is not None:\n            _echo: bool = echo_override\n        else:\n            _echo: bool = self.echo\n\n        try:\n            engine: sa.Engine = sa.create_engine(\n                url=self.get_db_uri().render_as_string(hide_password=False),\n                echo=_echo,\n            )\n\n            return engine\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception getting database engine. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def get_session_pool(self) -&gt; so.sessionmaker[so.Session]:\n        \"\"\"Configure a session pool using class's SQLAlchemy `Engine`.\n\n        Returns:\n            (sqlalchemy.orm.sessionmaker): A SQLAlchemy `Session` pool for database connections.\n\n        \"\"\"\n        engine: sa.Engine = self.get_engine()\n        assert engine is not None, ValueError(\"engine cannot be None\")\n        assert isinstance(engine, sa.Engine), TypeError(\n            f\"engine must be of type sqlalchemy.Engine. Got type: ({type(engine)})\"\n        )\n\n        session_pool: so.sessionmaker[so.Session] = so.sessionmaker(bind=engine)\n\n        return session_pool\n\n    @contextmanager\n    def get_db(self) -&gt; t.Generator[so.Session, t.Any, None]:\n        \"\"\"Context manager class to handle a SQLAlchemy Session pool.\n\n        Usage:\n\n        ```py title=\"get_db() dependency usage\" linenums=\"1\"\n\n        ## Assumes `db_settings` is an initialized instance of `DBSettings`.\n        with db_settings.get_db() as session:\n            repo = someRepoClass(session)\n\n            all = repo.get_all()\n        ```\n        \"\"\"\n        db: so.Session = self.get_session_pool()\n\n        try:\n            yield db\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception yielding database session. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n        finally:\n            db.close()\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/db_config/#red_utils.ext.sqlalchemy_utils.db_config.DBSettings.get_db","title":"<code>get_db()</code>","text":"<p>Context manager class to handle a SQLAlchemy Session pool.</p> <p>Usage:</p> get_db() dependency usage<pre><code>## Assumes `db_settings` is an initialized instance of `DBSettings`.\nwith db_settings.get_db() as session:\n    repo = someRepoClass(session)\n\n    all = repo.get_all()\n</code></pre> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\db_config.py</code> <pre><code>@contextmanager\ndef get_db(self) -&gt; t.Generator[so.Session, t.Any, None]:\n    \"\"\"Context manager class to handle a SQLAlchemy Session pool.\n\n    Usage:\n\n    ```py title=\"get_db() dependency usage\" linenums=\"1\"\n\n    ## Assumes `db_settings` is an initialized instance of `DBSettings`.\n    with db_settings.get_db() as session:\n        repo = someRepoClass(session)\n\n        all = repo.get_all()\n    ```\n    \"\"\"\n    db: so.Session = self.get_session_pool()\n\n    try:\n        yield db\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception yielding database session. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n    finally:\n        db.close()\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/db_config/#red_utils.ext.sqlalchemy_utils.db_config.DBSettings.get_db_uri","title":"<code>get_db_uri()</code>","text":"<p>Construct a SQLAlchemy <code>URL</code> from class params.</p> <p>Returns:</p> Type Description <code>URL</code> <p>An initialized database connection URL.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\db_config.py</code> <pre><code>def get_db_uri(self) -&gt; sa.URL:\n    \"\"\"Construct a SQLAlchemy `URL` from class params.\n\n    Returns:\n        (sqlalchemy.URL): An initialized database connection URL.\n\n    \"\"\"\n    try:\n        _uri: sa.URL = sa.URL.create(\n            drivername=self.drivername,\n            username=self.username,\n            password=self.password,\n            host=self.host,\n            port=self.port,\n            database=self.database,\n        )\n\n        return _uri\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting SQLAlchemy database URL. Details: {exc}\"\n        )\n        log.error(msg)\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/db_config/#red_utils.ext.sqlalchemy_utils.db_config.DBSettings.get_engine","title":"<code>get_engine(echo_override=None)</code>","text":"<p>Build &amp; return a SQLAlchemy <code>Engine</code>.</p> <p>Returns:</p> Type Description <code>Engine</code> <p><code>sqlalchemy.Engine</code>: A SQLAlchemy <code>Engine</code> instance.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\db_config.py</code> <pre><code>def get_engine(self, echo_override: bool | None = None) -&gt; sa.Engine:\n    \"\"\"Build &amp; return a SQLAlchemy `Engine`.\n\n    Returns:\n        `sqlalchemy.Engine`: A SQLAlchemy `Engine` instance.\n\n    \"\"\"\n    assert self.get_db_uri() is not None, ValueError(\"db_uri is not None\")\n    assert isinstance(self.get_db_uri(), sa.URL), TypeError(\n        f\"db_uri must be of type sqlalchemy.URL. Got type: ({type(self.db_uri)})\"\n    )\n\n    if echo_override is not None:\n        _echo: bool = echo_override\n    else:\n        _echo: bool = self.echo\n\n    try:\n        engine: sa.Engine = sa.create_engine(\n            url=self.get_db_uri().render_as_string(hide_password=False),\n            echo=_echo,\n        )\n\n        return engine\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting database engine. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/db_config/#red_utils.ext.sqlalchemy_utils.db_config.DBSettings.get_session_pool","title":"<code>get_session_pool()</code>","text":"<p>Configure a session pool using class's SQLAlchemy <code>Engine</code>.</p> <p>Returns:</p> Type Description <code>sessionmaker</code> <p>A SQLAlchemy <code>Session</code> pool for database connections.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\db_config.py</code> <pre><code>def get_session_pool(self) -&gt; so.sessionmaker[so.Session]:\n    \"\"\"Configure a session pool using class's SQLAlchemy `Engine`.\n\n    Returns:\n        (sqlalchemy.orm.sessionmaker): A SQLAlchemy `Session` pool for database connections.\n\n    \"\"\"\n    engine: sa.Engine = self.get_engine()\n    assert engine is not None, ValueError(\"engine cannot be None\")\n    assert isinstance(engine, sa.Engine), TypeError(\n        f\"engine must be of type sqlalchemy.Engine. Got type: ({type(engine)})\"\n    )\n\n    session_pool: so.sessionmaker[so.Session] = so.sessionmaker(bind=engine)\n\n    return session_pool\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/utils/","title":"utils","text":""},{"location":"reference/red_utils/ext/sqlalchemy_utils/utils/#red_utils.ext.sqlalchemy_utils.utils.saConnectionGeneric","title":"<code>saConnectionGeneric</code>  <code>dataclass</code>","text":"<p>               Bases: <code>saConnectionBase</code></p> <p>Generic SQLAlchemy connection class.</p> <p>Inherits settings &amp; properties from the base class, and can be extended if none of the other saConnection* models meet needs.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\connection_models.py</code> <pre><code>class saConnectionGeneric(saConnectionBase):\n    \"\"\"Generic SQLAlchemy connection class.\n\n    Inherits settings &amp; properties from the base class, and can be\n    extended if none of the other saConnection* models meet needs.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/utils/#red_utils.ext.sqlalchemy_utils.utils.saMSSQLConnection","title":"<code>saMSSQLConnection</code>  <code>dataclass</code>","text":"<p>               Bases: <code>saConnectionBase</code></p> <p>Default Microsoft SQL Server connection.</p> <p>Parameters:</p> Name Type Description Default <code>drivername</code> <code>str</code> <p>The SQLAlchemy drivername string</p> <code>'mssql+pyodbc'</code> <code>host</code> <code>str</code> <p>The PostgreSQL database server address/hostname</p> <code>'127.0.0.1'</code> <code>port</code> <code>int</code> <p>The PostgreSQL database connection port</p> <code>1433</code> <code>username</code> <code>str</code> <p>The PostgreSQL user to authenticate as</p> <code>'SA'</code> <code>password</code> <code>str</code> <p>The PostgreSQL password associated with <code>username</code> to authenticate with</p> <code>'1Secure*Password1'</code> <code>database</code> <code>str</code> <p>The name of the database to connect to</p> <code>'master'</code> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\connection_models.py</code> <pre><code>@dataclass\nclass saMSSQLConnection(saConnectionBase):\n    \"\"\"Default Microsoft SQL Server connection.\n\n    Params:\n        drivername (str): The SQLAlchemy drivername string\n        host (str): The PostgreSQL database server address/hostname\n        port (int): The PostgreSQL database connection port\n        username (str): The PostgreSQL user to authenticate as\n        password (str): The PostgreSQL password associated with `username` to authenticate with\n        database (str): The name of the database to connect to\n    \"\"\"\n\n    drivername: str = field(default=\"mssql+pyodbc\")\n    host: str = field(default=\"127.0.0.1\")\n    # instance: str = field(default=\"\\\\SQLEXPRESS\")\n    port: int = field(default=1433)\n    username: str = field(default=\"SA\")\n    ## Hide password from __repr__\n    password: str = field(default=\"1Secure*Password1\", repr=False)\n    database: str = field(default=\"master\")\n\n    @property\n    def connection_string(self) -&gt; sa.engine.url.URL:\n        \"\"\"Return a formatted SQLAlchemy `Engine` connection URI string.\"\"\"\n        _string: sa.engine.url.URL = sa.engine.url.URL.create(\n            drivername=self.drivername,\n            host=self.host,\n            username=self.username,\n            password=self.password,\n            port=self.port,\n            database=self.database,\n            query=dict(driver=\"ODBC Driver 17 for SQL Server\"),\n        )\n\n        return _string\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/utils/#red_utils.ext.sqlalchemy_utils.utils.saMSSQLConnection.connection_string","title":"<code>connection_string: sa.engine.url.URL</code>  <code>property</code>","text":"<p>Return a formatted SQLAlchemy <code>Engine</code> connection URI string.</p>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/utils/#red_utils.ext.sqlalchemy_utils.utils.saPGConnection","title":"<code>saPGConnection</code>  <code>dataclass</code>","text":"<p>               Bases: <code>saConnectionBase</code></p> <p>Default Postgres connection. Useful for local testing.</p> <p>For Postgres databases, the database you specify must exist before creating the initial connection/engine.</p> <p>Parameters:</p> Name Type Description Default <code>drivername</code> <code>str</code> <p>The SQLAlchemy drivername string</p> <code>'postgresql+psycopg2'</code> <code>host</code> <code>str</code> <p>The PostgreSQL database server address/hostname</p> <code>'127.0.0.1'</code> <code>port</code> <code>int</code> <p>The PostgreSQL database connection port</p> <code>5432</code> <code>username</code> <code>str</code> <p>The PostgreSQL user to authenticate as</p> <code>'postgres'</code> <code>password</code> <code>str</code> <p>The PostgreSQL password associated with <code>username</code> to authenticate with</p> <code>'postgres'</code> <code>database</code> <code>str</code> <p>The name of the database to connect to</p> <code>'postgres'</code> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\connection_models.py</code> <pre><code>@dataclass\nclass saPGConnection(saConnectionBase):\n    \"\"\"Default Postgres connection. Useful for local testing.\n\n    For Postgres databases, the database you specify must exist before\n    creating the initial connection/engine.\n\n    Params:\n        drivername (str): The SQLAlchemy drivername string\n        host (str): The PostgreSQL database server address/hostname\n        port (int): The PostgreSQL database connection port\n        username (str): The PostgreSQL user to authenticate as\n        password (str): The PostgreSQL password associated with `username` to authenticate with\n        database (str): The name of the database to connect to\n    \"\"\"\n\n    drivername: str = field(default=\"postgresql+psycopg2\")\n    host: str = field(default=\"127.0.0.1\")\n    port: int = field(default=5432)\n    username: str = field(default=\"postgres\")\n    ## Hide password from __repr__\n    password: str = field(default=\"postgres\", repr=False)\n    database: str = field(default=\"postgres\")\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/utils/#red_utils.ext.sqlalchemy_utils.utils.saSQLiteConnection","title":"<code>saSQLiteConnection</code>  <code>dataclass</code>","text":"<p>               Bases: <code>saConnectionBase</code></p> <p>Default SQLite connection. Useful for local testing.</p> <p>Parameters:</p> Name Type Description Default <code>drivername</code> <code>str</code> <p>The SQLAlchemy driver string for the database</p> <code>'sqlite+pysqlite'</code> <code>database</code> <code>str</code> <p>The name/path to the SQLite database. It is recommended to use .sqlite for the file extension, although .db or any other should work fine as well.</p> <code>'.db/default_unnamed.sqlite'</code> <p>Pass a value for <code>database</code> to change the name of the SQLite database file. If you use a path (i.e. <code>db/test.sqlite</code>), you need to create the Path manually.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\connection_models.py</code> <pre><code>@dataclass\nclass saSQLiteConnection(saConnectionBase):\n    \"\"\"Default SQLite connection. Useful for local testing.\n\n    Params:\n        drivername (str): The SQLAlchemy driver string for the database\n        database (str): The name/path to the SQLite database.\n            It is recommended to use .sqlite for the file extension,\n            although .db or any other should work fine as well.\n\n    Pass a value for `database` to change the name of the SQLite database file.\n    If you use a path (i.e. `db/test.sqlite`), you need to create the Path\n    manually.\n    \"\"\"\n\n    drivername: str = field(default=\"sqlite+pysqlite\")\n    database: str = field(default=\".db/default_unnamed.sqlite\")\n\n    def ensure_path(self) -&gt; None:\n        \"\"\"Ensure path to self.database exists.\n\n        Use `Path()` to split the directory path\n        from the filename, and ensure directores in path\n        exist.\n        \"\"\"\n        ## Get absolute path to immediate parent directory without filename.\n        _path = Path(self.database).parent.absolute()\n\n        ## Create directories along path if they do not exist\n        if not _path.exists():\n            try:\n                _path.mkdir(parents=True, exist_ok=True)\n            except PermissionError as perm_exc:\n                msg = Exception(\n                    f\"Permission error trying to open {str(_path)}. Details: {perm_exc}\"\n                )\n                log.error(msg)\n\n                raise exc\n            except Exception as exc:\n                msg = Exception(\n                    f\"Unhandled exception creating directories in path: {str(_path)}. Details: {exc}\"\n                )\n                log.error(msg)\n\n                raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/utils/#red_utils.ext.sqlalchemy_utils.utils.saSQLiteConnection.ensure_path","title":"<code>ensure_path()</code>","text":"<p>Ensure path to self.database exists.</p> <p>Use <code>Path()</code> to split the directory path from the filename, and ensure directores in path exist.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\connection_models.py</code> <pre><code>def ensure_path(self) -&gt; None:\n    \"\"\"Ensure path to self.database exists.\n\n    Use `Path()` to split the directory path\n    from the filename, and ensure directores in path\n    exist.\n    \"\"\"\n    ## Get absolute path to immediate parent directory without filename.\n    _path = Path(self.database).parent.absolute()\n\n    ## Create directories along path if they do not exist\n    if not _path.exists():\n        try:\n            _path.mkdir(parents=True, exist_ok=True)\n        except PermissionError as perm_exc:\n            msg = Exception(\n                f\"Permission error trying to open {str(_path)}. Details: {perm_exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception creating directories in path: {str(_path)}. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/utils/#red_utils.ext.sqlalchemy_utils.utils.create_base_metadata","title":"<code>create_base_metadata(base_obj=None, engine=None)</code>","text":"<p>Create <code>Base</code> object's metadata.</p> Description <p>Import this function early in your app/script (i.e. <code>main.py</code>) and run as soon as possible, i.e. after imports.</p> <p>This function accepts a SQLAlchemy <code>DeclarativeBase</code> object, and creates the table metadata from that object using the <code>Engine</code> passed.</p> <p>This function will only ever return <code>True</code> if successful. It does not return <code>False</code>, as an <code>Exception</code> is raised if metadata creation fails and the program is halted.</p> <p>Parameters:</p> Name Type Description Default <code>base_obj</code> <code>DeclarativeBase</code> <p>A SQLAlchemy <code>DeclarativeBase</code> object to extract metadata from</p> <code>None</code> <code>engine</code> <code>Engine</code> <p>The <code>Engine</code> to use for the database connection.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if creating <code>Base</code> metadata is successful</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When input values are invalid</p> <code>OperationalError</code> <p>When SQLAlchemy runs into an error with the database, usually starting on the database (not in SQLAlchemy)</p> <code>DBAPIERROR</code> <p>When SQLAlchemy runs into an issue, generally in the way you've coded a SQLAlchemy statement or operation</p> <code>Exception</code> <p>When an uncaught/unhandled exception occurs</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\utils.py</code> <pre><code>def create_base_metadata(\n    base_obj: so.DeclarativeBase = None, engine: sa.Engine = None\n) -&gt; bool:\n    \"\"\"Create `Base` object's metadata.\n\n    Description:\n        Import this function early in your app/script (i.e. `main.py`) and run as soon as\n        possible, i.e. after imports.\n\n        This function accepts a SQLAlchemy `DeclarativeBase` object, and creates the table\n        metadata from that object using the `Engine` passed.\n\n        This function will only ever return `True` if successful. It does not return `False`,\n        as an `Exception` is raised if metadata creation fails and the program is halted.\n\n    Params:\n        base_obj (sqlalchemy.DeclarativeBase): A SQLAlchemy `DeclarativeBase` object to extract metadata from\n        engine (sqlalchemy.Engine): The `Engine` to use for the database connection.\n\n    Returns:\n        (bool): `True` if creating `Base` metadata is successful\n\n    Raises:\n        ValueError: When input values are invalid\n        OperationalError: When SQLAlchemy runs into an error with the database, usually starting\n            on the database (not in SQLAlchemy)\n        DBAPIERROR: When SQLAlchemy runs into an issue, generally in the way you've coded a SQLAlchemy\n            statement or operation\n        Exception: When an uncaught/unhandled exception occurs\n\n    \"\"\"\n    try:\n        base_obj.metadata.create_all(bind=engine)\n\n        return True\n    except OperationalError as op_exc:\n        raise op_exc\n    except DBAPIError as dbapi_exc:\n        raise dbapi_exc\n    except Exception as exc:\n        raise Exception(f\"Unhandled exception creating Base metadata. Details: {exc}\")\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/utils/#red_utils.ext.sqlalchemy_utils.utils.debug_metadata_obj","title":"<code>debug_metadata_obj(metadata_obj=None)</code>","text":"<p>Debug-print a SQLAlchemy MetaData object.</p> <p>Loop over tables and print names.</p> <p>Parameters:</p> Name Type Description Default <code>metadata_obj</code> <code>MetaData</code> <p>A SQLAlchemy <code>MetaData</code> object to debug</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\utils.py</code> <pre><code>def debug_metadata_obj(metadata_obj: sa.MetaData = None) -&gt; None:\n    \"\"\"Debug-print a SQLAlchemy MetaData object.\n\n    Loop over tables and print names.\n\n    Params:\n        metadata_obj (sqlalchemy.MetaData): A SQLAlchemy `MetaData` object to debug\n    \"\"\"\n    if not metadata_obj:\n        raise ValueError(\"Missing a SQLAlchemy metadata object.\")\n\n    if not isinstance(metadata_obj, sa.MetaData):\n        raise ValueError(\n            f\"Expected a MetaData obj, not object of type '{type(metadata_obj).__name__}'\"\n        )\n\n    for _table in metadata_obj.sorted_tables:\n        print(f\"Table name: {_table.name}\")\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/utils/#red_utils.ext.sqlalchemy_utils.utils.generate_metadata","title":"<code>generate_metadata(metadata_obj=None, engine=None)</code>","text":"<p>Create SQLAlchemy table metadata.</p> <p>Accept a SQLalchemy MetaData object, run .create_all(engine) to create table metadata.</p> <p>Parameters:</p> Name Type Description Default <code>metadata_obj</code> <code>MetaData</code> <p>A SQLAlchemy <code>MetaData</code> object to use for generating in the database</p> <code>None</code> <code>engine</code> <code>Engine</code> <p>The SQLAlchemy <code>Engine</code> to use for the database connection</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>When input values are invalid</p> <code>OperationalError</code> <p>When SQLAlchemy runs into an error with the database, usually starting on the database (not in SQLAlchemy)</p> <code>DBAPIERROR</code> <p>When SQLAlchemy runs into an issue, generally in the way you've coded a SQLAlchemy statement or operation</p> <code>Exception</code> <p>When an uncaught/unhandled exception occurs</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\utils.py</code> <pre><code>def generate_metadata(\n    metadata_obj: sa.MetaData = None, engine: sa.Engine = None\n) -&gt; None:\n    \"\"\"Create SQLAlchemy table metadata.\n\n    Accept a SQLalchemy MetaData object, run .create_all(engine) to create\n    table metadata.\n\n    Params:\n        metadata_obj (sqlalchemy.MetaData): A SQLAlchemy `MetaData` object to use for generating in the database\n        engine (sqlalchemy.Engine): The SQLAlchemy `Engine` to use for the database connection\n\n    Raises:\n        ValueError: When input values are invalid\n        OperationalError: When SQLAlchemy runs into an error with the database, usually starting\n            on the database (not in SQLAlchemy)\n        DBAPIERROR: When SQLAlchemy runs into an issue, generally in the way you've coded a SQLAlchemy\n            statement or operation\n        Exception: When an uncaught/unhandled exception occurs\n\n    \"\"\"\n    if not metadata_obj:\n        raise ValueError(\"Missing a SQLAlchemy MetaData object.\")\n\n    if not isinstance(metadata_obj, sa.MetaData):\n        raise ValueError(\n            f\"Expected a MetaData obj, not object of type '{type(metadata_obj).__name__}'\"\n        )\n\n    if not engine:\n        raise ValueError(\"Missing a SQLAlchemy engine object.\")\n\n    if not isinstance(engine, sa.Engine):\n        raise ValueError(\n            f\"Expected a SQLAlchemy engine obj, not object of type '{type(engine).__name__}\"\n        )\n\n    try:\n        metadata_obj.create_all(engine)\n\n        return True\n    except OperationalError as op_exc:\n        raise op_exc\n    except DBAPIError as dbapi_exc:\n        raise dbapi_exc\n    except Exception as exc:\n        raise Exception(f\"Unhandled exception creating Base metadata. Details: {exc}\")\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/utils/#red_utils.ext.sqlalchemy_utils.utils.get_engine","title":"<code>get_engine(connection=None, db_type='sqlite', echo=False, pool_pre_ping=False)</code>","text":"<p>Return a SQLAlchemy Engine object.</p> <p>SQLAlchemy docs: Engine</p> <p>To use a database other than SQLite, i.e. Postgres or MySQL, pass the lowercase string name of the database.</p> Currently supported databases <ul> <li>[x] SQLite</li> <li>[x] Postgres</li> <li>[ ] MySQL</li> <li>[x] MSSQL</li> <li>[ ] Azure Cosmos</li> </ul> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>(saSQLiteConnection, saPGConnection)</code> <p>Instantiated instance of a custom database connection class</p> <code>None</code> <code>db_type</code> <code>str</code> <p>The string name (lowercase) of a database type</p> <code>'sqlite'</code> <code>echo</code> <code>bool</code> <p>If <code>True</code>, the SQL the <code>Engine</code> runs will be echoed to the CLI</p> <code>False</code> <code>pool_pre_ping</code> <code>bool</code> <p>Test connection pool before starting operations</p> <code>False</code> <p>Returns:</p> Type Description <code>Engine</code> <p>An initialized SQLAlchemy <code>Engine</code> object</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\utils.py</code> <pre><code>def get_engine(\n    connection: Union[saSQLiteConnection, saPGConnection, str] = None,\n    db_type: str = \"sqlite\",\n    echo: bool = False,\n    pool_pre_ping: bool = False,\n) -&gt; sa.Engine:\n    \"\"\"Return a SQLAlchemy Engine object.\n\n    [SQLAlchemy docs: Engine](https://docs.sqlalchemy.org/en/20/tutorial/engine.html)\n\n    To use a database other than SQLite, i.e. Postgres or MySQL, pass\n    the lowercase string name of the database.\n\n    Currently supported databases:\n        - [x] SQLite\n        - [x] Postgres\n        - [ ] MySQL\n        - [x] MSSQL\n        - [ ] Azure Cosmos\n\n    Params:\n        connection (saSQLiteConnection, saPGConnection): Instantiated instance of a custom database connection class\n        db_type (str): The string name (lowercase) of a database type\n        echo (bool): If `True`, the SQL the `Engine` runs will be echoed to the CLI\n        pool_pre_ping (bool): Test connection pool before starting operations\n\n    Returns:\n        (sqlalchemy.Engine): An initialized SQLAlchemy `Engine` object\n\n    \"\"\"\n    if not connection:\n        raise ValueError(\"Missing connection object/string.\")\n\n    if isinstance(connection, str):\n        if db_type == \"sqlite\":\n            connection: saSQLiteConnection = saSQLiteConnection(database=connection)\n\n    ## Validate db_type input\n    if db_type:\n        _valid: bool = validate_db_type(db_type)\n\n        if not _valid:\n            raise ValueError(\n                f\"Invalid db_type: {db_type}. Must be one of: {valid_db_types}\"\n            )\n\n    else:\n        ## Default to sqlite if no db_type is passed\n        db_type = \"sqlite\"\n\n    if db_type == \"sqlite\":\n        ## Ensure path to database file exists\n        connection.ensure_path()\n\n    if db_type == \"postgres\":\n        pass\n\n    if db_type == \"mssql\":\n        pass\n\n    try:\n        engine = sa.create_engine(\n            connection.connection_string, echo=echo, pool_pre_ping=pool_pre_ping\n        )\n\n        return engine\n\n    except OperationalError as op_exc:\n        raise OperationalError(\n            f\"SQLAlchemy OperationalError exception occurred connecting to database {connection.database}. Details: {op_exc}\"\n        )\n\n    except Exception as exc:\n        raise Exception(f\"Unhandled exception creating database engine. Details: {exc}\")\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/utils/#red_utils.ext.sqlalchemy_utils.utils.get_session_pool","title":"<code>get_session_pool(engine=None, autoflush=False, expire_on_commit=False, class_=so.Session)</code>","text":"<p>Define a factory for creating SQLAlchemy sessions.</p> <p>Returns a <code>sqlalchemy.orm.sessionmaker</code> <code>Session</code> instance. Import this function in scripts that interact with the database, and create a <code>SessionLocal</code> object with <code>SessionLocal = get_session(**args)</code></p> <p>Parameters:</p> Name Type Description Default <code>engine</code> <code>Engine</code> <p>A SQLAlchemy <code>Engine</code> object to use for connections</p> <code>None</code> <code>autoflush</code> <code>bool</code> <p>Automatically run <code>flush</code> operation on commits</p> <code>False</code> <code>expire_on_commit</code> <code>bool</code> <p>If <code>True</code>, connection expires once it's closed</p> <code>False</code> <code>class_</code> <p>You can specify a class which should be returned instead of <code>sqlalchemy.orm.Session</code>. SQLAlchemy: sessionmaker class_ docs</p> <code>Session</code> <p>Returns:</p> Type Description <code>sessionmaker[Session]</code> <p>An initialized <code>Session</code> instance</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\utils.py</code> <pre><code>def get_session_pool(\n    engine: sa.Engine = None,\n    autoflush: bool = False,\n    expire_on_commit: bool = False,\n    class_=so.Session,\n) -&gt; so.sessionmaker[so.Session]:\n    \"\"\"Define a factory for creating SQLAlchemy sessions.\n\n    Returns a `sqlalchemy.orm.sessionmaker` `Session` instance. Import this\n    function in scripts that interact with the database, and create a\n    `SessionLocal` object with `SessionLocal = get_session(**args)`\n\n    Params:\n        engine (sqlalchemy.Engine): A SQLAlchemy `Engine` object to use for connections\n        autoflush (bool): Automatically run `flush` operation on commits\n        expire_on_commit (bool): If `True`, connection expires once it's closed\n        class_: You can specify a class which should be returned instead of `sqlalchemy.orm.Session`.\n            [SQLAlchemy: sessionmaker class_ docs](https://docs.sqlalchemy.org/en/20/orm/session_api.html#sqlalchemy.orm.Session.params.class_)\n\n    Returns:\n        (sessionmaker[Session]): An initialized `Session` instance\n\n    \"\"\"\n    try:\n        session_pool: so.sessionmaker[so.Session] = so.sessionmaker(\n            bind=engine,\n            autoflush=autoflush,\n            expire_on_commit=expire_on_commit,\n            class_=class_,\n        )\n\n        return session_pool\n\n    except Exception as exc:\n        raise Exception(\n            f\"Unhandled exception creating a sessionmaker Session. Details: {exc}\"\n        )\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/utils/#red_utils.ext.sqlalchemy_utils.utils.validate_db_type","title":"<code>validate_db_type(in_str=None)</code>","text":"<p>Validate <code>db_type</code> string in functions that utilize <code>db_type</code>.</p> <p>Parameters:</p> Name Type Description Default <code>in_str</code> <code>str</code> <p>A <code>db_type</code> string to validate</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>in_str</code> is valid</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the <code>in_str</code> is not valid</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\utils.py</code> <pre><code>def validate_db_type(in_str: str = None) -&gt; bool:\n    \"\"\"Validate `db_type` string in functions that utilize `db_type`.\n\n    Params:\n        in_str (str): A `db_type` string to validate\n\n    Returns:\n        (bool): `True` if `in_str` is valid\n\n    Raises:\n        ValueError: If the `in_str` is not valid\n\n    \"\"\"\n    if not in_str:\n        raise ValueError(\"Missing input string to validate\")\n\n    if in_str not in valid_db_types:\n        return False\n\n    return True\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/custom_types/__init__/","title":"custom_types","text":""},{"location":"reference/red_utils/ext/sqlalchemy_utils/custom_types/__init__/#red_utils.ext.sqlalchemy_utils.custom_types.CompatibleUUID","title":"<code>CompatibleUUID</code>","text":"<p>               Bases: <code>TypeDecorator</code></p> <p>Define a custom UUID, overriding SQLAlchemy's UUId type.</p> <p>The main purpose of this class is to instruct SQLAlchemy to store UUIDs as a binary, instead of as a UUID type. This is useful for cross-database support, i.e. for SQLite which does not support the UUID type.</p> <p>Note</p> <ul> <li>SQLAlchemy docs: backend agnostic GUID type</li> </ul> <p>Usage:</p> <p>When defining a table model, after declaring <code>__tablename_</code>_, set the <code>type_annotation_map</code>, i.e.:</p> <pre><code>class ExampleModel(Base):\n    __tablename__ = \"__sometable__\"\n\n    type_annotation_map = {uuid.UUID: CompatibleUUID}\n</code></pre> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\custom_types\\type_classes.py</code> <pre><code>class CompatibleUUID(TypeDecorator):\n    \"\"\"Define a custom UUID, overriding SQLAlchemy's UUId type.\n\n    The main purpose of this class is to instruct SQLAlchemy to\n    store UUIDs as a binary, instead of as a UUID type. This is\n    useful for cross-database support, i.e. for SQLite which does\n    not support the UUID type.\n\n    !!! note\n    - [SQLAlchemy docs: backend agnostic GUID type](https://docs.sqlalchemy.org/en/20/core/custom_types.html#backend-agnostic-guid-type)\n\n    Usage:\n\n    When defining a table model, after declaring `__tablename_`_, set the `type_annotation_map`, i.e.:\n\n    ``` py linenums=\"1\"\n    class ExampleModel(Base):\n        __tablename__ = \"__sometable__\"\n\n        type_annotation_map = {uuid.UUID: CompatibleUUID}\n    ```\n    \"\"\"\n\n    impl = sa.BINARY\n    cache_ok = True\n\n    def load_diaclect_impl(self, dialect):\n        if dialect.name == \"postgresql\":\n            return dialect.type_descriptor(UUID())\n        else:\n            return dialect.type_descriptor(CHAR(32))\n\n    def process_bind_param(self, value, dialect):\n        if value is None:\n            return value\n        elif dialect.name == \"postgresql\":\n            return str(value)\n        else:\n            if not isinstance(value, uuid.UUID):\n                return \"%.32x\" % uuid.UUID(value).int\n            else:\n                ## Return hexstring\n                return \"%.32x\" % value.int\n\n    def process_result_value(self, value: Any | None, dialect: Dialect) -&gt; Any | None:\n        if value is None:\n            return value\n        else:\n            if not isinstance(value, uuid.UUID):\n                value = uuid.UUID(value)\n            return value\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/custom_types/columns/","title":"columns","text":""},{"location":"reference/red_utils/ext/sqlalchemy_utils/custom_types/columns/#red_utils.ext.sqlalchemy_utils.custom_types.columns.CompatibleUUID","title":"<code>CompatibleUUID</code>","text":"<p>               Bases: <code>TypeDecorator</code></p> <p>Define a custom UUID, overriding SQLAlchemy's UUId type.</p> <p>The main purpose of this class is to instruct SQLAlchemy to store UUIDs as a binary, instead of as a UUID type. This is useful for cross-database support, i.e. for SQLite which does not support the UUID type.</p> <p>Note</p> <ul> <li>SQLAlchemy docs: backend agnostic GUID type</li> </ul> <p>Usage:</p> <p>When defining a table model, after declaring <code>__tablename_</code>_, set the <code>type_annotation_map</code>, i.e.:</p> <pre><code>class ExampleModel(Base):\n    __tablename__ = \"__sometable__\"\n\n    type_annotation_map = {uuid.UUID: CompatibleUUID}\n</code></pre> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\custom_types\\type_classes.py</code> <pre><code>class CompatibleUUID(TypeDecorator):\n    \"\"\"Define a custom UUID, overriding SQLAlchemy's UUId type.\n\n    The main purpose of this class is to instruct SQLAlchemy to\n    store UUIDs as a binary, instead of as a UUID type. This is\n    useful for cross-database support, i.e. for SQLite which does\n    not support the UUID type.\n\n    !!! note\n    - [SQLAlchemy docs: backend agnostic GUID type](https://docs.sqlalchemy.org/en/20/core/custom_types.html#backend-agnostic-guid-type)\n\n    Usage:\n\n    When defining a table model, after declaring `__tablename_`_, set the `type_annotation_map`, i.e.:\n\n    ``` py linenums=\"1\"\n    class ExampleModel(Base):\n        __tablename__ = \"__sometable__\"\n\n        type_annotation_map = {uuid.UUID: CompatibleUUID}\n    ```\n    \"\"\"\n\n    impl = sa.BINARY\n    cache_ok = True\n\n    def load_diaclect_impl(self, dialect):\n        if dialect.name == \"postgresql\":\n            return dialect.type_descriptor(UUID())\n        else:\n            return dialect.type_descriptor(CHAR(32))\n\n    def process_bind_param(self, value, dialect):\n        if value is None:\n            return value\n        elif dialect.name == \"postgresql\":\n            return str(value)\n        else:\n            if not isinstance(value, uuid.UUID):\n                return \"%.32x\" % uuid.UUID(value).int\n            else:\n                ## Return hexstring\n                return \"%.32x\" % value.int\n\n    def process_result_value(self, value: Any | None, dialect: Dialect) -&gt; Any | None:\n        if value is None:\n            return value\n        else:\n            if not isinstance(value, uuid.UUID):\n                value = uuid.UUID(value)\n            return value\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/custom_types/meta/","title":"meta","text":""},{"location":"reference/red_utils/ext/sqlalchemy_utils/custom_types/meta/#red_utils.ext.sqlalchemy_utils.custom_types.meta.CompatibleUUID","title":"<code>CompatibleUUID</code>","text":"<p>               Bases: <code>TypeDecorator</code></p> <p>Define a custom UUID, overriding SQLAlchemy's UUId type.</p> <p>The main purpose of this class is to instruct SQLAlchemy to store UUIDs as a binary, instead of as a UUID type. This is useful for cross-database support, i.e. for SQLite which does not support the UUID type.</p> <p>Note</p> <ul> <li>SQLAlchemy docs: backend agnostic GUID type</li> </ul> <p>Usage:</p> <p>When defining a table model, after declaring <code>__tablename_</code>_, set the <code>type_annotation_map</code>, i.e.:</p> <pre><code>class ExampleModel(Base):\n    __tablename__ = \"__sometable__\"\n\n    type_annotation_map = {uuid.UUID: CompatibleUUID}\n</code></pre> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\custom_types\\type_classes.py</code> <pre><code>class CompatibleUUID(TypeDecorator):\n    \"\"\"Define a custom UUID, overriding SQLAlchemy's UUId type.\n\n    The main purpose of this class is to instruct SQLAlchemy to\n    store UUIDs as a binary, instead of as a UUID type. This is\n    useful for cross-database support, i.e. for SQLite which does\n    not support the UUID type.\n\n    !!! note\n    - [SQLAlchemy docs: backend agnostic GUID type](https://docs.sqlalchemy.org/en/20/core/custom_types.html#backend-agnostic-guid-type)\n\n    Usage:\n\n    When defining a table model, after declaring `__tablename_`_, set the `type_annotation_map`, i.e.:\n\n    ``` py linenums=\"1\"\n    class ExampleModel(Base):\n        __tablename__ = \"__sometable__\"\n\n        type_annotation_map = {uuid.UUID: CompatibleUUID}\n    ```\n    \"\"\"\n\n    impl = sa.BINARY\n    cache_ok = True\n\n    def load_diaclect_impl(self, dialect):\n        if dialect.name == \"postgresql\":\n            return dialect.type_descriptor(UUID())\n        else:\n            return dialect.type_descriptor(CHAR(32))\n\n    def process_bind_param(self, value, dialect):\n        if value is None:\n            return value\n        elif dialect.name == \"postgresql\":\n            return str(value)\n        else:\n            if not isinstance(value, uuid.UUID):\n                return \"%.32x\" % uuid.UUID(value).int\n            else:\n                ## Return hexstring\n                return \"%.32x\" % value.int\n\n    def process_result_value(self, value: Any | None, dialect: Dialect) -&gt; Any | None:\n        if value is None:\n            return value\n        else:\n            if not isinstance(value, uuid.UUID):\n                value = uuid.UUID(value)\n            return value\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/custom_types/type_classes/","title":"type_classes","text":"<p>Define custom type classes for SQLAlchemy.</p> <p>Note</p> <ul> <li>SQLAlchemy docs: Custom Types</li> </ul>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/custom_types/type_classes/#red_utils.ext.sqlalchemy_utils.custom_types.type_classes--how-to-use-custom-type-overrides","title":"How to use custom type overrides","text":"<p>After defining a customer class (by inheriting from overriding sqlalchemy.types.TypeDecorator), use it in a model, after declaring a <code>__tablename__</code>.</p> <p>Backend agnostic GUID type: example custom UUID class:</p> CompatibleUUID demo<pre><code>class SomeModel(Base):\n    __tablename__ = \"someTable\"\n\n    ## Tell this model to convert uuid.UUID Python types to custom CompatibleUUID class\n    type_annotation_map = {uuid.UUID: CompatibleUUID}\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/custom_types/type_classes/#red_utils.ext.sqlalchemy_utils.custom_types.type_classes.CompatibleUUID","title":"<code>CompatibleUUID</code>","text":"<p>               Bases: <code>TypeDecorator</code></p> <p>Define a custom UUID, overriding SQLAlchemy's UUId type.</p> <p>The main purpose of this class is to instruct SQLAlchemy to store UUIDs as a binary, instead of as a UUID type. This is useful for cross-database support, i.e. for SQLite which does not support the UUID type.</p> <p>Note</p> <ul> <li>SQLAlchemy docs: backend agnostic GUID type</li> </ul> <p>Usage:</p> <p>When defining a table model, after declaring <code>__tablename_</code>_, set the <code>type_annotation_map</code>, i.e.:</p> <pre><code>class ExampleModel(Base):\n    __tablename__ = \"__sometable__\"\n\n    type_annotation_map = {uuid.UUID: CompatibleUUID}\n</code></pre> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\custom_types\\type_classes.py</code> <pre><code>class CompatibleUUID(TypeDecorator):\n    \"\"\"Define a custom UUID, overriding SQLAlchemy's UUId type.\n\n    The main purpose of this class is to instruct SQLAlchemy to\n    store UUIDs as a binary, instead of as a UUID type. This is\n    useful for cross-database support, i.e. for SQLite which does\n    not support the UUID type.\n\n    !!! note\n    - [SQLAlchemy docs: backend agnostic GUID type](https://docs.sqlalchemy.org/en/20/core/custom_types.html#backend-agnostic-guid-type)\n\n    Usage:\n\n    When defining a table model, after declaring `__tablename_`_, set the `type_annotation_map`, i.e.:\n\n    ``` py linenums=\"1\"\n    class ExampleModel(Base):\n        __tablename__ = \"__sometable__\"\n\n        type_annotation_map = {uuid.UUID: CompatibleUUID}\n    ```\n    \"\"\"\n\n    impl = sa.BINARY\n    cache_ok = True\n\n    def load_diaclect_impl(self, dialect):\n        if dialect.name == \"postgresql\":\n            return dialect.type_descriptor(UUID())\n        else:\n            return dialect.type_descriptor(CHAR(32))\n\n    def process_bind_param(self, value, dialect):\n        if value is None:\n            return value\n        elif dialect.name == \"postgresql\":\n            return str(value)\n        else:\n            if not isinstance(value, uuid.UUID):\n                return \"%.32x\" % uuid.UUID(value).int\n            else:\n                ## Return hexstring\n                return \"%.32x\" % value.int\n\n    def process_result_value(self, value: Any | None, dialect: Dialect) -&gt; Any | None:\n        if value is None:\n            return value\n        else:\n            if not isinstance(value, uuid.UUID):\n                value = uuid.UUID(value)\n            return value\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/custom_types/type_classes/#red_utils.ext.sqlalchemy_utils.custom_types.type_classes.CustomJSON","title":"<code>CustomJSON</code>","text":"<p>               Bases: <code>TypeDecorator</code></p> <p>Class to handle storing JSON in a database.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\custom_types\\type_classes.py</code> <pre><code>class CustomJSON(TypeDecorator):\n    \"\"\"Class to handle storing JSON in a database.\"\"\"\n\n    @property\n    def python_type(self):\n        return object\n\n    impl = types.String\n\n    def process_bind_param(self, value, dialect):\n        return json.dumps(value)\n\n    def process_literal_param(self, value, dialect):\n        return value\n\n    def process_result_value(self, value, dialect):\n        try:\n            return json.loads(value)\n        except (ValueError, TypeError):\n            return None\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/mixins/__init__/","title":"mixins","text":""},{"location":"reference/red_utils/ext/sqlalchemy_utils/mixins/__init__/#red_utils.ext.sqlalchemy_utils.mixins.TableNameMixin","title":"<code>TableNameMixin</code>","text":"<p>Mixin to automatically name tables based on class name.</p> <p>Generates a <code>__tablename__</code> for classes inheriting from this mixin.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\mixins\\table_mixins.py</code> <pre><code>class TableNameMixin:\n    \"\"\"Mixin to automatically name tables based on class name.\n\n    Generates a `__tablename__` for classes inheriting from this mixin.\n    \"\"\"\n\n    @so.declared_attr.directive\n    def __tablename__(cls) -&gt; str:  # noqa: D105\n        return cls.__name__.lower() + \"s\"\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/mixins/__init__/#red_utils.ext.sqlalchemy_utils.mixins.TimestampMixin","title":"<code>TimestampMixin</code>","text":"<p>Add a created_at &amp; updated_at column to records.</p> <p>Add to class declaration to automatically create these columns on records.</p> <p>Usage:</p> <p>``` py linenums=1 class Record(Base, TimestampMixin):     tablename = ...</p> <pre><code>...\n</code></pre> <p>```</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\mixins\\table_mixins.py</code> <pre><code>class TimestampMixin:\n    \"\"\"Add a created_at &amp; updated_at column to records.\n\n    Add to class declaration to automatically create these columns on\n    records.\n\n    Usage:\n\n    ``` py linenums=1\n    class Record(Base, TimestampMixin):\n        __tablename__ = ...\n\n        ...\n    ```\n    \"\"\"\n\n    created_at: so.Mapped[datetime] = so.mapped_column(\n        sa.TIMESTAMP, server_default=sa.func.now()\n    )\n    updated_at: so.Mapped[datetime] = so.mapped_column(\n        sa.TIMESTAMP, server_default=sa.func.now(), onupdate=sa.func.now()\n    )\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/mixins/table_mixins/","title":"table_mixins","text":"<p>SQLAlchemy models support multi-inheritance.</p> <p>\"Mixins\" (SQLAlchemy declarative mixins docs) are partial classes that predefine some attributes and methods. These can enhance SQLAlchemy table classes you create (model classes that inherit from your <code>Base</code>), like adding a \"modified\" timestamp, or automatically naaming tables based on the model class's name.</p>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/mixins/table_mixins/#red_utils.ext.sqlalchemy_utils.mixins.table_mixins.TableNameMixin","title":"<code>TableNameMixin</code>","text":"<p>Mixin to automatically name tables based on class name.</p> <p>Generates a <code>__tablename__</code> for classes inheriting from this mixin.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\mixins\\table_mixins.py</code> <pre><code>class TableNameMixin:\n    \"\"\"Mixin to automatically name tables based on class name.\n\n    Generates a `__tablename__` for classes inheriting from this mixin.\n    \"\"\"\n\n    @so.declared_attr.directive\n    def __tablename__(cls) -&gt; str:  # noqa: D105\n        return cls.__name__.lower() + \"s\"\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/mixins/table_mixins/#red_utils.ext.sqlalchemy_utils.mixins.table_mixins.TimestampMixin","title":"<code>TimestampMixin</code>","text":"<p>Add a created_at &amp; updated_at column to records.</p> <p>Add to class declaration to automatically create these columns on records.</p> <p>Usage:</p> <p>``` py linenums=1 class Record(Base, TimestampMixin):     tablename = ...</p> <pre><code>...\n</code></pre> <p>```</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\mixins\\table_mixins.py</code> <pre><code>class TimestampMixin:\n    \"\"\"Add a created_at &amp; updated_at column to records.\n\n    Add to class declaration to automatically create these columns on\n    records.\n\n    Usage:\n\n    ``` py linenums=1\n    class Record(Base, TimestampMixin):\n        __tablename__ = ...\n\n        ...\n    ```\n    \"\"\"\n\n    created_at: so.Mapped[datetime] = so.mapped_column(\n        sa.TIMESTAMP, server_default=sa.func.now()\n    )\n    updated_at: so.Mapped[datetime] = so.mapped_column(\n        sa.TIMESTAMP, server_default=sa.func.now(), onupdate=sa.func.now()\n    )\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/repository/__init__/","title":"repository","text":""},{"location":"reference/red_utils/ext/sqlalchemy_utils/repository/__init__/#red_utils.ext.sqlalchemy_utils.repository.RepositoryBase","title":"<code>RepositoryBase</code>","text":"<p>               Bases: <code>Generic[T]</code></p> <p>A generic SQLAlchemy repository class base.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\repository\\_repository.py</code> <pre><code>class RepositoryBase(t.Generic[T], metaclass=abc.ABCMeta):\n    \"\"\"A generic SQLAlchemy repository class base.\"\"\"\n\n    @abc.abstractmethod\n    def add(self, entity: T):\n        \"\"\"Add new entity to database.\"\"\"\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def update(self, entity: T):\n        \"\"\"Update existing entity.\"\"\"\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def remove(self, entity: T):\n        \"\"\"Remove existing entity from database.\"\"\"\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def get_by_id(self, entity_id) -&gt; T:\n        \"\"\"Retrieve entity from database by its ID.\"\"\"\n        raise NotImplementedError()\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/repository/__init__/#red_utils.ext.sqlalchemy_utils.repository.RepositoryBase.add","title":"<code>add(entity)</code>  <code>abstractmethod</code>","text":"<p>Add new entity to database.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\repository\\_repository.py</code> <pre><code>@abc.abstractmethod\ndef add(self, entity: T):\n    \"\"\"Add new entity to database.\"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/repository/__init__/#red_utils.ext.sqlalchemy_utils.repository.RepositoryBase.get_by_id","title":"<code>get_by_id(entity_id)</code>  <code>abstractmethod</code>","text":"<p>Retrieve entity from database by its ID.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\repository\\_repository.py</code> <pre><code>@abc.abstractmethod\ndef get_by_id(self, entity_id) -&gt; T:\n    \"\"\"Retrieve entity from database by its ID.\"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/repository/__init__/#red_utils.ext.sqlalchemy_utils.repository.RepositoryBase.remove","title":"<code>remove(entity)</code>  <code>abstractmethod</code>","text":"<p>Remove existing entity from database.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\repository\\_repository.py</code> <pre><code>@abc.abstractmethod\ndef remove(self, entity: T):\n    \"\"\"Remove existing entity from database.\"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/repository/__init__/#red_utils.ext.sqlalchemy_utils.repository.RepositoryBase.update","title":"<code>update(entity)</code>  <code>abstractmethod</code>","text":"<p>Update existing entity.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\repository\\_repository.py</code> <pre><code>@abc.abstractmethod\ndef update(self, entity: T):\n    \"\"\"Update existing entity.\"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/repository/_repository/","title":"_repository","text":""},{"location":"reference/red_utils/ext/sqlalchemy_utils/repository/_repository/#red_utils.ext.sqlalchemy_utils.repository._repository.RepositoryBase","title":"<code>RepositoryBase</code>","text":"<p>               Bases: <code>Generic[T]</code></p> <p>A generic SQLAlchemy repository class base.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\repository\\_repository.py</code> <pre><code>class RepositoryBase(t.Generic[T], metaclass=abc.ABCMeta):\n    \"\"\"A generic SQLAlchemy repository class base.\"\"\"\n\n    @abc.abstractmethod\n    def add(self, entity: T):\n        \"\"\"Add new entity to database.\"\"\"\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def update(self, entity: T):\n        \"\"\"Update existing entity.\"\"\"\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def remove(self, entity: T):\n        \"\"\"Remove existing entity from database.\"\"\"\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def get_by_id(self, entity_id) -&gt; T:\n        \"\"\"Retrieve entity from database by its ID.\"\"\"\n        raise NotImplementedError()\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/repository/_repository/#red_utils.ext.sqlalchemy_utils.repository._repository.RepositoryBase.add","title":"<code>add(entity)</code>  <code>abstractmethod</code>","text":"<p>Add new entity to database.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\repository\\_repository.py</code> <pre><code>@abc.abstractmethod\ndef add(self, entity: T):\n    \"\"\"Add new entity to database.\"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/repository/_repository/#red_utils.ext.sqlalchemy_utils.repository._repository.RepositoryBase.get_by_id","title":"<code>get_by_id(entity_id)</code>  <code>abstractmethod</code>","text":"<p>Retrieve entity from database by its ID.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\repository\\_repository.py</code> <pre><code>@abc.abstractmethod\ndef get_by_id(self, entity_id) -&gt; T:\n    \"\"\"Retrieve entity from database by its ID.\"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/repository/_repository/#red_utils.ext.sqlalchemy_utils.repository._repository.RepositoryBase.remove","title":"<code>remove(entity)</code>  <code>abstractmethod</code>","text":"<p>Remove existing entity from database.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\repository\\_repository.py</code> <pre><code>@abc.abstractmethod\ndef remove(self, entity: T):\n    \"\"\"Remove existing entity from database.\"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/red_utils/ext/sqlalchemy_utils/repository/_repository/#red_utils.ext.sqlalchemy_utils.repository._repository.RepositoryBase.update","title":"<code>update(entity)</code>  <code>abstractmethod</code>","text":"<p>Update existing entity.</p> Source code in <code>src\\red_utils\\ext\\sqlalchemy_utils\\repository\\_repository.py</code> <pre><code>@abc.abstractmethod\ndef update(self, entity: T):\n    \"\"\"Update existing entity.\"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/red_utils/ext/time_utils/__init__/","title":"time_utils","text":"<p>Utilities for the <code>pendulum</code> library.</p>"},{"location":"reference/red_utils/ext/time_utils/__init__/#red_utils.ext.time_utils.MissingDependencyException","title":"<code>MissingDependencyException</code>  <code>dataclass</code>","text":"<p>               Bases: <code>CustomException</code></p> <p>Exception to raise when an import is called but a dependency is missing.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>A message to display with the exception.</p> <code>'Custom exception called'</code> <code>errors</code> <code>Any</code> <p>Property to store arbitrary data. Meant to be used for errors associated with the exception.</p> <code>None</code> <code>extra</code> <code>Any</code> <p>Property to store arbitrary data. Data stored in this property can be a Python object (i.e. a class instance, dict, str, or other), a list of objects/strings, etc.</p> <code>None</code> Usage <pre><code>try:\n    ...\nexcept CustomException as exc:\n    raise CustomException(msg=\"Custom exception occurred\", errors=exc)\n</code></pre> Source code in <code>src\\red_utils\\exc\\import_exc\\_import.py</code> <pre><code>@dataclass\nclass MissingDependencyException(CustomException):\n    \"\"\"Exception to raise when an import is called but a dependency is missing.\n\n    Params:\n        msg (str): A message to display with the exception.\n        errors (Any): Property to store arbitrary data. Meant to be used for errors associated with the exception.\n        extra (Any): Property to store arbitrary data.\n            Data stored in this property can be a Python object (i.e. a class\n            instance, dict, str, or other), a list of objects/strings, etc.\n\n    Usage:\n        ``` py\n        try:\n            ...\n        except CustomException as exc:\n            raise CustomException(msg=\"Custom exception occurred\", errors=exc)\n        ```\n    \"\"\"\n\n    errors: Any | None = field(default=None)\n    extra: Any | None = field(default=None)\n    missing_dependencies: list[str] | None = field(default_factory=list())\n\n    def __repr__(self):\n        repr_str: str = f\"{self.msg!r}\"\n\n        if self.errors is not None:\n            repr_str: str = f\"{repr_str}\\nErrors: {self.errors!r}\"\n        if self.extra is not None:\n            repr_str: str = f\"{repr_str}\\nExtra: {self.extra!r}\"\n\n        return repr_str\n\n    def __str__(self):\n        return repr(self)\n\n    @property\n    def exc_msg(self):\n        msg = CustomModuleNotFoundError(\n            msg=self.msg, missing_dependencies=self.missing_dependencies\n        )\n\n        return msg\n</code></pre>"},{"location":"reference/red_utils/ext/time_utils/__init__/#red_utils.ext.time_utils.get_ts","title":"<code>get_ts(tz=DEFAULT_TZ, as_str=False, str_fmt=TIME_FMT_24H, safe_str=False, char_replace_map=TS_STR_REPLACE_MAP)</code>","text":"<p>Return a <code>pendulum.DateTime</code> object of the current time.</p> <p>Optionally return timestamp as a string.</p> <p>Parameters:</p> Name Type Description Default <code>tz</code> <code>str</code> <p>Unix timezone string, defaults to <code>'America/New_York'</code>. Note: Unix timezone strings</p> <code>DEFAULT_TZ</code> <code>as_str</code> <code>bool</code> <p>If <code>True</code>, returns timestamp as a string instead of <code>DateTime</code>.</p> <code>False</code> <code>str_fmt</code> <code>str</code> <p>String that defines the format of the timestamp if <code>as_str=True</code>. Note: Pendulum Docs: String Formatting</p> <code>TIME_FMT_24H</code> <code>safe_str</code> <code>bool</code> <p>If <code>True</code>, replaces characters (like <code>':'</code> and <code>' '</code>) with a string value that is safe to use in a terminal, as a filename, etc (like <code>-</code> and <code>_</code>).</p> <code>False</code> <code>char_replace_map</code> <code>list[dict]</code> <p>A list of dicts defining characters to search for and replace in the timestamp str. Example replace map: <code>[{\"search\": \":\", \"replace\": \"-\"}, {\"search\": \" \", \"replace\": \"_\"}]</code></p> <code>TS_STR_REPLACE_MAP</code> <p>Returns:</p> Type Description <code>DateTime</code> <p>A <code>pendulum.DateTime</code> object of the current time</p> <code>str</code> <p>If <code>as_str=True</code>, returns a string representation of the <code>pendulum.DateTime</code> timestamp, formatted by <code>str_fmt</code></p> Source code in <code>src\\red_utils\\ext\\time_utils\\pendulum_utils\\operations.py</code> <pre><code>def get_ts(\n    tz: str = DEFAULT_TZ,\n    as_str: bool = False,\n    str_fmt: str = TIME_FMT_24H,\n    safe_str: bool = False,\n    char_replace_map: list[dict] = TS_STR_REPLACE_MAP,\n) -&gt; Union[str, pendulum.DateTime]:\n    \"\"\"Return a `pendulum.DateTime` object of the current time.\n\n    Optionally return timestamp as a string.\n\n    Params:\n        tz (str): Unix timezone string, defaults to `'America/New_York'`.\n            **Note**: [Unix timezone strings](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones)\n        as_str (bool): If `True`, returns timestamp as a string instead of `DateTime`.\n        str_fmt (str): String that defines the format of the timestamp if `as_str=True`.\n            **Note**: [Pendulum Docs: String Formatting](https://pendulum.eustace.io/docs/#string-formatting)\n        safe_str (bool): If `True`, replaces characters (like `':'` and `' '`) with a string value that is safe\n            to use in a terminal, as a filename, etc (like `-` and `_`).\n        char_replace_map (list[dict]): A list of dicts defining characters to search for and replace\n            in the timestamp str.\n            Example replace map: `[{\"search\": \":\", \"replace\": \"-\"}, {\"search\": \" \", \"replace\": \"_\"}]`\n\n    Returns:\n        (pendulum.DateTime): A `pendulum.DateTime` object of the current time\n        (str): If `as_str=True`, returns a string representation of the `pendulum.DateTime` timestamp, formatted by `str_fmt`\n\n    \"\"\"\n    now: pendulum.DateTime = pendulum.now(tz=tz)\n\n    if not as_str:\n        return now\n    else:\n        if safe_str:\n            str_fmt\n\n            for r in char_replace_map:\n                str_fmt = str_fmt.replace(r[\"search\"], r[\"replace\"])\n\n        now_fmt: str = now.format(fmt=str_fmt)\n\n        return now_fmt\n</code></pre>"},{"location":"reference/red_utils/ext/time_utils/__init__/#red_utils.ext.time_utils.validate_time_period","title":"<code>validate_time_period(period=None)</code>","text":"<p>Validate a time period string.</p> <p>Pass a time period (i.e. \"days\", \"weeks\", etc). If the period matches a valid time period, string is returned, otherwise a ValueError is raised.</p> <p>Parameters:</p> Name Type Description Default <code>period</code> <code>str</code> <p>A period of time, like 'days' or 'weeks'</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\time_utils\\pendulum_utils\\validators.py</code> <pre><code>def validate_time_period(period: str = None) -&gt; str:\n    \"\"\"Validate a time period string.\n\n    Pass a time period (i.e. \"days\", \"weeks\", etc). If the period\n    matches a valid time period, string is returned, otherwise a\n    ValueError is raised.\n\n    Params:\n        period (str): A period of time, like 'days' or 'weeks'\n    \"\"\"\n    if period is None:\n        raise ValueError(\"Missing a time period to evaluate\")\n    if not isinstance(period, str):\n        raise TypeError(\n            f\"Invalid type for time period: ({type(period)}). Must be one of {VALID_TIME_PERIODS}\"\n        )\n    if period not in VALID_TIME_PERIODS:\n        raise ValueError(\n            f\"Invalid time period: '{period}'. Must be one of {VALID_TIME_PERIODS}\"\n        )\n\n    return period\n</code></pre>"},{"location":"reference/red_utils/ext/time_utils/pendulum_utils/__init__/","title":"pendulum_utils","text":"<p>Utilities, constants, &amp; classes for the <code>pendulum</code> library.</p>"},{"location":"reference/red_utils/ext/time_utils/pendulum_utils/__init__/#red_utils.ext.time_utils.pendulum_utils.MissingDependencyException","title":"<code>MissingDependencyException</code>  <code>dataclass</code>","text":"<p>               Bases: <code>CustomException</code></p> <p>Exception to raise when an import is called but a dependency is missing.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>A message to display with the exception.</p> <code>'Custom exception called'</code> <code>errors</code> <code>Any</code> <p>Property to store arbitrary data. Meant to be used for errors associated with the exception.</p> <code>None</code> <code>extra</code> <code>Any</code> <p>Property to store arbitrary data. Data stored in this property can be a Python object (i.e. a class instance, dict, str, or other), a list of objects/strings, etc.</p> <code>None</code> Usage <pre><code>try:\n    ...\nexcept CustomException as exc:\n    raise CustomException(msg=\"Custom exception occurred\", errors=exc)\n</code></pre> Source code in <code>src\\red_utils\\exc\\import_exc\\_import.py</code> <pre><code>@dataclass\nclass MissingDependencyException(CustomException):\n    \"\"\"Exception to raise when an import is called but a dependency is missing.\n\n    Params:\n        msg (str): A message to display with the exception.\n        errors (Any): Property to store arbitrary data. Meant to be used for errors associated with the exception.\n        extra (Any): Property to store arbitrary data.\n            Data stored in this property can be a Python object (i.e. a class\n            instance, dict, str, or other), a list of objects/strings, etc.\n\n    Usage:\n        ``` py\n        try:\n            ...\n        except CustomException as exc:\n            raise CustomException(msg=\"Custom exception occurred\", errors=exc)\n        ```\n    \"\"\"\n\n    errors: Any | None = field(default=None)\n    extra: Any | None = field(default=None)\n    missing_dependencies: list[str] | None = field(default_factory=list())\n\n    def __repr__(self):\n        repr_str: str = f\"{self.msg!r}\"\n\n        if self.errors is not None:\n            repr_str: str = f\"{repr_str}\\nErrors: {self.errors!r}\"\n        if self.extra is not None:\n            repr_str: str = f\"{repr_str}\\nExtra: {self.extra!r}\"\n\n        return repr_str\n\n    def __str__(self):\n        return repr(self)\n\n    @property\n    def exc_msg(self):\n        msg = CustomModuleNotFoundError(\n            msg=self.msg, missing_dependencies=self.missing_dependencies\n        )\n\n        return msg\n</code></pre>"},{"location":"reference/red_utils/ext/time_utils/pendulum_utils/__init__/#red_utils.ext.time_utils.pendulum_utils.get_ts","title":"<code>get_ts(tz=DEFAULT_TZ, as_str=False, str_fmt=TIME_FMT_24H, safe_str=False, char_replace_map=TS_STR_REPLACE_MAP)</code>","text":"<p>Return a <code>pendulum.DateTime</code> object of the current time.</p> <p>Optionally return timestamp as a string.</p> <p>Parameters:</p> Name Type Description Default <code>tz</code> <code>str</code> <p>Unix timezone string, defaults to <code>'America/New_York'</code>. Note: Unix timezone strings</p> <code>DEFAULT_TZ</code> <code>as_str</code> <code>bool</code> <p>If <code>True</code>, returns timestamp as a string instead of <code>DateTime</code>.</p> <code>False</code> <code>str_fmt</code> <code>str</code> <p>String that defines the format of the timestamp if <code>as_str=True</code>. Note: Pendulum Docs: String Formatting</p> <code>TIME_FMT_24H</code> <code>safe_str</code> <code>bool</code> <p>If <code>True</code>, replaces characters (like <code>':'</code> and <code>' '</code>) with a string value that is safe to use in a terminal, as a filename, etc (like <code>-</code> and <code>_</code>).</p> <code>False</code> <code>char_replace_map</code> <code>list[dict]</code> <p>A list of dicts defining characters to search for and replace in the timestamp str. Example replace map: <code>[{\"search\": \":\", \"replace\": \"-\"}, {\"search\": \" \", \"replace\": \"_\"}]</code></p> <code>TS_STR_REPLACE_MAP</code> <p>Returns:</p> Type Description <code>DateTime</code> <p>A <code>pendulum.DateTime</code> object of the current time</p> <code>str</code> <p>If <code>as_str=True</code>, returns a string representation of the <code>pendulum.DateTime</code> timestamp, formatted by <code>str_fmt</code></p> Source code in <code>src\\red_utils\\ext\\time_utils\\pendulum_utils\\operations.py</code> <pre><code>def get_ts(\n    tz: str = DEFAULT_TZ,\n    as_str: bool = False,\n    str_fmt: str = TIME_FMT_24H,\n    safe_str: bool = False,\n    char_replace_map: list[dict] = TS_STR_REPLACE_MAP,\n) -&gt; Union[str, pendulum.DateTime]:\n    \"\"\"Return a `pendulum.DateTime` object of the current time.\n\n    Optionally return timestamp as a string.\n\n    Params:\n        tz (str): Unix timezone string, defaults to `'America/New_York'`.\n            **Note**: [Unix timezone strings](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones)\n        as_str (bool): If `True`, returns timestamp as a string instead of `DateTime`.\n        str_fmt (str): String that defines the format of the timestamp if `as_str=True`.\n            **Note**: [Pendulum Docs: String Formatting](https://pendulum.eustace.io/docs/#string-formatting)\n        safe_str (bool): If `True`, replaces characters (like `':'` and `' '`) with a string value that is safe\n            to use in a terminal, as a filename, etc (like `-` and `_`).\n        char_replace_map (list[dict]): A list of dicts defining characters to search for and replace\n            in the timestamp str.\n            Example replace map: `[{\"search\": \":\", \"replace\": \"-\"}, {\"search\": \" \", \"replace\": \"_\"}]`\n\n    Returns:\n        (pendulum.DateTime): A `pendulum.DateTime` object of the current time\n        (str): If `as_str=True`, returns a string representation of the `pendulum.DateTime` timestamp, formatted by `str_fmt`\n\n    \"\"\"\n    now: pendulum.DateTime = pendulum.now(tz=tz)\n\n    if not as_str:\n        return now\n    else:\n        if safe_str:\n            str_fmt\n\n            for r in char_replace_map:\n                str_fmt = str_fmt.replace(r[\"search\"], r[\"replace\"])\n\n        now_fmt: str = now.format(fmt=str_fmt)\n\n        return now_fmt\n</code></pre>"},{"location":"reference/red_utils/ext/time_utils/pendulum_utils/constants/","title":"constants","text":"<p>Constant values to use as defaults for the <code>pendulum_utils</code> module.</p> <p>Examples: <pre><code>TIME_FMT_24H: str = \"YYYY-MM-DD HH:MM:SS\"\nTIME_FMT_12H: str = \"YYYY-MM-DD hh:mm:ssA\"\nDEFAULT_TZ: str = \"America/New_York\"\n\nTS_STR_REPLACE_MAP = [\n    {\"search\": \":\", \"replace\": \"-\"},\n    {\"search\": \" \", \"replace\": \"_\"},\n]\n\nVALID_TIME_PERIODS: list[str] = [\n    \"years\",\n    \"months\",\n    \"weeks\",\n    \"days\",\n    \"hours\",\n    \"minutes\",\n    \"seconds\",\n]\n</code></pre></p>"},{"location":"reference/red_utils/ext/time_utils/pendulum_utils/operations/","title":"operations","text":""},{"location":"reference/red_utils/ext/time_utils/pendulum_utils/operations/#red_utils.ext.time_utils.pendulum_utils.operations.MissingDependencyException","title":"<code>MissingDependencyException</code>  <code>dataclass</code>","text":"<p>               Bases: <code>CustomException</code></p> <p>Exception to raise when an import is called but a dependency is missing.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>A message to display with the exception.</p> <code>'Custom exception called'</code> <code>errors</code> <code>Any</code> <p>Property to store arbitrary data. Meant to be used for errors associated with the exception.</p> <code>None</code> <code>extra</code> <code>Any</code> <p>Property to store arbitrary data. Data stored in this property can be a Python object (i.e. a class instance, dict, str, or other), a list of objects/strings, etc.</p> <code>None</code> Usage <pre><code>try:\n    ...\nexcept CustomException as exc:\n    raise CustomException(msg=\"Custom exception occurred\", errors=exc)\n</code></pre> Source code in <code>src\\red_utils\\exc\\import_exc\\_import.py</code> <pre><code>@dataclass\nclass MissingDependencyException(CustomException):\n    \"\"\"Exception to raise when an import is called but a dependency is missing.\n\n    Params:\n        msg (str): A message to display with the exception.\n        errors (Any): Property to store arbitrary data. Meant to be used for errors associated with the exception.\n        extra (Any): Property to store arbitrary data.\n            Data stored in this property can be a Python object (i.e. a class\n            instance, dict, str, or other), a list of objects/strings, etc.\n\n    Usage:\n        ``` py\n        try:\n            ...\n        except CustomException as exc:\n            raise CustomException(msg=\"Custom exception occurred\", errors=exc)\n        ```\n    \"\"\"\n\n    errors: Any | None = field(default=None)\n    extra: Any | None = field(default=None)\n    missing_dependencies: list[str] | None = field(default_factory=list())\n\n    def __repr__(self):\n        repr_str: str = f\"{self.msg!r}\"\n\n        if self.errors is not None:\n            repr_str: str = f\"{repr_str}\\nErrors: {self.errors!r}\"\n        if self.extra is not None:\n            repr_str: str = f\"{repr_str}\\nExtra: {self.extra!r}\"\n\n        return repr_str\n\n    def __str__(self):\n        return repr(self)\n\n    @property\n    def exc_msg(self):\n        msg = CustomModuleNotFoundError(\n            msg=self.msg, missing_dependencies=self.missing_dependencies\n        )\n\n        return msg\n</code></pre>"},{"location":"reference/red_utils/ext/time_utils/pendulum_utils/operations/#red_utils.ext.time_utils.pendulum_utils.operations.get_ts","title":"<code>get_ts(tz=DEFAULT_TZ, as_str=False, str_fmt=TIME_FMT_24H, safe_str=False, char_replace_map=TS_STR_REPLACE_MAP)</code>","text":"<p>Return a <code>pendulum.DateTime</code> object of the current time.</p> <p>Optionally return timestamp as a string.</p> <p>Parameters:</p> Name Type Description Default <code>tz</code> <code>str</code> <p>Unix timezone string, defaults to <code>'America/New_York'</code>. Note: Unix timezone strings</p> <code>DEFAULT_TZ</code> <code>as_str</code> <code>bool</code> <p>If <code>True</code>, returns timestamp as a string instead of <code>DateTime</code>.</p> <code>False</code> <code>str_fmt</code> <code>str</code> <p>String that defines the format of the timestamp if <code>as_str=True</code>. Note: Pendulum Docs: String Formatting</p> <code>TIME_FMT_24H</code> <code>safe_str</code> <code>bool</code> <p>If <code>True</code>, replaces characters (like <code>':'</code> and <code>' '</code>) with a string value that is safe to use in a terminal, as a filename, etc (like <code>-</code> and <code>_</code>).</p> <code>False</code> <code>char_replace_map</code> <code>list[dict]</code> <p>A list of dicts defining characters to search for and replace in the timestamp str. Example replace map: <code>[{\"search\": \":\", \"replace\": \"-\"}, {\"search\": \" \", \"replace\": \"_\"}]</code></p> <code>TS_STR_REPLACE_MAP</code> <p>Returns:</p> Type Description <code>DateTime</code> <p>A <code>pendulum.DateTime</code> object of the current time</p> <code>str</code> <p>If <code>as_str=True</code>, returns a string representation of the <code>pendulum.DateTime</code> timestamp, formatted by <code>str_fmt</code></p> Source code in <code>src\\red_utils\\ext\\time_utils\\pendulum_utils\\operations.py</code> <pre><code>def get_ts(\n    tz: str = DEFAULT_TZ,\n    as_str: bool = False,\n    str_fmt: str = TIME_FMT_24H,\n    safe_str: bool = False,\n    char_replace_map: list[dict] = TS_STR_REPLACE_MAP,\n) -&gt; Union[str, pendulum.DateTime]:\n    \"\"\"Return a `pendulum.DateTime` object of the current time.\n\n    Optionally return timestamp as a string.\n\n    Params:\n        tz (str): Unix timezone string, defaults to `'America/New_York'`.\n            **Note**: [Unix timezone strings](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones)\n        as_str (bool): If `True`, returns timestamp as a string instead of `DateTime`.\n        str_fmt (str): String that defines the format of the timestamp if `as_str=True`.\n            **Note**: [Pendulum Docs: String Formatting](https://pendulum.eustace.io/docs/#string-formatting)\n        safe_str (bool): If `True`, replaces characters (like `':'` and `' '`) with a string value that is safe\n            to use in a terminal, as a filename, etc (like `-` and `_`).\n        char_replace_map (list[dict]): A list of dicts defining characters to search for and replace\n            in the timestamp str.\n            Example replace map: `[{\"search\": \":\", \"replace\": \"-\"}, {\"search\": \" \", \"replace\": \"_\"}]`\n\n    Returns:\n        (pendulum.DateTime): A `pendulum.DateTime` object of the current time\n        (str): If `as_str=True`, returns a string representation of the `pendulum.DateTime` timestamp, formatted by `str_fmt`\n\n    \"\"\"\n    now: pendulum.DateTime = pendulum.now(tz=tz)\n\n    if not as_str:\n        return now\n    else:\n        if safe_str:\n            str_fmt\n\n            for r in char_replace_map:\n                str_fmt = str_fmt.replace(r[\"search\"], r[\"replace\"])\n\n        now_fmt: str = now.format(fmt=str_fmt)\n\n        return now_fmt\n</code></pre>"},{"location":"reference/red_utils/ext/time_utils/pendulum_utils/validators/","title":"validators","text":""},{"location":"reference/red_utils/ext/time_utils/pendulum_utils/validators/#red_utils.ext.time_utils.pendulum_utils.validators.validate_time_period","title":"<code>validate_time_period(period=None)</code>","text":"<p>Validate a time period string.</p> <p>Pass a time period (i.e. \"days\", \"weeks\", etc). If the period matches a valid time period, string is returned, otherwise a ValueError is raised.</p> <p>Parameters:</p> Name Type Description Default <code>period</code> <code>str</code> <p>A period of time, like 'days' or 'weeks'</p> <code>None</code> Source code in <code>src\\red_utils\\ext\\time_utils\\pendulum_utils\\validators.py</code> <pre><code>def validate_time_period(period: str = None) -&gt; str:\n    \"\"\"Validate a time period string.\n\n    Pass a time period (i.e. \"days\", \"weeks\", etc). If the period\n    matches a valid time period, string is returned, otherwise a\n    ValueError is raised.\n\n    Params:\n        period (str): A period of time, like 'days' or 'weeks'\n    \"\"\"\n    if period is None:\n        raise ValueError(\"Missing a time period to evaluate\")\n    if not isinstance(period, str):\n        raise TypeError(\n            f\"Invalid type for time period: ({type(period)}). Must be one of {VALID_TIME_PERIODS}\"\n        )\n    if period not in VALID_TIME_PERIODS:\n        raise ValueError(\n            f\"Invalid time period: '{period}'. Must be one of {VALID_TIME_PERIODS}\"\n        )\n\n    return period\n</code></pre>"},{"location":"reference/red_utils/std/__init__/","title":"std","text":"<p>Utilities that rely only on the Python <code>stdlib</code>. Any module in this package should be safe to import &amp; use without external dependencies.</p> <p>TODO: Write tests to ensure <code>red_utils.std</code> can be run successfully with no dependencies.</p>"},{"location":"reference/red_utils/std/context_managers/__init__/","title":"context_managers","text":"<p>A collection of context managers I use. Contains managers for database operations, function benchmarks, and classes that aid in updating <code>dict</code>s and <code>list</code>s by creating a working copy that only overwrites the original if the operation succeeds.</p>"},{"location":"reference/red_utils/std/context_managers/__init__/#red_utils.std.context_managers.DictProtect","title":"<code>DictProtect</code>","text":"<p>Protect a dict during modification by modifying a copy instead of the original.</p> <p>DictProtect creates a copy of a dict before running operations like .update(), and prevents errors on the original object by destroying the copy if an error is encountered, only overwriting the original if no errors occur.</p> <p>Parameters:</p> Name Type Description Default <code>original</code> <code>dict</code> <p>The original Python <code>dict</code>. A copy will be made during any operations, and will only overwrite the original if the operation succeeds.</p> required <p>Usage:</p> <pre><code>    ex_dict = {\"example\": \"value\"}\n\n    ## Protects from a ZeroDivision error\n    with DictProtect(ex_dict) as copy:\n        copy[\"example\"] = 1 / 0\n\n    print(f'Dict: {ex_dict}')\n</code></pre> Source code in <code>src\\red_utils\\std\\context_managers\\object_managers\\protect.py</code> <pre><code>class DictProtect:\n    \"\"\"Protect a dict during modification by modifying a copy instead of the original.\n\n    DictProtect creates a copy of a dict before running operations like .update(), and prevents\n    errors on the original object by destroying the copy if an error is encountered, only\n    overwriting the original if no errors occur.\n\n    Params:\n        original (dict): The original Python `dict`. A copy will be made during any operations, and will only overwrite\n            the original if the operation succeeds.\n\n    Usage:\n\n    ``` py linenums=\"1\"\n        ex_dict = {\"example\": \"value\"}\n\n        ## Protects from a ZeroDivision error\n        with DictProtect(ex_dict) as copy:\n            copy[\"example\"] = 1 / 0\n\n        print(f'Dict: {ex_dict}')\n    ```\n    \"\"\"\n\n    def __init__(self, original: dict) -&gt; None:  # noqa: D107\n        ## Call immediately after with DictProtect() as copy.\n        if not isinstance(original, dict):\n            raise TypeError(\n                f\"Invalid type for protected dict: ({type(original)}). Must be of type dict.\"\n            )\n\n        ## Set class value to original dict\n        self.original = original\n\n    def __enter__(self) -&gt; dict:  # noqa: D105\n        ## Call after initializing DictProtect instance.\n        ## Create a copy of the dict to work on\n        self.clone: dict = self.original.copy()\n\n        return self.clone\n\n    def __exit__(self, exc_type, exc_value, exc_traceback) -&gt; bool:  # noqa: D105\n        ## Call if DictProtect context manager encounters an error.\n        ## No exception encountered, update original\n        #  list and return\n        if exc_type is None:\n            self.original.update(self.clone)\n        if exc_traceback:\n            log.error(exc_traceback)\n\n        ## Error encountered, print details\n        else:\n            ## https://docs.python.org/3/library/inspect.html?highlight=currentframe\n            frame = inspect.currentframe()\n            ## Full path to error file\n            file_name = frame.f_code.co_filename\n            ## Line number where error occurred.\n            file_no = frame.f_lineno\n\n            ## Build error details dict\n            err = {\n                \"success\": False,\n                \"detail\": {\n                    \"module\": file_name,\n                    \"line\": file_no,\n                    \"exception_type\": exc_type,\n                    \"exception_text\": exc_value,\n                },\n            }\n\n            ## Return error, exit returning original list\n            log.error(\n                f\"Error encountered running dict operation on protected dict. Details: \\n{err}\"\n            )\n\n        return True\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/__init__/#red_utils.std.context_managers.ListProtect","title":"<code>ListProtect</code>","text":"<p>Protect a list during modification by modifying a copy instead of the original.</p> <p>ListProtect creates a copy of a list before running operations like .append(), and prevents errors on the original object by destroying the copy if an error is encountered, only overwriting the original if no errors occur.</p> <p>Parameters:</p> Name Type Description Default <code>original</code> <code>list</code> <p>The original Python <code>list</code>. A copy will be made during any operations, and will only overwrite the original if the operation succeeds.</p> required <p>Usage:</p> <pre><code>ex_list = [1, 2, 3]\n\n## Protects from a ZeroDivision error\nwith ListProtect(ex_list) as copy:\n    copy.append(1/0)\n\nprint(f'List: {ex_list}')\n</code></pre> Source code in <code>src\\red_utils\\std\\context_managers\\object_managers\\protect.py</code> <pre><code>class ListProtect:\n    \"\"\"Protect a list during modification by modifying a copy instead of the original.\n\n    ListProtect creates a copy of a list before running operations like .append(), and prevents\n    errors on the original object by destroying the copy if an error is encountered, only\n    overwriting the original if no errors occur.\n\n    Params:\n        original (list): The original Python `list`. A copy will be made during any operations, and will only overwrite\n            the original if the operation succeeds.\n\n    Usage:\n\n    ``` py linenums=\"1\"\n    ex_list = [1, 2, 3]\n\n    ## Protects from a ZeroDivision error\n    with ListProtect(ex_list) as copy:\n        copy.append(1/0)\n\n    print(f'List: {ex_list}')\n    ```\n    \"\"\"\n\n    def __init__(self, original: list):  # noqa: D107\n        ## Call immediately after with ListProtect() as copy.\n        if not isinstance(original, list):\n            raise TypeError(\n                f\"Invalid type for protected list: ({type(original)}). Must be of type list.\"\n            )\n\n        ## Set class value to original list\n        self.original = original\n\n    def __enter__(self):  # noqa: D105\n        ## Call after initializing ListProtect instance.\n        ## Create a copy of the list to work on\n        self.clone: list = self.original.copy()\n\n        return self.clone\n\n    def __exit__(self, exc_type, exc_value, exc_traceback) -&gt; bool:  # noqa: D105\n        ## Call if ListProtect context manager encounters an error.\n        ## No exception encountered, update original\n        #  list and return\n        if exc_type is None:\n            self.original[:] = self.clone\n        if exc_traceback:\n            log.error(exc_traceback)\n\n        ## Error encountered, print details\n        else:\n            ## https://docs.python.org/3/library/inspect.html?highlight=currentframe\n            frame = inspect.currentframe()\n            ## Full path to error file\n            file_name = frame.f_code.co_filename\n            ## Line number where error occurred.\n            file_no = frame.f_lineno\n\n            ## Build error details dict\n            err = {\n                \"success\": False,\n                \"detail\": {\n                    \"module\": file_name,\n                    \"line\": file_no,\n                    \"exception_type\": exc_type,\n                    \"exception_text\": exc_value,\n                },\n            }\n\n            ## Return error, exit returning original list\n            log.error(\n                f\"Error encountered running list operation on protected list. Details: \\n{err}\"\n            )\n\n        return True\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/__init__/#red_utils.std.context_managers.SQLiteConnManager","title":"<code>SQLiteConnManager</code>","text":"<p>Handle interactions with a SQLite database.</p> <p>Uses built-in functions to query a database, execute SQL statements, and gracefully open/close the DB using context managers.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>A path to a SQLite database file to work on.</p> required <p>Usage: Provide a path string to the SQLite database: <pre><code>sqlite_connection = SQLiteConnManager(path=\"/path/to/db.sqlite\")\n</code></pre></p> <p>Call sqlite3 functions, i.e. <code>.get_tables()</code>: <pre><code>tables = sqlite_conn.get_tables()\n</code></pre></p> Source code in <code>src\\red_utils\\std\\context_managers\\database_managers\\sqlite_managers.py</code> <pre><code>class SQLiteConnManager:\n    \"\"\"Handle interactions with a SQLite database.\n\n    Uses built-in functions to query a database, execute SQL statements,\n    and gracefully open/close the DB using context managers.\n\n    Params:\n        path (str | Path): A path to a SQLite database file to work on.\n\n    Usage:\n    Provide a path string to the SQLite database:\n    ``` py linenums=\"1\"\n    sqlite_connection = SQLiteConnManager(path=\"/path/to/db.sqlite\")\n    ```\n\n    Call sqlite3 functions, i.e. `.get_tables()`:\n    ``` py linenums=\"1\"\n    tables = sqlite_conn.get_tables()\n    ```\n    \"\"\"\n\n    def __init__(self, path: Path):  # noqa: D107\n        ## Initialize SQLite connection manager.\n        if isinstance(path, str):\n            path: Path = Path(path)\n\n        self.path = path\n\n    def __enter__(self):  # noqa: D105\n        ## Executed automatically when class is used as a context handler, like `with SQLiteConnManager() as conn: ...`\n        if not self.path.exists():\n            log.error(\n                FileNotFoundError(f\"Database does not exist at path: {self.path}.\")\n            )\n            with sqlite3.connect(self.path):\n                pass\n\n        try:\n            self.connection: sqlite3.Connection = sqlite3.connect(self.path)\n            self.connection.row_factory = sqlite3.Row\n            self.cursor: sqlite3.Cursor = self.connection.cursor()\n\n            ## Return self, a configured SQLite client\n            return self\n        except FileNotFoundError as fnf:\n            msg = FileNotFoundError(\n                f\"Database not found at path: {self.path}. Details: {fnf}\"\n            )\n            log.error(msg)\n\n            raise fnf\n        except PermissionError as perm:\n            msg = PermissionError(\n                f\"Unable to open database at path: {self.path}. Details: {perm}\"\n            )\n            log.error(msg)\n\n            raise perm\n        except sqlite3.Error as sqlite_exc:\n            msg = sqlite3.Error(f\"SQLite3 error encountered. Details: {sqlite_exc}\")\n            log.error(msg)\n\n            raise sqlite_exc\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception connecting to database. Details: ({exc.__class__}) {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def __exit__(self, exc_type, exc_val, exc_traceback):  # noqa: D105\n        if exc_val:\n            log.error(f\"({exc_type}): {exc_val}\")\n        if exc_traceback:\n            log.error(exc_traceback)\n\n        ## Executed automatically when `with SQLiteConnManager()` exits. Executes on success or failure.\n        self.connection.close()\n\n    def get_cols(self, table: str = None) -&gt; list[str]:\n        \"\"\"Return list of column names from a given table.\n\n        Params:\n            table (str): Name of the table in the SQLite database\n\n        Returns:\n            (list[str]): List of column names found in table\n\n        \"\"\"\n        cols: list[str] = []\n        stmt: str = f\"SELECT * FROM {table}\"\n\n        try:\n            with SQLiteConnManager(self.path) as conn:\n                cursor = conn.cursor\n                res = cursor.execute(stmt).fetchone()\n\n                for col in res.keys():\n                    cols.append(col)\n\n                return cols\n\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception executing SQL. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n    def get_tables(self) -&gt; list[str]:\n        \"\"\"Get all table names from a SQLite databse.\n\n        Returns:\n            (list[str]): List of table names found in SQLite database.\n\n        \"\"\"\n        get_tbls_stmt: str = \"SELECT name FROM sqlite_master WHERE type='table';\"\n        tables: list[str] = []\n\n        try:\n            with SQLiteConnManager(self.path) as conn:\n                cursor = conn.cursor\n                res = cursor.execute(get_tbls_stmt).fetchall()\n\n                for row in res:\n                    tables.append(row[\"name\"])\n\n                return tables\n\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception getting tables. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n    def run_sqlite_stmt(self, stmt: str = None) -&gt; list[sqlite3.Row]:\n        \"\"\"Execute a SQL statement.\n\n        Params:\n            stmt (str): The SQL statement to execute against a SQLite database\n\n        Returns:\n            (list[sqlite3.Row]): The results from executing the query\n\n        \"\"\"\n        assert stmt, \"Must pass a SQL statement\"\n        assert isinstance(stmt, str), \"Statement must be a Python str\"\n\n        try:\n            with SQLiteConnManager(self.path) as conn:\n                cursor = conn.cursor\n                res = cursor.execute(stmt).fetchall()\n\n            return res\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception running SQL statement. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/__init__/#red_utils.std.context_managers.SQLiteConnManager.get_cols","title":"<code>get_cols(table=None)</code>","text":"<p>Return list of column names from a given table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Name of the table in the SQLite database</p> <code>None</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of column names found in table</p> Source code in <code>src\\red_utils\\std\\context_managers\\database_managers\\sqlite_managers.py</code> <pre><code>def get_cols(self, table: str = None) -&gt; list[str]:\n    \"\"\"Return list of column names from a given table.\n\n    Params:\n        table (str): Name of the table in the SQLite database\n\n    Returns:\n        (list[str]): List of column names found in table\n\n    \"\"\"\n    cols: list[str] = []\n    stmt: str = f\"SELECT * FROM {table}\"\n\n    try:\n        with SQLiteConnManager(self.path) as conn:\n            cursor = conn.cursor\n            res = cursor.execute(stmt).fetchone()\n\n            for col in res.keys():\n                cols.append(col)\n\n            return cols\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception executing SQL. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/__init__/#red_utils.std.context_managers.SQLiteConnManager.get_tables","title":"<code>get_tables()</code>","text":"<p>Get all table names from a SQLite databse.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of table names found in SQLite database.</p> Source code in <code>src\\red_utils\\std\\context_managers\\database_managers\\sqlite_managers.py</code> <pre><code>def get_tables(self) -&gt; list[str]:\n    \"\"\"Get all table names from a SQLite databse.\n\n    Returns:\n        (list[str]): List of table names found in SQLite database.\n\n    \"\"\"\n    get_tbls_stmt: str = \"SELECT name FROM sqlite_master WHERE type='table';\"\n    tables: list[str] = []\n\n    try:\n        with SQLiteConnManager(self.path) as conn:\n            cursor = conn.cursor\n            res = cursor.execute(get_tbls_stmt).fetchall()\n\n            for row in res:\n                tables.append(row[\"name\"])\n\n            return tables\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception getting tables. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/__init__/#red_utils.std.context_managers.SQLiteConnManager.run_sqlite_stmt","title":"<code>run_sqlite_stmt(stmt=None)</code>","text":"<p>Execute a SQL statement.</p> <p>Parameters:</p> Name Type Description Default <code>stmt</code> <code>str</code> <p>The SQL statement to execute against a SQLite database</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Row]</code> <p>The results from executing the query</p> Source code in <code>src\\red_utils\\std\\context_managers\\database_managers\\sqlite_managers.py</code> <pre><code>def run_sqlite_stmt(self, stmt: str = None) -&gt; list[sqlite3.Row]:\n    \"\"\"Execute a SQL statement.\n\n    Params:\n        stmt (str): The SQL statement to execute against a SQLite database\n\n    Returns:\n        (list[sqlite3.Row]): The results from executing the query\n\n    \"\"\"\n    assert stmt, \"Must pass a SQL statement\"\n    assert isinstance(stmt, str), \"Statement must be a Python str\"\n\n    try:\n        with SQLiteConnManager(self.path) as conn:\n            cursor = conn.cursor\n            res = cursor.execute(stmt).fetchall()\n\n        return res\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception running SQL statement. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/__init__/#red_utils.std.context_managers.async_benchmark","title":"<code>async_benchmark(description='Unnamed async function timer')</code>  <code>async</code>","text":"<p>Time an asynchronous operation.</p> <p>Run an async function/operation with this context manager to time function execution.</p> <p>Parameters:</p> Name Type Description Default <code>description</code> <code>str</code> <p>A string that prints while the benchmark is running. This can be a message to the user, like \"benchmarking move_files()\", or a message like \"this will take a while...\". Once the benchmark finishes, details about the benchmarked function's execution will be printed to the terminal.</p> <code>'Unnamed async function timer'</code> <p>Usage: <pre><code>with async_benchmark(\"Short description here\"):\n    await some_async_function()\n</code></pre></p> Source code in <code>src\\red_utils\\std\\context_managers\\benchmarks\\fn_benchmarks.py</code> <pre><code>@asynccontextmanager\nasync def async_benchmark(description: str = \"Unnamed async function timer\") -&gt; None:\n    \"\"\"Time an asynchronous operation.\n\n    Run an async function/operation with this context manager to time function execution.\n\n    Params:\n        description (str): A string that prints while the benchmark is running. This can be a message to the user, like\n            \"benchmarking move_files()\", or a message like \"this will take a while...\".\n            Once the benchmark finishes, details about the benchmarked function's execution will be printed to the terminal.\n\n    Usage:\n    ``` py linenums=\"1\"\n    with async_benchmark(\"Short description here\"):\n        await some_async_function()\n    ```\n    \"\"\"\n    start = time.monotonic()\n\n    try:\n        yield\n    finally:\n        elapsed = time.monotonic() - start\n        print(f\"{description}: {elapsed}s\")\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/__init__/#red_utils.std.context_managers.benchmark","title":"<code>benchmark(description='Unnamed function timer')</code>","text":"<p>Time an operation.</p> <p>Run an operation with this context manager (<code>with benchmark(\"time some function\"):</code>) to time function execution.</p> <p>Parameters:</p> Name Type Description Default <code>description</code> <code>str</code> <p>A string that prints while the benchmark is running. This can be a message to the user, like \"benchmarking move_files()\", or a message like \"this will take a while...\". Once the benchmark finishes, details about the benchmarked function's execution will be printed to the terminal.</p> <code>'Unnamed function timer'</code> <p>Usage: <pre><code>with benchmark(\"Short description here\"):\n    some_function()\n</code></pre></p> Source code in <code>src\\red_utils\\std\\context_managers\\benchmarks\\fn_benchmarks.py</code> <pre><code>@contextmanager\ndef benchmark(description: str = \"Unnamed function timer\") -&gt; None:\n    \"\"\"Time an operation.\n\n    Run an operation with this context manager (`with benchmark(\"time some function\"):`) to time function execution.\n\n    Params:\n        description (str): A string that prints while the benchmark is running. This can be a message to the user, like\n            \"benchmarking move_files()\", or a message like \"this will take a while...\".\n            Once the benchmark finishes, details about the benchmarked function's execution will be printed to the terminal.\n\n    Usage:\n    ``` py linenums=\"1\"\n    with benchmark(\"Short description here\"):\n        some_function()\n    ```\n    \"\"\"\n    start = time.time()\n    yield\n    elapsed = time.time() - start\n\n    print(f\"{description}: {elapsed} seconds\")\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/benchmarks/__init__/","title":"benchmarks","text":"<p>Context managers to benchmark functions.</p>"},{"location":"reference/red_utils/std/context_managers/benchmarks/__init__/#red_utils.std.context_managers.benchmarks.async_benchmark","title":"<code>async_benchmark(description='Unnamed async function timer')</code>  <code>async</code>","text":"<p>Time an asynchronous operation.</p> <p>Run an async function/operation with this context manager to time function execution.</p> <p>Parameters:</p> Name Type Description Default <code>description</code> <code>str</code> <p>A string that prints while the benchmark is running. This can be a message to the user, like \"benchmarking move_files()\", or a message like \"this will take a while...\". Once the benchmark finishes, details about the benchmarked function's execution will be printed to the terminal.</p> <code>'Unnamed async function timer'</code> <p>Usage: <pre><code>with async_benchmark(\"Short description here\"):\n    await some_async_function()\n</code></pre></p> Source code in <code>src\\red_utils\\std\\context_managers\\benchmarks\\fn_benchmarks.py</code> <pre><code>@asynccontextmanager\nasync def async_benchmark(description: str = \"Unnamed async function timer\") -&gt; None:\n    \"\"\"Time an asynchronous operation.\n\n    Run an async function/operation with this context manager to time function execution.\n\n    Params:\n        description (str): A string that prints while the benchmark is running. This can be a message to the user, like\n            \"benchmarking move_files()\", or a message like \"this will take a while...\".\n            Once the benchmark finishes, details about the benchmarked function's execution will be printed to the terminal.\n\n    Usage:\n    ``` py linenums=\"1\"\n    with async_benchmark(\"Short description here\"):\n        await some_async_function()\n    ```\n    \"\"\"\n    start = time.monotonic()\n\n    try:\n        yield\n    finally:\n        elapsed = time.monotonic() - start\n        print(f\"{description}: {elapsed}s\")\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/benchmarks/__init__/#red_utils.std.context_managers.benchmarks.benchmark","title":"<code>benchmark(description='Unnamed function timer')</code>","text":"<p>Time an operation.</p> <p>Run an operation with this context manager (<code>with benchmark(\"time some function\"):</code>) to time function execution.</p> <p>Parameters:</p> Name Type Description Default <code>description</code> <code>str</code> <p>A string that prints while the benchmark is running. This can be a message to the user, like \"benchmarking move_files()\", or a message like \"this will take a while...\". Once the benchmark finishes, details about the benchmarked function's execution will be printed to the terminal.</p> <code>'Unnamed function timer'</code> <p>Usage: <pre><code>with benchmark(\"Short description here\"):\n    some_function()\n</code></pre></p> Source code in <code>src\\red_utils\\std\\context_managers\\benchmarks\\fn_benchmarks.py</code> <pre><code>@contextmanager\ndef benchmark(description: str = \"Unnamed function timer\") -&gt; None:\n    \"\"\"Time an operation.\n\n    Run an operation with this context manager (`with benchmark(\"time some function\"):`) to time function execution.\n\n    Params:\n        description (str): A string that prints while the benchmark is running. This can be a message to the user, like\n            \"benchmarking move_files()\", or a message like \"this will take a while...\".\n            Once the benchmark finishes, details about the benchmarked function's execution will be printed to the terminal.\n\n    Usage:\n    ``` py linenums=\"1\"\n    with benchmark(\"Short description here\"):\n        some_function()\n    ```\n    \"\"\"\n    start = time.time()\n    yield\n    elapsed = time.time() - start\n\n    print(f\"{description}: {elapsed} seconds\")\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/benchmarks/fn_benchmarks/","title":"fn_benchmarks","text":""},{"location":"reference/red_utils/std/context_managers/benchmarks/fn_benchmarks/#red_utils.std.context_managers.benchmarks.fn_benchmarks.async_benchmark","title":"<code>async_benchmark(description='Unnamed async function timer')</code>  <code>async</code>","text":"<p>Time an asynchronous operation.</p> <p>Run an async function/operation with this context manager to time function execution.</p> <p>Parameters:</p> Name Type Description Default <code>description</code> <code>str</code> <p>A string that prints while the benchmark is running. This can be a message to the user, like \"benchmarking move_files()\", or a message like \"this will take a while...\". Once the benchmark finishes, details about the benchmarked function's execution will be printed to the terminal.</p> <code>'Unnamed async function timer'</code> <p>Usage: <pre><code>with async_benchmark(\"Short description here\"):\n    await some_async_function()\n</code></pre></p> Source code in <code>src\\red_utils\\std\\context_managers\\benchmarks\\fn_benchmarks.py</code> <pre><code>@asynccontextmanager\nasync def async_benchmark(description: str = \"Unnamed async function timer\") -&gt; None:\n    \"\"\"Time an asynchronous operation.\n\n    Run an async function/operation with this context manager to time function execution.\n\n    Params:\n        description (str): A string that prints while the benchmark is running. This can be a message to the user, like\n            \"benchmarking move_files()\", or a message like \"this will take a while...\".\n            Once the benchmark finishes, details about the benchmarked function's execution will be printed to the terminal.\n\n    Usage:\n    ``` py linenums=\"1\"\n    with async_benchmark(\"Short description here\"):\n        await some_async_function()\n    ```\n    \"\"\"\n    start = time.monotonic()\n\n    try:\n        yield\n    finally:\n        elapsed = time.monotonic() - start\n        print(f\"{description}: {elapsed}s\")\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/benchmarks/fn_benchmarks/#red_utils.std.context_managers.benchmarks.fn_benchmarks.benchmark","title":"<code>benchmark(description='Unnamed function timer')</code>","text":"<p>Time an operation.</p> <p>Run an operation with this context manager (<code>with benchmark(\"time some function\"):</code>) to time function execution.</p> <p>Parameters:</p> Name Type Description Default <code>description</code> <code>str</code> <p>A string that prints while the benchmark is running. This can be a message to the user, like \"benchmarking move_files()\", or a message like \"this will take a while...\". Once the benchmark finishes, details about the benchmarked function's execution will be printed to the terminal.</p> <code>'Unnamed function timer'</code> <p>Usage: <pre><code>with benchmark(\"Short description here\"):\n    some_function()\n</code></pre></p> Source code in <code>src\\red_utils\\std\\context_managers\\benchmarks\\fn_benchmarks.py</code> <pre><code>@contextmanager\ndef benchmark(description: str = \"Unnamed function timer\") -&gt; None:\n    \"\"\"Time an operation.\n\n    Run an operation with this context manager (`with benchmark(\"time some function\"):`) to time function execution.\n\n    Params:\n        description (str): A string that prints while the benchmark is running. This can be a message to the user, like\n            \"benchmarking move_files()\", or a message like \"this will take a while...\".\n            Once the benchmark finishes, details about the benchmarked function's execution will be printed to the terminal.\n\n    Usage:\n    ``` py linenums=\"1\"\n    with benchmark(\"Short description here\"):\n        some_function()\n    ```\n    \"\"\"\n    start = time.time()\n    yield\n    elapsed = time.time() - start\n\n    print(f\"{description}: {elapsed} seconds\")\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/database_managers/__init__/","title":"database_managers","text":"<p>Context managers for database operations.</p>"},{"location":"reference/red_utils/std/context_managers/database_managers/__init__/#red_utils.std.context_managers.database_managers.SQLiteConnManager","title":"<code>SQLiteConnManager</code>","text":"<p>Handle interactions with a SQLite database.</p> <p>Uses built-in functions to query a database, execute SQL statements, and gracefully open/close the DB using context managers.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>A path to a SQLite database file to work on.</p> required <p>Usage: Provide a path string to the SQLite database: <pre><code>sqlite_connection = SQLiteConnManager(path=\"/path/to/db.sqlite\")\n</code></pre></p> <p>Call sqlite3 functions, i.e. <code>.get_tables()</code>: <pre><code>tables = sqlite_conn.get_tables()\n</code></pre></p> Source code in <code>src\\red_utils\\std\\context_managers\\database_managers\\sqlite_managers.py</code> <pre><code>class SQLiteConnManager:\n    \"\"\"Handle interactions with a SQLite database.\n\n    Uses built-in functions to query a database, execute SQL statements,\n    and gracefully open/close the DB using context managers.\n\n    Params:\n        path (str | Path): A path to a SQLite database file to work on.\n\n    Usage:\n    Provide a path string to the SQLite database:\n    ``` py linenums=\"1\"\n    sqlite_connection = SQLiteConnManager(path=\"/path/to/db.sqlite\")\n    ```\n\n    Call sqlite3 functions, i.e. `.get_tables()`:\n    ``` py linenums=\"1\"\n    tables = sqlite_conn.get_tables()\n    ```\n    \"\"\"\n\n    def __init__(self, path: Path):  # noqa: D107\n        ## Initialize SQLite connection manager.\n        if isinstance(path, str):\n            path: Path = Path(path)\n\n        self.path = path\n\n    def __enter__(self):  # noqa: D105\n        ## Executed automatically when class is used as a context handler, like `with SQLiteConnManager() as conn: ...`\n        if not self.path.exists():\n            log.error(\n                FileNotFoundError(f\"Database does not exist at path: {self.path}.\")\n            )\n            with sqlite3.connect(self.path):\n                pass\n\n        try:\n            self.connection: sqlite3.Connection = sqlite3.connect(self.path)\n            self.connection.row_factory = sqlite3.Row\n            self.cursor: sqlite3.Cursor = self.connection.cursor()\n\n            ## Return self, a configured SQLite client\n            return self\n        except FileNotFoundError as fnf:\n            msg = FileNotFoundError(\n                f\"Database not found at path: {self.path}. Details: {fnf}\"\n            )\n            log.error(msg)\n\n            raise fnf\n        except PermissionError as perm:\n            msg = PermissionError(\n                f\"Unable to open database at path: {self.path}. Details: {perm}\"\n            )\n            log.error(msg)\n\n            raise perm\n        except sqlite3.Error as sqlite_exc:\n            msg = sqlite3.Error(f\"SQLite3 error encountered. Details: {sqlite_exc}\")\n            log.error(msg)\n\n            raise sqlite_exc\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception connecting to database. Details: ({exc.__class__}) {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def __exit__(self, exc_type, exc_val, exc_traceback):  # noqa: D105\n        if exc_val:\n            log.error(f\"({exc_type}): {exc_val}\")\n        if exc_traceback:\n            log.error(exc_traceback)\n\n        ## Executed automatically when `with SQLiteConnManager()` exits. Executes on success or failure.\n        self.connection.close()\n\n    def get_cols(self, table: str = None) -&gt; list[str]:\n        \"\"\"Return list of column names from a given table.\n\n        Params:\n            table (str): Name of the table in the SQLite database\n\n        Returns:\n            (list[str]): List of column names found in table\n\n        \"\"\"\n        cols: list[str] = []\n        stmt: str = f\"SELECT * FROM {table}\"\n\n        try:\n            with SQLiteConnManager(self.path) as conn:\n                cursor = conn.cursor\n                res = cursor.execute(stmt).fetchone()\n\n                for col in res.keys():\n                    cols.append(col)\n\n                return cols\n\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception executing SQL. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n    def get_tables(self) -&gt; list[str]:\n        \"\"\"Get all table names from a SQLite databse.\n\n        Returns:\n            (list[str]): List of table names found in SQLite database.\n\n        \"\"\"\n        get_tbls_stmt: str = \"SELECT name FROM sqlite_master WHERE type='table';\"\n        tables: list[str] = []\n\n        try:\n            with SQLiteConnManager(self.path) as conn:\n                cursor = conn.cursor\n                res = cursor.execute(get_tbls_stmt).fetchall()\n\n                for row in res:\n                    tables.append(row[\"name\"])\n\n                return tables\n\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception getting tables. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n    def run_sqlite_stmt(self, stmt: str = None) -&gt; list[sqlite3.Row]:\n        \"\"\"Execute a SQL statement.\n\n        Params:\n            stmt (str): The SQL statement to execute against a SQLite database\n\n        Returns:\n            (list[sqlite3.Row]): The results from executing the query\n\n        \"\"\"\n        assert stmt, \"Must pass a SQL statement\"\n        assert isinstance(stmt, str), \"Statement must be a Python str\"\n\n        try:\n            with SQLiteConnManager(self.path) as conn:\n                cursor = conn.cursor\n                res = cursor.execute(stmt).fetchall()\n\n            return res\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception running SQL statement. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/database_managers/__init__/#red_utils.std.context_managers.database_managers.SQLiteConnManager.get_cols","title":"<code>get_cols(table=None)</code>","text":"<p>Return list of column names from a given table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Name of the table in the SQLite database</p> <code>None</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of column names found in table</p> Source code in <code>src\\red_utils\\std\\context_managers\\database_managers\\sqlite_managers.py</code> <pre><code>def get_cols(self, table: str = None) -&gt; list[str]:\n    \"\"\"Return list of column names from a given table.\n\n    Params:\n        table (str): Name of the table in the SQLite database\n\n    Returns:\n        (list[str]): List of column names found in table\n\n    \"\"\"\n    cols: list[str] = []\n    stmt: str = f\"SELECT * FROM {table}\"\n\n    try:\n        with SQLiteConnManager(self.path) as conn:\n            cursor = conn.cursor\n            res = cursor.execute(stmt).fetchone()\n\n            for col in res.keys():\n                cols.append(col)\n\n            return cols\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception executing SQL. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/database_managers/__init__/#red_utils.std.context_managers.database_managers.SQLiteConnManager.get_tables","title":"<code>get_tables()</code>","text":"<p>Get all table names from a SQLite databse.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of table names found in SQLite database.</p> Source code in <code>src\\red_utils\\std\\context_managers\\database_managers\\sqlite_managers.py</code> <pre><code>def get_tables(self) -&gt; list[str]:\n    \"\"\"Get all table names from a SQLite databse.\n\n    Returns:\n        (list[str]): List of table names found in SQLite database.\n\n    \"\"\"\n    get_tbls_stmt: str = \"SELECT name FROM sqlite_master WHERE type='table';\"\n    tables: list[str] = []\n\n    try:\n        with SQLiteConnManager(self.path) as conn:\n            cursor = conn.cursor\n            res = cursor.execute(get_tbls_stmt).fetchall()\n\n            for row in res:\n                tables.append(row[\"name\"])\n\n            return tables\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception getting tables. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/database_managers/__init__/#red_utils.std.context_managers.database_managers.SQLiteConnManager.run_sqlite_stmt","title":"<code>run_sqlite_stmt(stmt=None)</code>","text":"<p>Execute a SQL statement.</p> <p>Parameters:</p> Name Type Description Default <code>stmt</code> <code>str</code> <p>The SQL statement to execute against a SQLite database</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Row]</code> <p>The results from executing the query</p> Source code in <code>src\\red_utils\\std\\context_managers\\database_managers\\sqlite_managers.py</code> <pre><code>def run_sqlite_stmt(self, stmt: str = None) -&gt; list[sqlite3.Row]:\n    \"\"\"Execute a SQL statement.\n\n    Params:\n        stmt (str): The SQL statement to execute against a SQLite database\n\n    Returns:\n        (list[sqlite3.Row]): The results from executing the query\n\n    \"\"\"\n    assert stmt, \"Must pass a SQL statement\"\n    assert isinstance(stmt, str), \"Statement must be a Python str\"\n\n    try:\n        with SQLiteConnManager(self.path) as conn:\n            cursor = conn.cursor\n            res = cursor.execute(stmt).fetchall()\n\n        return res\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception running SQL statement. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/database_managers/sqlite_managers/","title":"sqlite_managers","text":"<p>Context manager utilities for interacting with SQLite databases, using the stdlib sqlite3 library.</p> <p>The <code>SQLiteConnManager</code> class facilitates clean &amp; safe transactions to the database by trying operations before committing.</p>"},{"location":"reference/red_utils/std/context_managers/database_managers/sqlite_managers/#red_utils.std.context_managers.database_managers.sqlite_managers.SQLiteConnManager","title":"<code>SQLiteConnManager</code>","text":"<p>Handle interactions with a SQLite database.</p> <p>Uses built-in functions to query a database, execute SQL statements, and gracefully open/close the DB using context managers.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>A path to a SQLite database file to work on.</p> required <p>Usage: Provide a path string to the SQLite database: <pre><code>sqlite_connection = SQLiteConnManager(path=\"/path/to/db.sqlite\")\n</code></pre></p> <p>Call sqlite3 functions, i.e. <code>.get_tables()</code>: <pre><code>tables = sqlite_conn.get_tables()\n</code></pre></p> Source code in <code>src\\red_utils\\std\\context_managers\\database_managers\\sqlite_managers.py</code> <pre><code>class SQLiteConnManager:\n    \"\"\"Handle interactions with a SQLite database.\n\n    Uses built-in functions to query a database, execute SQL statements,\n    and gracefully open/close the DB using context managers.\n\n    Params:\n        path (str | Path): A path to a SQLite database file to work on.\n\n    Usage:\n    Provide a path string to the SQLite database:\n    ``` py linenums=\"1\"\n    sqlite_connection = SQLiteConnManager(path=\"/path/to/db.sqlite\")\n    ```\n\n    Call sqlite3 functions, i.e. `.get_tables()`:\n    ``` py linenums=\"1\"\n    tables = sqlite_conn.get_tables()\n    ```\n    \"\"\"\n\n    def __init__(self, path: Path):  # noqa: D107\n        ## Initialize SQLite connection manager.\n        if isinstance(path, str):\n            path: Path = Path(path)\n\n        self.path = path\n\n    def __enter__(self):  # noqa: D105\n        ## Executed automatically when class is used as a context handler, like `with SQLiteConnManager() as conn: ...`\n        if not self.path.exists():\n            log.error(\n                FileNotFoundError(f\"Database does not exist at path: {self.path}.\")\n            )\n            with sqlite3.connect(self.path):\n                pass\n\n        try:\n            self.connection: sqlite3.Connection = sqlite3.connect(self.path)\n            self.connection.row_factory = sqlite3.Row\n            self.cursor: sqlite3.Cursor = self.connection.cursor()\n\n            ## Return self, a configured SQLite client\n            return self\n        except FileNotFoundError as fnf:\n            msg = FileNotFoundError(\n                f\"Database not found at path: {self.path}. Details: {fnf}\"\n            )\n            log.error(msg)\n\n            raise fnf\n        except PermissionError as perm:\n            msg = PermissionError(\n                f\"Unable to open database at path: {self.path}. Details: {perm}\"\n            )\n            log.error(msg)\n\n            raise perm\n        except sqlite3.Error as sqlite_exc:\n            msg = sqlite3.Error(f\"SQLite3 error encountered. Details: {sqlite_exc}\")\n            log.error(msg)\n\n            raise sqlite_exc\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception connecting to database. Details: ({exc.__class__}) {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    def __exit__(self, exc_type, exc_val, exc_traceback):  # noqa: D105\n        if exc_val:\n            log.error(f\"({exc_type}): {exc_val}\")\n        if exc_traceback:\n            log.error(exc_traceback)\n\n        ## Executed automatically when `with SQLiteConnManager()` exits. Executes on success or failure.\n        self.connection.close()\n\n    def get_cols(self, table: str = None) -&gt; list[str]:\n        \"\"\"Return list of column names from a given table.\n\n        Params:\n            table (str): Name of the table in the SQLite database\n\n        Returns:\n            (list[str]): List of column names found in table\n\n        \"\"\"\n        cols: list[str] = []\n        stmt: str = f\"SELECT * FROM {table}\"\n\n        try:\n            with SQLiteConnManager(self.path) as conn:\n                cursor = conn.cursor\n                res = cursor.execute(stmt).fetchone()\n\n                for col in res.keys():\n                    cols.append(col)\n\n                return cols\n\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception executing SQL. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n    def get_tables(self) -&gt; list[str]:\n        \"\"\"Get all table names from a SQLite databse.\n\n        Returns:\n            (list[str]): List of table names found in SQLite database.\n\n        \"\"\"\n        get_tbls_stmt: str = \"SELECT name FROM sqlite_master WHERE type='table';\"\n        tables: list[str] = []\n\n        try:\n            with SQLiteConnManager(self.path) as conn:\n                cursor = conn.cursor\n                res = cursor.execute(get_tbls_stmt).fetchall()\n\n                for row in res:\n                    tables.append(row[\"name\"])\n\n                return tables\n\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception getting tables. Details: {exc}\")\n            log.error(msg)\n\n            raise exc\n\n    def run_sqlite_stmt(self, stmt: str = None) -&gt; list[sqlite3.Row]:\n        \"\"\"Execute a SQL statement.\n\n        Params:\n            stmt (str): The SQL statement to execute against a SQLite database\n\n        Returns:\n            (list[sqlite3.Row]): The results from executing the query\n\n        \"\"\"\n        assert stmt, \"Must pass a SQL statement\"\n        assert isinstance(stmt, str), \"Statement must be a Python str\"\n\n        try:\n            with SQLiteConnManager(self.path) as conn:\n                cursor = conn.cursor\n                res = cursor.execute(stmt).fetchall()\n\n            return res\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception running SQL statement. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/database_managers/sqlite_managers/#red_utils.std.context_managers.database_managers.sqlite_managers.SQLiteConnManager.get_cols","title":"<code>get_cols(table=None)</code>","text":"<p>Return list of column names from a given table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Name of the table in the SQLite database</p> <code>None</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of column names found in table</p> Source code in <code>src\\red_utils\\std\\context_managers\\database_managers\\sqlite_managers.py</code> <pre><code>def get_cols(self, table: str = None) -&gt; list[str]:\n    \"\"\"Return list of column names from a given table.\n\n    Params:\n        table (str): Name of the table in the SQLite database\n\n    Returns:\n        (list[str]): List of column names found in table\n\n    \"\"\"\n    cols: list[str] = []\n    stmt: str = f\"SELECT * FROM {table}\"\n\n    try:\n        with SQLiteConnManager(self.path) as conn:\n            cursor = conn.cursor\n            res = cursor.execute(stmt).fetchone()\n\n            for col in res.keys():\n                cols.append(col)\n\n            return cols\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception executing SQL. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/database_managers/sqlite_managers/#red_utils.std.context_managers.database_managers.sqlite_managers.SQLiteConnManager.get_tables","title":"<code>get_tables()</code>","text":"<p>Get all table names from a SQLite databse.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of table names found in SQLite database.</p> Source code in <code>src\\red_utils\\std\\context_managers\\database_managers\\sqlite_managers.py</code> <pre><code>def get_tables(self) -&gt; list[str]:\n    \"\"\"Get all table names from a SQLite databse.\n\n    Returns:\n        (list[str]): List of table names found in SQLite database.\n\n    \"\"\"\n    get_tbls_stmt: str = \"SELECT name FROM sqlite_master WHERE type='table';\"\n    tables: list[str] = []\n\n    try:\n        with SQLiteConnManager(self.path) as conn:\n            cursor = conn.cursor\n            res = cursor.execute(get_tbls_stmt).fetchall()\n\n            for row in res:\n                tables.append(row[\"name\"])\n\n            return tables\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception getting tables. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/database_managers/sqlite_managers/#red_utils.std.context_managers.database_managers.sqlite_managers.SQLiteConnManager.run_sqlite_stmt","title":"<code>run_sqlite_stmt(stmt=None)</code>","text":"<p>Execute a SQL statement.</p> <p>Parameters:</p> Name Type Description Default <code>stmt</code> <code>str</code> <p>The SQL statement to execute against a SQLite database</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Row]</code> <p>The results from executing the query</p> Source code in <code>src\\red_utils\\std\\context_managers\\database_managers\\sqlite_managers.py</code> <pre><code>def run_sqlite_stmt(self, stmt: str = None) -&gt; list[sqlite3.Row]:\n    \"\"\"Execute a SQL statement.\n\n    Params:\n        stmt (str): The SQL statement to execute against a SQLite database\n\n    Returns:\n        (list[sqlite3.Row]): The results from executing the query\n\n    \"\"\"\n    assert stmt, \"Must pass a SQL statement\"\n    assert isinstance(stmt, str), \"Statement must be a Python str\"\n\n    try:\n        with SQLiteConnManager(self.path) as conn:\n            cursor = conn.cursor\n            res = cursor.execute(stmt).fetchall()\n\n        return res\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception running SQL statement. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/object_managers/__init__/","title":"object_managers","text":""},{"location":"reference/red_utils/std/context_managers/object_managers/__init__/#red_utils.std.context_managers.object_managers.DictProtect","title":"<code>DictProtect</code>","text":"<p>Protect a dict during modification by modifying a copy instead of the original.</p> <p>DictProtect creates a copy of a dict before running operations like .update(), and prevents errors on the original object by destroying the copy if an error is encountered, only overwriting the original if no errors occur.</p> <p>Parameters:</p> Name Type Description Default <code>original</code> <code>dict</code> <p>The original Python <code>dict</code>. A copy will be made during any operations, and will only overwrite the original if the operation succeeds.</p> required <p>Usage:</p> <pre><code>    ex_dict = {\"example\": \"value\"}\n\n    ## Protects from a ZeroDivision error\n    with DictProtect(ex_dict) as copy:\n        copy[\"example\"] = 1 / 0\n\n    print(f'Dict: {ex_dict}')\n</code></pre> Source code in <code>src\\red_utils\\std\\context_managers\\object_managers\\protect.py</code> <pre><code>class DictProtect:\n    \"\"\"Protect a dict during modification by modifying a copy instead of the original.\n\n    DictProtect creates a copy of a dict before running operations like .update(), and prevents\n    errors on the original object by destroying the copy if an error is encountered, only\n    overwriting the original if no errors occur.\n\n    Params:\n        original (dict): The original Python `dict`. A copy will be made during any operations, and will only overwrite\n            the original if the operation succeeds.\n\n    Usage:\n\n    ``` py linenums=\"1\"\n        ex_dict = {\"example\": \"value\"}\n\n        ## Protects from a ZeroDivision error\n        with DictProtect(ex_dict) as copy:\n            copy[\"example\"] = 1 / 0\n\n        print(f'Dict: {ex_dict}')\n    ```\n    \"\"\"\n\n    def __init__(self, original: dict) -&gt; None:  # noqa: D107\n        ## Call immediately after with DictProtect() as copy.\n        if not isinstance(original, dict):\n            raise TypeError(\n                f\"Invalid type for protected dict: ({type(original)}). Must be of type dict.\"\n            )\n\n        ## Set class value to original dict\n        self.original = original\n\n    def __enter__(self) -&gt; dict:  # noqa: D105\n        ## Call after initializing DictProtect instance.\n        ## Create a copy of the dict to work on\n        self.clone: dict = self.original.copy()\n\n        return self.clone\n\n    def __exit__(self, exc_type, exc_value, exc_traceback) -&gt; bool:  # noqa: D105\n        ## Call if DictProtect context manager encounters an error.\n        ## No exception encountered, update original\n        #  list and return\n        if exc_type is None:\n            self.original.update(self.clone)\n        if exc_traceback:\n            log.error(exc_traceback)\n\n        ## Error encountered, print details\n        else:\n            ## https://docs.python.org/3/library/inspect.html?highlight=currentframe\n            frame = inspect.currentframe()\n            ## Full path to error file\n            file_name = frame.f_code.co_filename\n            ## Line number where error occurred.\n            file_no = frame.f_lineno\n\n            ## Build error details dict\n            err = {\n                \"success\": False,\n                \"detail\": {\n                    \"module\": file_name,\n                    \"line\": file_no,\n                    \"exception_type\": exc_type,\n                    \"exception_text\": exc_value,\n                },\n            }\n\n            ## Return error, exit returning original list\n            log.error(\n                f\"Error encountered running dict operation on protected dict. Details: \\n{err}\"\n            )\n\n        return True\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/object_managers/__init__/#red_utils.std.context_managers.object_managers.ListProtect","title":"<code>ListProtect</code>","text":"<p>Protect a list during modification by modifying a copy instead of the original.</p> <p>ListProtect creates a copy of a list before running operations like .append(), and prevents errors on the original object by destroying the copy if an error is encountered, only overwriting the original if no errors occur.</p> <p>Parameters:</p> Name Type Description Default <code>original</code> <code>list</code> <p>The original Python <code>list</code>. A copy will be made during any operations, and will only overwrite the original if the operation succeeds.</p> required <p>Usage:</p> <pre><code>ex_list = [1, 2, 3]\n\n## Protects from a ZeroDivision error\nwith ListProtect(ex_list) as copy:\n    copy.append(1/0)\n\nprint(f'List: {ex_list}')\n</code></pre> Source code in <code>src\\red_utils\\std\\context_managers\\object_managers\\protect.py</code> <pre><code>class ListProtect:\n    \"\"\"Protect a list during modification by modifying a copy instead of the original.\n\n    ListProtect creates a copy of a list before running operations like .append(), and prevents\n    errors on the original object by destroying the copy if an error is encountered, only\n    overwriting the original if no errors occur.\n\n    Params:\n        original (list): The original Python `list`. A copy will be made during any operations, and will only overwrite\n            the original if the operation succeeds.\n\n    Usage:\n\n    ``` py linenums=\"1\"\n    ex_list = [1, 2, 3]\n\n    ## Protects from a ZeroDivision error\n    with ListProtect(ex_list) as copy:\n        copy.append(1/0)\n\n    print(f'List: {ex_list}')\n    ```\n    \"\"\"\n\n    def __init__(self, original: list):  # noqa: D107\n        ## Call immediately after with ListProtect() as copy.\n        if not isinstance(original, list):\n            raise TypeError(\n                f\"Invalid type for protected list: ({type(original)}). Must be of type list.\"\n            )\n\n        ## Set class value to original list\n        self.original = original\n\n    def __enter__(self):  # noqa: D105\n        ## Call after initializing ListProtect instance.\n        ## Create a copy of the list to work on\n        self.clone: list = self.original.copy()\n\n        return self.clone\n\n    def __exit__(self, exc_type, exc_value, exc_traceback) -&gt; bool:  # noqa: D105\n        ## Call if ListProtect context manager encounters an error.\n        ## No exception encountered, update original\n        #  list and return\n        if exc_type is None:\n            self.original[:] = self.clone\n        if exc_traceback:\n            log.error(exc_traceback)\n\n        ## Error encountered, print details\n        else:\n            ## https://docs.python.org/3/library/inspect.html?highlight=currentframe\n            frame = inspect.currentframe()\n            ## Full path to error file\n            file_name = frame.f_code.co_filename\n            ## Line number where error occurred.\n            file_no = frame.f_lineno\n\n            ## Build error details dict\n            err = {\n                \"success\": False,\n                \"detail\": {\n                    \"module\": file_name,\n                    \"line\": file_no,\n                    \"exception_type\": exc_type,\n                    \"exception_text\": exc_value,\n                },\n            }\n\n            ## Return error, exit returning original list\n            log.error(\n                f\"Error encountered running list operation on protected list. Details: \\n{err}\"\n            )\n\n        return True\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/object_managers/protect/","title":"protect","text":"<p>Context manager classes to protect instances of objects.</p>"},{"location":"reference/red_utils/std/context_managers/object_managers/protect/#red_utils.std.context_managers.object_managers.protect.DictProtect","title":"<code>DictProtect</code>","text":"<p>Protect a dict during modification by modifying a copy instead of the original.</p> <p>DictProtect creates a copy of a dict before running operations like .update(), and prevents errors on the original object by destroying the copy if an error is encountered, only overwriting the original if no errors occur.</p> <p>Parameters:</p> Name Type Description Default <code>original</code> <code>dict</code> <p>The original Python <code>dict</code>. A copy will be made during any operations, and will only overwrite the original if the operation succeeds.</p> required <p>Usage:</p> <pre><code>    ex_dict = {\"example\": \"value\"}\n\n    ## Protects from a ZeroDivision error\n    with DictProtect(ex_dict) as copy:\n        copy[\"example\"] = 1 / 0\n\n    print(f'Dict: {ex_dict}')\n</code></pre> Source code in <code>src\\red_utils\\std\\context_managers\\object_managers\\protect.py</code> <pre><code>class DictProtect:\n    \"\"\"Protect a dict during modification by modifying a copy instead of the original.\n\n    DictProtect creates a copy of a dict before running operations like .update(), and prevents\n    errors on the original object by destroying the copy if an error is encountered, only\n    overwriting the original if no errors occur.\n\n    Params:\n        original (dict): The original Python `dict`. A copy will be made during any operations, and will only overwrite\n            the original if the operation succeeds.\n\n    Usage:\n\n    ``` py linenums=\"1\"\n        ex_dict = {\"example\": \"value\"}\n\n        ## Protects from a ZeroDivision error\n        with DictProtect(ex_dict) as copy:\n            copy[\"example\"] = 1 / 0\n\n        print(f'Dict: {ex_dict}')\n    ```\n    \"\"\"\n\n    def __init__(self, original: dict) -&gt; None:  # noqa: D107\n        ## Call immediately after with DictProtect() as copy.\n        if not isinstance(original, dict):\n            raise TypeError(\n                f\"Invalid type for protected dict: ({type(original)}). Must be of type dict.\"\n            )\n\n        ## Set class value to original dict\n        self.original = original\n\n    def __enter__(self) -&gt; dict:  # noqa: D105\n        ## Call after initializing DictProtect instance.\n        ## Create a copy of the dict to work on\n        self.clone: dict = self.original.copy()\n\n        return self.clone\n\n    def __exit__(self, exc_type, exc_value, exc_traceback) -&gt; bool:  # noqa: D105\n        ## Call if DictProtect context manager encounters an error.\n        ## No exception encountered, update original\n        #  list and return\n        if exc_type is None:\n            self.original.update(self.clone)\n        if exc_traceback:\n            log.error(exc_traceback)\n\n        ## Error encountered, print details\n        else:\n            ## https://docs.python.org/3/library/inspect.html?highlight=currentframe\n            frame = inspect.currentframe()\n            ## Full path to error file\n            file_name = frame.f_code.co_filename\n            ## Line number where error occurred.\n            file_no = frame.f_lineno\n\n            ## Build error details dict\n            err = {\n                \"success\": False,\n                \"detail\": {\n                    \"module\": file_name,\n                    \"line\": file_no,\n                    \"exception_type\": exc_type,\n                    \"exception_text\": exc_value,\n                },\n            }\n\n            ## Return error, exit returning original list\n            log.error(\n                f\"Error encountered running dict operation on protected dict. Details: \\n{err}\"\n            )\n\n        return True\n</code></pre>"},{"location":"reference/red_utils/std/context_managers/object_managers/protect/#red_utils.std.context_managers.object_managers.protect.ListProtect","title":"<code>ListProtect</code>","text":"<p>Protect a list during modification by modifying a copy instead of the original.</p> <p>ListProtect creates a copy of a list before running operations like .append(), and prevents errors on the original object by destroying the copy if an error is encountered, only overwriting the original if no errors occur.</p> <p>Parameters:</p> Name Type Description Default <code>original</code> <code>list</code> <p>The original Python <code>list</code>. A copy will be made during any operations, and will only overwrite the original if the operation succeeds.</p> required <p>Usage:</p> <pre><code>ex_list = [1, 2, 3]\n\n## Protects from a ZeroDivision error\nwith ListProtect(ex_list) as copy:\n    copy.append(1/0)\n\nprint(f'List: {ex_list}')\n</code></pre> Source code in <code>src\\red_utils\\std\\context_managers\\object_managers\\protect.py</code> <pre><code>class ListProtect:\n    \"\"\"Protect a list during modification by modifying a copy instead of the original.\n\n    ListProtect creates a copy of a list before running operations like .append(), and prevents\n    errors on the original object by destroying the copy if an error is encountered, only\n    overwriting the original if no errors occur.\n\n    Params:\n        original (list): The original Python `list`. A copy will be made during any operations, and will only overwrite\n            the original if the operation succeeds.\n\n    Usage:\n\n    ``` py linenums=\"1\"\n    ex_list = [1, 2, 3]\n\n    ## Protects from a ZeroDivision error\n    with ListProtect(ex_list) as copy:\n        copy.append(1/0)\n\n    print(f'List: {ex_list}')\n    ```\n    \"\"\"\n\n    def __init__(self, original: list):  # noqa: D107\n        ## Call immediately after with ListProtect() as copy.\n        if not isinstance(original, list):\n            raise TypeError(\n                f\"Invalid type for protected list: ({type(original)}). Must be of type list.\"\n            )\n\n        ## Set class value to original list\n        self.original = original\n\n    def __enter__(self):  # noqa: D105\n        ## Call after initializing ListProtect instance.\n        ## Create a copy of the list to work on\n        self.clone: list = self.original.copy()\n\n        return self.clone\n\n    def __exit__(self, exc_type, exc_value, exc_traceback) -&gt; bool:  # noqa: D105\n        ## Call if ListProtect context manager encounters an error.\n        ## No exception encountered, update original\n        #  list and return\n        if exc_type is None:\n            self.original[:] = self.clone\n        if exc_traceback:\n            log.error(exc_traceback)\n\n        ## Error encountered, print details\n        else:\n            ## https://docs.python.org/3/library/inspect.html?highlight=currentframe\n            frame = inspect.currentframe()\n            ## Full path to error file\n            file_name = frame.f_code.co_filename\n            ## Line number where error occurred.\n            file_no = frame.f_lineno\n\n            ## Build error details dict\n            err = {\n                \"success\": False,\n                \"detail\": {\n                    \"module\": file_name,\n                    \"line\": file_no,\n                    \"exception_type\": exc_type,\n                    \"exception_text\": exc_value,\n                },\n            }\n\n            ## Return error, exit returning original list\n            log.error(\n                f\"Error encountered running list operation on protected list. Details: \\n{err}\"\n            )\n\n        return True\n</code></pre>"},{"location":"reference/red_utils/std/dict_utils/__init__/","title":"dict_utils","text":"<p>Utilities for interacting with Python <code>dict</code>s.</p>"},{"location":"reference/red_utils/std/dict_utils/__init__/#red_utils.std.dict_utils.debug_dict","title":"<code>debug_dict(in_dict=None)</code>","text":"<p>Debug print a dict by looping overkeys and printing.</p> <p>If type of key is also dict, re-run the loop on that key and continue.</p> <p>Parameters:</p> Name Type Description Default <code>in_dict</code> <code>dict</code> <p>The input dict to loop &amp; debug print</p> <code>None</code> <p>Raises:</p> Type Description <code>Exception</code> <p>A generic <code>Exception</code> whenever debug printing a <code>dict</code> fails</p> Source code in <code>src\\red_utils\\std\\dict_utils\\operations.py</code> <pre><code>def debug_dict(in_dict: dict = None) -&gt; None:\n    \"\"\"Debug print a dict by looping overkeys and printing.\n\n    If type of key is also dict, re-run the loop on that key and continue.\n\n    Params:\n        in_dict (dict): The input dict to loop &amp; debug print\n\n    Raises:\n        Exception: A generic `Exception` whenever debug printing a `dict` fails\n\n    \"\"\"\n    validate_dict(in_dict)\n\n    try:\n        for k in in_dict.keys():\n            if not isinstance(in_dict[k], dict):\n                print(f\"Key [{k}]:\\n\\tType: {type(in_dict[k])}\\n\\tValue: {in_dict[k]}\")\n            else:\n                print(f\"Key [{k}] is type dict. Looping over sub-dict\")\n                debug_dict(in_dict=in_dict[k])\n\n                continue\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception looping dict. Errored on key {k}. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/dict_utils/__init__/#red_utils.std.dict_utils.merge_dicts","title":"<code>merge_dicts(original_dict=None, update_vals=None)</code>","text":"<p>Merge dicts into new dict.</p> <p>Parameters:</p> Name Type Description Default <code>original_dict</code> <code>dict</code> <p>The first <code>dict</code></p> <code>None</code> <code>update_vals</code> <code>dict</code> <p>The new <code>dict</code> to be merged into the first <code>dict</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A merged <code>dict</code> from the 2 input <code>dict</code>s</p> <p>Raises:</p> Type Description <code>Exception</code> <p>When merging the <code>dict</code>s fails</p> Source code in <code>src\\red_utils\\std\\dict_utils\\operations.py</code> <pre><code>def merge_dicts(\n    original_dict: dict[str, Any] = None,\n    update_vals: dict[str, Any] = None,\n) -&gt; dict[str, str]:\n    \"\"\"Merge dicts into new dict.\n\n    Params:\n        original_dict (dict): The first `dict`\n        update_vals (dict): The new `dict` to be merged into the first `dict`.\n\n    Returns:\n        (dict): A merged `dict` from the 2 input `dict`s\n\n\n    Raises:\n        Exception: When merging the `dict`s fails\n\n    \"\"\"\n    validate_dict(original_dict)\n    validate_dict(update_vals)\n\n    try:\n        _new: dict = {**update_vals, **original_dict}\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception merging dicts. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n\n    return _new\n</code></pre>"},{"location":"reference/red_utils/std/dict_utils/__init__/#red_utils.std.dict_utils.update_dict","title":"<code>update_dict(original_dict=None, update_vals=None)</code>","text":"<p>Update a dict with values from a second dict.</p> <p>Parameters:</p> Name Type Description Default <code>original_dict</code> <code>dict[str, Any]</code> <p>The original dictionary to be updated.</p> <code>None</code> <code>update_vals</code> <code>dict[str, Any]</code> <p>The dict with values with which to update the original dict.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A <code>dict</code> with updated values</p> Source code in <code>src\\red_utils\\std\\dict_utils\\operations.py</code> <pre><code>def update_dict(\n    original_dict: dict[str, Any] = None,\n    update_vals: dict[str, Any] = None,\n) -&gt; dict[str, str]:\n    \"\"\"Update a dict with values from a second dict.\n\n    Params:\n        original_dict: The original dictionary to be updated.\n        update_vals: The dict with values with which to update the original dict.\n\n    Returns:\n        (dict): A `dict` with updated values\n\n    \"\"\"\n    validate_dict(original_dict)\n    validate_dict(update_vals)\n\n    try:\n        ## Create a copy of original_dict to update\n        new_dict: dict[str, str] = original_dict.copy()\n        ## Update new_dict with update_vals dict\n        new_dict.update(update_vals)\n\n        return new_dict\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception updating dict. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/dict_utils/__init__/#red_utils.std.dict_utils.validate_dict","title":"<code>validate_dict(_dict=None)</code>","text":"<p>Validate an input dict.</p> <p>Parameters:</p> Name Type Description Default <code>_dict</code> <code>dict</code> <p>The Python <code>dict</code> to validate</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A validated <code>dict</code></p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If _dict is <code>None</code> or an invalid type</p> <code>TypeError</code> <p>When <code>_dict</code>'s type is not <code>dict</code></p> Source code in <code>src\\red_utils\\std\\dict_utils\\validators.py</code> <pre><code>def validate_dict(_dict: dict[str, str] = None) -&gt; dict[Any, Any]:\n    \"\"\"Validate an input dict.\n\n    Params:\n        _dict (dict): The Python `dict` to validate\n\n    Returns:\n        (dict): A validated `dict`\n\n    Raises:\n        ValueError: If _dict is `None` or an invalid type\n        TypeError: When `_dict`'s type is not `dict`\n\n    \"\"\"\n    assert _dict is not None, ValueError(\"Missing dict to evaluate\")\n\n    if not isinstance(_dict, dict):\n        raise TypeError(\n            f\"Invalid type for input _dict: ({type(_dict)}). Must be dict[str, str]\"\n        )\n\n    return _dict\n</code></pre>"},{"location":"reference/red_utils/std/dict_utils/operations/","title":"operations","text":""},{"location":"reference/red_utils/std/dict_utils/operations/#red_utils.std.dict_utils.operations.debug_dict","title":"<code>debug_dict(in_dict=None)</code>","text":"<p>Debug print a dict by looping overkeys and printing.</p> <p>If type of key is also dict, re-run the loop on that key and continue.</p> <p>Parameters:</p> Name Type Description Default <code>in_dict</code> <code>dict</code> <p>The input dict to loop &amp; debug print</p> <code>None</code> <p>Raises:</p> Type Description <code>Exception</code> <p>A generic <code>Exception</code> whenever debug printing a <code>dict</code> fails</p> Source code in <code>src\\red_utils\\std\\dict_utils\\operations.py</code> <pre><code>def debug_dict(in_dict: dict = None) -&gt; None:\n    \"\"\"Debug print a dict by looping overkeys and printing.\n\n    If type of key is also dict, re-run the loop on that key and continue.\n\n    Params:\n        in_dict (dict): The input dict to loop &amp; debug print\n\n    Raises:\n        Exception: A generic `Exception` whenever debug printing a `dict` fails\n\n    \"\"\"\n    validate_dict(in_dict)\n\n    try:\n        for k in in_dict.keys():\n            if not isinstance(in_dict[k], dict):\n                print(f\"Key [{k}]:\\n\\tType: {type(in_dict[k])}\\n\\tValue: {in_dict[k]}\")\n            else:\n                print(f\"Key [{k}] is type dict. Looping over sub-dict\")\n                debug_dict(in_dict=in_dict[k])\n\n                continue\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception looping dict. Errored on key {k}. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/dict_utils/operations/#red_utils.std.dict_utils.operations.merge_dicts","title":"<code>merge_dicts(original_dict=None, update_vals=None)</code>","text":"<p>Merge dicts into new dict.</p> <p>Parameters:</p> Name Type Description Default <code>original_dict</code> <code>dict</code> <p>The first <code>dict</code></p> <code>None</code> <code>update_vals</code> <code>dict</code> <p>The new <code>dict</code> to be merged into the first <code>dict</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A merged <code>dict</code> from the 2 input <code>dict</code>s</p> <p>Raises:</p> Type Description <code>Exception</code> <p>When merging the <code>dict</code>s fails</p> Source code in <code>src\\red_utils\\std\\dict_utils\\operations.py</code> <pre><code>def merge_dicts(\n    original_dict: dict[str, Any] = None,\n    update_vals: dict[str, Any] = None,\n) -&gt; dict[str, str]:\n    \"\"\"Merge dicts into new dict.\n\n    Params:\n        original_dict (dict): The first `dict`\n        update_vals (dict): The new `dict` to be merged into the first `dict`.\n\n    Returns:\n        (dict): A merged `dict` from the 2 input `dict`s\n\n\n    Raises:\n        Exception: When merging the `dict`s fails\n\n    \"\"\"\n    validate_dict(original_dict)\n    validate_dict(update_vals)\n\n    try:\n        _new: dict = {**update_vals, **original_dict}\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception merging dicts. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n\n    return _new\n</code></pre>"},{"location":"reference/red_utils/std/dict_utils/operations/#red_utils.std.dict_utils.operations.update_dict","title":"<code>update_dict(original_dict=None, update_vals=None)</code>","text":"<p>Update a dict with values from a second dict.</p> <p>Parameters:</p> Name Type Description Default <code>original_dict</code> <code>dict[str, Any]</code> <p>The original dictionary to be updated.</p> <code>None</code> <code>update_vals</code> <code>dict[str, Any]</code> <p>The dict with values with which to update the original dict.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A <code>dict</code> with updated values</p> Source code in <code>src\\red_utils\\std\\dict_utils\\operations.py</code> <pre><code>def update_dict(\n    original_dict: dict[str, Any] = None,\n    update_vals: dict[str, Any] = None,\n) -&gt; dict[str, str]:\n    \"\"\"Update a dict with values from a second dict.\n\n    Params:\n        original_dict: The original dictionary to be updated.\n        update_vals: The dict with values with which to update the original dict.\n\n    Returns:\n        (dict): A `dict` with updated values\n\n    \"\"\"\n    validate_dict(original_dict)\n    validate_dict(update_vals)\n\n    try:\n        ## Create a copy of original_dict to update\n        new_dict: dict[str, str] = original_dict.copy()\n        ## Update new_dict with update_vals dict\n        new_dict.update(update_vals)\n\n        return new_dict\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception updating dict. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/dict_utils/operations/#red_utils.std.dict_utils.operations.validate_dict","title":"<code>validate_dict(_dict=None)</code>","text":"<p>Validate an input dict.</p> <p>Parameters:</p> Name Type Description Default <code>_dict</code> <code>dict</code> <p>The Python <code>dict</code> to validate</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A validated <code>dict</code></p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If _dict is <code>None</code> or an invalid type</p> <code>TypeError</code> <p>When <code>_dict</code>'s type is not <code>dict</code></p> Source code in <code>src\\red_utils\\std\\dict_utils\\validators.py</code> <pre><code>def validate_dict(_dict: dict[str, str] = None) -&gt; dict[Any, Any]:\n    \"\"\"Validate an input dict.\n\n    Params:\n        _dict (dict): The Python `dict` to validate\n\n    Returns:\n        (dict): A validated `dict`\n\n    Raises:\n        ValueError: If _dict is `None` or an invalid type\n        TypeError: When `_dict`'s type is not `dict`\n\n    \"\"\"\n    assert _dict is not None, ValueError(\"Missing dict to evaluate\")\n\n    if not isinstance(_dict, dict):\n        raise TypeError(\n            f\"Invalid type for input _dict: ({type(_dict)}). Must be dict[str, str]\"\n        )\n\n    return _dict\n</code></pre>"},{"location":"reference/red_utils/std/dict_utils/validators/","title":"validators","text":"<p>Functions to validate inputs for other <code>red_utils.std.dict_utils</code> methods.</p>"},{"location":"reference/red_utils/std/dict_utils/validators/#red_utils.std.dict_utils.validators.validate_dict","title":"<code>validate_dict(_dict=None)</code>","text":"<p>Validate an input dict.</p> <p>Parameters:</p> Name Type Description Default <code>_dict</code> <code>dict</code> <p>The Python <code>dict</code> to validate</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A validated <code>dict</code></p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If _dict is <code>None</code> or an invalid type</p> <code>TypeError</code> <p>When <code>_dict</code>'s type is not <code>dict</code></p> Source code in <code>src\\red_utils\\std\\dict_utils\\validators.py</code> <pre><code>def validate_dict(_dict: dict[str, str] = None) -&gt; dict[Any, Any]:\n    \"\"\"Validate an input dict.\n\n    Params:\n        _dict (dict): The Python `dict` to validate\n\n    Returns:\n        (dict): A validated `dict`\n\n    Raises:\n        ValueError: If _dict is `None` or an invalid type\n        TypeError: When `_dict`'s type is not `dict`\n\n    \"\"\"\n    assert _dict is not None, ValueError(\"Missing dict to evaluate\")\n\n    if not isinstance(_dict, dict):\n        raise TypeError(\n            f\"Invalid type for input _dict: ({type(_dict)}). Must be dict[str, str]\"\n        )\n\n    return _dict\n</code></pre>"},{"location":"reference/red_utils/std/hash_utils/__init__/","title":"hash_utils","text":"<p>Utilities for interacting with Pythons <code>hashlib</code> module.</p>"},{"location":"reference/red_utils/std/hash_utils/__init__/#red_utils.std.hash_utils.get_hash_from_str","title":"<code>get_hash_from_str(input_str=None, encoding='utf-8')</code>","text":"<p>Return a hashed version of an input string.</p> <p>Parameters:</p> Name Type Description Default <code>input_str</code> <code>str</code> <p>The string to hash</p> <code>None</code> <code>encoding</code> <code>str</code> <p>The character encoding to use</p> <code>'utf-8'</code> <p>Returns:</p> Type Description <code>str</code> <p>A hashed representation of <code>input_str</code></p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When input validation fails</p> <code>Exception</code> <p>A generic <code>Exception</code> when converting string to hash fails</p> Source code in <code>src\\red_utils\\std\\hash_utils\\operations.py</code> <pre><code>def get_hash_from_str(input_str: str = None, encoding: str = \"utf-8\") -&gt; str:\n    \"\"\"Return a hashed version of an input string.\n\n    Params:\n        input_str (str): The string to hash\n        encoding (str): The character encoding to use\n\n    Returns:\n        (str): A hashed representation of `input_str`\n\n    Raises:\n        ValueError: When input validation fails\n        Exception: A generic `Exception` when converting string to hash fails\n\n    \"\"\"\n    if not input_str:\n        raise ValueError(\"Missing input string\")\n\n    if not encoding:\n        raise ValueError(\"Missing encoding\")\n\n    if not isinstance(input_str, str):\n        try:\n            input_str: str = str(input_str)\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception converting input string ({type(input_str)}) to str()\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    try:\n        hash = hashlib.md5(input_str.encode(encoding)).hexdigest()\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception converting string to hash. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n\n    return hash\n</code></pre>"},{"location":"reference/red_utils/std/hash_utils/operations/","title":"operations","text":""},{"location":"reference/red_utils/std/hash_utils/operations/#red_utils.std.hash_utils.operations.get_hash_from_str","title":"<code>get_hash_from_str(input_str=None, encoding='utf-8')</code>","text":"<p>Return a hashed version of an input string.</p> <p>Parameters:</p> Name Type Description Default <code>input_str</code> <code>str</code> <p>The string to hash</p> <code>None</code> <code>encoding</code> <code>str</code> <p>The character encoding to use</p> <code>'utf-8'</code> <p>Returns:</p> Type Description <code>str</code> <p>A hashed representation of <code>input_str</code></p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When input validation fails</p> <code>Exception</code> <p>A generic <code>Exception</code> when converting string to hash fails</p> Source code in <code>src\\red_utils\\std\\hash_utils\\operations.py</code> <pre><code>def get_hash_from_str(input_str: str = None, encoding: str = \"utf-8\") -&gt; str:\n    \"\"\"Return a hashed version of an input string.\n\n    Params:\n        input_str (str): The string to hash\n        encoding (str): The character encoding to use\n\n    Returns:\n        (str): A hashed representation of `input_str`\n\n    Raises:\n        ValueError: When input validation fails\n        Exception: A generic `Exception` when converting string to hash fails\n\n    \"\"\"\n    if not input_str:\n        raise ValueError(\"Missing input string\")\n\n    if not encoding:\n        raise ValueError(\"Missing encoding\")\n\n    if not isinstance(input_str, str):\n        try:\n            input_str: str = str(input_str)\n\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception converting input string ({type(input_str)}) to str()\"\n            )\n            log.error(msg)\n\n            raise exc\n\n    try:\n        hash = hashlib.md5(input_str.encode(encoding)).hexdigest()\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception converting string to hash. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n\n    return hash\n</code></pre>"},{"location":"reference/red_utils/std/list_utils/__init__/","title":"list_utils","text":""},{"location":"reference/red_utils/std/list_utils/__init__/#red_utils.std.list_utils.select_random_from_list","title":"<code>select_random_from_list(lst=None)</code>","text":"<p>Return a randomly selected item from the list.</p> <p>Parameters:</p> Name Type Description Default <code>lst</code> <code>list</code> <p>The Python list to select from.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>An object from the original list.</p> Source code in <code>src\\red_utils\\std\\list_utils\\operations.py</code> <pre><code>def select_random_from_list(lst: list[t.Any] = None) -&gt; t.Any:\n    \"\"\"Return a randomly selected item from the list.\n\n    Params:\n        lst (list): The Python list to select from.\n\n    Returns:\n        (Any): An object from the original list.\n\n    \"\"\"\n    validate_list(lst)\n\n    rand_index: int = random.randint(0, len(lst) - 1)\n\n    return lst[rand_index]\n</code></pre>"},{"location":"reference/red_utils/std/list_utils/__init__/#red_utils.std.list_utils.validate_list","title":"<code>validate_list(_list=None)</code>","text":"<p>Validate an input_list.</p> <p>Parameters:</p> Name Type Description Default <code>_list</code> <code>list</code> <p>The Python <code>list</code> to validate</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>A validated <code>list</code>.</p> Source code in <code>src\\red_utils\\std\\list_utils\\validators.py</code> <pre><code>def validate_list(_list: list[t.Any] = None) -&gt; list[t.Any]:\n    \"\"\"Validate an input_list.\n\n    Params:\n        _list (list): The Python `list` to validate\n\n    Returns:\n        (list): A validated `list`.\n\n    \"\"\"\n    assert _list is not None, ValueError(\"Missing list to evaluate\")\n    assert isinstance(_list, list), TypeError(\n        f\"Invalid type for input _list: ({type(_list)}). Must be a list.\"\n    )\n\n    return _list\n</code></pre>"},{"location":"reference/red_utils/std/list_utils/operations/","title":"operations","text":""},{"location":"reference/red_utils/std/list_utils/operations/#red_utils.std.list_utils.operations.select_random_from_list","title":"<code>select_random_from_list(lst=None)</code>","text":"<p>Return a randomly selected item from the list.</p> <p>Parameters:</p> Name Type Description Default <code>lst</code> <code>list</code> <p>The Python list to select from.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>An object from the original list.</p> Source code in <code>src\\red_utils\\std\\list_utils\\operations.py</code> <pre><code>def select_random_from_list(lst: list[t.Any] = None) -&gt; t.Any:\n    \"\"\"Return a randomly selected item from the list.\n\n    Params:\n        lst (list): The Python list to select from.\n\n    Returns:\n        (Any): An object from the original list.\n\n    \"\"\"\n    validate_list(lst)\n\n    rand_index: int = random.randint(0, len(lst) - 1)\n\n    return lst[rand_index]\n</code></pre>"},{"location":"reference/red_utils/std/list_utils/operations/#red_utils.std.list_utils.operations.validate_list","title":"<code>validate_list(_list=None)</code>","text":"<p>Validate an input_list.</p> <p>Parameters:</p> Name Type Description Default <code>_list</code> <code>list</code> <p>The Python <code>list</code> to validate</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>A validated <code>list</code>.</p> Source code in <code>src\\red_utils\\std\\list_utils\\validators.py</code> <pre><code>def validate_list(_list: list[t.Any] = None) -&gt; list[t.Any]:\n    \"\"\"Validate an input_list.\n\n    Params:\n        _list (list): The Python `list` to validate\n\n    Returns:\n        (list): A validated `list`.\n\n    \"\"\"\n    assert _list is not None, ValueError(\"Missing list to evaluate\")\n    assert isinstance(_list, list), TypeError(\n        f\"Invalid type for input _list: ({type(_list)}). Must be a list.\"\n    )\n\n    return _list\n</code></pre>"},{"location":"reference/red_utils/std/list_utils/validators/","title":"validators","text":"<p>Functions to validate inputs for other <code>red_utils.std.list_utils</code> methods.</p>"},{"location":"reference/red_utils/std/list_utils/validators/#red_utils.std.list_utils.validators.validate_list","title":"<code>validate_list(_list=None)</code>","text":"<p>Validate an input_list.</p> <p>Parameters:</p> Name Type Description Default <code>_list</code> <code>list</code> <p>The Python <code>list</code> to validate</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>A validated <code>list</code>.</p> Source code in <code>src\\red_utils\\std\\list_utils\\validators.py</code> <pre><code>def validate_list(_list: list[t.Any] = None) -&gt; list[t.Any]:\n    \"\"\"Validate an input_list.\n\n    Params:\n        _list (list): The Python `list` to validate\n\n    Returns:\n        (list): A validated `list`.\n\n    \"\"\"\n    assert _list is not None, ValueError(\"Missing list to evaluate\")\n    assert isinstance(_list, list), TypeError(\n        f\"Invalid type for input _list: ({type(_list)}). Must be a list.\"\n    )\n\n    return _list\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__base/","title":"__base","text":"<p>Stores a base logging config dict in <code>BASE_LOGGING_CONFIG_DICT</code>.</p> <p>This can be imported and updated to create a valid logging dictConfig.</p> Base logging config dict<pre><code>BASE_LOGGING_CONFIG_DICT: dict[str, t.Any] = {\n    \"version\": 1,\n    \"disable_existing_loggers\": False,\n    \"propagate\": True,\n    \"root\": {},\n    \"formatters\": {},\n    \"handlers\": {},\n    \"loggers\": {},\n}\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__init__/","title":"logging_utils","text":"<p>Classes and utilities to help configure the stdlib <code>logging</code> library for Python.</p> <p>Configurations (formatters, handlers, loggers, filters) can be created as classes, which can be compiled down to <code>logging.config.dictConfig</code>-compatible dicts using each class's <code>.get_dictconfig()</code> method, or by passing multiple initialized configuration classes to the <code>assemble_configdict()</code> method.</p>"},{"location":"reference/red_utils/std/logging_utils/__init__/#red_utils.std.logging_utils.assemble_configdict","title":"<code>assemble_configdict(disable_existing_loggers=False, propagate=False, root_handlers=['console'], root_level='DEBUG', formatters=None, handlers=None, loggers=None)</code>","text":"<p>Build a logging dictConfig dict.</p> Description Example logging config dict<pre><code>logging_config: dict = {\n    \"version\": 1,\n    \"disable_existing_loggers\": False,\n    \"propagate\": True,\n    \"root\": {},\n    \"formatters\": {},\n    \"handlers\": {},\n    \"loggers\": {},\n}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>disable_existing_loggers</code> <code>bool</code> <p>When <code>True</code>, disables all currently configured loggers to \"start fresh.\"</p> <code>False</code> <code>propagate</code> <code>bool</code> <p>When <code>True</code>, log messages will propagate up/down to the root logger.</p> <code>False</code> <code>root_handlers</code> <code>list[str]</code> <p>List of handlers for the root logger. These handler configs must exist in the logging dictConfig.</p> <code>['console']</code> <code>root_level</code> <code>str</code> <p>The log level for the root logger.</p> <code>'DEBUG'</code> <code>formatters</code> <code>list[FormatterConfig] | list[dict[str, dict[str, Any]]] | None</code> <p>List of logging formatter config objects.</p> <code>None</code> <code>handlers</code> <code>list[BaseHandlerConfig | dict[str, dict[str, Any]]] | None</code> <p>List of logging handler config objects.</p> <code>None</code> <code>loggers</code> <code>list[LoggerConfig | LoggerFactory | dict[str, dict[str, t.Any]]]] | None</code> <p>List of logging logger config objects.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>An initialized logging config dict created from inputs. Used with <code>logging.config.dictConfig()</code></p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def assemble_configdict(\n    disable_existing_loggers: bool = False,\n    propagate: bool = False,\n    root_handlers: list[str] = [\"console\"],\n    root_level: str = \"DEBUG\",\n    formatters: (\n        t.Union[list[FormatterConfig], list[LOGGING_CONFIG_DICT_TYPE_ANNOTATION]] | None\n    ) = None,\n    handlers: (\n        t.Union[HANDLER_CLASSES_TYPE_ANNOTATION, LOGGING_CONFIG_DICT_TYPE_ANNOTATION]\n        | None\n    ) = None,\n    loggers: (\n        t.Union[\n            list[t.Union[LoggerConfig, LoggerFactory]],\n            list[LOGGING_CONFIG_DICT_TYPE_ANNOTATION],\n        ]\n        | None\n    ) = None,\n) -&gt; dict[str, t.Any]:\n    \"\"\"Build a logging dictConfig dict.\n\n    Description:\n        ```python title=\"Example logging config dict\" linenums=\"1\"\n        logging_config: dict = {\n            \"version\": 1,\n            \"disable_existing_loggers\": False,\n            \"propagate\": True,\n            \"root\": {},\n            \"formatters\": {},\n            \"handlers\": {},\n            \"loggers\": {},\n        }\n        ```\n\n    Params:\n        disable_existing_loggers (bool): When `True`, disables all currently configured loggers to \"start fresh.\"\n        propagate (bool): When `True`, log messages will propagate up/down to the root logger.\n        root_handlers (list[str]): List of handlers for the root logger. These handler configs must exist in the logging dictConfig.\n        root_level (str): The log level for the root logger.\n        formatters (list[FormatterConfig] | list[dict[str, dict[str, t.Any]]] | None): List of logging formatter config objects.\n        handlers (list[BaseHandlerConfig | dict[str, dict[str, t.Any]]] | None): List of logging handler config objects.\n        loggers (list[LoggerConfig | LoggerFactory | dict[str, dict[str, t.Any]]]] | None): List of logging logger config objects.\n\n    Returns:\n        (dict[str, Any]): An initialized logging config dict created from inputs. Used with `logging.config.dictConfig()`\n\n    \"\"\"\n    ## Get base logging configDict object, with empty formatters, loggers, etc\n    logging_config: dict[str, t.Any] = BASE_LOGGING_CONFIG_DICT\n\n    ## Set logging config options\n    logging_config[\"disable_existing_loggers\"] = disable_existing_loggers\n    logging_config[\"propagate\"] = propagate\n\n    ## Build root logger\n    config_key_root = {\n        ## Set handlers\n        \"handlers\": root_handlers,\n        ## Set log level string\n        \"level\": root_level.upper(),\n    }\n\n    ## Update config dict's `root` key\n    logging_config[\"root\"] = config_key_root\n\n    ## Initialize formatter, handler, logger config dicts\n    formatter_configdicts: LOGGING_CONFIG_DICT_TYPE = {}\n    handler_configdicts: LOGGING_CONFIG_DICT_TYPE = {}\n    logger_configdicts: LOGGING_CONFIG_DICT_TYPE = {}\n\n    if formatters is not None:\n        ## Formatters passed to function, parse and add to config\n        for formatter_dict in formatters:\n            if isinstance(formatter_dict, dict):\n                pass\n            elif isinstance(formatter_dict, FormatterConfig):\n                try:\n                    formatter_dict: dict = formatter_dict.get_configdict()\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Unhandled exception getting config dict for FormatterConfig object. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n            formatter_configdicts.update(formatter_dict)\n\n    if handlers is not None:\n        ## Handlers passed to function, parse and add to config\n        for handler_dict in handlers:\n            if isinstance(handler_dict, dict):\n                pass\n            elif isinstance(handler_dict, HANDLER_CLASSES_TYPE):\n                try:\n                    handler_dict = handler_dict.get_configdict()\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Unhandled exception getting config dict for *HandlerConfig object. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n            handler_configdicts.update(handler_dict)\n\n    if loggers:\n        ## Loggers passed to function, parse and add to config\n        for logger_dict in loggers:\n            if isinstance(logger_dict, dict):\n                pass\n            elif isinstance(logger_dict, LoggerConfig):\n                try:\n                    logger_dict = logger_dict.get_configdict()\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Unhandled exception getting config dict for LoggerConfig object. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n            logger_configdicts.update(logger_dict)\n\n    ## Create a copy of the original config\n    try:\n        return_dict = deepcopy(logging_config)\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception copying original logging config. Proceeding with original logging config\"\n        )\n        log.warning(msg)\n\n        return_dict = logging_config\n\n    ## Update formatters, handlers, loggers in logging config copy\n    return_dict[\"formatters\"] = formatter_configdicts\n    return_dict[\"handlers\"] = handler_configdicts\n    return_dict[\"loggers\"] = logger_configdicts\n\n    ## Return initialized logging config\n    return return_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__init__/#red_utils.std.logging_utils.get_formatter_config","title":"<code>get_formatter_config(name='default', fmt=MESSAGE_FMT_STANDARD, datefmt=DATE_FMT_STANDARD, style='%', validate=True, as_dict=False)</code>","text":"<p>Return a FormatterConfig, or a dict representing a Formatter.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name for the formatter. Reference this formatter by name in a LoggerConfig.</p> <code>'default'</code> <code>fmt</code> <code>str</code> <p>The string format for log messages. Python docs: Log Record Attributes</p> <code>MESSAGE_FMT_STANDARD</code> <code>datefmt</code> <code>str</code> <p>The format for log message timestamps, if <code>%(asctime)s</code> is used in the logging <code>fmt</code>.</p> <code>DATE_FMT_STANDARD</code> <code>style</code> <code>str</code> <p>The style of string substitution to use for the formatter. Options include <code>%</code> for <code>'%', some_var</code>, <code>{</code> for <code>'{some_var}</code>, etc.</p> <code>'%'</code> <code>validate</code> <code>bool</code> <p>If <code>True</code>, the handler will be validated by the logging module before fully initializing.</p> <code>True</code> <code>as_dict</code> <code>bool</code> <p>If <code>True</code>, return the configuration as a dict that can be joined into <code>dictConfig()</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>If <code>as_dict=True</code>, return a config dict instead of a FormatterConfig object.</p> <code>FormatterConfig</code> <p>If <code>as_dict=False</code>, return a FormatterConfig object.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def get_formatter_config(\n    name: str = \"default\",\n    fmt: str = MESSAGE_FMT_STANDARD,\n    datefmt: str = DATE_FMT_STANDARD,\n    style: str = \"%\",\n    validate: bool = True,\n    as_dict: bool = False,\n) -&gt; dict[str, dict[str, str]] | FormatterConfig:\n    \"\"\"Return a FormatterConfig, or a dict representing a Formatter.\n\n    Params:\n        name (str): The name for the formatter. Reference this formatter by name in a LoggerConfig.\n        fmt (str): The string format for log messages.\n            [Python docs: Log Record Attributes](https://docs.python.org/3/library/logging.html#logrecord-attributes)\n        datefmt (str): The format for log message timestamps, if `%(asctime)s` is used in the logging `fmt`.\n        style (str): The style of string substitution to use for the formatter. Options include `%` for `'%', some_var`,\n            `{` for `'{some_var}`, etc.\n        validate (bool): If `True`, the handler will be validated by the logging module before fully initializing.\n        as_dict (bool): If `True`, return the configuration as a dict that can be joined into `dictConfig()`.\n\n    Returns:\n        (dict[str, dict[str, Any]]): If `as_dict=True`, return a config dict instead of a FormatterConfig object.\n        (FormatterConfig): If `as_dict=False`, return a FormatterConfig object.\n\n    \"\"\"\n    try:\n        ## Initialize formatter object\n        _formatter: FormatterConfig = FormatterConfig(\n            name=name, fmt=fmt, datefmt=datefmt, style=style, validate=validate\n        )\n\n        if as_dict:\n            ## Return formatter representation as a dict\n            return _formatter.get_configdict()\n        else:\n            ## Return FormatterConfig object\n            return _formatter\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception building FormatterConfig. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__init__/#red_utils.std.logging_utils.get_logger_config","title":"<code>get_logger_config(name='app', handlers=['console'], level='DEBUG', propagate=False, as_dict=False)</code>","text":"<p>Return a LoggerConfig, or a dict representing a Logger.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name for the logger. Reference this logger by name in a LoggerConfig.</p> <code>'app'</code> <code>level</code> <code>str</code> <p>The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'DEBUG'</code> <code>handlers</code> <code>list[str]</code> <p>List of handler names that exist in the logging configDict that this logger should use.</p> <code>['console']</code> <code>propagate</code> <code>bool</code> <p>If <code>True</code>, log messages will be propagated up/down to the root logger.</p> <code>False</code> <code>as_dict</code> <code>bool</code> <p>If <code>True</code>, return the configuration as a dict that can be joined into <code>dictConfig()</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>If <code>as_dict=True</code>, return a config dict instead of a RotatingFileHandlerConfig object.</p> <code>RotatingFileHandlerConfig</code> <p>If <code>as_dict=False</code>, return a RotatingFileHandlerConfig object.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def get_logger_config(\n    name: str = \"app\",\n    handlers: list[str] = [\"console\"],\n    level: str = \"DEBUG\",\n    propagate: bool = False,\n    as_dict: bool = False,\n) -&gt; dict[str, dict[str, str]] | LoggerConfig:\n    \"\"\"Return a LoggerConfig, or a dict representing a Logger.\n\n    Params:\n        name (str): The name for the logger. Reference this logger by name in a LoggerConfig.\n        level (str): The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        handlers (list[str]): List of handler names that exist in the logging configDict that this logger should use.\n        propagate (bool): If `True`, log messages will be propagated up/down to the root logger.\n        as_dict (bool): If `True`, return the configuration as a dict that can be joined into `dictConfig()`.\n\n    Returns:\n        (dict[str, dict[str, Any]]): If `as_dict=True`, return a config dict instead of a RotatingFileHandlerConfig object.\n        (RotatingFileHandlerConfig): If `as_dict=False`, return a RotatingFileHandlerConfig object.\n\n    \"\"\"\n    try:\n        ## Initialize logger object\n        _logger: LoggerConfig = LoggerConfig(\n            name=name, level=level.upper(), handlers=handlers, propagate=propagate\n        )\n\n        if as_dict:\n            ## Return logger representation as a dict\n            return _logger.get_configdict()\n        else:\n            ## Return LoggerConfig object\n            return _logger\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception initializing logger. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__init__/#red_utils.std.logging_utils.get_rotatingfilehandler_config","title":"<code>get_rotatingfilehandler_config(name='rotating_app_file', level='DEBUG', formatter='default', filters=None, filename=None, maxBytes=100000, backupCount=3, as_dict=False)</code>","text":"<p>Return a RotatingFileHandlerConfig, or a dict representing a RotatingFileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name for the rotating file handler. Reference this handler by name in a LoggerConfig.</p> <code>'rotating_app_file'</code> <code>level</code> <code>str</code> <p>The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'DEBUG'</code> <code>formatter</code> <code>str</code> <p>The name of a formatter that exists in the overall logging dictConfig.</p> <code>'default'</code> <code>filters</code> <code>list[str] | None</code> <p>A list of function names for logging filters.</p> <code>None</code> <code>filename</code> <code>str | Path</code> <p>The full path to the log file you want to create. If parent directories do not exist, this method will handle creating them.</p> <code>None</code> <code>maxBytes</code> <code>int</code> <p>The maximum size (in bytes) before a logfile is rotated.</p> <code>100000</code> <code>backupCount</code> <code>int</code> <p>The number of backups to keep as log files rotate.</p> <code>3</code> <code>as_dict</code> <code>bool</code> <p>If <code>True</code>, return the configuration as a dict that can be joined into <code>dictConfig()</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>If <code>as_dict=True</code>, return a config dict instead of a RotatingFileHandlerConfig object.</p> <code>RotatingFileHandlerConfig</code> <p>If <code>as_dict=False</code>, return a RotatingFileHandlerConfig object.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def get_rotatingfilehandler_config(\n    name: str = \"rotating_app_file\",\n    level: str = \"DEBUG\",\n    formatter: str = \"default\",\n    filters: list | None = None,\n    filename: t.Union[str, Path] = None,\n    maxBytes: int = 100000,\n    backupCount: int = 3,\n    as_dict: bool = False,\n) -&gt; dict[str, dict[str, t.Any]] | RotatingFileHandlerConfig:\n    \"\"\"Return a RotatingFileHandlerConfig, or a dict representing a RotatingFileHandler.\n\n    Params:\n        name (str): The name for the rotating file handler. Reference this handler by name in a LoggerConfig.\n        level (str): The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        formatter (str): The name of a formatter that exists in the overall logging dictConfig.\n        filters (list[str] | None): A list of function names for logging filters.\n        filename (str | Path): The full path to the log file you want to create. If parent directories do not exist,\n            this method will handle creating them.\n        maxBytes (int): The maximum size (in bytes) before a logfile is rotated.\n        backupCount (int): The number of backups to keep as log files rotate.\n        as_dict (bool): If `True`, return the configuration as a dict that can be joined into `dictConfig()`.\n\n    Returns:\n        (dict[str, dict[str, Any]]): If `as_dict=True`, return a config dict instead of a RotatingFileHandlerConfig object.\n        (RotatingFileHandlerConfig): If `as_dict=False`, return a RotatingFileHandlerConfig object.\n\n    \"\"\"\n    ## Convert &amp; optionally expand input path\n    filename: Path = Path(f\"{filename}\")\n    if \"~\" in f\"{filename}\":\n        filename = filename.expanduser()\n\n    ## Create parent dirs for logging file, if they don't exist\n    ensure_logdir(p=filename.parent)\n\n    try:\n        ## Initialize handler object\n        _handler: RotatingFileHandlerConfig = RotatingFileHandlerConfig(\n            name=name,\n            level=level,\n            formatter=formatter,\n            filters=filters,\n            filename=filename,\n            maxBytes=maxBytes,\n            backupCount=backupCount,\n        )\n\n        if as_dict:\n            ## Return handler representation as a dict\n            return _handler.get_configdict()\n        else:\n            ## Return RotatingFileHandlerConfig object\n            return _handler\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception building RotatingFileHandlerConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__init__/#red_utils.std.logging_utils.get_streamhandler_config","title":"<code>get_streamhandler_config(name='console', level='INFO', formatter='default', filters=None, stream='ext://sys.stdout', as_dict=False)</code>","text":"<p>Return a StreamHandlerConfig, or a dict representing a StreamingHandler.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name for the stream handler. Reference this handler by name in a LoggerConfig.</p> <code>'console'</code> <code>level</code> <code>str</code> <p>The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'INFO'</code> <code>formatter</code> <code>str</code> <p>The name of a formatter that exists in the overall logging dictConfig.</p> <code>'default'</code> <code>filters</code> <code>list[str] | None</code> <p>A list of function names for logging filters.</p> <code>None</code> <code>stream</code> <code>str</code> <p>The stream this handler should use, i.e. <code>ext://sys.stdout</code>, <code>ext://sys.stderr</code>, etc.</p> <code>'ext://sys.stdout'</code> <code>as_dict</code> <code>bool</code> <p>If <code>True</code>, return the configuration as a dict that can be joined into <code>dictConfig()</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>If <code>as_dict=True</code>, return a config dict instead of a StreamHandlerConfig object.</p> <code>StreamHandlerConfig</code> <p>If <code>as_dict=False</code>, return a StreamHandlerConfig object.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def get_streamhandler_config(\n    name: str = \"console\",\n    level: str = \"INFO\",\n    formatter: str = \"default\",\n    filters: list | None = None,\n    stream: str = \"ext://sys.stdout\",\n    as_dict: bool = False,\n) -&gt; dict[str, dict[str, str]] | StreamHandlerConfig:\n    \"\"\"Return a StreamHandlerConfig, or a dict representing a StreamingHandler.\n\n    Params:\n        name (str): The name for the stream handler. Reference this handler by name in a LoggerConfig.\n        level (str): The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        formatter (str): The name of a formatter that exists in the overall logging dictConfig.\n        filters (list[str] | None): A list of function names for logging filters.\n        stream (str): The stream this handler should use, i.e. `ext://sys.stdout`, `ext://sys.stderr`, etc.\n        as_dict (bool): If `True`, return the configuration as a dict that can be joined into `dictConfig()`.\n\n    Returns:\n        (dict[str, dict[str, Any]]): If `as_dict=True`, return a config dict instead of a StreamHandlerConfig object.\n        (StreamHandlerConfig): If `as_dict=False`, return a StreamHandlerConfig object.\n\n    \"\"\"\n    try:\n        ## Initialize handler object\n        _handler: StreamHandlerConfig = StreamHandlerConfig(\n            name=name, level=level, formatter=formatter, filters=filters, stream=stream\n        )\n\n        if as_dict:\n            ## Return handler representation as a dict\n            return _handler.get_configdict()\n        else:\n            ## Return StreamHandlerConfig object\n            return _handler\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception building StreamHandlerConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__init__/#red_utils.std.logging_utils.print_configdict","title":"<code>print_configdict(logging_config=None)</code>","text":"<p>Print a logging config dict as a JSON string.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def print_configdict(logging_config: dict = None) -&gt; None:\n    \"\"\"Print a logging config dict as a JSON string.\"\"\"\n    assert logging_config, ValueError(\"Missing a logging dictConfig to print.\")\n\n    print_msg: str = json.dumps(logging_config)\n\n    print(f\"Logging config dict:\\n{print_msg}\")\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__init__/#red_utils.std.logging_utils.save_configdict","title":"<code>save_configdict(logging_config=None, output_file=Path('logging_config.json'), overwrite=False)</code>","text":"<p>Save a logging dictConfig to a JSON file.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def save_configdict(\n    logging_config: dict = None,\n    output_file: t.Union[str, Path] = Path(\"logging_config.json\"),\n    overwrite: bool = False,\n) -&gt; None:\n    \"\"\"Save a logging dictConfig to a JSON file.\"\"\"\n    output_file: Path = Path(f\"{output_file}\")\n    if \"~\" in f\"{output_file}\":\n        output_file = output_file.expanduser()\n\n    ensure_logdir(p=output_file.parent)\n\n    if output_file.exists() and not overwrite:\n        log.warning(\n            f\"Logging dictConfig already saved to file '{output_file}' and overwrite=False. Skipping.\"\n        )\n\n        return\n\n    try:\n        config_json = json.dumps(logging_config, indent=2)\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception converting logging dict to JSON. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n\n    try:\n        with open(output_file, \"w\") as f:\n            f.write(config_json)\n    except PermissionError as perm_err:\n        msg = Exception(\n            f\"Permission denied saving logging dictConfig to file '{output_file}'. Details: {perm_err}\"\n        )\n        log.error(msg)\n\n        raise perm_err\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception saving logging dictConfig to JSON file '{output_file}'. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/","title":"__methods","text":"<p>Functions to add in creating/working with the logging config classes in this module.</p>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.FileHandlerConfig","title":"<code>FileHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging FileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file to log messages to.</p> <code>'app.log'</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass FileHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging FileHandler.\n\n    Params:\n        filename (str): The name of the file to log messages to.\n    \"\"\"\n\n    filename: str | None = field(default=\"app.log\")\n\n    def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, str]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"filename\": self.filename,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.FileHandler`.\n\n        \"\"\"\n        return \"logging.FileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.FileHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, str]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"filename\": self.filename,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.FileHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.FileHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.FileHandler`.\n\n    \"\"\"\n    return \"logging.FileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.FormatterConfig","title":"<code>FormatterConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseLoggingConfig</code></p> <p>Define a logging formatter.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the formatter.</p> <code>None</code> <code>fmt</code> <code>str</code> <p>The string formatting to use for log messages.</p> <code>MESSAGE_FMT_STANDARD</code> <code>datefmt</code> <code>str</code> <p>The string formatting to use for log message timestamps.</p> <code>DATE_FMT_STANDARD</code> <code>style</code> <code>str</code> <p>The string substitution style to use for log formats. Default is <code>%</code>, which means formats need to be written like <code>%(asctime)s %(levelname)s %(message)s</code>. If you change this style, make sure the <code>fmt</code> you pass uses the correct formatting style.</p> <code>'%'</code> <code>validate</code> <code>bool</code> <p>When <code>True</code>, the configuration dict this formatter returns will be validated by the logging module.</p> <code>True</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\formatters\\_formatters.py</code> <pre><code>@dataclass\nclass FormatterConfig(BaseLoggingConfig):\n    \"\"\"Define a logging formatter.\n\n    Params:\n        name (str): The name of the formatter.\n        fmt (str): The string formatting to use for log messages.\n        datefmt (str): The string formatting to use for log message timestamps.\n        style (str): The string substitution style to use for log formats. Default is `%`, which\n            means formats need to be written like `%(asctime)s %(levelname)s %(message)s`. If\n            you change this style, make sure the `fmt` you pass uses the correct formatting style.\n        validate (bool): When `True`, the configuration dict this formatter returns will be validated by the logging module.\n\n    \"\"\"\n\n    name: str = None\n    fmt: str = MESSAGE_FMT_STANDARD\n    datefmt: str = DATE_FMT_STANDARD\n    style: str = \"%\"\n    validate: bool = True\n\n    def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Return a dict representation of the formatter described by this class.\"\"\"\n        formatter_dict: dict[str, dict[str, str]] = {self.name: {\"format\": self.fmt}}\n        if self.datefmt:\n            formatter_dict[self.name][\"datefmt\"] = self.datefmt\n        if self.style:\n            formatter_dict[self.name][\"style\"] = self.style\n        formatter_dict[self.name][\"validate\"] = self.validate\n\n        return formatter_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.FormatterConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the formatter described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\formatters\\_formatters.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Return a dict representation of the formatter described by this class.\"\"\"\n    formatter_dict: dict[str, dict[str, str]] = {self.name: {\"format\": self.fmt}}\n    if self.datefmt:\n        formatter_dict[self.name][\"datefmt\"] = self.datefmt\n    if self.style:\n        formatter_dict[self.name][\"style\"] = self.style\n    formatter_dict[self.name][\"validate\"] = self.validate\n\n    return formatter_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.LoggerConfig","title":"<code>LoggerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseLoggingConfig</code></p> <p>Define a logging Logger.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the logger.</p> required <code>level</code> <code>str</code> <p>The level of log messages this logger should show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> required <code>handlers</code> <code>list[str]</code> <p>List of handler names this logger should use. These handlers must exist in the logging dictConfig.</p> required <code>propagate</code> <code>bool</code> <p>If <code>True</code>, messages will be propagated up/down to the root logger.</p> <code>False</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_loggers.py</code> <pre><code>@dataclass\nclass LoggerConfig(BaseLoggingConfig):\n    \"\"\"Define a logging Logger.\n\n    Params:\n        name (str): The name of the logger.\n        level (str): The level of log messages this logger should show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        handlers (list[str]): List of handler names this logger should use. These handlers must exist in the logging dictConfig.\n        propagate (bool): If `True`, messages will be propagated up/down to the root logger.\n    \"\"\"\n\n    name: str\n    level: str\n    handlers: list[str]\n    propagate: bool = False\n\n    def get_configdict(self) -&gt; dict:\n        \"\"\"Return a dict representation of the logger described by this class.\"\"\"\n        logger_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"level\": self.level,\n                \"handlers\": self.handlers,\n                \"propagate\": self.propagate,\n            }\n        }\n        return logger_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.LoggerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the logger described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_loggers.py</code> <pre><code>def get_configdict(self) -&gt; dict:\n    \"\"\"Return a dict representation of the logger described by this class.\"\"\"\n    logger_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"level\": self.level,\n            \"handlers\": self.handlers,\n            \"propagate\": self.propagate,\n        }\n    }\n    return logger_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.LoggerFactory","title":"<code>LoggerFactory</code>","text":"<p>Generate loggers based on LoggerFactory's config.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_factory.py</code> <pre><code>class LoggerFactory:\n    \"\"\"Generate loggers based on LoggerFactory's config.\"\"\"\n\n    _LOG: logging.Logger | None = None\n\n    @staticmethod\n    def __create_logger(\n        name: str,\n        log_level: str,\n        handlers: dict[str, dict],\n        formatters: dict[str, dict],\n        loggers: dict[str, dict],\n    ) -&gt; logging.Logger:\n        \"\"\"Create a logger cnofig from inputs.\n\n        Params:\n            name (str): The name of the logger.\n            log_level (str): The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n            handlers (dict[str, dict[str, Any]]): A dict describing the handlers for this logger config.\n            formatters (dict[str, dict[str, Any]]): A dict describing the formatters for this logger config.\n            loggers (dict[str, dict[str, Any]]): A dict describing the loggers for this logger config.\n        \"\"\"\n        log_level = log_level.upper()\n\n        # Configure logging using dictConfig\n        logging_config = {\n            \"version\": 1,\n            \"handlers\": handlers,\n            \"formatters\": formatters,\n            \"loggers\": loggers,\n            \"root\": {\n                \"level\": log_level,\n                \"handlers\": list(handlers.keys()),\n            },\n        }\n\n        try:\n            logging.config.dictConfig(logging_config)\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception configuring logger. Details: {exc}\")\n            # log.error(msg)\n\n            raise msg\n\n        # Get or create logger\n        LoggerFactory._LOG = logging.getLogger(name)\n\n        return LoggerFactory._LOG\n\n    @staticmethod\n    def get_logger(\n        name: str,\n        log_level: str,\n        handlers: dict[str, dict],\n        formatters: dict[str, dict],\n        loggers: dict[str, dict],\n    ) -&gt; logging.Logger:\n        \"\"\"Initialize a logger.\n\n        Params:\n            name (str): The name of the logger.\n            log_level (str): The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n            handlers (dict[str, dict[str, Any]]): A dict describing the handlers for this logger config.\n            formatters (dict[str, dict[str, Any]]): A dict describing the formatters for this logger config.\n            loggers (dict[str, dict[str, Any]]): A dict describing the loggers for this logger config.\n        \"\"\"\n        logger = LoggerFactory.__create_logger(\n            name=name,\n            log_level=log_level,\n            handlers=handlers,\n            formatters=formatters,\n            loggers=loggers,\n        )\n\n        return logger\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.LoggerFactory.get_logger","title":"<code>get_logger(name, log_level, handlers, formatters, loggers)</code>  <code>staticmethod</code>","text":"<p>Initialize a logger.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the logger.</p> required <code>log_level</code> <code>str</code> <p>The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> required <code>handlers</code> <code>dict[str, dict[str, Any]]</code> <p>A dict describing the handlers for this logger config.</p> required <code>formatters</code> <code>dict[str, dict[str, Any]]</code> <p>A dict describing the formatters for this logger config.</p> required <code>loggers</code> <code>dict[str, dict[str, Any]]</code> <p>A dict describing the loggers for this logger config.</p> required Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_factory.py</code> <pre><code>@staticmethod\ndef get_logger(\n    name: str,\n    log_level: str,\n    handlers: dict[str, dict],\n    formatters: dict[str, dict],\n    loggers: dict[str, dict],\n) -&gt; logging.Logger:\n    \"\"\"Initialize a logger.\n\n    Params:\n        name (str): The name of the logger.\n        log_level (str): The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        handlers (dict[str, dict[str, Any]]): A dict describing the handlers for this logger config.\n        formatters (dict[str, dict[str, Any]]): A dict describing the formatters for this logger config.\n        loggers (dict[str, dict[str, Any]]): A dict describing the loggers for this logger config.\n    \"\"\"\n    logger = LoggerFactory.__create_logger(\n        name=name,\n        log_level=log_level,\n        handlers=handlers,\n        formatters=formatters,\n        loggers=loggers,\n    )\n\n    return logger\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.QueueHandlerConfig","title":"<code>QueueHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging QueueHandler.</p> <p>Parameters:</p> Name Type Description Default <code>queue</code> <code>Queue</code> <p>The queue to send log messages to.</p> <code>None</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass QueueHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging QueueHandler.\n\n    Params:\n        queue (queue.Queue): The queue to send log messages to.\n    \"\"\"\n\n    queue: Queue = field(default=None)\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"queue\": self.queue,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.QueueHandler`.\n\n        \"\"\"\n        return \"logging.handlers.QueueHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.QueueHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"queue\": self.queue,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.QueueHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.QueueHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.QueueHandler`.\n\n    \"\"\"\n    return \"logging.handlers.QueueHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.QueueListenerConfig","title":"<code>QueueListenerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseLoggingConfig</code></p> <p>Define a logging QueueListener.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the handler.</p> required <code>queue</code> <code>Queue</code> <p>The queue to listen for log messages in.</p> required <code>handlers</code> <code>list[str]</code> <p>List of handler names to apply to this listener.</p> required Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass QueueListenerConfig(BaseLoggingConfig):\n    \"\"\"Define a logging QueueListener.\n\n    Params:\n        name (str): The name of the handler.\n        queue (queue.Queue): The queue to listen for log messages in.\n        handlers (list[str]): List of handler names to apply to this listener.\n\n    \"\"\"\n\n    name: str\n    queue: Queue\n    handlers: list\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        listener_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"queue\": self.queue,\n                \"handlers\": self.handlers,\n            }\n        }\n        return listener_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.QueueListener`.\n\n        \"\"\"\n        return \"logging.handleres.QueueListener\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.QueueListenerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    listener_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"queue\": self.queue,\n            \"handlers\": self.handlers,\n        }\n    }\n    return listener_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.QueueListenerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.QueueListener</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.QueueListener`.\n\n    \"\"\"\n    return \"logging.handleres.QueueListener\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.RotatingFileHandlerConfig","title":"<code>RotatingFileHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging RotatingFileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | None</code> <p>The name/path of the file to log messages to.</p> <code>'app.log'</code> <code>maxBytes</code> <code>int</code> <p>The maximum size of the file (in bytes) before a new file is rotated.</p> <code>0</code> <code>backupCount</code> <code>int</code> <p>Number of rotated log files to keep.</p> <code>0</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass RotatingFileHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging RotatingFileHandler.\n\n    Params:\n        filename (str | None): The name/path of the file to log messages to.\n        maxBytes (int): The maximum size of the file (in bytes) before a new file is rotated.\n        backupCount (int): Number of rotated log files to keep.\n\n    \"\"\"\n\n    filename: str | None = field(default=\"app.log\")\n    maxBytes: int = 0\n    backupCount: int = 0\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"filename\": f\"{self.filename}\",\n                \"maxBytes\": self.maxBytes,\n                \"backupCount\": self.backupCount,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.RotatingFileHandler`.\n\n        \"\"\"\n        return \"logging.handlers.RotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.RotatingFileHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"filename\": f\"{self.filename}\",\n            \"maxBytes\": self.maxBytes,\n            \"backupCount\": self.backupCount,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.RotatingFileHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.RotatingFileHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.RotatingFileHandler`.\n\n    \"\"\"\n    return \"logging.handlers.RotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.SocketHandlerConfig","title":"<code>SocketHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging SocketHandler.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Host IP/FQDN.</p> <code>'localhost'</code> <code>port</code> <code>int</code> <p>Host port where log messages should be sent.</p> <code>0</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass SocketHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging SocketHandler.\n\n    Params:\n        host (str): Host IP/FQDN.\n        port (int): Host port where log messages should be sent.\n    \"\"\"\n\n    host: str = \"localhost\"\n    port: int = 0\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"host\": self.host,\n                \"port\": self.port,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.SocketHandler`.\n\n        \"\"\"\n        return \"logging.handlers.SocketHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.SocketHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"host\": self.host,\n            \"port\": self.port,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.SocketHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.SocketHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.SocketHandler`.\n\n    \"\"\"\n    return \"logging.handlers.SocketHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.StreamHandlerConfig","title":"<code>StreamHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging StreamHandler.</p> <p>Parameters:</p> Name Type Description Default <code>stream</code> <code>Any</code> <p>The stream this handler controls, i.e. <code>ext://sys.stdout</code>, <code>ext://sys.stderr</code>, etc.</p> <code>'ext://sys.stdout'</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass StreamHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging StreamHandler.\n\n    Params:\n        stream (Any): The stream this handler controls, i.e. `ext://sys.stdout`, `ext://sys.stderr`, etc.\n    \"\"\"\n\n    stream: t.Any | None = \"ext://sys.stdout\"\n\n    def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, str]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"stream\": self.stream,\n            }\n        }\n        if self.filters:\n            handler_dict[\"filters\"] = self.filters\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.StreamHandler`.\n\n        \"\"\"\n        return \"logging.StreamHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.StreamHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, str]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"stream\": self.stream,\n        }\n    }\n    if self.filters:\n        handler_dict[\"filters\"] = self.filters\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.StreamHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.StreamHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.StreamHandler`.\n\n    \"\"\"\n    return \"logging.StreamHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.TimedRotatingFileHandlerConfig","title":"<code>TimedRotatingFileHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging TimedRotatingFileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name/path of the file to log messages to.</p> <code>'app.log'</code> <code>when</code> <code>str</code> <p>Time of day to rotate log files, i.e. <code>midnight</code>.</p> <code>'midnight'</code> <code>interval</code> <code>int</code> <p>When to rotate the file as the interval defined in <code>when</code> occurs. <code>1=every occurrence</code>, <code>2=every other occurrence</code>, etc.</p> <code>1</code> <code>backupCount</code> <code>int</code> <p>The number of rotated log files to save.</p> <code>0</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass TimedRotatingFileHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging TimedRotatingFileHandler.\n\n    Params:\n        filename (str): The name/path of the file to log messages to.\n        when (str): Time of day to rotate log files, i.e. `midnight`.\n        interval (int): When to rotate the file as the interval defined in `when` occurs.\n            `1=every occurrence`, `2=every other occurrence`, etc.\n        backupCount (int): The number of rotated log files to save.\n    \"\"\"\n\n    filename: str | None = field(default=\"app.log\")\n    when: str | None = field(default=\"midnight\")\n    interval: int = 1\n    backupCount: int = 0\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"filename\": self.filename,\n                \"when\": self.when,\n                \"interval\": self.interval,\n                \"backupCount\": self.backupCount,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.TimedRotatingFileHandler`.\n\n        \"\"\"\n        return \"logging.handlers.TimedRotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.TimedRotatingFileHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"filename\": self.filename,\n            \"when\": self.when,\n            \"interval\": self.interval,\n            \"backupCount\": self.backupCount,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.TimedRotatingFileHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.TimedRotatingFileHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.TimedRotatingFileHandler`.\n\n    \"\"\"\n    return \"logging.handlers.TimedRotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.assemble_configdict","title":"<code>assemble_configdict(disable_existing_loggers=False, propagate=False, root_handlers=['console'], root_level='DEBUG', formatters=None, handlers=None, loggers=None)</code>","text":"<p>Build a logging dictConfig dict.</p> Description Example logging config dict<pre><code>logging_config: dict = {\n    \"version\": 1,\n    \"disable_existing_loggers\": False,\n    \"propagate\": True,\n    \"root\": {},\n    \"formatters\": {},\n    \"handlers\": {},\n    \"loggers\": {},\n}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>disable_existing_loggers</code> <code>bool</code> <p>When <code>True</code>, disables all currently configured loggers to \"start fresh.\"</p> <code>False</code> <code>propagate</code> <code>bool</code> <p>When <code>True</code>, log messages will propagate up/down to the root logger.</p> <code>False</code> <code>root_handlers</code> <code>list[str]</code> <p>List of handlers for the root logger. These handler configs must exist in the logging dictConfig.</p> <code>['console']</code> <code>root_level</code> <code>str</code> <p>The log level for the root logger.</p> <code>'DEBUG'</code> <code>formatters</code> <code>list[FormatterConfig] | list[dict[str, dict[str, Any]]] | None</code> <p>List of logging formatter config objects.</p> <code>None</code> <code>handlers</code> <code>list[BaseHandlerConfig | dict[str, dict[str, Any]]] | None</code> <p>List of logging handler config objects.</p> <code>None</code> <code>loggers</code> <code>list[LoggerConfig | LoggerFactory | dict[str, dict[str, t.Any]]]] | None</code> <p>List of logging logger config objects.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>An initialized logging config dict created from inputs. Used with <code>logging.config.dictConfig()</code></p> Source code in <code>src\\red_utils\\std\\logging_utils\\__methods.py</code> <pre><code>def assemble_configdict(\n    disable_existing_loggers: bool = False,\n    propagate: bool = False,\n    root_handlers: list[str] = [\"console\"],\n    root_level: str = \"DEBUG\",\n    formatters: (\n        t.Union[list[FormatterConfig], list[LOGGING_CONFIG_DICT_TYPE_ANNOTATION]] | None\n    ) = None,\n    handlers: (\n        t.Union[HANDLER_CLASSES_TYPE_ANNOTATION, LOGGING_CONFIG_DICT_TYPE_ANNOTATION]\n        | None\n    ) = None,\n    loggers: (\n        t.Union[\n            list[t.Union[LoggerConfig, LoggerFactory]],\n            list[LOGGING_CONFIG_DICT_TYPE_ANNOTATION],\n        ]\n        | None\n    ) = None,\n) -&gt; dict[str, t.Any]:\n    \"\"\"Build a logging dictConfig dict.\n\n    Description:\n        ```python title=\"Example logging config dict\" linenums=\"1\"\n        logging_config: dict = {\n            \"version\": 1,\n            \"disable_existing_loggers\": False,\n            \"propagate\": True,\n            \"root\": {},\n            \"formatters\": {},\n            \"handlers\": {},\n            \"loggers\": {},\n        }\n        ```\n\n    Params:\n        disable_existing_loggers (bool): When `True`, disables all currently configured loggers to \"start fresh.\"\n        propagate (bool): When `True`, log messages will propagate up/down to the root logger.\n        root_handlers (list[str]): List of handlers for the root logger. These handler configs must exist in the logging dictConfig.\n        root_level (str): The log level for the root logger.\n        formatters (list[FormatterConfig] | list[dict[str, dict[str, t.Any]]] | None): List of logging formatter config objects.\n        handlers (list[BaseHandlerConfig | dict[str, dict[str, t.Any]]] | None): List of logging handler config objects.\n        loggers (list[LoggerConfig | LoggerFactory | dict[str, dict[str, t.Any]]]] | None): List of logging logger config objects.\n\n    Returns:\n        (dict[str, Any]): An initialized logging config dict created from inputs. Used with `logging.config.dictConfig()`\n\n    \"\"\"\n    ## Get base logging configDict object, with empty formatters, loggers, etc\n    logging_config: dict[str, t.Any] = BASE_LOGGING_CONFIG_DICT\n\n    ## Set logging config options\n    logging_config[\"disable_existing_loggers\"] = disable_existing_loggers\n    logging_config[\"propagate\"] = propagate\n\n    ## Build root logger\n    config_key_root = {\n        ## Set handlers\n        \"handlers\": root_handlers,\n        ## Set log level string\n        \"level\": root_level.upper(),\n    }\n\n    ## Update config dict's `root` key\n    logging_config[\"root\"] = config_key_root\n\n    ## Initialize formatter, handler, logger config dicts\n    formatter_configdicts: LOGGING_CONFIG_DICT_TYPE = {}\n    handler_configdicts: LOGGING_CONFIG_DICT_TYPE = {}\n    logger_configdicts: LOGGING_CONFIG_DICT_TYPE = {}\n\n    if formatters is not None:\n        ## Formatters passed to function, parse and add to config\n        for formatter_dict in formatters:\n            if isinstance(formatter_dict, dict):\n                pass\n            elif isinstance(formatter_dict, FormatterConfig):\n                try:\n                    formatter_dict: dict = formatter_dict.get_configdict()\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Unhandled exception getting config dict for FormatterConfig object. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n            formatter_configdicts.update(formatter_dict)\n\n    if handlers is not None:\n        ## Handlers passed to function, parse and add to config\n        for handler_dict in handlers:\n            if isinstance(handler_dict, dict):\n                pass\n            elif isinstance(handler_dict, HANDLER_CLASSES_TYPE):\n                try:\n                    handler_dict = handler_dict.get_configdict()\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Unhandled exception getting config dict for *HandlerConfig object. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n            handler_configdicts.update(handler_dict)\n\n    if loggers:\n        ## Loggers passed to function, parse and add to config\n        for logger_dict in loggers:\n            if isinstance(logger_dict, dict):\n                pass\n            elif isinstance(logger_dict, LoggerConfig):\n                try:\n                    logger_dict = logger_dict.get_configdict()\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Unhandled exception getting config dict for LoggerConfig object. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n            logger_configdicts.update(logger_dict)\n\n    ## Create a copy of the original config\n    try:\n        return_dict = deepcopy(logging_config)\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception copying original logging config. Proceeding with original logging config\"\n        )\n        log.warning(msg)\n\n        return_dict = logging_config\n\n    ## Update formatters, handlers, loggers in logging config copy\n    return_dict[\"formatters\"] = formatter_configdicts\n    return_dict[\"handlers\"] = handler_configdicts\n    return_dict[\"loggers\"] = logger_configdicts\n\n    ## Return initialized logging config\n    return return_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.get_formatter_config","title":"<code>get_formatter_config(name='default', fmt=MESSAGE_FMT_STANDARD, datefmt=DATE_FMT_STANDARD, style='%', validate=True, as_dict=False)</code>","text":"<p>Return a FormatterConfig, or a dict representing a Formatter.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name for the formatter. Reference this formatter by name in a LoggerConfig.</p> <code>'default'</code> <code>fmt</code> <code>str</code> <p>The string format for log messages. Python docs: Log Record Attributes</p> <code>MESSAGE_FMT_STANDARD</code> <code>datefmt</code> <code>str</code> <p>The format for log message timestamps, if <code>%(asctime)s</code> is used in the logging <code>fmt</code>.</p> <code>DATE_FMT_STANDARD</code> <code>style</code> <code>str</code> <p>The style of string substitution to use for the formatter. Options include <code>%</code> for <code>'%', some_var</code>, <code>{</code> for <code>'{some_var}</code>, etc.</p> <code>'%'</code> <code>validate</code> <code>bool</code> <p>If <code>True</code>, the handler will be validated by the logging module before fully initializing.</p> <code>True</code> <code>as_dict</code> <code>bool</code> <p>If <code>True</code>, return the configuration as a dict that can be joined into <code>dictConfig()</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>If <code>as_dict=True</code>, return a config dict instead of a FormatterConfig object.</p> <code>FormatterConfig</code> <p>If <code>as_dict=False</code>, return a FormatterConfig object.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\__methods.py</code> <pre><code>def get_formatter_config(\n    name: str = \"default\",\n    fmt: str = MESSAGE_FMT_STANDARD,\n    datefmt: str = DATE_FMT_STANDARD,\n    style: str = \"%\",\n    validate: bool = True,\n    as_dict: bool = False,\n) -&gt; dict[str, dict[str, str]] | FormatterConfig:\n    \"\"\"Return a FormatterConfig, or a dict representing a Formatter.\n\n    Params:\n        name (str): The name for the formatter. Reference this formatter by name in a LoggerConfig.\n        fmt (str): The string format for log messages.\n            [Python docs: Log Record Attributes](https://docs.python.org/3/library/logging.html#logrecord-attributes)\n        datefmt (str): The format for log message timestamps, if `%(asctime)s` is used in the logging `fmt`.\n        style (str): The style of string substitution to use for the formatter. Options include `%` for `'%', some_var`,\n            `{` for `'{some_var}`, etc.\n        validate (bool): If `True`, the handler will be validated by the logging module before fully initializing.\n        as_dict (bool): If `True`, return the configuration as a dict that can be joined into `dictConfig()`.\n\n    Returns:\n        (dict[str, dict[str, Any]]): If `as_dict=True`, return a config dict instead of a FormatterConfig object.\n        (FormatterConfig): If `as_dict=False`, return a FormatterConfig object.\n\n    \"\"\"\n    try:\n        ## Initialize formatter object\n        _formatter: FormatterConfig = FormatterConfig(\n            name=name, fmt=fmt, datefmt=datefmt, style=style, validate=validate\n        )\n\n        if as_dict:\n            ## Return formatter representation as a dict\n            return _formatter.get_configdict()\n        else:\n            ## Return FormatterConfig object\n            return _formatter\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception building FormatterConfig. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.get_logger_config","title":"<code>get_logger_config(name='app', handlers=['console'], level='DEBUG', propagate=False, as_dict=False)</code>","text":"<p>Return a LoggerConfig, or a dict representing a Logger.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name for the logger. Reference this logger by name in a LoggerConfig.</p> <code>'app'</code> <code>level</code> <code>str</code> <p>The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'DEBUG'</code> <code>handlers</code> <code>list[str]</code> <p>List of handler names that exist in the logging configDict that this logger should use.</p> <code>['console']</code> <code>propagate</code> <code>bool</code> <p>If <code>True</code>, log messages will be propagated up/down to the root logger.</p> <code>False</code> <code>as_dict</code> <code>bool</code> <p>If <code>True</code>, return the configuration as a dict that can be joined into <code>dictConfig()</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>If <code>as_dict=True</code>, return a config dict instead of a RotatingFileHandlerConfig object.</p> <code>RotatingFileHandlerConfig</code> <p>If <code>as_dict=False</code>, return a RotatingFileHandlerConfig object.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\__methods.py</code> <pre><code>def get_logger_config(\n    name: str = \"app\",\n    handlers: list[str] = [\"console\"],\n    level: str = \"DEBUG\",\n    propagate: bool = False,\n    as_dict: bool = False,\n) -&gt; dict[str, dict[str, str]] | LoggerConfig:\n    \"\"\"Return a LoggerConfig, or a dict representing a Logger.\n\n    Params:\n        name (str): The name for the logger. Reference this logger by name in a LoggerConfig.\n        level (str): The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        handlers (list[str]): List of handler names that exist in the logging configDict that this logger should use.\n        propagate (bool): If `True`, log messages will be propagated up/down to the root logger.\n        as_dict (bool): If `True`, return the configuration as a dict that can be joined into `dictConfig()`.\n\n    Returns:\n        (dict[str, dict[str, Any]]): If `as_dict=True`, return a config dict instead of a RotatingFileHandlerConfig object.\n        (RotatingFileHandlerConfig): If `as_dict=False`, return a RotatingFileHandlerConfig object.\n\n    \"\"\"\n    try:\n        ## Initialize logger object\n        _logger: LoggerConfig = LoggerConfig(\n            name=name, level=level.upper(), handlers=handlers, propagate=propagate\n        )\n\n        if as_dict:\n            ## Return logger representation as a dict\n            return _logger.get_configdict()\n        else:\n            ## Return LoggerConfig object\n            return _logger\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception initializing logger. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.get_rotatingfilehandler_config","title":"<code>get_rotatingfilehandler_config(name='rotating_app_file', level='DEBUG', formatter='default', filters=None, filename=None, maxBytes=100000, backupCount=3, as_dict=False)</code>","text":"<p>Return a RotatingFileHandlerConfig, or a dict representing a RotatingFileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name for the rotating file handler. Reference this handler by name in a LoggerConfig.</p> <code>'rotating_app_file'</code> <code>level</code> <code>str</code> <p>The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'DEBUG'</code> <code>formatter</code> <code>str</code> <p>The name of a formatter that exists in the overall logging dictConfig.</p> <code>'default'</code> <code>filters</code> <code>list[str] | None</code> <p>A list of function names for logging filters.</p> <code>None</code> <code>filename</code> <code>str | Path</code> <p>The full path to the log file you want to create. If parent directories do not exist, this method will handle creating them.</p> <code>None</code> <code>maxBytes</code> <code>int</code> <p>The maximum size (in bytes) before a logfile is rotated.</p> <code>100000</code> <code>backupCount</code> <code>int</code> <p>The number of backups to keep as log files rotate.</p> <code>3</code> <code>as_dict</code> <code>bool</code> <p>If <code>True</code>, return the configuration as a dict that can be joined into <code>dictConfig()</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>If <code>as_dict=True</code>, return a config dict instead of a RotatingFileHandlerConfig object.</p> <code>RotatingFileHandlerConfig</code> <p>If <code>as_dict=False</code>, return a RotatingFileHandlerConfig object.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\__methods.py</code> <pre><code>def get_rotatingfilehandler_config(\n    name: str = \"rotating_app_file\",\n    level: str = \"DEBUG\",\n    formatter: str = \"default\",\n    filters: list | None = None,\n    filename: t.Union[str, Path] = None,\n    maxBytes: int = 100000,\n    backupCount: int = 3,\n    as_dict: bool = False,\n) -&gt; dict[str, dict[str, t.Any]] | RotatingFileHandlerConfig:\n    \"\"\"Return a RotatingFileHandlerConfig, or a dict representing a RotatingFileHandler.\n\n    Params:\n        name (str): The name for the rotating file handler. Reference this handler by name in a LoggerConfig.\n        level (str): The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        formatter (str): The name of a formatter that exists in the overall logging dictConfig.\n        filters (list[str] | None): A list of function names for logging filters.\n        filename (str | Path): The full path to the log file you want to create. If parent directories do not exist,\n            this method will handle creating them.\n        maxBytes (int): The maximum size (in bytes) before a logfile is rotated.\n        backupCount (int): The number of backups to keep as log files rotate.\n        as_dict (bool): If `True`, return the configuration as a dict that can be joined into `dictConfig()`.\n\n    Returns:\n        (dict[str, dict[str, Any]]): If `as_dict=True`, return a config dict instead of a RotatingFileHandlerConfig object.\n        (RotatingFileHandlerConfig): If `as_dict=False`, return a RotatingFileHandlerConfig object.\n\n    \"\"\"\n    ## Convert &amp; optionally expand input path\n    filename: Path = Path(f\"{filename}\")\n    if \"~\" in f\"{filename}\":\n        filename = filename.expanduser()\n\n    ## Create parent dirs for logging file, if they don't exist\n    _ensure_logdir(p=filename.parent)\n\n    try:\n        ## Initialize handler object\n        _handler: RotatingFileHandlerConfig = RotatingFileHandlerConfig(\n            name=name,\n            level=level,\n            formatter=formatter,\n            filters=filters,\n            filename=filename,\n            maxBytes=maxBytes,\n            backupCount=backupCount,\n        )\n\n        if as_dict:\n            ## Return handler representation as a dict\n            return _handler.get_configdict()\n        else:\n            ## Return RotatingFileHandlerConfig object\n            return _handler\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception building RotatingFileHandlerConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/__methods/#red_utils.std.logging_utils.__methods.get_streamhandler_config","title":"<code>get_streamhandler_config(name='console', level='INFO', formatter='default', filters=None, stream='ext://sys.stdout', as_dict=False)</code>","text":"<p>Return a StreamHandlerConfig, or a dict representing a StreamingHandler.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name for the stream handler. Reference this handler by name in a LoggerConfig.</p> <code>'console'</code> <code>level</code> <code>str</code> <p>The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'INFO'</code> <code>formatter</code> <code>str</code> <p>The name of a formatter that exists in the overall logging dictConfig.</p> <code>'default'</code> <code>filters</code> <code>list[str] | None</code> <p>A list of function names for logging filters.</p> <code>None</code> <code>stream</code> <code>str</code> <p>The stream this handler should use, i.e. <code>ext://sys.stdout</code>, <code>ext://sys.stderr</code>, etc.</p> <code>'ext://sys.stdout'</code> <code>as_dict</code> <code>bool</code> <p>If <code>True</code>, return the configuration as a dict that can be joined into <code>dictConfig()</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>If <code>as_dict=True</code>, return a config dict instead of a StreamHandlerConfig object.</p> <code>StreamHandlerConfig</code> <p>If <code>as_dict=False</code>, return a StreamHandlerConfig object.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\__methods.py</code> <pre><code>def get_streamhandler_config(\n    name: str = \"console\",\n    level: str = \"INFO\",\n    formatter: str = \"default\",\n    filters: list | None = None,\n    stream: str = \"ext://sys.stdout\",\n    as_dict: bool = False,\n) -&gt; dict[str, dict[str, str]] | StreamHandlerConfig:\n    \"\"\"Return a StreamHandlerConfig, or a dict representing a StreamingHandler.\n\n    Params:\n        name (str): The name for the stream handler. Reference this handler by name in a LoggerConfig.\n        level (str): The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        formatter (str): The name of a formatter that exists in the overall logging dictConfig.\n        filters (list[str] | None): A list of function names for logging filters.\n        stream (str): The stream this handler should use, i.e. `ext://sys.stdout`, `ext://sys.stderr`, etc.\n        as_dict (bool): If `True`, return the configuration as a dict that can be joined into `dictConfig()`.\n\n    Returns:\n        (dict[str, dict[str, Any]]): If `as_dict=True`, return a config dict instead of a StreamHandlerConfig object.\n        (StreamHandlerConfig): If `as_dict=False`, return a StreamHandlerConfig object.\n\n    \"\"\"\n    try:\n        ## Initialize handler object\n        _handler: StreamHandlerConfig = StreamHandlerConfig(\n            name=name, level=level, formatter=formatter, filters=filters, stream=stream\n        )\n\n        if as_dict:\n            ## Return handler representation as a dict\n            return _handler.get_configdict()\n        else:\n            ## Return StreamHandlerConfig object\n            return _handler\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception building StreamHandlerConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/","title":"config_classes","text":"<p>The 'secret sauce' of the logging module.</p> <p>These classes serve as configuration containers for various logging objects, like formatters, handlers, and loggers. Each class inherits from a \"base\" configuration, which has a <code>.get_configdict()</code> method. So for each formatter, handler, or logger, you can use <code>.get_configdict()</code> to return a dict representation of the class's configuration, which is compatible with the logging dictConfig.</p> <p>These dicts must be added to the configuration using the <code>.assemble_configdict()</code> method in <code>logging_utils()</code>. The classes exist to aid in creating formatters, handlers, and loggers for a logging configuration by presenting all available options.</p>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.FileHandlerConfig","title":"<code>FileHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging FileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file to log messages to.</p> <code>'app.log'</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass FileHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging FileHandler.\n\n    Params:\n        filename (str): The name of the file to log messages to.\n    \"\"\"\n\n    filename: str | None = field(default=\"app.log\")\n\n    def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, str]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"filename\": self.filename,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.FileHandler`.\n\n        \"\"\"\n        return \"logging.FileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.FileHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, str]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"filename\": self.filename,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.FileHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.FileHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.FileHandler`.\n\n    \"\"\"\n    return \"logging.FileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.FormatterConfig","title":"<code>FormatterConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseLoggingConfig</code></p> <p>Define a logging formatter.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the formatter.</p> <code>None</code> <code>fmt</code> <code>str</code> <p>The string formatting to use for log messages.</p> <code>MESSAGE_FMT_STANDARD</code> <code>datefmt</code> <code>str</code> <p>The string formatting to use for log message timestamps.</p> <code>DATE_FMT_STANDARD</code> <code>style</code> <code>str</code> <p>The string substitution style to use for log formats. Default is <code>%</code>, which means formats need to be written like <code>%(asctime)s %(levelname)s %(message)s</code>. If you change this style, make sure the <code>fmt</code> you pass uses the correct formatting style.</p> <code>'%'</code> <code>validate</code> <code>bool</code> <p>When <code>True</code>, the configuration dict this formatter returns will be validated by the logging module.</p> <code>True</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\formatters\\_formatters.py</code> <pre><code>@dataclass\nclass FormatterConfig(BaseLoggingConfig):\n    \"\"\"Define a logging formatter.\n\n    Params:\n        name (str): The name of the formatter.\n        fmt (str): The string formatting to use for log messages.\n        datefmt (str): The string formatting to use for log message timestamps.\n        style (str): The string substitution style to use for log formats. Default is `%`, which\n            means formats need to be written like `%(asctime)s %(levelname)s %(message)s`. If\n            you change this style, make sure the `fmt` you pass uses the correct formatting style.\n        validate (bool): When `True`, the configuration dict this formatter returns will be validated by the logging module.\n\n    \"\"\"\n\n    name: str = None\n    fmt: str = MESSAGE_FMT_STANDARD\n    datefmt: str = DATE_FMT_STANDARD\n    style: str = \"%\"\n    validate: bool = True\n\n    def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Return a dict representation of the formatter described by this class.\"\"\"\n        formatter_dict: dict[str, dict[str, str]] = {self.name: {\"format\": self.fmt}}\n        if self.datefmt:\n            formatter_dict[self.name][\"datefmt\"] = self.datefmt\n        if self.style:\n            formatter_dict[self.name][\"style\"] = self.style\n        formatter_dict[self.name][\"validate\"] = self.validate\n\n        return formatter_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.FormatterConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the formatter described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\formatters\\_formatters.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Return a dict representation of the formatter described by this class.\"\"\"\n    formatter_dict: dict[str, dict[str, str]] = {self.name: {\"format\": self.fmt}}\n    if self.datefmt:\n        formatter_dict[self.name][\"datefmt\"] = self.datefmt\n    if self.style:\n        formatter_dict[self.name][\"style\"] = self.style\n    formatter_dict[self.name][\"validate\"] = self.validate\n\n    return formatter_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.LoggerConfig","title":"<code>LoggerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseLoggingConfig</code></p> <p>Define a logging Logger.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the logger.</p> required <code>level</code> <code>str</code> <p>The level of log messages this logger should show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> required <code>handlers</code> <code>list[str]</code> <p>List of handler names this logger should use. These handlers must exist in the logging dictConfig.</p> required <code>propagate</code> <code>bool</code> <p>If <code>True</code>, messages will be propagated up/down to the root logger.</p> <code>False</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_loggers.py</code> <pre><code>@dataclass\nclass LoggerConfig(BaseLoggingConfig):\n    \"\"\"Define a logging Logger.\n\n    Params:\n        name (str): The name of the logger.\n        level (str): The level of log messages this logger should show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        handlers (list[str]): List of handler names this logger should use. These handlers must exist in the logging dictConfig.\n        propagate (bool): If `True`, messages will be propagated up/down to the root logger.\n    \"\"\"\n\n    name: str\n    level: str\n    handlers: list[str]\n    propagate: bool = False\n\n    def get_configdict(self) -&gt; dict:\n        \"\"\"Return a dict representation of the logger described by this class.\"\"\"\n        logger_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"level\": self.level,\n                \"handlers\": self.handlers,\n                \"propagate\": self.propagate,\n            }\n        }\n        return logger_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.LoggerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the logger described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_loggers.py</code> <pre><code>def get_configdict(self) -&gt; dict:\n    \"\"\"Return a dict representation of the logger described by this class.\"\"\"\n    logger_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"level\": self.level,\n            \"handlers\": self.handlers,\n            \"propagate\": self.propagate,\n        }\n    }\n    return logger_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.LoggerFactory","title":"<code>LoggerFactory</code>","text":"<p>Generate loggers based on LoggerFactory's config.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_factory.py</code> <pre><code>class LoggerFactory:\n    \"\"\"Generate loggers based on LoggerFactory's config.\"\"\"\n\n    _LOG: logging.Logger | None = None\n\n    @staticmethod\n    def __create_logger(\n        name: str,\n        log_level: str,\n        handlers: dict[str, dict],\n        formatters: dict[str, dict],\n        loggers: dict[str, dict],\n    ) -&gt; logging.Logger:\n        \"\"\"Create a logger cnofig from inputs.\n\n        Params:\n            name (str): The name of the logger.\n            log_level (str): The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n            handlers (dict[str, dict[str, Any]]): A dict describing the handlers for this logger config.\n            formatters (dict[str, dict[str, Any]]): A dict describing the formatters for this logger config.\n            loggers (dict[str, dict[str, Any]]): A dict describing the loggers for this logger config.\n        \"\"\"\n        log_level = log_level.upper()\n\n        # Configure logging using dictConfig\n        logging_config = {\n            \"version\": 1,\n            \"handlers\": handlers,\n            \"formatters\": formatters,\n            \"loggers\": loggers,\n            \"root\": {\n                \"level\": log_level,\n                \"handlers\": list(handlers.keys()),\n            },\n        }\n\n        try:\n            logging.config.dictConfig(logging_config)\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception configuring logger. Details: {exc}\")\n            # log.error(msg)\n\n            raise msg\n\n        # Get or create logger\n        LoggerFactory._LOG = logging.getLogger(name)\n\n        return LoggerFactory._LOG\n\n    @staticmethod\n    def get_logger(\n        name: str,\n        log_level: str,\n        handlers: dict[str, dict],\n        formatters: dict[str, dict],\n        loggers: dict[str, dict],\n    ) -&gt; logging.Logger:\n        \"\"\"Initialize a logger.\n\n        Params:\n            name (str): The name of the logger.\n            log_level (str): The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n            handlers (dict[str, dict[str, Any]]): A dict describing the handlers for this logger config.\n            formatters (dict[str, dict[str, Any]]): A dict describing the formatters for this logger config.\n            loggers (dict[str, dict[str, Any]]): A dict describing the loggers for this logger config.\n        \"\"\"\n        logger = LoggerFactory.__create_logger(\n            name=name,\n            log_level=log_level,\n            handlers=handlers,\n            formatters=formatters,\n            loggers=loggers,\n        )\n\n        return logger\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.LoggerFactory.get_logger","title":"<code>get_logger(name, log_level, handlers, formatters, loggers)</code>  <code>staticmethod</code>","text":"<p>Initialize a logger.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the logger.</p> required <code>log_level</code> <code>str</code> <p>The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> required <code>handlers</code> <code>dict[str, dict[str, Any]]</code> <p>A dict describing the handlers for this logger config.</p> required <code>formatters</code> <code>dict[str, dict[str, Any]]</code> <p>A dict describing the formatters for this logger config.</p> required <code>loggers</code> <code>dict[str, dict[str, Any]]</code> <p>A dict describing the loggers for this logger config.</p> required Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_factory.py</code> <pre><code>@staticmethod\ndef get_logger(\n    name: str,\n    log_level: str,\n    handlers: dict[str, dict],\n    formatters: dict[str, dict],\n    loggers: dict[str, dict],\n) -&gt; logging.Logger:\n    \"\"\"Initialize a logger.\n\n    Params:\n        name (str): The name of the logger.\n        log_level (str): The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        handlers (dict[str, dict[str, Any]]): A dict describing the handlers for this logger config.\n        formatters (dict[str, dict[str, Any]]): A dict describing the formatters for this logger config.\n        loggers (dict[str, dict[str, Any]]): A dict describing the loggers for this logger config.\n    \"\"\"\n    logger = LoggerFactory.__create_logger(\n        name=name,\n        log_level=log_level,\n        handlers=handlers,\n        formatters=formatters,\n        loggers=loggers,\n    )\n\n    return logger\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.RotatingFileHandlerConfig","title":"<code>RotatingFileHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging RotatingFileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | None</code> <p>The name/path of the file to log messages to.</p> <code>'app.log'</code> <code>maxBytes</code> <code>int</code> <p>The maximum size of the file (in bytes) before a new file is rotated.</p> <code>0</code> <code>backupCount</code> <code>int</code> <p>Number of rotated log files to keep.</p> <code>0</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass RotatingFileHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging RotatingFileHandler.\n\n    Params:\n        filename (str | None): The name/path of the file to log messages to.\n        maxBytes (int): The maximum size of the file (in bytes) before a new file is rotated.\n        backupCount (int): Number of rotated log files to keep.\n\n    \"\"\"\n\n    filename: str | None = field(default=\"app.log\")\n    maxBytes: int = 0\n    backupCount: int = 0\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"filename\": f\"{self.filename}\",\n                \"maxBytes\": self.maxBytes,\n                \"backupCount\": self.backupCount,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.RotatingFileHandler`.\n\n        \"\"\"\n        return \"logging.handlers.RotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.RotatingFileHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"filename\": f\"{self.filename}\",\n            \"maxBytes\": self.maxBytes,\n            \"backupCount\": self.backupCount,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.RotatingFileHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.RotatingFileHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.RotatingFileHandler`.\n\n    \"\"\"\n    return \"logging.handlers.RotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.StreamHandlerConfig","title":"<code>StreamHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging StreamHandler.</p> <p>Parameters:</p> Name Type Description Default <code>stream</code> <code>Any</code> <p>The stream this handler controls, i.e. <code>ext://sys.stdout</code>, <code>ext://sys.stderr</code>, etc.</p> <code>'ext://sys.stdout'</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass StreamHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging StreamHandler.\n\n    Params:\n        stream (Any): The stream this handler controls, i.e. `ext://sys.stdout`, `ext://sys.stderr`, etc.\n    \"\"\"\n\n    stream: t.Any | None = \"ext://sys.stdout\"\n\n    def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, str]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"stream\": self.stream,\n            }\n        }\n        if self.filters:\n            handler_dict[\"filters\"] = self.filters\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.StreamHandler`.\n\n        \"\"\"\n        return \"logging.StreamHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.StreamHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, str]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"stream\": self.stream,\n        }\n    }\n    if self.filters:\n        handler_dict[\"filters\"] = self.filters\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.StreamHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.StreamHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.StreamHandler`.\n\n    \"\"\"\n    return \"logging.StreamHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.critical_filter","title":"<code>critical_filter(record)</code>","text":"<p>Filter to only show CRITICAL and above.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\filters\\loglevel_filters\\_loglevel_filters.py</code> <pre><code>def critical_filter(record: logging.LogRecord) -&gt; bool:\n    \"\"\"Filter to only show CRITICAL and above.\"\"\"\n    return record.levelno &gt;= logging.CRITICAL\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.debug_filter","title":"<code>debug_filter(record)</code>","text":"<p>Filter to only show DEBUG and above.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\filters\\loglevel_filters\\_loglevel_filters.py</code> <pre><code>def debug_filter(record: logging.LogRecord) -&gt; bool:\n    \"\"\"Filter to only show DEBUG and above.\"\"\"\n    return record.levelno &gt;= logging.DEBUG\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.error_filter","title":"<code>error_filter(record)</code>","text":"<p>Filter to only show ERROR and above.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\filters\\loglevel_filters\\_loglevel_filters.py</code> <pre><code>def error_filter(record: logging.LogRecord) -&gt; bool:\n    \"\"\"Filter to only show ERROR and above.\"\"\"\n    return record.levelno &gt;= logging.ERROR\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.get_red_utils_console_handler","title":"<code>get_red_utils_console_handler(name='red_utils_console', level='DEBUG', formatter='red_utils', filters=None)</code>","text":"<p>Return an initialized StreamHandlerConfig for the red_utils library.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the handler, which you will reference in a logger config.</p> <code>'red_utils_console'</code> <code>level</code> <code>str</code> <p>The log level for the handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'DEBUG'</code> <code>formatter</code> <code>str</code> <p>The name of the formatter to use. This formatter must exist in the logging dictConfig, and can be generated with a FormatterConfig.</p> <code>'red_utils'</code> <code>filters</code> <code>list[str] | None</code> <p>Optional list of filter function names to apply to the handler.</p> <code>None</code> <p>Returns:</p> Type Description <code>StreamHandlerConfig</code> <p>An initialized StreamHandlerConfig class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\prefab\\third_party\\red_utils_logging\\_configs.py</code> <pre><code>def get_red_utils_console_handler(\n    name: str = \"red_utils_console\",\n    level: str = \"DEBUG\",\n    formatter: str = \"red_utils\",\n    filters: list[str] | None = None,\n) -&gt; StreamHandlerConfig:\n    \"\"\"Return an initialized StreamHandlerConfig for the red_utils library.\n\n    Params:\n        name (str): The name of the handler, which you will reference in a logger config.\n        level (str): The log level for the handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        formatter (str): The name of the formatter to use. This formatter must exist in the logging dictConfig,\n            and can be generated with a FormatterConfig.\n        filters (list[str]|None): Optional list of filter function names to apply to the handler.\n\n    Returns:\n        (StreamHandlerConfig): An initialized StreamHandlerConfig class.\n\n    \"\"\"\n    try:\n        _handler: StreamHandlerConfig = StreamHandlerConfig(\n            name=name, level=level.upper(), formatter=formatter, filters=filters\n        )\n\n        return _handler\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting red_utils StreamHandlerConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.get_red_utils_formatter","title":"<code>get_red_utils_formatter(name='red_utils', fmt=RED_UTILS_FMT, datefmt=DATE_FMT_STANDARD)</code>","text":"<p>Return a pre-configured FormatterConfig for the red_utils library.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the formatter, which you will reference in a handler config.</p> <code>'red_utils'</code> <code>fmt</code> <code>str</code> <p>The log message format string.</p> <code>RED_UTILS_FMT</code> <code>datefmt</code> <code>str</code> <p>The format for timestamps in log messages.</p> <code>DATE_FMT_STANDARD</code> <p>Returns:</p> Type Description <code>FormatterConfig</code> <p>An initialized FormatterConfig class</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\prefab\\third_party\\red_utils_logging\\_configs.py</code> <pre><code>def get_red_utils_formatter(\n    name: str = \"red_utils\", fmt: str = RED_UTILS_FMT, datefmt: str = DATE_FMT_STANDARD\n) -&gt; FormatterConfig:\n    \"\"\"Return a pre-configured FormatterConfig for the red_utils library.\n\n    Params:\n        name (str): The name of the formatter, which you will reference in a handler config.\n        fmt (str): The log message format string.\n        datefmt (str): The format for timestamps in log messages.\n\n    Returns:\n        (FormatterConfig): An initialized FormatterConfig class\n\n    \"\"\"\n    try:\n        _formatter: FormatterConfig = get_formatter_config(\n            name=name, fmt=fmt, datefmt=datefmt\n        )\n\n        return _formatter\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting red_utils FormatterConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.get_red_utils_logger","title":"<code>get_red_utils_logger(name='red_utils', handlers=['red_utils_console'], level='WARNING', propagate=False)</code>","text":"<p>Return an initialized LoggerConfig for the red_utils library.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the logger, which you will reference in a logging config dict.</p> <code>'red_utils'</code> <code>handlers</code> <code>list[str]</code> <p>A list of handler names for the logger. These loggers must exist in the dictConfig.</p> <code>['red_utils_console']</code> <code>level</code> <code>str</code> <p>The log level for the handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'WARNING'</code> <code>propagate</code> <code>bool</code> <p>If <code>False</code>, logs from this logger will not be propagated down/up to the root logger.</p> <code>False</code> <p>Returns:</p> Type Description <code>LoggerConfig</code> <p>An initialized LoggerConfig class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\prefab\\third_party\\red_utils_logging\\_configs.py</code> <pre><code>def get_red_utils_logger(\n    name: str = \"red_utils\",\n    handlers: list[str] = [\"red_utils_console\"],\n    level: str = \"WARNING\",\n    propagate: bool = False,\n) -&gt; LoggerConfig:\n    \"\"\"Return an initialized LoggerConfig for the red_utils library.\n\n    Params:\n        name (str): The name of the logger, which you will reference in a logging config dict.\n        handlers (list[str]): A list of handler names for the logger. These loggers must exist in the dictConfig.\n        level (str): The log level for the handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        propagate (bool): If `False`, logs from this logger will not be propagated down/up to the root logger.\n\n    Returns:\n        (LoggerConfig): An initialized LoggerConfig class.\n\n    \"\"\"\n    try:\n        _logger: LoggerConfig = get_logger_config(\n            name=name, handlers=handlers, level=level.upper(), propagate=propagate\n        )\n\n        return _logger\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting red_utils LoggerConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.info_filter","title":"<code>info_filter(record)</code>","text":"<p>Filter to only show INFO and above.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\filters\\loglevel_filters\\_loglevel_filters.py</code> <pre><code>def info_filter(record: logging.LogRecord) -&gt; bool:\n    \"\"\"Filter to only show INFO and above.\"\"\"\n    return record.levelno &gt;= logging.INFO\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/__init__/#red_utils.std.logging_utils.config_classes.warning_filter","title":"<code>warning_filter(record)</code>","text":"<p>Filter to only show WARNING and above.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\filters\\loglevel_filters\\_loglevel_filters.py</code> <pre><code>def warning_filter(record: logging.LogRecord) -&gt; bool:\n    \"\"\"Filter to only show WARNING and above.\"\"\"\n    return record.levelno &gt;= logging.WARNING\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/types/","title":"types","text":"<p>Types and annotations for my customer logging config objects.</p>"},{"location":"reference/red_utils/std/logging_utils/config_classes/types/#red_utils.std.logging_utils.config_classes.types.FileHandlerConfig","title":"<code>FileHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging FileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file to log messages to.</p> <code>'app.log'</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass FileHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging FileHandler.\n\n    Params:\n        filename (str): The name of the file to log messages to.\n    \"\"\"\n\n    filename: str | None = field(default=\"app.log\")\n\n    def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, str]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"filename\": self.filename,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.FileHandler`.\n\n        \"\"\"\n        return \"logging.FileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/types/#red_utils.std.logging_utils.config_classes.types.FileHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, str]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"filename\": self.filename,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/types/#red_utils.std.logging_utils.config_classes.types.FileHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.FileHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.FileHandler`.\n\n    \"\"\"\n    return \"logging.FileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/types/#red_utils.std.logging_utils.config_classes.types.QueueHandlerConfig","title":"<code>QueueHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging QueueHandler.</p> <p>Parameters:</p> Name Type Description Default <code>queue</code> <code>Queue</code> <p>The queue to send log messages to.</p> <code>None</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass QueueHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging QueueHandler.\n\n    Params:\n        queue (queue.Queue): The queue to send log messages to.\n    \"\"\"\n\n    queue: Queue = field(default=None)\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"queue\": self.queue,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.QueueHandler`.\n\n        \"\"\"\n        return \"logging.handlers.QueueHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/types/#red_utils.std.logging_utils.config_classes.types.QueueHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"queue\": self.queue,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/types/#red_utils.std.logging_utils.config_classes.types.QueueHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.QueueHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.QueueHandler`.\n\n    \"\"\"\n    return \"logging.handlers.QueueHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/types/#red_utils.std.logging_utils.config_classes.types.QueueListenerConfig","title":"<code>QueueListenerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseLoggingConfig</code></p> <p>Define a logging QueueListener.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the handler.</p> required <code>queue</code> <code>Queue</code> <p>The queue to listen for log messages in.</p> required <code>handlers</code> <code>list[str]</code> <p>List of handler names to apply to this listener.</p> required Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass QueueListenerConfig(BaseLoggingConfig):\n    \"\"\"Define a logging QueueListener.\n\n    Params:\n        name (str): The name of the handler.\n        queue (queue.Queue): The queue to listen for log messages in.\n        handlers (list[str]): List of handler names to apply to this listener.\n\n    \"\"\"\n\n    name: str\n    queue: Queue\n    handlers: list\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        listener_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"queue\": self.queue,\n                \"handlers\": self.handlers,\n            }\n        }\n        return listener_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.QueueListener`.\n\n        \"\"\"\n        return \"logging.handleres.QueueListener\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/types/#red_utils.std.logging_utils.config_classes.types.QueueListenerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    listener_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"queue\": self.queue,\n            \"handlers\": self.handlers,\n        }\n    }\n    return listener_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/types/#red_utils.std.logging_utils.config_classes.types.QueueListenerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.QueueListener</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.QueueListener`.\n\n    \"\"\"\n    return \"logging.handleres.QueueListener\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/types/#red_utils.std.logging_utils.config_classes.types.RotatingFileHandlerConfig","title":"<code>RotatingFileHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging RotatingFileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | None</code> <p>The name/path of the file to log messages to.</p> <code>'app.log'</code> <code>maxBytes</code> <code>int</code> <p>The maximum size of the file (in bytes) before a new file is rotated.</p> <code>0</code> <code>backupCount</code> <code>int</code> <p>Number of rotated log files to keep.</p> <code>0</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass RotatingFileHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging RotatingFileHandler.\n\n    Params:\n        filename (str | None): The name/path of the file to log messages to.\n        maxBytes (int): The maximum size of the file (in bytes) before a new file is rotated.\n        backupCount (int): Number of rotated log files to keep.\n\n    \"\"\"\n\n    filename: str | None = field(default=\"app.log\")\n    maxBytes: int = 0\n    backupCount: int = 0\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"filename\": f\"{self.filename}\",\n                \"maxBytes\": self.maxBytes,\n                \"backupCount\": self.backupCount,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.RotatingFileHandler`.\n\n        \"\"\"\n        return \"logging.handlers.RotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/types/#red_utils.std.logging_utils.config_classes.types.RotatingFileHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"filename\": f\"{self.filename}\",\n            \"maxBytes\": self.maxBytes,\n            \"backupCount\": self.backupCount,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/types/#red_utils.std.logging_utils.config_classes.types.RotatingFileHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.RotatingFileHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.RotatingFileHandler`.\n\n    \"\"\"\n    return \"logging.handlers.RotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/types/#red_utils.std.logging_utils.config_classes.types.SocketHandlerConfig","title":"<code>SocketHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging SocketHandler.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Host IP/FQDN.</p> <code>'localhost'</code> <code>port</code> <code>int</code> <p>Host port where log messages should be sent.</p> <code>0</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass SocketHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging SocketHandler.\n\n    Params:\n        host (str): Host IP/FQDN.\n        port (int): Host port where log messages should be sent.\n    \"\"\"\n\n    host: str = \"localhost\"\n    port: int = 0\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"host\": self.host,\n                \"port\": self.port,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.SocketHandler`.\n\n        \"\"\"\n        return \"logging.handlers.SocketHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/types/#red_utils.std.logging_utils.config_classes.types.SocketHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"host\": self.host,\n            \"port\": self.port,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/types/#red_utils.std.logging_utils.config_classes.types.SocketHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.SocketHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.SocketHandler`.\n\n    \"\"\"\n    return \"logging.handlers.SocketHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/types/#red_utils.std.logging_utils.config_classes.types.StreamHandlerConfig","title":"<code>StreamHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging StreamHandler.</p> <p>Parameters:</p> Name Type Description Default <code>stream</code> <code>Any</code> <p>The stream this handler controls, i.e. <code>ext://sys.stdout</code>, <code>ext://sys.stderr</code>, etc.</p> <code>'ext://sys.stdout'</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass StreamHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging StreamHandler.\n\n    Params:\n        stream (Any): The stream this handler controls, i.e. `ext://sys.stdout`, `ext://sys.stderr`, etc.\n    \"\"\"\n\n    stream: t.Any | None = \"ext://sys.stdout\"\n\n    def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, str]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"stream\": self.stream,\n            }\n        }\n        if self.filters:\n            handler_dict[\"filters\"] = self.filters\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.StreamHandler`.\n\n        \"\"\"\n        return \"logging.StreamHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/types/#red_utils.std.logging_utils.config_classes.types.StreamHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, str]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"stream\": self.stream,\n        }\n    }\n    if self.filters:\n        handler_dict[\"filters\"] = self.filters\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/types/#red_utils.std.logging_utils.config_classes.types.StreamHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.StreamHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.StreamHandler`.\n\n    \"\"\"\n    return \"logging.StreamHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/types/#red_utils.std.logging_utils.config_classes.types.TimedRotatingFileHandlerConfig","title":"<code>TimedRotatingFileHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging TimedRotatingFileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name/path of the file to log messages to.</p> <code>'app.log'</code> <code>when</code> <code>str</code> <p>Time of day to rotate log files, i.e. <code>midnight</code>.</p> <code>'midnight'</code> <code>interval</code> <code>int</code> <p>When to rotate the file as the interval defined in <code>when</code> occurs. <code>1=every occurrence</code>, <code>2=every other occurrence</code>, etc.</p> <code>1</code> <code>backupCount</code> <code>int</code> <p>The number of rotated log files to save.</p> <code>0</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass TimedRotatingFileHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging TimedRotatingFileHandler.\n\n    Params:\n        filename (str): The name/path of the file to log messages to.\n        when (str): Time of day to rotate log files, i.e. `midnight`.\n        interval (int): When to rotate the file as the interval defined in `when` occurs.\n            `1=every occurrence`, `2=every other occurrence`, etc.\n        backupCount (int): The number of rotated log files to save.\n    \"\"\"\n\n    filename: str | None = field(default=\"app.log\")\n    when: str | None = field(default=\"midnight\")\n    interval: int = 1\n    backupCount: int = 0\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"filename\": self.filename,\n                \"when\": self.when,\n                \"interval\": self.interval,\n                \"backupCount\": self.backupCount,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.TimedRotatingFileHandler`.\n\n        \"\"\"\n        return \"logging.handlers.TimedRotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/types/#red_utils.std.logging_utils.config_classes.types.TimedRotatingFileHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"filename\": self.filename,\n            \"when\": self.when,\n            \"interval\": self.interval,\n            \"backupCount\": self.backupCount,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/types/#red_utils.std.logging_utils.config_classes.types.TimedRotatingFileHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.TimedRotatingFileHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.TimedRotatingFileHandler`.\n\n    \"\"\"\n    return \"logging.handlers.TimedRotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/base/__init__/","title":"base","text":"<p>Base classes and objects for logging configs.</p>"},{"location":"reference/red_utils/std/logging_utils/config_classes/base/__init__/#red_utils.std.logging_utils.config_classes.base.BaseHandlerConfig","title":"<code>BaseHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseLoggingConfig</code></p> <p>Abstract base class for a logging handler dict.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The handler's name.</p> <code>None</code> <code>level</code> <code>str</code> <p>The handler's logging level (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'NOTSET'</code> <code>formatter</code> <code>str</code> <p>The name of a formatter that exists in the logging config.</p> <code>None</code> <code>filters</code> <code>list[str] | None</code> <p>The names of logging filter methods/classes. These methods/classes must be imported into the script where <code>logging.config.dictConfig()</code> is run.</p> <code>None</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\base\\_bases.py</code> <pre><code>@dataclass\nclass BaseHandlerConfig(BaseLoggingConfig):\n    \"\"\"Abstract base class for a logging handler dict.\n\n    Params:\n        name (str): The handler's name.\n        level (str): The handler's logging level (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        formatter (str): The name of a formatter that exists in the logging config.\n        filters (list[str] | None): The names of logging filter methods/classes. These methods/classes\n            must be imported into the script where `logging.config.dictConfig()` is run.\n    \"\"\"\n\n    name: str = None\n    level: str = \"NOTSET\"\n    formatter: str = None\n    filters: list[str] | None = field(default=None)\n\n    @abstractmethod\n    def get_configdict(self) -&gt; None:\n        \"\"\"Return a dict representation of the handler config.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n            }\n        }\n        if self.filters:\n            handler_dict[self.name][\"filters\"] = self.filters\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler's class name.\"\"\"\n        raise NotImplementedError(\"Subclasses must implement get_handler_class method\")\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/base/__init__/#red_utils.std.logging_utils.config_classes.base.BaseHandlerConfig.get_configdict","title":"<code>get_configdict()</code>  <code>abstractmethod</code>","text":"<p>Return a dict representation of the handler config.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\base\\_bases.py</code> <pre><code>@abstractmethod\ndef get_configdict(self) -&gt; None:\n    \"\"\"Return a dict representation of the handler config.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n        }\n    }\n    if self.filters:\n        handler_dict[self.name][\"filters\"] = self.filters\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/base/__init__/#red_utils.std.logging_utils.config_classes.base.BaseHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler's class name.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\base\\_bases.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler's class name.\"\"\"\n    raise NotImplementedError(\"Subclasses must implement get_handler_class method\")\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/base/__init__/#red_utils.std.logging_utils.config_classes.base.BaseLoggingConfig","title":"<code>BaseLoggingConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for a full logging config dict.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\base\\_bases.py</code> <pre><code>@dataclass\nclass BaseLoggingConfig(ABC):\n    \"\"\"Abstract base class for a full logging config dict.\"\"\"\n\n    @abstractmethod\n    def get_configdict(self) -&gt; None:\n        pass\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/base/_base_config/","title":"_base_config","text":"<p>An empty, valid/complete logging config dict.</p> <p>This can be imported and added to so you can create your own logging config, and it is also used by the <code>.assemble_configdict()</code> method as the basis for the returned logging dictConfig.</p> Base logging config dict<pre><code>BASE_LOGGING_CONFIG_DICT: dict = {\n    \"version\": 1,\n    \"disable_existing_loggers\": False,\n    \"propagate\": True,\n    \"root\": {},\n    \"formatters\": {},\n    \"handlers\": {},\n    \"loggers\": {},\n}\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/base/_bases/","title":"_bases","text":"<p>Abstract base classes for logging object classes.</p>"},{"location":"reference/red_utils/std/logging_utils/config_classes/base/_bases/#red_utils.std.logging_utils.config_classes.base._bases.BaseHandlerConfig","title":"<code>BaseHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseLoggingConfig</code></p> <p>Abstract base class for a logging handler dict.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The handler's name.</p> <code>None</code> <code>level</code> <code>str</code> <p>The handler's logging level (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'NOTSET'</code> <code>formatter</code> <code>str</code> <p>The name of a formatter that exists in the logging config.</p> <code>None</code> <code>filters</code> <code>list[str] | None</code> <p>The names of logging filter methods/classes. These methods/classes must be imported into the script where <code>logging.config.dictConfig()</code> is run.</p> <code>None</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\base\\_bases.py</code> <pre><code>@dataclass\nclass BaseHandlerConfig(BaseLoggingConfig):\n    \"\"\"Abstract base class for a logging handler dict.\n\n    Params:\n        name (str): The handler's name.\n        level (str): The handler's logging level (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        formatter (str): The name of a formatter that exists in the logging config.\n        filters (list[str] | None): The names of logging filter methods/classes. These methods/classes\n            must be imported into the script where `logging.config.dictConfig()` is run.\n    \"\"\"\n\n    name: str = None\n    level: str = \"NOTSET\"\n    formatter: str = None\n    filters: list[str] | None = field(default=None)\n\n    @abstractmethod\n    def get_configdict(self) -&gt; None:\n        \"\"\"Return a dict representation of the handler config.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n            }\n        }\n        if self.filters:\n            handler_dict[self.name][\"filters\"] = self.filters\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler's class name.\"\"\"\n        raise NotImplementedError(\"Subclasses must implement get_handler_class method\")\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/base/_bases/#red_utils.std.logging_utils.config_classes.base._bases.BaseHandlerConfig.get_configdict","title":"<code>get_configdict()</code>  <code>abstractmethod</code>","text":"<p>Return a dict representation of the handler config.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\base\\_bases.py</code> <pre><code>@abstractmethod\ndef get_configdict(self) -&gt; None:\n    \"\"\"Return a dict representation of the handler config.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n        }\n    }\n    if self.filters:\n        handler_dict[self.name][\"filters\"] = self.filters\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/base/_bases/#red_utils.std.logging_utils.config_classes.base._bases.BaseHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler's class name.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\base\\_bases.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler's class name.\"\"\"\n    raise NotImplementedError(\"Subclasses must implement get_handler_class method\")\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/base/_bases/#red_utils.std.logging_utils.config_classes.base._bases.BaseLoggingConfig","title":"<code>BaseLoggingConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for a full logging config dict.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\base\\_bases.py</code> <pre><code>@dataclass\nclass BaseLoggingConfig(ABC):\n    \"\"\"Abstract base class for a full logging config dict.\"\"\"\n\n    @abstractmethod\n    def get_configdict(self) -&gt; None:\n        pass\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/filters/__init__/","title":"filters","text":"<p>Apply filters to handlers to control the types of log messages displayed by the logger.</p> <p>When using a dictConfig, you only need to reference these filters by name, i.e. <code>filters=[\"info_filter\", \"debug_filter\", ...]</code>, but you do need to import the filter function into whatever script runs the <code>logging.config.dictConfig()</code> function.</p>"},{"location":"reference/red_utils/std/logging_utils/config_classes/filters/__init__/#red_utils.std.logging_utils.config_classes.filters.critical_filter","title":"<code>critical_filter(record)</code>","text":"<p>Filter to only show CRITICAL and above.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\filters\\loglevel_filters\\_loglevel_filters.py</code> <pre><code>def critical_filter(record: logging.LogRecord) -&gt; bool:\n    \"\"\"Filter to only show CRITICAL and above.\"\"\"\n    return record.levelno &gt;= logging.CRITICAL\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/filters/__init__/#red_utils.std.logging_utils.config_classes.filters.debug_filter","title":"<code>debug_filter(record)</code>","text":"<p>Filter to only show DEBUG and above.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\filters\\loglevel_filters\\_loglevel_filters.py</code> <pre><code>def debug_filter(record: logging.LogRecord) -&gt; bool:\n    \"\"\"Filter to only show DEBUG and above.\"\"\"\n    return record.levelno &gt;= logging.DEBUG\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/filters/__init__/#red_utils.std.logging_utils.config_classes.filters.error_filter","title":"<code>error_filter(record)</code>","text":"<p>Filter to only show ERROR and above.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\filters\\loglevel_filters\\_loglevel_filters.py</code> <pre><code>def error_filter(record: logging.LogRecord) -&gt; bool:\n    \"\"\"Filter to only show ERROR and above.\"\"\"\n    return record.levelno &gt;= logging.ERROR\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/filters/__init__/#red_utils.std.logging_utils.config_classes.filters.info_filter","title":"<code>info_filter(record)</code>","text":"<p>Filter to only show INFO and above.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\filters\\loglevel_filters\\_loglevel_filters.py</code> <pre><code>def info_filter(record: logging.LogRecord) -&gt; bool:\n    \"\"\"Filter to only show INFO and above.\"\"\"\n    return record.levelno &gt;= logging.INFO\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/filters/__init__/#red_utils.std.logging_utils.config_classes.filters.warning_filter","title":"<code>warning_filter(record)</code>","text":"<p>Filter to only show WARNING and above.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\filters\\loglevel_filters\\_loglevel_filters.py</code> <pre><code>def warning_filter(record: logging.LogRecord) -&gt; bool:\n    \"\"\"Filter to only show WARNING and above.\"\"\"\n    return record.levelno &gt;= logging.WARNING\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/filters/_filters/","title":"_filters","text":"<p>Define filter classes for logging configs.</p>"},{"location":"reference/red_utils/std/logging_utils/config_classes/filters/_filters/#red_utils.std.logging_utils.config_classes.filters._filters.BaseLoggingConfig","title":"<code>BaseLoggingConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for a full logging config dict.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\base\\_bases.py</code> <pre><code>@dataclass\nclass BaseLoggingConfig(ABC):\n    \"\"\"Abstract base class for a full logging config dict.\"\"\"\n\n    @abstractmethod\n    def get_configdict(self) -&gt; None:\n        pass\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/filters/_filters/#red_utils.std.logging_utils.config_classes.filters._filters.FilterConfig","title":"<code>FilterConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseLoggingConfig</code></p> <p>Define a logging filter.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>A name for the filter, which can be added to a dictConfig's <code>filters</code> param.</p> required <code>func</code> <code>callable</code> <p>The filter function to use when this class is called by a handler.</p> required Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\filters\\_filters.py</code> <pre><code>@dataclass\nclass FilterConfig(BaseLoggingConfig):\n    \"\"\"Define a logging filter.\n\n    Params:\n        name (str): A name for the filter, which can be added to a dictConfig's `filters` param.\n        func (callable): The filter function to use when this class is called by a handler.\n    \"\"\"\n\n    name: str\n    func: callable\n\n    def get_filter(self) -&gt; logging.Filter:\n        filter_obj = logging.Filter(name=self.name)\n        filter_obj.filter = self.func\n        return filter_obj\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/filters/loglevel_filters/__init__/","title":"loglevel_filters","text":"<p>Filter functions for logging handlers.</p>"},{"location":"reference/red_utils/std/logging_utils/config_classes/filters/loglevel_filters/__init__/#red_utils.std.logging_utils.config_classes.filters.loglevel_filters.critical_filter","title":"<code>critical_filter(record)</code>","text":"<p>Filter to only show CRITICAL and above.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\filters\\loglevel_filters\\_loglevel_filters.py</code> <pre><code>def critical_filter(record: logging.LogRecord) -&gt; bool:\n    \"\"\"Filter to only show CRITICAL and above.\"\"\"\n    return record.levelno &gt;= logging.CRITICAL\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/filters/loglevel_filters/__init__/#red_utils.std.logging_utils.config_classes.filters.loglevel_filters.debug_filter","title":"<code>debug_filter(record)</code>","text":"<p>Filter to only show DEBUG and above.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\filters\\loglevel_filters\\_loglevel_filters.py</code> <pre><code>def debug_filter(record: logging.LogRecord) -&gt; bool:\n    \"\"\"Filter to only show DEBUG and above.\"\"\"\n    return record.levelno &gt;= logging.DEBUG\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/filters/loglevel_filters/__init__/#red_utils.std.logging_utils.config_classes.filters.loglevel_filters.error_filter","title":"<code>error_filter(record)</code>","text":"<p>Filter to only show ERROR and above.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\filters\\loglevel_filters\\_loglevel_filters.py</code> <pre><code>def error_filter(record: logging.LogRecord) -&gt; bool:\n    \"\"\"Filter to only show ERROR and above.\"\"\"\n    return record.levelno &gt;= logging.ERROR\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/filters/loglevel_filters/__init__/#red_utils.std.logging_utils.config_classes.filters.loglevel_filters.info_filter","title":"<code>info_filter(record)</code>","text":"<p>Filter to only show INFO and above.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\filters\\loglevel_filters\\_loglevel_filters.py</code> <pre><code>def info_filter(record: logging.LogRecord) -&gt; bool:\n    \"\"\"Filter to only show INFO and above.\"\"\"\n    return record.levelno &gt;= logging.INFO\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/filters/loglevel_filters/__init__/#red_utils.std.logging_utils.config_classes.filters.loglevel_filters.warning_filter","title":"<code>warning_filter(record)</code>","text":"<p>Filter to only show WARNING and above.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\filters\\loglevel_filters\\_loglevel_filters.py</code> <pre><code>def warning_filter(record: logging.LogRecord) -&gt; bool:\n    \"\"\"Filter to only show WARNING and above.\"\"\"\n    return record.levelno &gt;= logging.WARNING\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/filters/loglevel_filters/_loglevel_filters/","title":"_loglevel_filters","text":"<p>Filter functions that can be referenced by function name in a logging dictConfig to apply filtering to a handler.</p> <p>For example, to only show DEBUG level messages, you could add <code>filters=[\"debug_filter\"]</code> to a logging dictConfig.</p> <p>When adding these methods to a config, you must import the function into the same script where <code>logging.config.dictConfig()</code> is executed.</p>"},{"location":"reference/red_utils/std/logging_utils/config_classes/filters/loglevel_filters/_loglevel_filters/#red_utils.std.logging_utils.config_classes.filters.loglevel_filters._loglevel_filters.critical_filter","title":"<code>critical_filter(record)</code>","text":"<p>Filter to only show CRITICAL and above.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\filters\\loglevel_filters\\_loglevel_filters.py</code> <pre><code>def critical_filter(record: logging.LogRecord) -&gt; bool:\n    \"\"\"Filter to only show CRITICAL and above.\"\"\"\n    return record.levelno &gt;= logging.CRITICAL\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/filters/loglevel_filters/_loglevel_filters/#red_utils.std.logging_utils.config_classes.filters.loglevel_filters._loglevel_filters.debug_filter","title":"<code>debug_filter(record)</code>","text":"<p>Filter to only show DEBUG and above.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\filters\\loglevel_filters\\_loglevel_filters.py</code> <pre><code>def debug_filter(record: logging.LogRecord) -&gt; bool:\n    \"\"\"Filter to only show DEBUG and above.\"\"\"\n    return record.levelno &gt;= logging.DEBUG\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/filters/loglevel_filters/_loglevel_filters/#red_utils.std.logging_utils.config_classes.filters.loglevel_filters._loglevel_filters.error_filter","title":"<code>error_filter(record)</code>","text":"<p>Filter to only show ERROR and above.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\filters\\loglevel_filters\\_loglevel_filters.py</code> <pre><code>def error_filter(record: logging.LogRecord) -&gt; bool:\n    \"\"\"Filter to only show ERROR and above.\"\"\"\n    return record.levelno &gt;= logging.ERROR\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/filters/loglevel_filters/_loglevel_filters/#red_utils.std.logging_utils.config_classes.filters.loglevel_filters._loglevel_filters.info_filter","title":"<code>info_filter(record)</code>","text":"<p>Filter to only show INFO and above.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\filters\\loglevel_filters\\_loglevel_filters.py</code> <pre><code>def info_filter(record: logging.LogRecord) -&gt; bool:\n    \"\"\"Filter to only show INFO and above.\"\"\"\n    return record.levelno &gt;= logging.INFO\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/filters/loglevel_filters/_loglevel_filters/#red_utils.std.logging_utils.config_classes.filters.loglevel_filters._loglevel_filters.warning_filter","title":"<code>warning_filter(record)</code>","text":"<p>Filter to only show WARNING and above.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\filters\\loglevel_filters\\_loglevel_filters.py</code> <pre><code>def warning_filter(record: logging.LogRecord) -&gt; bool:\n    \"\"\"Filter to only show WARNING and above.\"\"\"\n    return record.levelno &gt;= logging.WARNING\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/formatters/__init__/","title":"formatters","text":"<p>Formatters for a logging dictConfig.</p> <p>Formatters define the message and timestamp format for log messages.</p>"},{"location":"reference/red_utils/std/logging_utils/config_classes/formatters/__init__/#red_utils.std.logging_utils.config_classes.formatters.FormatterConfig","title":"<code>FormatterConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseLoggingConfig</code></p> <p>Define a logging formatter.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the formatter.</p> <code>None</code> <code>fmt</code> <code>str</code> <p>The string formatting to use for log messages.</p> <code>MESSAGE_FMT_STANDARD</code> <code>datefmt</code> <code>str</code> <p>The string formatting to use for log message timestamps.</p> <code>DATE_FMT_STANDARD</code> <code>style</code> <code>str</code> <p>The string substitution style to use for log formats. Default is <code>%</code>, which means formats need to be written like <code>%(asctime)s %(levelname)s %(message)s</code>. If you change this style, make sure the <code>fmt</code> you pass uses the correct formatting style.</p> <code>'%'</code> <code>validate</code> <code>bool</code> <p>When <code>True</code>, the configuration dict this formatter returns will be validated by the logging module.</p> <code>True</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\formatters\\_formatters.py</code> <pre><code>@dataclass\nclass FormatterConfig(BaseLoggingConfig):\n    \"\"\"Define a logging formatter.\n\n    Params:\n        name (str): The name of the formatter.\n        fmt (str): The string formatting to use for log messages.\n        datefmt (str): The string formatting to use for log message timestamps.\n        style (str): The string substitution style to use for log formats. Default is `%`, which\n            means formats need to be written like `%(asctime)s %(levelname)s %(message)s`. If\n            you change this style, make sure the `fmt` you pass uses the correct formatting style.\n        validate (bool): When `True`, the configuration dict this formatter returns will be validated by the logging module.\n\n    \"\"\"\n\n    name: str = None\n    fmt: str = MESSAGE_FMT_STANDARD\n    datefmt: str = DATE_FMT_STANDARD\n    style: str = \"%\"\n    validate: bool = True\n\n    def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Return a dict representation of the formatter described by this class.\"\"\"\n        formatter_dict: dict[str, dict[str, str]] = {self.name: {\"format\": self.fmt}}\n        if self.datefmt:\n            formatter_dict[self.name][\"datefmt\"] = self.datefmt\n        if self.style:\n            formatter_dict[self.name][\"style\"] = self.style\n        formatter_dict[self.name][\"validate\"] = self.validate\n\n        return formatter_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/formatters/__init__/#red_utils.std.logging_utils.config_classes.formatters.FormatterConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the formatter described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\formatters\\_formatters.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Return a dict representation of the formatter described by this class.\"\"\"\n    formatter_dict: dict[str, dict[str, str]] = {self.name: {\"format\": self.fmt}}\n    if self.datefmt:\n        formatter_dict[self.name][\"datefmt\"] = self.datefmt\n    if self.style:\n        formatter_dict[self.name][\"style\"] = self.style\n    formatter_dict[self.name][\"validate\"] = self.validate\n\n    return formatter_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/formatters/_formatters/","title":"_formatters","text":"<p>Use these classes to instantiate logging formatters for a logging dictConfig.</p> <p>Each class has a <code>.get_configdict()</code> method, which returns a dict representation of the class that can be added to a logging config dict.</p>"},{"location":"reference/red_utils/std/logging_utils/config_classes/formatters/_formatters/#red_utils.std.logging_utils.config_classes.formatters._formatters.BaseLoggingConfig","title":"<code>BaseLoggingConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for a full logging config dict.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\base\\_bases.py</code> <pre><code>@dataclass\nclass BaseLoggingConfig(ABC):\n    \"\"\"Abstract base class for a full logging config dict.\"\"\"\n\n    @abstractmethod\n    def get_configdict(self) -&gt; None:\n        pass\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/formatters/_formatters/#red_utils.std.logging_utils.config_classes.formatters._formatters.FormatterConfig","title":"<code>FormatterConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseLoggingConfig</code></p> <p>Define a logging formatter.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the formatter.</p> <code>None</code> <code>fmt</code> <code>str</code> <p>The string formatting to use for log messages.</p> <code>MESSAGE_FMT_STANDARD</code> <code>datefmt</code> <code>str</code> <p>The string formatting to use for log message timestamps.</p> <code>DATE_FMT_STANDARD</code> <code>style</code> <code>str</code> <p>The string substitution style to use for log formats. Default is <code>%</code>, which means formats need to be written like <code>%(asctime)s %(levelname)s %(message)s</code>. If you change this style, make sure the <code>fmt</code> you pass uses the correct formatting style.</p> <code>'%'</code> <code>validate</code> <code>bool</code> <p>When <code>True</code>, the configuration dict this formatter returns will be validated by the logging module.</p> <code>True</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\formatters\\_formatters.py</code> <pre><code>@dataclass\nclass FormatterConfig(BaseLoggingConfig):\n    \"\"\"Define a logging formatter.\n\n    Params:\n        name (str): The name of the formatter.\n        fmt (str): The string formatting to use for log messages.\n        datefmt (str): The string formatting to use for log message timestamps.\n        style (str): The string substitution style to use for log formats. Default is `%`, which\n            means formats need to be written like `%(asctime)s %(levelname)s %(message)s`. If\n            you change this style, make sure the `fmt` you pass uses the correct formatting style.\n        validate (bool): When `True`, the configuration dict this formatter returns will be validated by the logging module.\n\n    \"\"\"\n\n    name: str = None\n    fmt: str = MESSAGE_FMT_STANDARD\n    datefmt: str = DATE_FMT_STANDARD\n    style: str = \"%\"\n    validate: bool = True\n\n    def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Return a dict representation of the formatter described by this class.\"\"\"\n        formatter_dict: dict[str, dict[str, str]] = {self.name: {\"format\": self.fmt}}\n        if self.datefmt:\n            formatter_dict[self.name][\"datefmt\"] = self.datefmt\n        if self.style:\n            formatter_dict[self.name][\"style\"] = self.style\n        formatter_dict[self.name][\"validate\"] = self.validate\n\n        return formatter_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/formatters/_formatters/#red_utils.std.logging_utils.config_classes.formatters._formatters.FormatterConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the formatter described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\formatters\\_formatters.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Return a dict representation of the formatter described by this class.\"\"\"\n    formatter_dict: dict[str, dict[str, str]] = {self.name: {\"format\": self.fmt}}\n    if self.datefmt:\n        formatter_dict[self.name][\"datefmt\"] = self.datefmt\n    if self.style:\n        formatter_dict[self.name][\"style\"] = self.style\n    formatter_dict[self.name][\"validate\"] = self.validate\n\n    return formatter_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/","title":"handlers","text":"<p>Handlers for a logging dictConfig.</p> <p>Handlers define what to do with log messages as they are created.</p>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.FileHandlerConfig","title":"<code>FileHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging FileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file to log messages to.</p> <code>'app.log'</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass FileHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging FileHandler.\n\n    Params:\n        filename (str): The name of the file to log messages to.\n    \"\"\"\n\n    filename: str | None = field(default=\"app.log\")\n\n    def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, str]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"filename\": self.filename,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.FileHandler`.\n\n        \"\"\"\n        return \"logging.FileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.FileHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, str]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"filename\": self.filename,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.FileHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.FileHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.FileHandler`.\n\n    \"\"\"\n    return \"logging.FileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.QueueHandlerConfig","title":"<code>QueueHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging QueueHandler.</p> <p>Parameters:</p> Name Type Description Default <code>queue</code> <code>Queue</code> <p>The queue to send log messages to.</p> <code>None</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass QueueHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging QueueHandler.\n\n    Params:\n        queue (queue.Queue): The queue to send log messages to.\n    \"\"\"\n\n    queue: Queue = field(default=None)\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"queue\": self.queue,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.QueueHandler`.\n\n        \"\"\"\n        return \"logging.handlers.QueueHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.QueueHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"queue\": self.queue,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.QueueHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.QueueHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.QueueHandler`.\n\n    \"\"\"\n    return \"logging.handlers.QueueHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.QueueListenerConfig","title":"<code>QueueListenerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseLoggingConfig</code></p> <p>Define a logging QueueListener.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the handler.</p> required <code>queue</code> <code>Queue</code> <p>The queue to listen for log messages in.</p> required <code>handlers</code> <code>list[str]</code> <p>List of handler names to apply to this listener.</p> required Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass QueueListenerConfig(BaseLoggingConfig):\n    \"\"\"Define a logging QueueListener.\n\n    Params:\n        name (str): The name of the handler.\n        queue (queue.Queue): The queue to listen for log messages in.\n        handlers (list[str]): List of handler names to apply to this listener.\n\n    \"\"\"\n\n    name: str\n    queue: Queue\n    handlers: list\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        listener_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"queue\": self.queue,\n                \"handlers\": self.handlers,\n            }\n        }\n        return listener_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.QueueListener`.\n\n        \"\"\"\n        return \"logging.handleres.QueueListener\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.QueueListenerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    listener_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"queue\": self.queue,\n            \"handlers\": self.handlers,\n        }\n    }\n    return listener_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.QueueListenerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.QueueListener</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.QueueListener`.\n\n    \"\"\"\n    return \"logging.handleres.QueueListener\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.RotatingFileHandlerConfig","title":"<code>RotatingFileHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging RotatingFileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | None</code> <p>The name/path of the file to log messages to.</p> <code>'app.log'</code> <code>maxBytes</code> <code>int</code> <p>The maximum size of the file (in bytes) before a new file is rotated.</p> <code>0</code> <code>backupCount</code> <code>int</code> <p>Number of rotated log files to keep.</p> <code>0</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass RotatingFileHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging RotatingFileHandler.\n\n    Params:\n        filename (str | None): The name/path of the file to log messages to.\n        maxBytes (int): The maximum size of the file (in bytes) before a new file is rotated.\n        backupCount (int): Number of rotated log files to keep.\n\n    \"\"\"\n\n    filename: str | None = field(default=\"app.log\")\n    maxBytes: int = 0\n    backupCount: int = 0\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"filename\": f\"{self.filename}\",\n                \"maxBytes\": self.maxBytes,\n                \"backupCount\": self.backupCount,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.RotatingFileHandler`.\n\n        \"\"\"\n        return \"logging.handlers.RotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.RotatingFileHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"filename\": f\"{self.filename}\",\n            \"maxBytes\": self.maxBytes,\n            \"backupCount\": self.backupCount,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.RotatingFileHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.RotatingFileHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.RotatingFileHandler`.\n\n    \"\"\"\n    return \"logging.handlers.RotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.SMTPHandlerConfig","title":"<code>SMTPHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging SMTPHandler.</p> <p>Parameters:</p> Name Type Description Default <code>mailhost</code> <code>Any</code> <p>...</p> <code>None</code> <code>fromaddr</code> <code>str</code> <p>...</p> <code>'from@example.com'</code> <code>toaddrs</code> <code>list</code> <p>...</p> <code>lambda: []()</code> <code>subject</code> <code>str</code> <p>...</p> <code>'SMTPHandler Log Event'</code> <code>credentials</code> <code>tuple</code> <p>...</p> <code>None</code> <code>secure</code> <code>tuple</code> <p>...</p> <code>None</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass SMTPHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging SMTPHandler.\n\n    Params:\n        mailhost (Any): ...\n        fromaddr (str): ...\n        toaddrs (list): ...\n        subject (str): ...\n        credentials (tuple): ...\n        secure (tuple): ...\n    \"\"\"\n\n    mailhost: t.Any = None\n    fromaddr: str = \"from@example.com\"\n    toaddrs: list = field(default_factory=lambda: [])\n    subject: str = \"SMTPHandler Log Event\"\n    credentials: tuple | None = None\n    secure: tuple | None = None\n\n    def get_configdict(self):\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"mailhost\": self.mailhost,\n                \"fromaddr\": self.fromaddr,\n                \"toaddrs\": self.toaddrs,\n                \"subject\": self.subject,\n            }\n        }\n        if self.credentials:\n            handler_dict[self.name][\"credentials\"] = self.credentials\n        if self.secure:\n            handler_dict[self.name][\"secure\"] = self.secure\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.SMTPHandler`.\n\n        \"\"\"\n        return \"logging.handlers.SMTPHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.SMTPHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self):\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"mailhost\": self.mailhost,\n            \"fromaddr\": self.fromaddr,\n            \"toaddrs\": self.toaddrs,\n            \"subject\": self.subject,\n        }\n    }\n    if self.credentials:\n        handler_dict[self.name][\"credentials\"] = self.credentials\n    if self.secure:\n        handler_dict[self.name][\"secure\"] = self.secure\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.SMTPHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.SMTPHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.SMTPHandler`.\n\n    \"\"\"\n    return \"logging.handlers.SMTPHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.SocketHandlerConfig","title":"<code>SocketHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging SocketHandler.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Host IP/FQDN.</p> <code>'localhost'</code> <code>port</code> <code>int</code> <p>Host port where log messages should be sent.</p> <code>0</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass SocketHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging SocketHandler.\n\n    Params:\n        host (str): Host IP/FQDN.\n        port (int): Host port where log messages should be sent.\n    \"\"\"\n\n    host: str = \"localhost\"\n    port: int = 0\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"host\": self.host,\n                \"port\": self.port,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.SocketHandler`.\n\n        \"\"\"\n        return \"logging.handlers.SocketHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.SocketHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"host\": self.host,\n            \"port\": self.port,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.SocketHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.SocketHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.SocketHandler`.\n\n    \"\"\"\n    return \"logging.handlers.SocketHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.StreamHandlerConfig","title":"<code>StreamHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging StreamHandler.</p> <p>Parameters:</p> Name Type Description Default <code>stream</code> <code>Any</code> <p>The stream this handler controls, i.e. <code>ext://sys.stdout</code>, <code>ext://sys.stderr</code>, etc.</p> <code>'ext://sys.stdout'</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass StreamHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging StreamHandler.\n\n    Params:\n        stream (Any): The stream this handler controls, i.e. `ext://sys.stdout`, `ext://sys.stderr`, etc.\n    \"\"\"\n\n    stream: t.Any | None = \"ext://sys.stdout\"\n\n    def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, str]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"stream\": self.stream,\n            }\n        }\n        if self.filters:\n            handler_dict[\"filters\"] = self.filters\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.StreamHandler`.\n\n        \"\"\"\n        return \"logging.StreamHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.StreamHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, str]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"stream\": self.stream,\n        }\n    }\n    if self.filters:\n        handler_dict[\"filters\"] = self.filters\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.StreamHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.StreamHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.StreamHandler`.\n\n    \"\"\"\n    return \"logging.StreamHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.TimedRotatingFileHandlerConfig","title":"<code>TimedRotatingFileHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging TimedRotatingFileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name/path of the file to log messages to.</p> <code>'app.log'</code> <code>when</code> <code>str</code> <p>Time of day to rotate log files, i.e. <code>midnight</code>.</p> <code>'midnight'</code> <code>interval</code> <code>int</code> <p>When to rotate the file as the interval defined in <code>when</code> occurs. <code>1=every occurrence</code>, <code>2=every other occurrence</code>, etc.</p> <code>1</code> <code>backupCount</code> <code>int</code> <p>The number of rotated log files to save.</p> <code>0</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass TimedRotatingFileHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging TimedRotatingFileHandler.\n\n    Params:\n        filename (str): The name/path of the file to log messages to.\n        when (str): Time of day to rotate log files, i.e. `midnight`.\n        interval (int): When to rotate the file as the interval defined in `when` occurs.\n            `1=every occurrence`, `2=every other occurrence`, etc.\n        backupCount (int): The number of rotated log files to save.\n    \"\"\"\n\n    filename: str | None = field(default=\"app.log\")\n    when: str | None = field(default=\"midnight\")\n    interval: int = 1\n    backupCount: int = 0\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"filename\": self.filename,\n                \"when\": self.when,\n                \"interval\": self.interval,\n                \"backupCount\": self.backupCount,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.TimedRotatingFileHandler`.\n\n        \"\"\"\n        return \"logging.handlers.TimedRotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.TimedRotatingFileHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"filename\": self.filename,\n            \"when\": self.when,\n            \"interval\": self.interval,\n            \"backupCount\": self.backupCount,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/__init__/#red_utils.std.logging_utils.config_classes.handlers.TimedRotatingFileHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.TimedRotatingFileHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.TimedRotatingFileHandler`.\n\n    \"\"\"\n    return \"logging.handlers.TimedRotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/","title":"_handlers","text":"<p>Use these classes to instantiate logging handlers for a logging dictConfig.</p> <p>Each class has a <code>.get_configdict()</code> method, which returns a dict representation of the class that can be added to a logging config dict.</p>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.BaseHandlerConfig","title":"<code>BaseHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseLoggingConfig</code></p> <p>Abstract base class for a logging handler dict.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The handler's name.</p> <code>None</code> <code>level</code> <code>str</code> <p>The handler's logging level (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'NOTSET'</code> <code>formatter</code> <code>str</code> <p>The name of a formatter that exists in the logging config.</p> <code>None</code> <code>filters</code> <code>list[str] | None</code> <p>The names of logging filter methods/classes. These methods/classes must be imported into the script where <code>logging.config.dictConfig()</code> is run.</p> <code>None</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\base\\_bases.py</code> <pre><code>@dataclass\nclass BaseHandlerConfig(BaseLoggingConfig):\n    \"\"\"Abstract base class for a logging handler dict.\n\n    Params:\n        name (str): The handler's name.\n        level (str): The handler's logging level (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        formatter (str): The name of a formatter that exists in the logging config.\n        filters (list[str] | None): The names of logging filter methods/classes. These methods/classes\n            must be imported into the script where `logging.config.dictConfig()` is run.\n    \"\"\"\n\n    name: str = None\n    level: str = \"NOTSET\"\n    formatter: str = None\n    filters: list[str] | None = field(default=None)\n\n    @abstractmethod\n    def get_configdict(self) -&gt; None:\n        \"\"\"Return a dict representation of the handler config.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n            }\n        }\n        if self.filters:\n            handler_dict[self.name][\"filters\"] = self.filters\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler's class name.\"\"\"\n        raise NotImplementedError(\"Subclasses must implement get_handler_class method\")\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.BaseHandlerConfig.get_configdict","title":"<code>get_configdict()</code>  <code>abstractmethod</code>","text":"<p>Return a dict representation of the handler config.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\base\\_bases.py</code> <pre><code>@abstractmethod\ndef get_configdict(self) -&gt; None:\n    \"\"\"Return a dict representation of the handler config.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n        }\n    }\n    if self.filters:\n        handler_dict[self.name][\"filters\"] = self.filters\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.BaseHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler's class name.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\base\\_bases.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler's class name.\"\"\"\n    raise NotImplementedError(\"Subclasses must implement get_handler_class method\")\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.BaseLoggingConfig","title":"<code>BaseLoggingConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for a full logging config dict.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\base\\_bases.py</code> <pre><code>@dataclass\nclass BaseLoggingConfig(ABC):\n    \"\"\"Abstract base class for a full logging config dict.\"\"\"\n\n    @abstractmethod\n    def get_configdict(self) -&gt; None:\n        pass\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.FileHandlerConfig","title":"<code>FileHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging FileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file to log messages to.</p> <code>'app.log'</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass FileHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging FileHandler.\n\n    Params:\n        filename (str): The name of the file to log messages to.\n    \"\"\"\n\n    filename: str | None = field(default=\"app.log\")\n\n    def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, str]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"filename\": self.filename,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.FileHandler`.\n\n        \"\"\"\n        return \"logging.FileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.FileHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, str]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"filename\": self.filename,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.FileHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.FileHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.FileHandler`.\n\n    \"\"\"\n    return \"logging.FileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.QueueHandlerConfig","title":"<code>QueueHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging QueueHandler.</p> <p>Parameters:</p> Name Type Description Default <code>queue</code> <code>Queue</code> <p>The queue to send log messages to.</p> <code>None</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass QueueHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging QueueHandler.\n\n    Params:\n        queue (queue.Queue): The queue to send log messages to.\n    \"\"\"\n\n    queue: Queue = field(default=None)\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"queue\": self.queue,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.QueueHandler`.\n\n        \"\"\"\n        return \"logging.handlers.QueueHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.QueueHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"queue\": self.queue,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.QueueHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.QueueHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.QueueHandler`.\n\n    \"\"\"\n    return \"logging.handlers.QueueHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.QueueListenerConfig","title":"<code>QueueListenerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseLoggingConfig</code></p> <p>Define a logging QueueListener.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the handler.</p> required <code>queue</code> <code>Queue</code> <p>The queue to listen for log messages in.</p> required <code>handlers</code> <code>list[str]</code> <p>List of handler names to apply to this listener.</p> required Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass QueueListenerConfig(BaseLoggingConfig):\n    \"\"\"Define a logging QueueListener.\n\n    Params:\n        name (str): The name of the handler.\n        queue (queue.Queue): The queue to listen for log messages in.\n        handlers (list[str]): List of handler names to apply to this listener.\n\n    \"\"\"\n\n    name: str\n    queue: Queue\n    handlers: list\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        listener_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"queue\": self.queue,\n                \"handlers\": self.handlers,\n            }\n        }\n        return listener_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.QueueListener`.\n\n        \"\"\"\n        return \"logging.handleres.QueueListener\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.QueueListenerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    listener_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"queue\": self.queue,\n            \"handlers\": self.handlers,\n        }\n    }\n    return listener_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.QueueListenerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.QueueListener</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.QueueListener`.\n\n    \"\"\"\n    return \"logging.handleres.QueueListener\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.RotatingFileHandlerConfig","title":"<code>RotatingFileHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging RotatingFileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | None</code> <p>The name/path of the file to log messages to.</p> <code>'app.log'</code> <code>maxBytes</code> <code>int</code> <p>The maximum size of the file (in bytes) before a new file is rotated.</p> <code>0</code> <code>backupCount</code> <code>int</code> <p>Number of rotated log files to keep.</p> <code>0</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass RotatingFileHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging RotatingFileHandler.\n\n    Params:\n        filename (str | None): The name/path of the file to log messages to.\n        maxBytes (int): The maximum size of the file (in bytes) before a new file is rotated.\n        backupCount (int): Number of rotated log files to keep.\n\n    \"\"\"\n\n    filename: str | None = field(default=\"app.log\")\n    maxBytes: int = 0\n    backupCount: int = 0\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"filename\": f\"{self.filename}\",\n                \"maxBytes\": self.maxBytes,\n                \"backupCount\": self.backupCount,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.RotatingFileHandler`.\n\n        \"\"\"\n        return \"logging.handlers.RotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.RotatingFileHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"filename\": f\"{self.filename}\",\n            \"maxBytes\": self.maxBytes,\n            \"backupCount\": self.backupCount,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.RotatingFileHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.RotatingFileHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.RotatingFileHandler`.\n\n    \"\"\"\n    return \"logging.handlers.RotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.SMTPHandlerConfig","title":"<code>SMTPHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging SMTPHandler.</p> <p>Parameters:</p> Name Type Description Default <code>mailhost</code> <code>Any</code> <p>...</p> <code>None</code> <code>fromaddr</code> <code>str</code> <p>...</p> <code>'from@example.com'</code> <code>toaddrs</code> <code>list</code> <p>...</p> <code>lambda: []()</code> <code>subject</code> <code>str</code> <p>...</p> <code>'SMTPHandler Log Event'</code> <code>credentials</code> <code>tuple</code> <p>...</p> <code>None</code> <code>secure</code> <code>tuple</code> <p>...</p> <code>None</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass SMTPHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging SMTPHandler.\n\n    Params:\n        mailhost (Any): ...\n        fromaddr (str): ...\n        toaddrs (list): ...\n        subject (str): ...\n        credentials (tuple): ...\n        secure (tuple): ...\n    \"\"\"\n\n    mailhost: t.Any = None\n    fromaddr: str = \"from@example.com\"\n    toaddrs: list = field(default_factory=lambda: [])\n    subject: str = \"SMTPHandler Log Event\"\n    credentials: tuple | None = None\n    secure: tuple | None = None\n\n    def get_configdict(self):\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"mailhost\": self.mailhost,\n                \"fromaddr\": self.fromaddr,\n                \"toaddrs\": self.toaddrs,\n                \"subject\": self.subject,\n            }\n        }\n        if self.credentials:\n            handler_dict[self.name][\"credentials\"] = self.credentials\n        if self.secure:\n            handler_dict[self.name][\"secure\"] = self.secure\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.SMTPHandler`.\n\n        \"\"\"\n        return \"logging.handlers.SMTPHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.SMTPHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self):\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"mailhost\": self.mailhost,\n            \"fromaddr\": self.fromaddr,\n            \"toaddrs\": self.toaddrs,\n            \"subject\": self.subject,\n        }\n    }\n    if self.credentials:\n        handler_dict[self.name][\"credentials\"] = self.credentials\n    if self.secure:\n        handler_dict[self.name][\"secure\"] = self.secure\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.SMTPHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.SMTPHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.SMTPHandler`.\n\n    \"\"\"\n    return \"logging.handlers.SMTPHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.SocketHandlerConfig","title":"<code>SocketHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging SocketHandler.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Host IP/FQDN.</p> <code>'localhost'</code> <code>port</code> <code>int</code> <p>Host port where log messages should be sent.</p> <code>0</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass SocketHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging SocketHandler.\n\n    Params:\n        host (str): Host IP/FQDN.\n        port (int): Host port where log messages should be sent.\n    \"\"\"\n\n    host: str = \"localhost\"\n    port: int = 0\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"host\": self.host,\n                \"port\": self.port,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.SocketHandler`.\n\n        \"\"\"\n        return \"logging.handlers.SocketHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.SocketHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"host\": self.host,\n            \"port\": self.port,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.SocketHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.SocketHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.SocketHandler`.\n\n    \"\"\"\n    return \"logging.handlers.SocketHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.StreamHandlerConfig","title":"<code>StreamHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging StreamHandler.</p> <p>Parameters:</p> Name Type Description Default <code>stream</code> <code>Any</code> <p>The stream this handler controls, i.e. <code>ext://sys.stdout</code>, <code>ext://sys.stderr</code>, etc.</p> <code>'ext://sys.stdout'</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass StreamHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging StreamHandler.\n\n    Params:\n        stream (Any): The stream this handler controls, i.e. `ext://sys.stdout`, `ext://sys.stderr`, etc.\n    \"\"\"\n\n    stream: t.Any | None = \"ext://sys.stdout\"\n\n    def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, str]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"stream\": self.stream,\n            }\n        }\n        if self.filters:\n            handler_dict[\"filters\"] = self.filters\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.StreamHandler`.\n\n        \"\"\"\n        return \"logging.StreamHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.StreamHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, str]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"stream\": self.stream,\n        }\n    }\n    if self.filters:\n        handler_dict[\"filters\"] = self.filters\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.StreamHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.StreamHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.StreamHandler`.\n\n    \"\"\"\n    return \"logging.StreamHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.TimedRotatingFileHandlerConfig","title":"<code>TimedRotatingFileHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging TimedRotatingFileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name/path of the file to log messages to.</p> <code>'app.log'</code> <code>when</code> <code>str</code> <p>Time of day to rotate log files, i.e. <code>midnight</code>.</p> <code>'midnight'</code> <code>interval</code> <code>int</code> <p>When to rotate the file as the interval defined in <code>when</code> occurs. <code>1=every occurrence</code>, <code>2=every other occurrence</code>, etc.</p> <code>1</code> <code>backupCount</code> <code>int</code> <p>The number of rotated log files to save.</p> <code>0</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass TimedRotatingFileHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging TimedRotatingFileHandler.\n\n    Params:\n        filename (str): The name/path of the file to log messages to.\n        when (str): Time of day to rotate log files, i.e. `midnight`.\n        interval (int): When to rotate the file as the interval defined in `when` occurs.\n            `1=every occurrence`, `2=every other occurrence`, etc.\n        backupCount (int): The number of rotated log files to save.\n    \"\"\"\n\n    filename: str | None = field(default=\"app.log\")\n    when: str | None = field(default=\"midnight\")\n    interval: int = 1\n    backupCount: int = 0\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"filename\": self.filename,\n                \"when\": self.when,\n                \"interval\": self.interval,\n                \"backupCount\": self.backupCount,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.TimedRotatingFileHandler`.\n\n        \"\"\"\n        return \"logging.handlers.TimedRotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.TimedRotatingFileHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"filename\": self.filename,\n            \"when\": self.when,\n            \"interval\": self.interval,\n            \"backupCount\": self.backupCount,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/handlers/_handlers/#red_utils.std.logging_utils.config_classes.handlers._handlers.TimedRotatingFileHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.TimedRotatingFileHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.TimedRotatingFileHandler`.\n\n    \"\"\"\n    return \"logging.handlers.TimedRotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/loggers/__init__/","title":"loggers","text":"<p>Describe loggers as a class, or get a fully initialized logger with <code>LoggerFactory</code>.</p>"},{"location":"reference/red_utils/std/logging_utils/config_classes/loggers/__init__/#red_utils.std.logging_utils.config_classes.loggers.LoggerConfig","title":"<code>LoggerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseLoggingConfig</code></p> <p>Define a logging Logger.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the logger.</p> required <code>level</code> <code>str</code> <p>The level of log messages this logger should show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> required <code>handlers</code> <code>list[str]</code> <p>List of handler names this logger should use. These handlers must exist in the logging dictConfig.</p> required <code>propagate</code> <code>bool</code> <p>If <code>True</code>, messages will be propagated up/down to the root logger.</p> <code>False</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_loggers.py</code> <pre><code>@dataclass\nclass LoggerConfig(BaseLoggingConfig):\n    \"\"\"Define a logging Logger.\n\n    Params:\n        name (str): The name of the logger.\n        level (str): The level of log messages this logger should show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        handlers (list[str]): List of handler names this logger should use. These handlers must exist in the logging dictConfig.\n        propagate (bool): If `True`, messages will be propagated up/down to the root logger.\n    \"\"\"\n\n    name: str\n    level: str\n    handlers: list[str]\n    propagate: bool = False\n\n    def get_configdict(self) -&gt; dict:\n        \"\"\"Return a dict representation of the logger described by this class.\"\"\"\n        logger_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"level\": self.level,\n                \"handlers\": self.handlers,\n                \"propagate\": self.propagate,\n            }\n        }\n        return logger_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/loggers/__init__/#red_utils.std.logging_utils.config_classes.loggers.LoggerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the logger described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_loggers.py</code> <pre><code>def get_configdict(self) -&gt; dict:\n    \"\"\"Return a dict representation of the logger described by this class.\"\"\"\n    logger_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"level\": self.level,\n            \"handlers\": self.handlers,\n            \"propagate\": self.propagate,\n        }\n    }\n    return logger_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/loggers/__init__/#red_utils.std.logging_utils.config_classes.loggers.LoggerFactory","title":"<code>LoggerFactory</code>","text":"<p>Generate loggers based on LoggerFactory's config.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_factory.py</code> <pre><code>class LoggerFactory:\n    \"\"\"Generate loggers based on LoggerFactory's config.\"\"\"\n\n    _LOG: logging.Logger | None = None\n\n    @staticmethod\n    def __create_logger(\n        name: str,\n        log_level: str,\n        handlers: dict[str, dict],\n        formatters: dict[str, dict],\n        loggers: dict[str, dict],\n    ) -&gt; logging.Logger:\n        \"\"\"Create a logger cnofig from inputs.\n\n        Params:\n            name (str): The name of the logger.\n            log_level (str): The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n            handlers (dict[str, dict[str, Any]]): A dict describing the handlers for this logger config.\n            formatters (dict[str, dict[str, Any]]): A dict describing the formatters for this logger config.\n            loggers (dict[str, dict[str, Any]]): A dict describing the loggers for this logger config.\n        \"\"\"\n        log_level = log_level.upper()\n\n        # Configure logging using dictConfig\n        logging_config = {\n            \"version\": 1,\n            \"handlers\": handlers,\n            \"formatters\": formatters,\n            \"loggers\": loggers,\n            \"root\": {\n                \"level\": log_level,\n                \"handlers\": list(handlers.keys()),\n            },\n        }\n\n        try:\n            logging.config.dictConfig(logging_config)\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception configuring logger. Details: {exc}\")\n            # log.error(msg)\n\n            raise msg\n\n        # Get or create logger\n        LoggerFactory._LOG = logging.getLogger(name)\n\n        return LoggerFactory._LOG\n\n    @staticmethod\n    def get_logger(\n        name: str,\n        log_level: str,\n        handlers: dict[str, dict],\n        formatters: dict[str, dict],\n        loggers: dict[str, dict],\n    ) -&gt; logging.Logger:\n        \"\"\"Initialize a logger.\n\n        Params:\n            name (str): The name of the logger.\n            log_level (str): The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n            handlers (dict[str, dict[str, Any]]): A dict describing the handlers for this logger config.\n            formatters (dict[str, dict[str, Any]]): A dict describing the formatters for this logger config.\n            loggers (dict[str, dict[str, Any]]): A dict describing the loggers for this logger config.\n        \"\"\"\n        logger = LoggerFactory.__create_logger(\n            name=name,\n            log_level=log_level,\n            handlers=handlers,\n            formatters=formatters,\n            loggers=loggers,\n        )\n\n        return logger\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/loggers/__init__/#red_utils.std.logging_utils.config_classes.loggers.LoggerFactory.get_logger","title":"<code>get_logger(name, log_level, handlers, formatters, loggers)</code>  <code>staticmethod</code>","text":"<p>Initialize a logger.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the logger.</p> required <code>log_level</code> <code>str</code> <p>The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> required <code>handlers</code> <code>dict[str, dict[str, Any]]</code> <p>A dict describing the handlers for this logger config.</p> required <code>formatters</code> <code>dict[str, dict[str, Any]]</code> <p>A dict describing the formatters for this logger config.</p> required <code>loggers</code> <code>dict[str, dict[str, Any]]</code> <p>A dict describing the loggers for this logger config.</p> required Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_factory.py</code> <pre><code>@staticmethod\ndef get_logger(\n    name: str,\n    log_level: str,\n    handlers: dict[str, dict],\n    formatters: dict[str, dict],\n    loggers: dict[str, dict],\n) -&gt; logging.Logger:\n    \"\"\"Initialize a logger.\n\n    Params:\n        name (str): The name of the logger.\n        log_level (str): The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        handlers (dict[str, dict[str, Any]]): A dict describing the handlers for this logger config.\n        formatters (dict[str, dict[str, Any]]): A dict describing the formatters for this logger config.\n        loggers (dict[str, dict[str, Any]]): A dict describing the loggers for this logger config.\n    \"\"\"\n    logger = LoggerFactory.__create_logger(\n        name=name,\n        log_level=log_level,\n        handlers=handlers,\n        formatters=formatters,\n        loggers=loggers,\n    )\n\n    return logger\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/loggers/_factory/","title":"_factory","text":"<p>Class to simplify generating loggers.</p>"},{"location":"reference/red_utils/std/logging_utils/config_classes/loggers/_factory/#red_utils.std.logging_utils.config_classes.loggers._factory.LoggerFactory","title":"<code>LoggerFactory</code>","text":"<p>Generate loggers based on LoggerFactory's config.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_factory.py</code> <pre><code>class LoggerFactory:\n    \"\"\"Generate loggers based on LoggerFactory's config.\"\"\"\n\n    _LOG: logging.Logger | None = None\n\n    @staticmethod\n    def __create_logger(\n        name: str,\n        log_level: str,\n        handlers: dict[str, dict],\n        formatters: dict[str, dict],\n        loggers: dict[str, dict],\n    ) -&gt; logging.Logger:\n        \"\"\"Create a logger cnofig from inputs.\n\n        Params:\n            name (str): The name of the logger.\n            log_level (str): The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n            handlers (dict[str, dict[str, Any]]): A dict describing the handlers for this logger config.\n            formatters (dict[str, dict[str, Any]]): A dict describing the formatters for this logger config.\n            loggers (dict[str, dict[str, Any]]): A dict describing the loggers for this logger config.\n        \"\"\"\n        log_level = log_level.upper()\n\n        # Configure logging using dictConfig\n        logging_config = {\n            \"version\": 1,\n            \"handlers\": handlers,\n            \"formatters\": formatters,\n            \"loggers\": loggers,\n            \"root\": {\n                \"level\": log_level,\n                \"handlers\": list(handlers.keys()),\n            },\n        }\n\n        try:\n            logging.config.dictConfig(logging_config)\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception configuring logger. Details: {exc}\")\n            # log.error(msg)\n\n            raise msg\n\n        # Get or create logger\n        LoggerFactory._LOG = logging.getLogger(name)\n\n        return LoggerFactory._LOG\n\n    @staticmethod\n    def get_logger(\n        name: str,\n        log_level: str,\n        handlers: dict[str, dict],\n        formatters: dict[str, dict],\n        loggers: dict[str, dict],\n    ) -&gt; logging.Logger:\n        \"\"\"Initialize a logger.\n\n        Params:\n            name (str): The name of the logger.\n            log_level (str): The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n            handlers (dict[str, dict[str, Any]]): A dict describing the handlers for this logger config.\n            formatters (dict[str, dict[str, Any]]): A dict describing the formatters for this logger config.\n            loggers (dict[str, dict[str, Any]]): A dict describing the loggers for this logger config.\n        \"\"\"\n        logger = LoggerFactory.__create_logger(\n            name=name,\n            log_level=log_level,\n            handlers=handlers,\n            formatters=formatters,\n            loggers=loggers,\n        )\n\n        return logger\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/loggers/_factory/#red_utils.std.logging_utils.config_classes.loggers._factory.LoggerFactory.get_logger","title":"<code>get_logger(name, log_level, handlers, formatters, loggers)</code>  <code>staticmethod</code>","text":"<p>Initialize a logger.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the logger.</p> required <code>log_level</code> <code>str</code> <p>The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> required <code>handlers</code> <code>dict[str, dict[str, Any]]</code> <p>A dict describing the handlers for this logger config.</p> required <code>formatters</code> <code>dict[str, dict[str, Any]]</code> <p>A dict describing the formatters for this logger config.</p> required <code>loggers</code> <code>dict[str, dict[str, Any]]</code> <p>A dict describing the loggers for this logger config.</p> required Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_factory.py</code> <pre><code>@staticmethod\ndef get_logger(\n    name: str,\n    log_level: str,\n    handlers: dict[str, dict],\n    formatters: dict[str, dict],\n    loggers: dict[str, dict],\n) -&gt; logging.Logger:\n    \"\"\"Initialize a logger.\n\n    Params:\n        name (str): The name of the logger.\n        log_level (str): The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        handlers (dict[str, dict[str, Any]]): A dict describing the handlers for this logger config.\n        formatters (dict[str, dict[str, Any]]): A dict describing the formatters for this logger config.\n        loggers (dict[str, dict[str, Any]]): A dict describing the loggers for this logger config.\n    \"\"\"\n    logger = LoggerFactory.__create_logger(\n        name=name,\n        log_level=log_level,\n        handlers=handlers,\n        formatters=formatters,\n        loggers=loggers,\n    )\n\n    return logger\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/loggers/_loggers/","title":"_loggers","text":"<p>Define loggers for a logging dictConfig.</p>"},{"location":"reference/red_utils/std/logging_utils/config_classes/loggers/_loggers/#red_utils.std.logging_utils.config_classes.loggers._loggers.BaseLoggingConfig","title":"<code>BaseLoggingConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for a full logging config dict.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\base\\_bases.py</code> <pre><code>@dataclass\nclass BaseLoggingConfig(ABC):\n    \"\"\"Abstract base class for a full logging config dict.\"\"\"\n\n    @abstractmethod\n    def get_configdict(self) -&gt; None:\n        pass\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/loggers/_loggers/#red_utils.std.logging_utils.config_classes.loggers._loggers.LoggerConfig","title":"<code>LoggerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseLoggingConfig</code></p> <p>Define a logging Logger.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the logger.</p> required <code>level</code> <code>str</code> <p>The level of log messages this logger should show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> required <code>handlers</code> <code>list[str]</code> <p>List of handler names this logger should use. These handlers must exist in the logging dictConfig.</p> required <code>propagate</code> <code>bool</code> <p>If <code>True</code>, messages will be propagated up/down to the root logger.</p> <code>False</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_loggers.py</code> <pre><code>@dataclass\nclass LoggerConfig(BaseLoggingConfig):\n    \"\"\"Define a logging Logger.\n\n    Params:\n        name (str): The name of the logger.\n        level (str): The level of log messages this logger should show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        handlers (list[str]): List of handler names this logger should use. These handlers must exist in the logging dictConfig.\n        propagate (bool): If `True`, messages will be propagated up/down to the root logger.\n    \"\"\"\n\n    name: str\n    level: str\n    handlers: list[str]\n    propagate: bool = False\n\n    def get_configdict(self) -&gt; dict:\n        \"\"\"Return a dict representation of the logger described by this class.\"\"\"\n        logger_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"level\": self.level,\n                \"handlers\": self.handlers,\n                \"propagate\": self.propagate,\n            }\n        }\n        return logger_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/loggers/_loggers/#red_utils.std.logging_utils.config_classes.loggers._loggers.LoggerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the logger described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_loggers.py</code> <pre><code>def get_configdict(self) -&gt; dict:\n    \"\"\"Return a dict representation of the logger described by this class.\"\"\"\n    logger_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"level\": self.level,\n            \"handlers\": self.handlers,\n            \"propagate\": self.propagate,\n        }\n    }\n    return logger_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/__init__/","title":"prefab","text":"<p>Pre-defined logging configs that can be imported and added to a <code>assemble_dictconfig()</code> call.</p>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/__init__/#red_utils.std.logging_utils.config_classes.prefab.get_red_utils_console_handler","title":"<code>get_red_utils_console_handler(name='red_utils_console', level='DEBUG', formatter='red_utils', filters=None)</code>","text":"<p>Return an initialized StreamHandlerConfig for the red_utils library.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the handler, which you will reference in a logger config.</p> <code>'red_utils_console'</code> <code>level</code> <code>str</code> <p>The log level for the handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'DEBUG'</code> <code>formatter</code> <code>str</code> <p>The name of the formatter to use. This formatter must exist in the logging dictConfig, and can be generated with a FormatterConfig.</p> <code>'red_utils'</code> <code>filters</code> <code>list[str] | None</code> <p>Optional list of filter function names to apply to the handler.</p> <code>None</code> <p>Returns:</p> Type Description <code>StreamHandlerConfig</code> <p>An initialized StreamHandlerConfig class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\prefab\\third_party\\red_utils_logging\\_configs.py</code> <pre><code>def get_red_utils_console_handler(\n    name: str = \"red_utils_console\",\n    level: str = \"DEBUG\",\n    formatter: str = \"red_utils\",\n    filters: list[str] | None = None,\n) -&gt; StreamHandlerConfig:\n    \"\"\"Return an initialized StreamHandlerConfig for the red_utils library.\n\n    Params:\n        name (str): The name of the handler, which you will reference in a logger config.\n        level (str): The log level for the handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        formatter (str): The name of the formatter to use. This formatter must exist in the logging dictConfig,\n            and can be generated with a FormatterConfig.\n        filters (list[str]|None): Optional list of filter function names to apply to the handler.\n\n    Returns:\n        (StreamHandlerConfig): An initialized StreamHandlerConfig class.\n\n    \"\"\"\n    try:\n        _handler: StreamHandlerConfig = StreamHandlerConfig(\n            name=name, level=level.upper(), formatter=formatter, filters=filters\n        )\n\n        return _handler\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting red_utils StreamHandlerConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/__init__/#red_utils.std.logging_utils.config_classes.prefab.get_red_utils_formatter","title":"<code>get_red_utils_formatter(name='red_utils', fmt=RED_UTILS_FMT, datefmt=DATE_FMT_STANDARD)</code>","text":"<p>Return a pre-configured FormatterConfig for the red_utils library.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the formatter, which you will reference in a handler config.</p> <code>'red_utils'</code> <code>fmt</code> <code>str</code> <p>The log message format string.</p> <code>RED_UTILS_FMT</code> <code>datefmt</code> <code>str</code> <p>The format for timestamps in log messages.</p> <code>DATE_FMT_STANDARD</code> <p>Returns:</p> Type Description <code>FormatterConfig</code> <p>An initialized FormatterConfig class</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\prefab\\third_party\\red_utils_logging\\_configs.py</code> <pre><code>def get_red_utils_formatter(\n    name: str = \"red_utils\", fmt: str = RED_UTILS_FMT, datefmt: str = DATE_FMT_STANDARD\n) -&gt; FormatterConfig:\n    \"\"\"Return a pre-configured FormatterConfig for the red_utils library.\n\n    Params:\n        name (str): The name of the formatter, which you will reference in a handler config.\n        fmt (str): The log message format string.\n        datefmt (str): The format for timestamps in log messages.\n\n    Returns:\n        (FormatterConfig): An initialized FormatterConfig class\n\n    \"\"\"\n    try:\n        _formatter: FormatterConfig = get_formatter_config(\n            name=name, fmt=fmt, datefmt=datefmt\n        )\n\n        return _formatter\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting red_utils FormatterConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/__init__/#red_utils.std.logging_utils.config_classes.prefab.get_red_utils_logger","title":"<code>get_red_utils_logger(name='red_utils', handlers=['red_utils_console'], level='WARNING', propagate=False)</code>","text":"<p>Return an initialized LoggerConfig for the red_utils library.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the logger, which you will reference in a logging config dict.</p> <code>'red_utils'</code> <code>handlers</code> <code>list[str]</code> <p>A list of handler names for the logger. These loggers must exist in the dictConfig.</p> <code>['red_utils_console']</code> <code>level</code> <code>str</code> <p>The log level for the handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'WARNING'</code> <code>propagate</code> <code>bool</code> <p>If <code>False</code>, logs from this logger will not be propagated down/up to the root logger.</p> <code>False</code> <p>Returns:</p> Type Description <code>LoggerConfig</code> <p>An initialized LoggerConfig class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\prefab\\third_party\\red_utils_logging\\_configs.py</code> <pre><code>def get_red_utils_logger(\n    name: str = \"red_utils\",\n    handlers: list[str] = [\"red_utils_console\"],\n    level: str = \"WARNING\",\n    propagate: bool = False,\n) -&gt; LoggerConfig:\n    \"\"\"Return an initialized LoggerConfig for the red_utils library.\n\n    Params:\n        name (str): The name of the logger, which you will reference in a logging config dict.\n        handlers (list[str]): A list of handler names for the logger. These loggers must exist in the dictConfig.\n        level (str): The log level for the handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        propagate (bool): If `False`, logs from this logger will not be propagated down/up to the root logger.\n\n    Returns:\n        (LoggerConfig): An initialized LoggerConfig class.\n\n    \"\"\"\n    try:\n        _logger: LoggerConfig = get_logger_config(\n            name=name, handlers=handlers, level=level.upper(), propagate=propagate\n        )\n\n        return _logger\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting red_utils LoggerConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/__init__/","title":"third_party","text":"<p>Define formatters, handlers, and loggers for third-party dependencies.</p>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/__init__/#red_utils.std.logging_utils.config_classes.prefab.third_party.get_red_utils_console_handler","title":"<code>get_red_utils_console_handler(name='red_utils_console', level='DEBUG', formatter='red_utils', filters=None)</code>","text":"<p>Return an initialized StreamHandlerConfig for the red_utils library.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the handler, which you will reference in a logger config.</p> <code>'red_utils_console'</code> <code>level</code> <code>str</code> <p>The log level for the handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'DEBUG'</code> <code>formatter</code> <code>str</code> <p>The name of the formatter to use. This formatter must exist in the logging dictConfig, and can be generated with a FormatterConfig.</p> <code>'red_utils'</code> <code>filters</code> <code>list[str] | None</code> <p>Optional list of filter function names to apply to the handler.</p> <code>None</code> <p>Returns:</p> Type Description <code>StreamHandlerConfig</code> <p>An initialized StreamHandlerConfig class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\prefab\\third_party\\red_utils_logging\\_configs.py</code> <pre><code>def get_red_utils_console_handler(\n    name: str = \"red_utils_console\",\n    level: str = \"DEBUG\",\n    formatter: str = \"red_utils\",\n    filters: list[str] | None = None,\n) -&gt; StreamHandlerConfig:\n    \"\"\"Return an initialized StreamHandlerConfig for the red_utils library.\n\n    Params:\n        name (str): The name of the handler, which you will reference in a logger config.\n        level (str): The log level for the handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        formatter (str): The name of the formatter to use. This formatter must exist in the logging dictConfig,\n            and can be generated with a FormatterConfig.\n        filters (list[str]|None): Optional list of filter function names to apply to the handler.\n\n    Returns:\n        (StreamHandlerConfig): An initialized StreamHandlerConfig class.\n\n    \"\"\"\n    try:\n        _handler: StreamHandlerConfig = StreamHandlerConfig(\n            name=name, level=level.upper(), formatter=formatter, filters=filters\n        )\n\n        return _handler\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting red_utils StreamHandlerConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/__init__/#red_utils.std.logging_utils.config_classes.prefab.third_party.get_red_utils_formatter","title":"<code>get_red_utils_formatter(name='red_utils', fmt=RED_UTILS_FMT, datefmt=DATE_FMT_STANDARD)</code>","text":"<p>Return a pre-configured FormatterConfig for the red_utils library.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the formatter, which you will reference in a handler config.</p> <code>'red_utils'</code> <code>fmt</code> <code>str</code> <p>The log message format string.</p> <code>RED_UTILS_FMT</code> <code>datefmt</code> <code>str</code> <p>The format for timestamps in log messages.</p> <code>DATE_FMT_STANDARD</code> <p>Returns:</p> Type Description <code>FormatterConfig</code> <p>An initialized FormatterConfig class</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\prefab\\third_party\\red_utils_logging\\_configs.py</code> <pre><code>def get_red_utils_formatter(\n    name: str = \"red_utils\", fmt: str = RED_UTILS_FMT, datefmt: str = DATE_FMT_STANDARD\n) -&gt; FormatterConfig:\n    \"\"\"Return a pre-configured FormatterConfig for the red_utils library.\n\n    Params:\n        name (str): The name of the formatter, which you will reference in a handler config.\n        fmt (str): The log message format string.\n        datefmt (str): The format for timestamps in log messages.\n\n    Returns:\n        (FormatterConfig): An initialized FormatterConfig class\n\n    \"\"\"\n    try:\n        _formatter: FormatterConfig = get_formatter_config(\n            name=name, fmt=fmt, datefmt=datefmt\n        )\n\n        return _formatter\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting red_utils FormatterConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/__init__/#red_utils.std.logging_utils.config_classes.prefab.third_party.get_red_utils_logger","title":"<code>get_red_utils_logger(name='red_utils', handlers=['red_utils_console'], level='WARNING', propagate=False)</code>","text":"<p>Return an initialized LoggerConfig for the red_utils library.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the logger, which you will reference in a logging config dict.</p> <code>'red_utils'</code> <code>handlers</code> <code>list[str]</code> <p>A list of handler names for the logger. These loggers must exist in the dictConfig.</p> <code>['red_utils_console']</code> <code>level</code> <code>str</code> <p>The log level for the handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'WARNING'</code> <code>propagate</code> <code>bool</code> <p>If <code>False</code>, logs from this logger will not be propagated down/up to the root logger.</p> <code>False</code> <p>Returns:</p> Type Description <code>LoggerConfig</code> <p>An initialized LoggerConfig class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\prefab\\third_party\\red_utils_logging\\_configs.py</code> <pre><code>def get_red_utils_logger(\n    name: str = \"red_utils\",\n    handlers: list[str] = [\"red_utils_console\"],\n    level: str = \"WARNING\",\n    propagate: bool = False,\n) -&gt; LoggerConfig:\n    \"\"\"Return an initialized LoggerConfig for the red_utils library.\n\n    Params:\n        name (str): The name of the logger, which you will reference in a logging config dict.\n        handlers (list[str]): A list of handler names for the logger. These loggers must exist in the dictConfig.\n        level (str): The log level for the handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        propagate (bool): If `False`, logs from this logger will not be propagated down/up to the root logger.\n\n    Returns:\n        (LoggerConfig): An initialized LoggerConfig class.\n\n    \"\"\"\n    try:\n        _logger: LoggerConfig = get_logger_config(\n            name=name, handlers=handlers, level=level.upper(), propagate=propagate\n        )\n\n        return _logger\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting red_utils LoggerConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/__init__/","title":"red_utils_logging","text":"<p>Functions to retrieve pre-defined formatters, handlers, and loggers for the <code>red_utils</code> library.</p>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/__init__/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging.get_red_utils_console_handler","title":"<code>get_red_utils_console_handler(name='red_utils_console', level='DEBUG', formatter='red_utils', filters=None)</code>","text":"<p>Return an initialized StreamHandlerConfig for the red_utils library.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the handler, which you will reference in a logger config.</p> <code>'red_utils_console'</code> <code>level</code> <code>str</code> <p>The log level for the handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'DEBUG'</code> <code>formatter</code> <code>str</code> <p>The name of the formatter to use. This formatter must exist in the logging dictConfig, and can be generated with a FormatterConfig.</p> <code>'red_utils'</code> <code>filters</code> <code>list[str] | None</code> <p>Optional list of filter function names to apply to the handler.</p> <code>None</code> <p>Returns:</p> Type Description <code>StreamHandlerConfig</code> <p>An initialized StreamHandlerConfig class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\prefab\\third_party\\red_utils_logging\\_configs.py</code> <pre><code>def get_red_utils_console_handler(\n    name: str = \"red_utils_console\",\n    level: str = \"DEBUG\",\n    formatter: str = \"red_utils\",\n    filters: list[str] | None = None,\n) -&gt; StreamHandlerConfig:\n    \"\"\"Return an initialized StreamHandlerConfig for the red_utils library.\n\n    Params:\n        name (str): The name of the handler, which you will reference in a logger config.\n        level (str): The log level for the handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        formatter (str): The name of the formatter to use. This formatter must exist in the logging dictConfig,\n            and can be generated with a FormatterConfig.\n        filters (list[str]|None): Optional list of filter function names to apply to the handler.\n\n    Returns:\n        (StreamHandlerConfig): An initialized StreamHandlerConfig class.\n\n    \"\"\"\n    try:\n        _handler: StreamHandlerConfig = StreamHandlerConfig(\n            name=name, level=level.upper(), formatter=formatter, filters=filters\n        )\n\n        return _handler\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting red_utils StreamHandlerConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/__init__/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging.get_red_utils_formatter","title":"<code>get_red_utils_formatter(name='red_utils', fmt=RED_UTILS_FMT, datefmt=DATE_FMT_STANDARD)</code>","text":"<p>Return a pre-configured FormatterConfig for the red_utils library.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the formatter, which you will reference in a handler config.</p> <code>'red_utils'</code> <code>fmt</code> <code>str</code> <p>The log message format string.</p> <code>RED_UTILS_FMT</code> <code>datefmt</code> <code>str</code> <p>The format for timestamps in log messages.</p> <code>DATE_FMT_STANDARD</code> <p>Returns:</p> Type Description <code>FormatterConfig</code> <p>An initialized FormatterConfig class</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\prefab\\third_party\\red_utils_logging\\_configs.py</code> <pre><code>def get_red_utils_formatter(\n    name: str = \"red_utils\", fmt: str = RED_UTILS_FMT, datefmt: str = DATE_FMT_STANDARD\n) -&gt; FormatterConfig:\n    \"\"\"Return a pre-configured FormatterConfig for the red_utils library.\n\n    Params:\n        name (str): The name of the formatter, which you will reference in a handler config.\n        fmt (str): The log message format string.\n        datefmt (str): The format for timestamps in log messages.\n\n    Returns:\n        (FormatterConfig): An initialized FormatterConfig class\n\n    \"\"\"\n    try:\n        _formatter: FormatterConfig = get_formatter_config(\n            name=name, fmt=fmt, datefmt=datefmt\n        )\n\n        return _formatter\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting red_utils FormatterConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/__init__/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging.get_red_utils_logger","title":"<code>get_red_utils_logger(name='red_utils', handlers=['red_utils_console'], level='WARNING', propagate=False)</code>","text":"<p>Return an initialized LoggerConfig for the red_utils library.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the logger, which you will reference in a logging config dict.</p> <code>'red_utils'</code> <code>handlers</code> <code>list[str]</code> <p>A list of handler names for the logger. These loggers must exist in the dictConfig.</p> <code>['red_utils_console']</code> <code>level</code> <code>str</code> <p>The log level for the handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'WARNING'</code> <code>propagate</code> <code>bool</code> <p>If <code>False</code>, logs from this logger will not be propagated down/up to the root logger.</p> <code>False</code> <p>Returns:</p> Type Description <code>LoggerConfig</code> <p>An initialized LoggerConfig class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\prefab\\third_party\\red_utils_logging\\_configs.py</code> <pre><code>def get_red_utils_logger(\n    name: str = \"red_utils\",\n    handlers: list[str] = [\"red_utils_console\"],\n    level: str = \"WARNING\",\n    propagate: bool = False,\n) -&gt; LoggerConfig:\n    \"\"\"Return an initialized LoggerConfig for the red_utils library.\n\n    Params:\n        name (str): The name of the logger, which you will reference in a logging config dict.\n        handlers (list[str]): A list of handler names for the logger. These loggers must exist in the dictConfig.\n        level (str): The log level for the handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        propagate (bool): If `False`, logs from this logger will not be propagated down/up to the root logger.\n\n    Returns:\n        (LoggerConfig): An initialized LoggerConfig class.\n\n    \"\"\"\n    try:\n        _logger: LoggerConfig = get_logger_config(\n            name=name, handlers=handlers, level=level.upper(), propagate=propagate\n        )\n\n        return _logger\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting red_utils LoggerConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/","title":"_configs","text":"<p>The classes and functions in this file define logging for the <code>red_utils</code> library.</p> <p>If you want to see messages from <code>red_utils</code> modules in your app, you will need to add a logging config by using the methods in this script.</p>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.FileHandlerConfig","title":"<code>FileHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging FileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file to log messages to.</p> <code>'app.log'</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass FileHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging FileHandler.\n\n    Params:\n        filename (str): The name of the file to log messages to.\n    \"\"\"\n\n    filename: str | None = field(default=\"app.log\")\n\n    def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, str]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"filename\": self.filename,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.FileHandler`.\n\n        \"\"\"\n        return \"logging.FileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.FileHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, str]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"filename\": self.filename,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.FileHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.FileHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.FileHandler`.\n\n    \"\"\"\n    return \"logging.FileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.FormatterConfig","title":"<code>FormatterConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseLoggingConfig</code></p> <p>Define a logging formatter.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the formatter.</p> <code>None</code> <code>fmt</code> <code>str</code> <p>The string formatting to use for log messages.</p> <code>MESSAGE_FMT_STANDARD</code> <code>datefmt</code> <code>str</code> <p>The string formatting to use for log message timestamps.</p> <code>DATE_FMT_STANDARD</code> <code>style</code> <code>str</code> <p>The string substitution style to use for log formats. Default is <code>%</code>, which means formats need to be written like <code>%(asctime)s %(levelname)s %(message)s</code>. If you change this style, make sure the <code>fmt</code> you pass uses the correct formatting style.</p> <code>'%'</code> <code>validate</code> <code>bool</code> <p>When <code>True</code>, the configuration dict this formatter returns will be validated by the logging module.</p> <code>True</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\formatters\\_formatters.py</code> <pre><code>@dataclass\nclass FormatterConfig(BaseLoggingConfig):\n    \"\"\"Define a logging formatter.\n\n    Params:\n        name (str): The name of the formatter.\n        fmt (str): The string formatting to use for log messages.\n        datefmt (str): The string formatting to use for log message timestamps.\n        style (str): The string substitution style to use for log formats. Default is `%`, which\n            means formats need to be written like `%(asctime)s %(levelname)s %(message)s`. If\n            you change this style, make sure the `fmt` you pass uses the correct formatting style.\n        validate (bool): When `True`, the configuration dict this formatter returns will be validated by the logging module.\n\n    \"\"\"\n\n    name: str = None\n    fmt: str = MESSAGE_FMT_STANDARD\n    datefmt: str = DATE_FMT_STANDARD\n    style: str = \"%\"\n    validate: bool = True\n\n    def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Return a dict representation of the formatter described by this class.\"\"\"\n        formatter_dict: dict[str, dict[str, str]] = {self.name: {\"format\": self.fmt}}\n        if self.datefmt:\n            formatter_dict[self.name][\"datefmt\"] = self.datefmt\n        if self.style:\n            formatter_dict[self.name][\"style\"] = self.style\n        formatter_dict[self.name][\"validate\"] = self.validate\n\n        return formatter_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.FormatterConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the formatter described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\formatters\\_formatters.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Return a dict representation of the formatter described by this class.\"\"\"\n    formatter_dict: dict[str, dict[str, str]] = {self.name: {\"format\": self.fmt}}\n    if self.datefmt:\n        formatter_dict[self.name][\"datefmt\"] = self.datefmt\n    if self.style:\n        formatter_dict[self.name][\"style\"] = self.style\n    formatter_dict[self.name][\"validate\"] = self.validate\n\n    return formatter_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.LoggerConfig","title":"<code>LoggerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseLoggingConfig</code></p> <p>Define a logging Logger.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the logger.</p> required <code>level</code> <code>str</code> <p>The level of log messages this logger should show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> required <code>handlers</code> <code>list[str]</code> <p>List of handler names this logger should use. These handlers must exist in the logging dictConfig.</p> required <code>propagate</code> <code>bool</code> <p>If <code>True</code>, messages will be propagated up/down to the root logger.</p> <code>False</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_loggers.py</code> <pre><code>@dataclass\nclass LoggerConfig(BaseLoggingConfig):\n    \"\"\"Define a logging Logger.\n\n    Params:\n        name (str): The name of the logger.\n        level (str): The level of log messages this logger should show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        handlers (list[str]): List of handler names this logger should use. These handlers must exist in the logging dictConfig.\n        propagate (bool): If `True`, messages will be propagated up/down to the root logger.\n    \"\"\"\n\n    name: str\n    level: str\n    handlers: list[str]\n    propagate: bool = False\n\n    def get_configdict(self) -&gt; dict:\n        \"\"\"Return a dict representation of the logger described by this class.\"\"\"\n        logger_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"level\": self.level,\n                \"handlers\": self.handlers,\n                \"propagate\": self.propagate,\n            }\n        }\n        return logger_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.LoggerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the logger described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_loggers.py</code> <pre><code>def get_configdict(self) -&gt; dict:\n    \"\"\"Return a dict representation of the logger described by this class.\"\"\"\n    logger_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"level\": self.level,\n            \"handlers\": self.handlers,\n            \"propagate\": self.propagate,\n        }\n    }\n    return logger_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.LoggerFactory","title":"<code>LoggerFactory</code>","text":"<p>Generate loggers based on LoggerFactory's config.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_factory.py</code> <pre><code>class LoggerFactory:\n    \"\"\"Generate loggers based on LoggerFactory's config.\"\"\"\n\n    _LOG: logging.Logger | None = None\n\n    @staticmethod\n    def __create_logger(\n        name: str,\n        log_level: str,\n        handlers: dict[str, dict],\n        formatters: dict[str, dict],\n        loggers: dict[str, dict],\n    ) -&gt; logging.Logger:\n        \"\"\"Create a logger cnofig from inputs.\n\n        Params:\n            name (str): The name of the logger.\n            log_level (str): The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n            handlers (dict[str, dict[str, Any]]): A dict describing the handlers for this logger config.\n            formatters (dict[str, dict[str, Any]]): A dict describing the formatters for this logger config.\n            loggers (dict[str, dict[str, Any]]): A dict describing the loggers for this logger config.\n        \"\"\"\n        log_level = log_level.upper()\n\n        # Configure logging using dictConfig\n        logging_config = {\n            \"version\": 1,\n            \"handlers\": handlers,\n            \"formatters\": formatters,\n            \"loggers\": loggers,\n            \"root\": {\n                \"level\": log_level,\n                \"handlers\": list(handlers.keys()),\n            },\n        }\n\n        try:\n            logging.config.dictConfig(logging_config)\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception configuring logger. Details: {exc}\")\n            # log.error(msg)\n\n            raise msg\n\n        # Get or create logger\n        LoggerFactory._LOG = logging.getLogger(name)\n\n        return LoggerFactory._LOG\n\n    @staticmethod\n    def get_logger(\n        name: str,\n        log_level: str,\n        handlers: dict[str, dict],\n        formatters: dict[str, dict],\n        loggers: dict[str, dict],\n    ) -&gt; logging.Logger:\n        \"\"\"Initialize a logger.\n\n        Params:\n            name (str): The name of the logger.\n            log_level (str): The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n            handlers (dict[str, dict[str, Any]]): A dict describing the handlers for this logger config.\n            formatters (dict[str, dict[str, Any]]): A dict describing the formatters for this logger config.\n            loggers (dict[str, dict[str, Any]]): A dict describing the loggers for this logger config.\n        \"\"\"\n        logger = LoggerFactory.__create_logger(\n            name=name,\n            log_level=log_level,\n            handlers=handlers,\n            formatters=formatters,\n            loggers=loggers,\n        )\n\n        return logger\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.LoggerFactory.get_logger","title":"<code>get_logger(name, log_level, handlers, formatters, loggers)</code>  <code>staticmethod</code>","text":"<p>Initialize a logger.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the logger.</p> required <code>log_level</code> <code>str</code> <p>The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> required <code>handlers</code> <code>dict[str, dict[str, Any]]</code> <p>A dict describing the handlers for this logger config.</p> required <code>formatters</code> <code>dict[str, dict[str, Any]]</code> <p>A dict describing the formatters for this logger config.</p> required <code>loggers</code> <code>dict[str, dict[str, Any]]</code> <p>A dict describing the loggers for this logger config.</p> required Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_factory.py</code> <pre><code>@staticmethod\ndef get_logger(\n    name: str,\n    log_level: str,\n    handlers: dict[str, dict],\n    formatters: dict[str, dict],\n    loggers: dict[str, dict],\n) -&gt; logging.Logger:\n    \"\"\"Initialize a logger.\n\n    Params:\n        name (str): The name of the logger.\n        log_level (str): The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        handlers (dict[str, dict[str, Any]]): A dict describing the handlers for this logger config.\n        formatters (dict[str, dict[str, Any]]): A dict describing the formatters for this logger config.\n        loggers (dict[str, dict[str, Any]]): A dict describing the loggers for this logger config.\n    \"\"\"\n    logger = LoggerFactory.__create_logger(\n        name=name,\n        log_level=log_level,\n        handlers=handlers,\n        formatters=formatters,\n        loggers=loggers,\n    )\n\n    return logger\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.QueueHandlerConfig","title":"<code>QueueHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging QueueHandler.</p> <p>Parameters:</p> Name Type Description Default <code>queue</code> <code>Queue</code> <p>The queue to send log messages to.</p> <code>None</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass QueueHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging QueueHandler.\n\n    Params:\n        queue (queue.Queue): The queue to send log messages to.\n    \"\"\"\n\n    queue: Queue = field(default=None)\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"queue\": self.queue,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.QueueHandler`.\n\n        \"\"\"\n        return \"logging.handlers.QueueHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.QueueHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"queue\": self.queue,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.QueueHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.QueueHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.QueueHandler`.\n\n    \"\"\"\n    return \"logging.handlers.QueueHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.QueueListenerConfig","title":"<code>QueueListenerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseLoggingConfig</code></p> <p>Define a logging QueueListener.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the handler.</p> required <code>queue</code> <code>Queue</code> <p>The queue to listen for log messages in.</p> required <code>handlers</code> <code>list[str]</code> <p>List of handler names to apply to this listener.</p> required Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass QueueListenerConfig(BaseLoggingConfig):\n    \"\"\"Define a logging QueueListener.\n\n    Params:\n        name (str): The name of the handler.\n        queue (queue.Queue): The queue to listen for log messages in.\n        handlers (list[str]): List of handler names to apply to this listener.\n\n    \"\"\"\n\n    name: str\n    queue: Queue\n    handlers: list\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        listener_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"queue\": self.queue,\n                \"handlers\": self.handlers,\n            }\n        }\n        return listener_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.QueueListener`.\n\n        \"\"\"\n        return \"logging.handleres.QueueListener\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.QueueListenerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    listener_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"queue\": self.queue,\n            \"handlers\": self.handlers,\n        }\n    }\n    return listener_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.QueueListenerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.QueueListener</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.QueueListener`.\n\n    \"\"\"\n    return \"logging.handleres.QueueListener\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.RotatingFileHandlerConfig","title":"<code>RotatingFileHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging RotatingFileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | None</code> <p>The name/path of the file to log messages to.</p> <code>'app.log'</code> <code>maxBytes</code> <code>int</code> <p>The maximum size of the file (in bytes) before a new file is rotated.</p> <code>0</code> <code>backupCount</code> <code>int</code> <p>Number of rotated log files to keep.</p> <code>0</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass RotatingFileHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging RotatingFileHandler.\n\n    Params:\n        filename (str | None): The name/path of the file to log messages to.\n        maxBytes (int): The maximum size of the file (in bytes) before a new file is rotated.\n        backupCount (int): Number of rotated log files to keep.\n\n    \"\"\"\n\n    filename: str | None = field(default=\"app.log\")\n    maxBytes: int = 0\n    backupCount: int = 0\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"filename\": f\"{self.filename}\",\n                \"maxBytes\": self.maxBytes,\n                \"backupCount\": self.backupCount,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.RotatingFileHandler`.\n\n        \"\"\"\n        return \"logging.handlers.RotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.RotatingFileHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"filename\": f\"{self.filename}\",\n            \"maxBytes\": self.maxBytes,\n            \"backupCount\": self.backupCount,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.RotatingFileHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.RotatingFileHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.RotatingFileHandler`.\n\n    \"\"\"\n    return \"logging.handlers.RotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.SMTPHandlerConfig","title":"<code>SMTPHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging SMTPHandler.</p> <p>Parameters:</p> Name Type Description Default <code>mailhost</code> <code>Any</code> <p>...</p> <code>None</code> <code>fromaddr</code> <code>str</code> <p>...</p> <code>'from@example.com'</code> <code>toaddrs</code> <code>list</code> <p>...</p> <code>lambda: []()</code> <code>subject</code> <code>str</code> <p>...</p> <code>'SMTPHandler Log Event'</code> <code>credentials</code> <code>tuple</code> <p>...</p> <code>None</code> <code>secure</code> <code>tuple</code> <p>...</p> <code>None</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass SMTPHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging SMTPHandler.\n\n    Params:\n        mailhost (Any): ...\n        fromaddr (str): ...\n        toaddrs (list): ...\n        subject (str): ...\n        credentials (tuple): ...\n        secure (tuple): ...\n    \"\"\"\n\n    mailhost: t.Any = None\n    fromaddr: str = \"from@example.com\"\n    toaddrs: list = field(default_factory=lambda: [])\n    subject: str = \"SMTPHandler Log Event\"\n    credentials: tuple | None = None\n    secure: tuple | None = None\n\n    def get_configdict(self):\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"mailhost\": self.mailhost,\n                \"fromaddr\": self.fromaddr,\n                \"toaddrs\": self.toaddrs,\n                \"subject\": self.subject,\n            }\n        }\n        if self.credentials:\n            handler_dict[self.name][\"credentials\"] = self.credentials\n        if self.secure:\n            handler_dict[self.name][\"secure\"] = self.secure\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.SMTPHandler`.\n\n        \"\"\"\n        return \"logging.handlers.SMTPHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.SMTPHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self):\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"mailhost\": self.mailhost,\n            \"fromaddr\": self.fromaddr,\n            \"toaddrs\": self.toaddrs,\n            \"subject\": self.subject,\n        }\n    }\n    if self.credentials:\n        handler_dict[self.name][\"credentials\"] = self.credentials\n    if self.secure:\n        handler_dict[self.name][\"secure\"] = self.secure\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.SMTPHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.SMTPHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.SMTPHandler`.\n\n    \"\"\"\n    return \"logging.handlers.SMTPHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.SocketHandlerConfig","title":"<code>SocketHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging SocketHandler.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Host IP/FQDN.</p> <code>'localhost'</code> <code>port</code> <code>int</code> <p>Host port where log messages should be sent.</p> <code>0</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass SocketHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging SocketHandler.\n\n    Params:\n        host (str): Host IP/FQDN.\n        port (int): Host port where log messages should be sent.\n    \"\"\"\n\n    host: str = \"localhost\"\n    port: int = 0\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"host\": self.host,\n                \"port\": self.port,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.SocketHandler`.\n\n        \"\"\"\n        return \"logging.handlers.SocketHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.SocketHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"host\": self.host,\n            \"port\": self.port,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.SocketHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.SocketHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.SocketHandler`.\n\n    \"\"\"\n    return \"logging.handlers.SocketHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.StreamHandlerConfig","title":"<code>StreamHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging StreamHandler.</p> <p>Parameters:</p> Name Type Description Default <code>stream</code> <code>Any</code> <p>The stream this handler controls, i.e. <code>ext://sys.stdout</code>, <code>ext://sys.stderr</code>, etc.</p> <code>'ext://sys.stdout'</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass StreamHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging StreamHandler.\n\n    Params:\n        stream (Any): The stream this handler controls, i.e. `ext://sys.stdout`, `ext://sys.stderr`, etc.\n    \"\"\"\n\n    stream: t.Any | None = \"ext://sys.stdout\"\n\n    def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, str]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"stream\": self.stream,\n            }\n        }\n        if self.filters:\n            handler_dict[\"filters\"] = self.filters\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.StreamHandler`.\n\n        \"\"\"\n        return \"logging.StreamHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.StreamHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, str]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"stream\": self.stream,\n        }\n    }\n    if self.filters:\n        handler_dict[\"filters\"] = self.filters\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.StreamHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.StreamHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.StreamHandler`.\n\n    \"\"\"\n    return \"logging.StreamHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.TimedRotatingFileHandlerConfig","title":"<code>TimedRotatingFileHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging TimedRotatingFileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name/path of the file to log messages to.</p> <code>'app.log'</code> <code>when</code> <code>str</code> <p>Time of day to rotate log files, i.e. <code>midnight</code>.</p> <code>'midnight'</code> <code>interval</code> <code>int</code> <p>When to rotate the file as the interval defined in <code>when</code> occurs. <code>1=every occurrence</code>, <code>2=every other occurrence</code>, etc.</p> <code>1</code> <code>backupCount</code> <code>int</code> <p>The number of rotated log files to save.</p> <code>0</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass TimedRotatingFileHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging TimedRotatingFileHandler.\n\n    Params:\n        filename (str): The name/path of the file to log messages to.\n        when (str): Time of day to rotate log files, i.e. `midnight`.\n        interval (int): When to rotate the file as the interval defined in `when` occurs.\n            `1=every occurrence`, `2=every other occurrence`, etc.\n        backupCount (int): The number of rotated log files to save.\n    \"\"\"\n\n    filename: str | None = field(default=\"app.log\")\n    when: str | None = field(default=\"midnight\")\n    interval: int = 1\n    backupCount: int = 0\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"filename\": self.filename,\n                \"when\": self.when,\n                \"interval\": self.interval,\n                \"backupCount\": self.backupCount,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.TimedRotatingFileHandler`.\n\n        \"\"\"\n        return \"logging.handlers.TimedRotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.TimedRotatingFileHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"filename\": self.filename,\n            \"when\": self.when,\n            \"interval\": self.interval,\n            \"backupCount\": self.backupCount,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.TimedRotatingFileHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.TimedRotatingFileHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.TimedRotatingFileHandler`.\n\n    \"\"\"\n    return \"logging.handlers.TimedRotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.get_formatter_config","title":"<code>get_formatter_config(name='default', fmt=MESSAGE_FMT_STANDARD, datefmt=DATE_FMT_STANDARD, style='%', validate=True, as_dict=False)</code>","text":"<p>Return a FormatterConfig, or a dict representing a Formatter.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name for the formatter. Reference this formatter by name in a LoggerConfig.</p> <code>'default'</code> <code>fmt</code> <code>str</code> <p>The string format for log messages. Python docs: Log Record Attributes</p> <code>MESSAGE_FMT_STANDARD</code> <code>datefmt</code> <code>str</code> <p>The format for log message timestamps, if <code>%(asctime)s</code> is used in the logging <code>fmt</code>.</p> <code>DATE_FMT_STANDARD</code> <code>style</code> <code>str</code> <p>The style of string substitution to use for the formatter. Options include <code>%</code> for <code>'%', some_var</code>, <code>{</code> for <code>'{some_var}</code>, etc.</p> <code>'%'</code> <code>validate</code> <code>bool</code> <p>If <code>True</code>, the handler will be validated by the logging module before fully initializing.</p> <code>True</code> <code>as_dict</code> <code>bool</code> <p>If <code>True</code>, return the configuration as a dict that can be joined into <code>dictConfig()</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>If <code>as_dict=True</code>, return a config dict instead of a FormatterConfig object.</p> <code>FormatterConfig</code> <p>If <code>as_dict=False</code>, return a FormatterConfig object.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def get_formatter_config(\n    name: str = \"default\",\n    fmt: str = MESSAGE_FMT_STANDARD,\n    datefmt: str = DATE_FMT_STANDARD,\n    style: str = \"%\",\n    validate: bool = True,\n    as_dict: bool = False,\n) -&gt; dict[str, dict[str, str]] | FormatterConfig:\n    \"\"\"Return a FormatterConfig, or a dict representing a Formatter.\n\n    Params:\n        name (str): The name for the formatter. Reference this formatter by name in a LoggerConfig.\n        fmt (str): The string format for log messages.\n            [Python docs: Log Record Attributes](https://docs.python.org/3/library/logging.html#logrecord-attributes)\n        datefmt (str): The format for log message timestamps, if `%(asctime)s` is used in the logging `fmt`.\n        style (str): The style of string substitution to use for the formatter. Options include `%` for `'%', some_var`,\n            `{` for `'{some_var}`, etc.\n        validate (bool): If `True`, the handler will be validated by the logging module before fully initializing.\n        as_dict (bool): If `True`, return the configuration as a dict that can be joined into `dictConfig()`.\n\n    Returns:\n        (dict[str, dict[str, Any]]): If `as_dict=True`, return a config dict instead of a FormatterConfig object.\n        (FormatterConfig): If `as_dict=False`, return a FormatterConfig object.\n\n    \"\"\"\n    try:\n        ## Initialize formatter object\n        _formatter: FormatterConfig = FormatterConfig(\n            name=name, fmt=fmt, datefmt=datefmt, style=style, validate=validate\n        )\n\n        if as_dict:\n            ## Return formatter representation as a dict\n            return _formatter.get_configdict()\n        else:\n            ## Return FormatterConfig object\n            return _formatter\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception building FormatterConfig. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.get_logger_config","title":"<code>get_logger_config(name='app', handlers=['console'], level='DEBUG', propagate=False, as_dict=False)</code>","text":"<p>Return a LoggerConfig, or a dict representing a Logger.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name for the logger. Reference this logger by name in a LoggerConfig.</p> <code>'app'</code> <code>level</code> <code>str</code> <p>The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'DEBUG'</code> <code>handlers</code> <code>list[str]</code> <p>List of handler names that exist in the logging configDict that this logger should use.</p> <code>['console']</code> <code>propagate</code> <code>bool</code> <p>If <code>True</code>, log messages will be propagated up/down to the root logger.</p> <code>False</code> <code>as_dict</code> <code>bool</code> <p>If <code>True</code>, return the configuration as a dict that can be joined into <code>dictConfig()</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>If <code>as_dict=True</code>, return a config dict instead of a RotatingFileHandlerConfig object.</p> <code>RotatingFileHandlerConfig</code> <p>If <code>as_dict=False</code>, return a RotatingFileHandlerConfig object.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def get_logger_config(\n    name: str = \"app\",\n    handlers: list[str] = [\"console\"],\n    level: str = \"DEBUG\",\n    propagate: bool = False,\n    as_dict: bool = False,\n) -&gt; dict[str, dict[str, str]] | LoggerConfig:\n    \"\"\"Return a LoggerConfig, or a dict representing a Logger.\n\n    Params:\n        name (str): The name for the logger. Reference this logger by name in a LoggerConfig.\n        level (str): The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        handlers (list[str]): List of handler names that exist in the logging configDict that this logger should use.\n        propagate (bool): If `True`, log messages will be propagated up/down to the root logger.\n        as_dict (bool): If `True`, return the configuration as a dict that can be joined into `dictConfig()`.\n\n    Returns:\n        (dict[str, dict[str, Any]]): If `as_dict=True`, return a config dict instead of a RotatingFileHandlerConfig object.\n        (RotatingFileHandlerConfig): If `as_dict=False`, return a RotatingFileHandlerConfig object.\n\n    \"\"\"\n    try:\n        ## Initialize logger object\n        _logger: LoggerConfig = LoggerConfig(\n            name=name, level=level.upper(), handlers=handlers, propagate=propagate\n        )\n\n        if as_dict:\n            ## Return logger representation as a dict\n            return _logger.get_configdict()\n        else:\n            ## Return LoggerConfig object\n            return _logger\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception initializing logger. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.get_red_utils_console_handler","title":"<code>get_red_utils_console_handler(name='red_utils_console', level='DEBUG', formatter='red_utils', filters=None)</code>","text":"<p>Return an initialized StreamHandlerConfig for the red_utils library.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the handler, which you will reference in a logger config.</p> <code>'red_utils_console'</code> <code>level</code> <code>str</code> <p>The log level for the handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'DEBUG'</code> <code>formatter</code> <code>str</code> <p>The name of the formatter to use. This formatter must exist in the logging dictConfig, and can be generated with a FormatterConfig.</p> <code>'red_utils'</code> <code>filters</code> <code>list[str] | None</code> <p>Optional list of filter function names to apply to the handler.</p> <code>None</code> <p>Returns:</p> Type Description <code>StreamHandlerConfig</code> <p>An initialized StreamHandlerConfig class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\prefab\\third_party\\red_utils_logging\\_configs.py</code> <pre><code>def get_red_utils_console_handler(\n    name: str = \"red_utils_console\",\n    level: str = \"DEBUG\",\n    formatter: str = \"red_utils\",\n    filters: list[str] | None = None,\n) -&gt; StreamHandlerConfig:\n    \"\"\"Return an initialized StreamHandlerConfig for the red_utils library.\n\n    Params:\n        name (str): The name of the handler, which you will reference in a logger config.\n        level (str): The log level for the handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        formatter (str): The name of the formatter to use. This formatter must exist in the logging dictConfig,\n            and can be generated with a FormatterConfig.\n        filters (list[str]|None): Optional list of filter function names to apply to the handler.\n\n    Returns:\n        (StreamHandlerConfig): An initialized StreamHandlerConfig class.\n\n    \"\"\"\n    try:\n        _handler: StreamHandlerConfig = StreamHandlerConfig(\n            name=name, level=level.upper(), formatter=formatter, filters=filters\n        )\n\n        return _handler\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting red_utils StreamHandlerConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.get_red_utils_formatter","title":"<code>get_red_utils_formatter(name='red_utils', fmt=RED_UTILS_FMT, datefmt=DATE_FMT_STANDARD)</code>","text":"<p>Return a pre-configured FormatterConfig for the red_utils library.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the formatter, which you will reference in a handler config.</p> <code>'red_utils'</code> <code>fmt</code> <code>str</code> <p>The log message format string.</p> <code>RED_UTILS_FMT</code> <code>datefmt</code> <code>str</code> <p>The format for timestamps in log messages.</p> <code>DATE_FMT_STANDARD</code> <p>Returns:</p> Type Description <code>FormatterConfig</code> <p>An initialized FormatterConfig class</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\prefab\\third_party\\red_utils_logging\\_configs.py</code> <pre><code>def get_red_utils_formatter(\n    name: str = \"red_utils\", fmt: str = RED_UTILS_FMT, datefmt: str = DATE_FMT_STANDARD\n) -&gt; FormatterConfig:\n    \"\"\"Return a pre-configured FormatterConfig for the red_utils library.\n\n    Params:\n        name (str): The name of the formatter, which you will reference in a handler config.\n        fmt (str): The log message format string.\n        datefmt (str): The format for timestamps in log messages.\n\n    Returns:\n        (FormatterConfig): An initialized FormatterConfig class\n\n    \"\"\"\n    try:\n        _formatter: FormatterConfig = get_formatter_config(\n            name=name, fmt=fmt, datefmt=datefmt\n        )\n\n        return _formatter\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting red_utils FormatterConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.get_red_utils_logger","title":"<code>get_red_utils_logger(name='red_utils', handlers=['red_utils_console'], level='WARNING', propagate=False)</code>","text":"<p>Return an initialized LoggerConfig for the red_utils library.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the logger, which you will reference in a logging config dict.</p> <code>'red_utils'</code> <code>handlers</code> <code>list[str]</code> <p>A list of handler names for the logger. These loggers must exist in the dictConfig.</p> <code>['red_utils_console']</code> <code>level</code> <code>str</code> <p>The log level for the handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'WARNING'</code> <code>propagate</code> <code>bool</code> <p>If <code>False</code>, logs from this logger will not be propagated down/up to the root logger.</p> <code>False</code> <p>Returns:</p> Type Description <code>LoggerConfig</code> <p>An initialized LoggerConfig class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\prefab\\third_party\\red_utils_logging\\_configs.py</code> <pre><code>def get_red_utils_logger(\n    name: str = \"red_utils\",\n    handlers: list[str] = [\"red_utils_console\"],\n    level: str = \"WARNING\",\n    propagate: bool = False,\n) -&gt; LoggerConfig:\n    \"\"\"Return an initialized LoggerConfig for the red_utils library.\n\n    Params:\n        name (str): The name of the logger, which you will reference in a logging config dict.\n        handlers (list[str]): A list of handler names for the logger. These loggers must exist in the dictConfig.\n        level (str): The log level for the handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        propagate (bool): If `False`, logs from this logger will not be propagated down/up to the root logger.\n\n    Returns:\n        (LoggerConfig): An initialized LoggerConfig class.\n\n    \"\"\"\n    try:\n        _logger: LoggerConfig = get_logger_config(\n            name=name, handlers=handlers, level=level.upper(), propagate=propagate\n        )\n\n        return _logger\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception getting red_utils LoggerConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.get_rotatingfilehandler_config","title":"<code>get_rotatingfilehandler_config(name='rotating_app_file', level='DEBUG', formatter='default', filters=None, filename=None, maxBytes=100000, backupCount=3, as_dict=False)</code>","text":"<p>Return a RotatingFileHandlerConfig, or a dict representing a RotatingFileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name for the rotating file handler. Reference this handler by name in a LoggerConfig.</p> <code>'rotating_app_file'</code> <code>level</code> <code>str</code> <p>The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'DEBUG'</code> <code>formatter</code> <code>str</code> <p>The name of a formatter that exists in the overall logging dictConfig.</p> <code>'default'</code> <code>filters</code> <code>list[str] | None</code> <p>A list of function names for logging filters.</p> <code>None</code> <code>filename</code> <code>str | Path</code> <p>The full path to the log file you want to create. If parent directories do not exist, this method will handle creating them.</p> <code>None</code> <code>maxBytes</code> <code>int</code> <p>The maximum size (in bytes) before a logfile is rotated.</p> <code>100000</code> <code>backupCount</code> <code>int</code> <p>The number of backups to keep as log files rotate.</p> <code>3</code> <code>as_dict</code> <code>bool</code> <p>If <code>True</code>, return the configuration as a dict that can be joined into <code>dictConfig()</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>If <code>as_dict=True</code>, return a config dict instead of a RotatingFileHandlerConfig object.</p> <code>RotatingFileHandlerConfig</code> <p>If <code>as_dict=False</code>, return a RotatingFileHandlerConfig object.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def get_rotatingfilehandler_config(\n    name: str = \"rotating_app_file\",\n    level: str = \"DEBUG\",\n    formatter: str = \"default\",\n    filters: list | None = None,\n    filename: t.Union[str, Path] = None,\n    maxBytes: int = 100000,\n    backupCount: int = 3,\n    as_dict: bool = False,\n) -&gt; dict[str, dict[str, t.Any]] | RotatingFileHandlerConfig:\n    \"\"\"Return a RotatingFileHandlerConfig, or a dict representing a RotatingFileHandler.\n\n    Params:\n        name (str): The name for the rotating file handler. Reference this handler by name in a LoggerConfig.\n        level (str): The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        formatter (str): The name of a formatter that exists in the overall logging dictConfig.\n        filters (list[str] | None): A list of function names for logging filters.\n        filename (str | Path): The full path to the log file you want to create. If parent directories do not exist,\n            this method will handle creating them.\n        maxBytes (int): The maximum size (in bytes) before a logfile is rotated.\n        backupCount (int): The number of backups to keep as log files rotate.\n        as_dict (bool): If `True`, return the configuration as a dict that can be joined into `dictConfig()`.\n\n    Returns:\n        (dict[str, dict[str, Any]]): If `as_dict=True`, return a config dict instead of a RotatingFileHandlerConfig object.\n        (RotatingFileHandlerConfig): If `as_dict=False`, return a RotatingFileHandlerConfig object.\n\n    \"\"\"\n    ## Convert &amp; optionally expand input path\n    filename: Path = Path(f\"{filename}\")\n    if \"~\" in f\"{filename}\":\n        filename = filename.expanduser()\n\n    ## Create parent dirs for logging file, if they don't exist\n    ensure_logdir(p=filename.parent)\n\n    try:\n        ## Initialize handler object\n        _handler: RotatingFileHandlerConfig = RotatingFileHandlerConfig(\n            name=name,\n            level=level,\n            formatter=formatter,\n            filters=filters,\n            filename=filename,\n            maxBytes=maxBytes,\n            backupCount=backupCount,\n        )\n\n        if as_dict:\n            ## Return handler representation as a dict\n            return _handler.get_configdict()\n        else:\n            ## Return RotatingFileHandlerConfig object\n            return _handler\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception building RotatingFileHandlerConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/config_classes/prefab/third_party/red_utils_logging/_configs/#red_utils.std.logging_utils.config_classes.prefab.third_party.red_utils_logging._configs.get_streamhandler_config","title":"<code>get_streamhandler_config(name='console', level='INFO', formatter='default', filters=None, stream='ext://sys.stdout', as_dict=False)</code>","text":"<p>Return a StreamHandlerConfig, or a dict representing a StreamingHandler.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name for the stream handler. Reference this handler by name in a LoggerConfig.</p> <code>'console'</code> <code>level</code> <code>str</code> <p>The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'INFO'</code> <code>formatter</code> <code>str</code> <p>The name of a formatter that exists in the overall logging dictConfig.</p> <code>'default'</code> <code>filters</code> <code>list[str] | None</code> <p>A list of function names for logging filters.</p> <code>None</code> <code>stream</code> <code>str</code> <p>The stream this handler should use, i.e. <code>ext://sys.stdout</code>, <code>ext://sys.stderr</code>, etc.</p> <code>'ext://sys.stdout'</code> <code>as_dict</code> <code>bool</code> <p>If <code>True</code>, return the configuration as a dict that can be joined into <code>dictConfig()</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>If <code>as_dict=True</code>, return a config dict instead of a StreamHandlerConfig object.</p> <code>StreamHandlerConfig</code> <p>If <code>as_dict=False</code>, return a StreamHandlerConfig object.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def get_streamhandler_config(\n    name: str = \"console\",\n    level: str = \"INFO\",\n    formatter: str = \"default\",\n    filters: list | None = None,\n    stream: str = \"ext://sys.stdout\",\n    as_dict: bool = False,\n) -&gt; dict[str, dict[str, str]] | StreamHandlerConfig:\n    \"\"\"Return a StreamHandlerConfig, or a dict representing a StreamingHandler.\n\n    Params:\n        name (str): The name for the stream handler. Reference this handler by name in a LoggerConfig.\n        level (str): The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        formatter (str): The name of a formatter that exists in the overall logging dictConfig.\n        filters (list[str] | None): A list of function names for logging filters.\n        stream (str): The stream this handler should use, i.e. `ext://sys.stdout`, `ext://sys.stderr`, etc.\n        as_dict (bool): If `True`, return the configuration as a dict that can be joined into `dictConfig()`.\n\n    Returns:\n        (dict[str, dict[str, Any]]): If `as_dict=True`, return a config dict instead of a StreamHandlerConfig object.\n        (StreamHandlerConfig): If `as_dict=False`, return a StreamHandlerConfig object.\n\n    \"\"\"\n    try:\n        ## Initialize handler object\n        _handler: StreamHandlerConfig = StreamHandlerConfig(\n            name=name, level=level, formatter=formatter, filters=filters, stream=stream\n        )\n\n        if as_dict:\n            ## Return handler representation as a dict\n            return _handler.get_configdict()\n        else:\n            ## Return StreamHandlerConfig object\n            return _handler\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception building StreamHandlerConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/fmts/__init__/","title":"fmts","text":"<p>Formats for the logging config.</p>"},{"location":"reference/red_utils/std/logging_utils/fmts/_formats/","title":"_formats","text":"<p>Pre-built formats that can be imported and set as a logger/handler's <code>format</code> and <code>datefmt</code> params.</p>"},{"location":"reference/red_utils/std/logging_utils/helpers/__init__/","title":"helpers","text":""},{"location":"reference/red_utils/std/logging_utils/helpers/__init__/#red_utils.std.logging_utils.helpers.assemble_configdict","title":"<code>assemble_configdict(disable_existing_loggers=False, propagate=False, root_handlers=['console'], root_level='DEBUG', formatters=None, handlers=None, loggers=None)</code>","text":"<p>Build a logging dictConfig dict.</p> Description Example logging config dict<pre><code>logging_config: dict = {\n    \"version\": 1,\n    \"disable_existing_loggers\": False,\n    \"propagate\": True,\n    \"root\": {},\n    \"formatters\": {},\n    \"handlers\": {},\n    \"loggers\": {},\n}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>disable_existing_loggers</code> <code>bool</code> <p>When <code>True</code>, disables all currently configured loggers to \"start fresh.\"</p> <code>False</code> <code>propagate</code> <code>bool</code> <p>When <code>True</code>, log messages will propagate up/down to the root logger.</p> <code>False</code> <code>root_handlers</code> <code>list[str]</code> <p>List of handlers for the root logger. These handler configs must exist in the logging dictConfig.</p> <code>['console']</code> <code>root_level</code> <code>str</code> <p>The log level for the root logger.</p> <code>'DEBUG'</code> <code>formatters</code> <code>list[FormatterConfig] | list[dict[str, dict[str, Any]]] | None</code> <p>List of logging formatter config objects.</p> <code>None</code> <code>handlers</code> <code>list[BaseHandlerConfig | dict[str, dict[str, Any]]] | None</code> <p>List of logging handler config objects.</p> <code>None</code> <code>loggers</code> <code>list[LoggerConfig | LoggerFactory | dict[str, dict[str, t.Any]]]] | None</code> <p>List of logging logger config objects.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>An initialized logging config dict created from inputs. Used with <code>logging.config.dictConfig()</code></p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def assemble_configdict(\n    disable_existing_loggers: bool = False,\n    propagate: bool = False,\n    root_handlers: list[str] = [\"console\"],\n    root_level: str = \"DEBUG\",\n    formatters: (\n        t.Union[list[FormatterConfig], list[LOGGING_CONFIG_DICT_TYPE_ANNOTATION]] | None\n    ) = None,\n    handlers: (\n        t.Union[HANDLER_CLASSES_TYPE_ANNOTATION, LOGGING_CONFIG_DICT_TYPE_ANNOTATION]\n        | None\n    ) = None,\n    loggers: (\n        t.Union[\n            list[t.Union[LoggerConfig, LoggerFactory]],\n            list[LOGGING_CONFIG_DICT_TYPE_ANNOTATION],\n        ]\n        | None\n    ) = None,\n) -&gt; dict[str, t.Any]:\n    \"\"\"Build a logging dictConfig dict.\n\n    Description:\n        ```python title=\"Example logging config dict\" linenums=\"1\"\n        logging_config: dict = {\n            \"version\": 1,\n            \"disable_existing_loggers\": False,\n            \"propagate\": True,\n            \"root\": {},\n            \"formatters\": {},\n            \"handlers\": {},\n            \"loggers\": {},\n        }\n        ```\n\n    Params:\n        disable_existing_loggers (bool): When `True`, disables all currently configured loggers to \"start fresh.\"\n        propagate (bool): When `True`, log messages will propagate up/down to the root logger.\n        root_handlers (list[str]): List of handlers for the root logger. These handler configs must exist in the logging dictConfig.\n        root_level (str): The log level for the root logger.\n        formatters (list[FormatterConfig] | list[dict[str, dict[str, t.Any]]] | None): List of logging formatter config objects.\n        handlers (list[BaseHandlerConfig | dict[str, dict[str, t.Any]]] | None): List of logging handler config objects.\n        loggers (list[LoggerConfig | LoggerFactory | dict[str, dict[str, t.Any]]]] | None): List of logging logger config objects.\n\n    Returns:\n        (dict[str, Any]): An initialized logging config dict created from inputs. Used with `logging.config.dictConfig()`\n\n    \"\"\"\n    ## Get base logging configDict object, with empty formatters, loggers, etc\n    logging_config: dict[str, t.Any] = BASE_LOGGING_CONFIG_DICT\n\n    ## Set logging config options\n    logging_config[\"disable_existing_loggers\"] = disable_existing_loggers\n    logging_config[\"propagate\"] = propagate\n\n    ## Build root logger\n    config_key_root = {\n        ## Set handlers\n        \"handlers\": root_handlers,\n        ## Set log level string\n        \"level\": root_level.upper(),\n    }\n\n    ## Update config dict's `root` key\n    logging_config[\"root\"] = config_key_root\n\n    ## Initialize formatter, handler, logger config dicts\n    formatter_configdicts: LOGGING_CONFIG_DICT_TYPE = {}\n    handler_configdicts: LOGGING_CONFIG_DICT_TYPE = {}\n    logger_configdicts: LOGGING_CONFIG_DICT_TYPE = {}\n\n    if formatters is not None:\n        ## Formatters passed to function, parse and add to config\n        for formatter_dict in formatters:\n            if isinstance(formatter_dict, dict):\n                pass\n            elif isinstance(formatter_dict, FormatterConfig):\n                try:\n                    formatter_dict: dict = formatter_dict.get_configdict()\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Unhandled exception getting config dict for FormatterConfig object. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n            formatter_configdicts.update(formatter_dict)\n\n    if handlers is not None:\n        ## Handlers passed to function, parse and add to config\n        for handler_dict in handlers:\n            if isinstance(handler_dict, dict):\n                pass\n            elif isinstance(handler_dict, HANDLER_CLASSES_TYPE):\n                try:\n                    handler_dict = handler_dict.get_configdict()\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Unhandled exception getting config dict for *HandlerConfig object. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n            handler_configdicts.update(handler_dict)\n\n    if loggers:\n        ## Loggers passed to function, parse and add to config\n        for logger_dict in loggers:\n            if isinstance(logger_dict, dict):\n                pass\n            elif isinstance(logger_dict, LoggerConfig):\n                try:\n                    logger_dict = logger_dict.get_configdict()\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Unhandled exception getting config dict for LoggerConfig object. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n            logger_configdicts.update(logger_dict)\n\n    ## Create a copy of the original config\n    try:\n        return_dict = deepcopy(logging_config)\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception copying original logging config. Proceeding with original logging config\"\n        )\n        log.warning(msg)\n\n        return_dict = logging_config\n\n    ## Update formatters, handlers, loggers in logging config copy\n    return_dict[\"formatters\"] = formatter_configdicts\n    return_dict[\"handlers\"] = handler_configdicts\n    return_dict[\"loggers\"] = logger_configdicts\n\n    ## Return initialized logging config\n    return return_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__init__/#red_utils.std.logging_utils.helpers.ensure_logdir","title":"<code>ensure_logdir(p=None)</code>","text":"<p>Ensure a directory exists.</p> <p>Used by logging FileHandlers (RotatingFileHandler, TimedRotatingFileHandler, etc) if a logging file path is nested, like <code>logs/example/test.log</code>.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>str | Path</code> <p>A path to a logging directory, i.e. <code>logs/</code>, <code>logs/app/</code>, <code>logs/app/dev/</code>. This should not be the full path to a logging config, like <code>logs/app/test.log</code>; instead, call this function like <code>ensure_logdir(p=log_filename.parent)</code>.</p> <code>None</code> <p>Raises:</p> Type Description <code>PermissionError</code> <p>When permission to create the path in <code>p</code> is denied.</p> <code>Exception</code> <p>When any unhandled exception occurs.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def ensure_logdir(p: t.Union[str, Path] = None) -&gt; None:\n    \"\"\"Ensure a directory exists.\n\n    Used by logging FileHandlers (RotatingFileHandler, TimedRotatingFileHandler, etc) if\n    a logging file path is nested, like `logs/example/test.log`.\n\n    Params:\n        p (str | Path): A path to a logging directory, i.e. `logs/`, `logs/app/`, `logs/app/dev/`.\n            This should *not* be the full path to a logging config, like `logs/app/test.log`; instead,\n            call this function like `ensure_logdir(p=log_filename.parent)`.\n\n    Raises:\n        PermissionError: When permission to create the path in `p` is denied.\n        Exception: When any unhandled exception occurs.\n\n    \"\"\"\n    p: Path = Path(f\"{p}\")\n    if \"~\" in f\"{p}\":\n        p = p.expanduser()\n\n    if not p.exists():\n        try:\n            p.mkdir(parents=True, exist_ok=True)\n        except PermissionError as perm_err:\n            msg = Exception(f\"Permission denied creating path '{p}'. Details: {exc}\")\n            log.error(msg)\n\n            raise perm_err\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception creating directory '{p}'. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n    else:\n        return\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__init__/#red_utils.std.logging_utils.helpers.get_formatter_config","title":"<code>get_formatter_config(name='default', fmt=MESSAGE_FMT_STANDARD, datefmt=DATE_FMT_STANDARD, style='%', validate=True, as_dict=False)</code>","text":"<p>Return a FormatterConfig, or a dict representing a Formatter.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name for the formatter. Reference this formatter by name in a LoggerConfig.</p> <code>'default'</code> <code>fmt</code> <code>str</code> <p>The string format for log messages. Python docs: Log Record Attributes</p> <code>MESSAGE_FMT_STANDARD</code> <code>datefmt</code> <code>str</code> <p>The format for log message timestamps, if <code>%(asctime)s</code> is used in the logging <code>fmt</code>.</p> <code>DATE_FMT_STANDARD</code> <code>style</code> <code>str</code> <p>The style of string substitution to use for the formatter. Options include <code>%</code> for <code>'%', some_var</code>, <code>{</code> for <code>'{some_var}</code>, etc.</p> <code>'%'</code> <code>validate</code> <code>bool</code> <p>If <code>True</code>, the handler will be validated by the logging module before fully initializing.</p> <code>True</code> <code>as_dict</code> <code>bool</code> <p>If <code>True</code>, return the configuration as a dict that can be joined into <code>dictConfig()</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>If <code>as_dict=True</code>, return a config dict instead of a FormatterConfig object.</p> <code>FormatterConfig</code> <p>If <code>as_dict=False</code>, return a FormatterConfig object.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def get_formatter_config(\n    name: str = \"default\",\n    fmt: str = MESSAGE_FMT_STANDARD,\n    datefmt: str = DATE_FMT_STANDARD,\n    style: str = \"%\",\n    validate: bool = True,\n    as_dict: bool = False,\n) -&gt; dict[str, dict[str, str]] | FormatterConfig:\n    \"\"\"Return a FormatterConfig, or a dict representing a Formatter.\n\n    Params:\n        name (str): The name for the formatter. Reference this formatter by name in a LoggerConfig.\n        fmt (str): The string format for log messages.\n            [Python docs: Log Record Attributes](https://docs.python.org/3/library/logging.html#logrecord-attributes)\n        datefmt (str): The format for log message timestamps, if `%(asctime)s` is used in the logging `fmt`.\n        style (str): The style of string substitution to use for the formatter. Options include `%` for `'%', some_var`,\n            `{` for `'{some_var}`, etc.\n        validate (bool): If `True`, the handler will be validated by the logging module before fully initializing.\n        as_dict (bool): If `True`, return the configuration as a dict that can be joined into `dictConfig()`.\n\n    Returns:\n        (dict[str, dict[str, Any]]): If `as_dict=True`, return a config dict instead of a FormatterConfig object.\n        (FormatterConfig): If `as_dict=False`, return a FormatterConfig object.\n\n    \"\"\"\n    try:\n        ## Initialize formatter object\n        _formatter: FormatterConfig = FormatterConfig(\n            name=name, fmt=fmt, datefmt=datefmt, style=style, validate=validate\n        )\n\n        if as_dict:\n            ## Return formatter representation as a dict\n            return _formatter.get_configdict()\n        else:\n            ## Return FormatterConfig object\n            return _formatter\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception building FormatterConfig. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__init__/#red_utils.std.logging_utils.helpers.get_logger_config","title":"<code>get_logger_config(name='app', handlers=['console'], level='DEBUG', propagate=False, as_dict=False)</code>","text":"<p>Return a LoggerConfig, or a dict representing a Logger.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name for the logger. Reference this logger by name in a LoggerConfig.</p> <code>'app'</code> <code>level</code> <code>str</code> <p>The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'DEBUG'</code> <code>handlers</code> <code>list[str]</code> <p>List of handler names that exist in the logging configDict that this logger should use.</p> <code>['console']</code> <code>propagate</code> <code>bool</code> <p>If <code>True</code>, log messages will be propagated up/down to the root logger.</p> <code>False</code> <code>as_dict</code> <code>bool</code> <p>If <code>True</code>, return the configuration as a dict that can be joined into <code>dictConfig()</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>If <code>as_dict=True</code>, return a config dict instead of a RotatingFileHandlerConfig object.</p> <code>RotatingFileHandlerConfig</code> <p>If <code>as_dict=False</code>, return a RotatingFileHandlerConfig object.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def get_logger_config(\n    name: str = \"app\",\n    handlers: list[str] = [\"console\"],\n    level: str = \"DEBUG\",\n    propagate: bool = False,\n    as_dict: bool = False,\n) -&gt; dict[str, dict[str, str]] | LoggerConfig:\n    \"\"\"Return a LoggerConfig, or a dict representing a Logger.\n\n    Params:\n        name (str): The name for the logger. Reference this logger by name in a LoggerConfig.\n        level (str): The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        handlers (list[str]): List of handler names that exist in the logging configDict that this logger should use.\n        propagate (bool): If `True`, log messages will be propagated up/down to the root logger.\n        as_dict (bool): If `True`, return the configuration as a dict that can be joined into `dictConfig()`.\n\n    Returns:\n        (dict[str, dict[str, Any]]): If `as_dict=True`, return a config dict instead of a RotatingFileHandlerConfig object.\n        (RotatingFileHandlerConfig): If `as_dict=False`, return a RotatingFileHandlerConfig object.\n\n    \"\"\"\n    try:\n        ## Initialize logger object\n        _logger: LoggerConfig = LoggerConfig(\n            name=name, level=level.upper(), handlers=handlers, propagate=propagate\n        )\n\n        if as_dict:\n            ## Return logger representation as a dict\n            return _logger.get_configdict()\n        else:\n            ## Return LoggerConfig object\n            return _logger\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception initializing logger. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__init__/#red_utils.std.logging_utils.helpers.get_rotatingfilehandler_config","title":"<code>get_rotatingfilehandler_config(name='rotating_app_file', level='DEBUG', formatter='default', filters=None, filename=None, maxBytes=100000, backupCount=3, as_dict=False)</code>","text":"<p>Return a RotatingFileHandlerConfig, or a dict representing a RotatingFileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name for the rotating file handler. Reference this handler by name in a LoggerConfig.</p> <code>'rotating_app_file'</code> <code>level</code> <code>str</code> <p>The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'DEBUG'</code> <code>formatter</code> <code>str</code> <p>The name of a formatter that exists in the overall logging dictConfig.</p> <code>'default'</code> <code>filters</code> <code>list[str] | None</code> <p>A list of function names for logging filters.</p> <code>None</code> <code>filename</code> <code>str | Path</code> <p>The full path to the log file you want to create. If parent directories do not exist, this method will handle creating them.</p> <code>None</code> <code>maxBytes</code> <code>int</code> <p>The maximum size (in bytes) before a logfile is rotated.</p> <code>100000</code> <code>backupCount</code> <code>int</code> <p>The number of backups to keep as log files rotate.</p> <code>3</code> <code>as_dict</code> <code>bool</code> <p>If <code>True</code>, return the configuration as a dict that can be joined into <code>dictConfig()</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>If <code>as_dict=True</code>, return a config dict instead of a RotatingFileHandlerConfig object.</p> <code>RotatingFileHandlerConfig</code> <p>If <code>as_dict=False</code>, return a RotatingFileHandlerConfig object.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def get_rotatingfilehandler_config(\n    name: str = \"rotating_app_file\",\n    level: str = \"DEBUG\",\n    formatter: str = \"default\",\n    filters: list | None = None,\n    filename: t.Union[str, Path] = None,\n    maxBytes: int = 100000,\n    backupCount: int = 3,\n    as_dict: bool = False,\n) -&gt; dict[str, dict[str, t.Any]] | RotatingFileHandlerConfig:\n    \"\"\"Return a RotatingFileHandlerConfig, or a dict representing a RotatingFileHandler.\n\n    Params:\n        name (str): The name for the rotating file handler. Reference this handler by name in a LoggerConfig.\n        level (str): The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        formatter (str): The name of a formatter that exists in the overall logging dictConfig.\n        filters (list[str] | None): A list of function names for logging filters.\n        filename (str | Path): The full path to the log file you want to create. If parent directories do not exist,\n            this method will handle creating them.\n        maxBytes (int): The maximum size (in bytes) before a logfile is rotated.\n        backupCount (int): The number of backups to keep as log files rotate.\n        as_dict (bool): If `True`, return the configuration as a dict that can be joined into `dictConfig()`.\n\n    Returns:\n        (dict[str, dict[str, Any]]): If `as_dict=True`, return a config dict instead of a RotatingFileHandlerConfig object.\n        (RotatingFileHandlerConfig): If `as_dict=False`, return a RotatingFileHandlerConfig object.\n\n    \"\"\"\n    ## Convert &amp; optionally expand input path\n    filename: Path = Path(f\"{filename}\")\n    if \"~\" in f\"{filename}\":\n        filename = filename.expanduser()\n\n    ## Create parent dirs for logging file, if they don't exist\n    ensure_logdir(p=filename.parent)\n\n    try:\n        ## Initialize handler object\n        _handler: RotatingFileHandlerConfig = RotatingFileHandlerConfig(\n            name=name,\n            level=level,\n            formatter=formatter,\n            filters=filters,\n            filename=filename,\n            maxBytes=maxBytes,\n            backupCount=backupCount,\n        )\n\n        if as_dict:\n            ## Return handler representation as a dict\n            return _handler.get_configdict()\n        else:\n            ## Return RotatingFileHandlerConfig object\n            return _handler\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception building RotatingFileHandlerConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__init__/#red_utils.std.logging_utils.helpers.get_streamhandler_config","title":"<code>get_streamhandler_config(name='console', level='INFO', formatter='default', filters=None, stream='ext://sys.stdout', as_dict=False)</code>","text":"<p>Return a StreamHandlerConfig, or a dict representing a StreamingHandler.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name for the stream handler. Reference this handler by name in a LoggerConfig.</p> <code>'console'</code> <code>level</code> <code>str</code> <p>The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'INFO'</code> <code>formatter</code> <code>str</code> <p>The name of a formatter that exists in the overall logging dictConfig.</p> <code>'default'</code> <code>filters</code> <code>list[str] | None</code> <p>A list of function names for logging filters.</p> <code>None</code> <code>stream</code> <code>str</code> <p>The stream this handler should use, i.e. <code>ext://sys.stdout</code>, <code>ext://sys.stderr</code>, etc.</p> <code>'ext://sys.stdout'</code> <code>as_dict</code> <code>bool</code> <p>If <code>True</code>, return the configuration as a dict that can be joined into <code>dictConfig()</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>If <code>as_dict=True</code>, return a config dict instead of a StreamHandlerConfig object.</p> <code>StreamHandlerConfig</code> <p>If <code>as_dict=False</code>, return a StreamHandlerConfig object.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def get_streamhandler_config(\n    name: str = \"console\",\n    level: str = \"INFO\",\n    formatter: str = \"default\",\n    filters: list | None = None,\n    stream: str = \"ext://sys.stdout\",\n    as_dict: bool = False,\n) -&gt; dict[str, dict[str, str]] | StreamHandlerConfig:\n    \"\"\"Return a StreamHandlerConfig, or a dict representing a StreamingHandler.\n\n    Params:\n        name (str): The name for the stream handler. Reference this handler by name in a LoggerConfig.\n        level (str): The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        formatter (str): The name of a formatter that exists in the overall logging dictConfig.\n        filters (list[str] | None): A list of function names for logging filters.\n        stream (str): The stream this handler should use, i.e. `ext://sys.stdout`, `ext://sys.stderr`, etc.\n        as_dict (bool): If `True`, return the configuration as a dict that can be joined into `dictConfig()`.\n\n    Returns:\n        (dict[str, dict[str, Any]]): If `as_dict=True`, return a config dict instead of a StreamHandlerConfig object.\n        (StreamHandlerConfig): If `as_dict=False`, return a StreamHandlerConfig object.\n\n    \"\"\"\n    try:\n        ## Initialize handler object\n        _handler: StreamHandlerConfig = StreamHandlerConfig(\n            name=name, level=level, formatter=formatter, filters=filters, stream=stream\n        )\n\n        if as_dict:\n            ## Return handler representation as a dict\n            return _handler.get_configdict()\n        else:\n            ## Return StreamHandlerConfig object\n            return _handler\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception building StreamHandlerConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__init__/#red_utils.std.logging_utils.helpers.print_configdict","title":"<code>print_configdict(logging_config=None)</code>","text":"<p>Print a logging config dict as a JSON string.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def print_configdict(logging_config: dict = None) -&gt; None:\n    \"\"\"Print a logging config dict as a JSON string.\"\"\"\n    assert logging_config, ValueError(\"Missing a logging dictConfig to print.\")\n\n    print_msg: str = json.dumps(logging_config)\n\n    print(f\"Logging config dict:\\n{print_msg}\")\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__init__/#red_utils.std.logging_utils.helpers.save_configdict","title":"<code>save_configdict(logging_config=None, output_file=Path('logging_config.json'), overwrite=False)</code>","text":"<p>Save a logging dictConfig to a JSON file.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def save_configdict(\n    logging_config: dict = None,\n    output_file: t.Union[str, Path] = Path(\"logging_config.json\"),\n    overwrite: bool = False,\n) -&gt; None:\n    \"\"\"Save a logging dictConfig to a JSON file.\"\"\"\n    output_file: Path = Path(f\"{output_file}\")\n    if \"~\" in f\"{output_file}\":\n        output_file = output_file.expanduser()\n\n    ensure_logdir(p=output_file.parent)\n\n    if output_file.exists() and not overwrite:\n        log.warning(\n            f\"Logging dictConfig already saved to file '{output_file}' and overwrite=False. Skipping.\"\n        )\n\n        return\n\n    try:\n        config_json = json.dumps(logging_config, indent=2)\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception converting logging dict to JSON. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n\n    try:\n        with open(output_file, \"w\") as f:\n            f.write(config_json)\n    except PermissionError as perm_err:\n        msg = Exception(\n            f\"Permission denied saving logging dictConfig to file '{output_file}'. Details: {perm_err}\"\n        )\n        log.error(msg)\n\n        raise perm_err\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception saving logging dictConfig to JSON file '{output_file}'. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/","title":"__methods","text":"<p>Functions to add in creating/working with the logging config classes in this module.</p>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.FileHandlerConfig","title":"<code>FileHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging FileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file to log messages to.</p> <code>'app.log'</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass FileHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging FileHandler.\n\n    Params:\n        filename (str): The name of the file to log messages to.\n    \"\"\"\n\n    filename: str | None = field(default=\"app.log\")\n\n    def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, str]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"filename\": self.filename,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.FileHandler`.\n\n        \"\"\"\n        return \"logging.FileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.FileHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, str]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"filename\": self.filename,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.FileHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.FileHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.FileHandler`.\n\n    \"\"\"\n    return \"logging.FileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.FormatterConfig","title":"<code>FormatterConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseLoggingConfig</code></p> <p>Define a logging formatter.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the formatter.</p> <code>None</code> <code>fmt</code> <code>str</code> <p>The string formatting to use for log messages.</p> <code>MESSAGE_FMT_STANDARD</code> <code>datefmt</code> <code>str</code> <p>The string formatting to use for log message timestamps.</p> <code>DATE_FMT_STANDARD</code> <code>style</code> <code>str</code> <p>The string substitution style to use for log formats. Default is <code>%</code>, which means formats need to be written like <code>%(asctime)s %(levelname)s %(message)s</code>. If you change this style, make sure the <code>fmt</code> you pass uses the correct formatting style.</p> <code>'%'</code> <code>validate</code> <code>bool</code> <p>When <code>True</code>, the configuration dict this formatter returns will be validated by the logging module.</p> <code>True</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\formatters\\_formatters.py</code> <pre><code>@dataclass\nclass FormatterConfig(BaseLoggingConfig):\n    \"\"\"Define a logging formatter.\n\n    Params:\n        name (str): The name of the formatter.\n        fmt (str): The string formatting to use for log messages.\n        datefmt (str): The string formatting to use for log message timestamps.\n        style (str): The string substitution style to use for log formats. Default is `%`, which\n            means formats need to be written like `%(asctime)s %(levelname)s %(message)s`. If\n            you change this style, make sure the `fmt` you pass uses the correct formatting style.\n        validate (bool): When `True`, the configuration dict this formatter returns will be validated by the logging module.\n\n    \"\"\"\n\n    name: str = None\n    fmt: str = MESSAGE_FMT_STANDARD\n    datefmt: str = DATE_FMT_STANDARD\n    style: str = \"%\"\n    validate: bool = True\n\n    def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Return a dict representation of the formatter described by this class.\"\"\"\n        formatter_dict: dict[str, dict[str, str]] = {self.name: {\"format\": self.fmt}}\n        if self.datefmt:\n            formatter_dict[self.name][\"datefmt\"] = self.datefmt\n        if self.style:\n            formatter_dict[self.name][\"style\"] = self.style\n        formatter_dict[self.name][\"validate\"] = self.validate\n\n        return formatter_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.FormatterConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the formatter described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\formatters\\_formatters.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Return a dict representation of the formatter described by this class.\"\"\"\n    formatter_dict: dict[str, dict[str, str]] = {self.name: {\"format\": self.fmt}}\n    if self.datefmt:\n        formatter_dict[self.name][\"datefmt\"] = self.datefmt\n    if self.style:\n        formatter_dict[self.name][\"style\"] = self.style\n    formatter_dict[self.name][\"validate\"] = self.validate\n\n    return formatter_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.LoggerConfig","title":"<code>LoggerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseLoggingConfig</code></p> <p>Define a logging Logger.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the logger.</p> required <code>level</code> <code>str</code> <p>The level of log messages this logger should show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> required <code>handlers</code> <code>list[str]</code> <p>List of handler names this logger should use. These handlers must exist in the logging dictConfig.</p> required <code>propagate</code> <code>bool</code> <p>If <code>True</code>, messages will be propagated up/down to the root logger.</p> <code>False</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_loggers.py</code> <pre><code>@dataclass\nclass LoggerConfig(BaseLoggingConfig):\n    \"\"\"Define a logging Logger.\n\n    Params:\n        name (str): The name of the logger.\n        level (str): The level of log messages this logger should show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        handlers (list[str]): List of handler names this logger should use. These handlers must exist in the logging dictConfig.\n        propagate (bool): If `True`, messages will be propagated up/down to the root logger.\n    \"\"\"\n\n    name: str\n    level: str\n    handlers: list[str]\n    propagate: bool = False\n\n    def get_configdict(self) -&gt; dict:\n        \"\"\"Return a dict representation of the logger described by this class.\"\"\"\n        logger_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"level\": self.level,\n                \"handlers\": self.handlers,\n                \"propagate\": self.propagate,\n            }\n        }\n        return logger_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.LoggerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the logger described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_loggers.py</code> <pre><code>def get_configdict(self) -&gt; dict:\n    \"\"\"Return a dict representation of the logger described by this class.\"\"\"\n    logger_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"level\": self.level,\n            \"handlers\": self.handlers,\n            \"propagate\": self.propagate,\n        }\n    }\n    return logger_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.LoggerFactory","title":"<code>LoggerFactory</code>","text":"<p>Generate loggers based on LoggerFactory's config.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_factory.py</code> <pre><code>class LoggerFactory:\n    \"\"\"Generate loggers based on LoggerFactory's config.\"\"\"\n\n    _LOG: logging.Logger | None = None\n\n    @staticmethod\n    def __create_logger(\n        name: str,\n        log_level: str,\n        handlers: dict[str, dict],\n        formatters: dict[str, dict],\n        loggers: dict[str, dict],\n    ) -&gt; logging.Logger:\n        \"\"\"Create a logger cnofig from inputs.\n\n        Params:\n            name (str): The name of the logger.\n            log_level (str): The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n            handlers (dict[str, dict[str, Any]]): A dict describing the handlers for this logger config.\n            formatters (dict[str, dict[str, Any]]): A dict describing the formatters for this logger config.\n            loggers (dict[str, dict[str, Any]]): A dict describing the loggers for this logger config.\n        \"\"\"\n        log_level = log_level.upper()\n\n        # Configure logging using dictConfig\n        logging_config = {\n            \"version\": 1,\n            \"handlers\": handlers,\n            \"formatters\": formatters,\n            \"loggers\": loggers,\n            \"root\": {\n                \"level\": log_level,\n                \"handlers\": list(handlers.keys()),\n            },\n        }\n\n        try:\n            logging.config.dictConfig(logging_config)\n        except Exception as exc:\n            msg = Exception(f\"Unhandled exception configuring logger. Details: {exc}\")\n            # log.error(msg)\n\n            raise msg\n\n        # Get or create logger\n        LoggerFactory._LOG = logging.getLogger(name)\n\n        return LoggerFactory._LOG\n\n    @staticmethod\n    def get_logger(\n        name: str,\n        log_level: str,\n        handlers: dict[str, dict],\n        formatters: dict[str, dict],\n        loggers: dict[str, dict],\n    ) -&gt; logging.Logger:\n        \"\"\"Initialize a logger.\n\n        Params:\n            name (str): The name of the logger.\n            log_level (str): The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n            handlers (dict[str, dict[str, Any]]): A dict describing the handlers for this logger config.\n            formatters (dict[str, dict[str, Any]]): A dict describing the formatters for this logger config.\n            loggers (dict[str, dict[str, Any]]): A dict describing the loggers for this logger config.\n        \"\"\"\n        logger = LoggerFactory.__create_logger(\n            name=name,\n            log_level=log_level,\n            handlers=handlers,\n            formatters=formatters,\n            loggers=loggers,\n        )\n\n        return logger\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.LoggerFactory.get_logger","title":"<code>get_logger(name, log_level, handlers, formatters, loggers)</code>  <code>staticmethod</code>","text":"<p>Initialize a logger.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the logger.</p> required <code>log_level</code> <code>str</code> <p>The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> required <code>handlers</code> <code>dict[str, dict[str, Any]]</code> <p>A dict describing the handlers for this logger config.</p> required <code>formatters</code> <code>dict[str, dict[str, Any]]</code> <p>A dict describing the formatters for this logger config.</p> required <code>loggers</code> <code>dict[str, dict[str, Any]]</code> <p>A dict describing the loggers for this logger config.</p> required Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\loggers\\_factory.py</code> <pre><code>@staticmethod\ndef get_logger(\n    name: str,\n    log_level: str,\n    handlers: dict[str, dict],\n    formatters: dict[str, dict],\n    loggers: dict[str, dict],\n) -&gt; logging.Logger:\n    \"\"\"Initialize a logger.\n\n    Params:\n        name (str): The name of the logger.\n        log_level (str): The log levels to show (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        handlers (dict[str, dict[str, Any]]): A dict describing the handlers for this logger config.\n        formatters (dict[str, dict[str, Any]]): A dict describing the formatters for this logger config.\n        loggers (dict[str, dict[str, Any]]): A dict describing the loggers for this logger config.\n    \"\"\"\n    logger = LoggerFactory.__create_logger(\n        name=name,\n        log_level=log_level,\n        handlers=handlers,\n        formatters=formatters,\n        loggers=loggers,\n    )\n\n    return logger\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.QueueHandlerConfig","title":"<code>QueueHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging QueueHandler.</p> <p>Parameters:</p> Name Type Description Default <code>queue</code> <code>Queue</code> <p>The queue to send log messages to.</p> <code>None</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass QueueHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging QueueHandler.\n\n    Params:\n        queue (queue.Queue): The queue to send log messages to.\n    \"\"\"\n\n    queue: Queue = field(default=None)\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"queue\": self.queue,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.QueueHandler`.\n\n        \"\"\"\n        return \"logging.handlers.QueueHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.QueueHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"queue\": self.queue,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.QueueHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.QueueHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.QueueHandler`.\n\n    \"\"\"\n    return \"logging.handlers.QueueHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.QueueListenerConfig","title":"<code>QueueListenerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseLoggingConfig</code></p> <p>Define a logging QueueListener.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the handler.</p> required <code>queue</code> <code>Queue</code> <p>The queue to listen for log messages in.</p> required <code>handlers</code> <code>list[str]</code> <p>List of handler names to apply to this listener.</p> required Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass QueueListenerConfig(BaseLoggingConfig):\n    \"\"\"Define a logging QueueListener.\n\n    Params:\n        name (str): The name of the handler.\n        queue (queue.Queue): The queue to listen for log messages in.\n        handlers (list[str]): List of handler names to apply to this listener.\n\n    \"\"\"\n\n    name: str\n    queue: Queue\n    handlers: list\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        listener_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"queue\": self.queue,\n                \"handlers\": self.handlers,\n            }\n        }\n        return listener_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.QueueListener`.\n\n        \"\"\"\n        return \"logging.handleres.QueueListener\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.QueueListenerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    listener_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"queue\": self.queue,\n            \"handlers\": self.handlers,\n        }\n    }\n    return listener_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.QueueListenerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.QueueListener</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.QueueListener`.\n\n    \"\"\"\n    return \"logging.handleres.QueueListener\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.RotatingFileHandlerConfig","title":"<code>RotatingFileHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging RotatingFileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | None</code> <p>The name/path of the file to log messages to.</p> <code>'app.log'</code> <code>maxBytes</code> <code>int</code> <p>The maximum size of the file (in bytes) before a new file is rotated.</p> <code>0</code> <code>backupCount</code> <code>int</code> <p>Number of rotated log files to keep.</p> <code>0</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass RotatingFileHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging RotatingFileHandler.\n\n    Params:\n        filename (str | None): The name/path of the file to log messages to.\n        maxBytes (int): The maximum size of the file (in bytes) before a new file is rotated.\n        backupCount (int): Number of rotated log files to keep.\n\n    \"\"\"\n\n    filename: str | None = field(default=\"app.log\")\n    maxBytes: int = 0\n    backupCount: int = 0\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"filename\": f\"{self.filename}\",\n                \"maxBytes\": self.maxBytes,\n                \"backupCount\": self.backupCount,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.RotatingFileHandler`.\n\n        \"\"\"\n        return \"logging.handlers.RotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.RotatingFileHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"filename\": f\"{self.filename}\",\n            \"maxBytes\": self.maxBytes,\n            \"backupCount\": self.backupCount,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.RotatingFileHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.RotatingFileHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.RotatingFileHandler`.\n\n    \"\"\"\n    return \"logging.handlers.RotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.SocketHandlerConfig","title":"<code>SocketHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging SocketHandler.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Host IP/FQDN.</p> <code>'localhost'</code> <code>port</code> <code>int</code> <p>Host port where log messages should be sent.</p> <code>0</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass SocketHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging SocketHandler.\n\n    Params:\n        host (str): Host IP/FQDN.\n        port (int): Host port where log messages should be sent.\n    \"\"\"\n\n    host: str = \"localhost\"\n    port: int = 0\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"host\": self.host,\n                \"port\": self.port,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.SocketHandler`.\n\n        \"\"\"\n        return \"logging.handlers.SocketHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.SocketHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"host\": self.host,\n            \"port\": self.port,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.SocketHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.SocketHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.SocketHandler`.\n\n    \"\"\"\n    return \"logging.handlers.SocketHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.StreamHandlerConfig","title":"<code>StreamHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging StreamHandler.</p> <p>Parameters:</p> Name Type Description Default <code>stream</code> <code>Any</code> <p>The stream this handler controls, i.e. <code>ext://sys.stdout</code>, <code>ext://sys.stderr</code>, etc.</p> <code>'ext://sys.stdout'</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass StreamHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging StreamHandler.\n\n    Params:\n        stream (Any): The stream this handler controls, i.e. `ext://sys.stdout`, `ext://sys.stderr`, etc.\n    \"\"\"\n\n    stream: t.Any | None = \"ext://sys.stdout\"\n\n    def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, str]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"stream\": self.stream,\n            }\n        }\n        if self.filters:\n            handler_dict[\"filters\"] = self.filters\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.StreamHandler`.\n\n        \"\"\"\n        return \"logging.StreamHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.StreamHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, str]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"stream\": self.stream,\n        }\n    }\n    if self.filters:\n        handler_dict[\"filters\"] = self.filters\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.StreamHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.StreamHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.StreamHandler`.\n\n    \"\"\"\n    return \"logging.StreamHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.TimedRotatingFileHandlerConfig","title":"<code>TimedRotatingFileHandlerConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseHandlerConfig</code></p> <p>Define a logging TimedRotatingFileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name/path of the file to log messages to.</p> <code>'app.log'</code> <code>when</code> <code>str</code> <p>Time of day to rotate log files, i.e. <code>midnight</code>.</p> <code>'midnight'</code> <code>interval</code> <code>int</code> <p>When to rotate the file as the interval defined in <code>when</code> occurs. <code>1=every occurrence</code>, <code>2=every other occurrence</code>, etc.</p> <code>1</code> <code>backupCount</code> <code>int</code> <p>The number of rotated log files to save.</p> <code>0</code> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>@dataclass\nclass TimedRotatingFileHandlerConfig(BaseHandlerConfig):\n    \"\"\"Define a logging TimedRotatingFileHandler.\n\n    Params:\n        filename (str): The name/path of the file to log messages to.\n        when (str): Time of day to rotate log files, i.e. `midnight`.\n        interval (int): When to rotate the file as the interval defined in `when` occurs.\n            `1=every occurrence`, `2=every other occurrence`, etc.\n        backupCount (int): The number of rotated log files to save.\n    \"\"\"\n\n    filename: str | None = field(default=\"app.log\")\n    when: str | None = field(default=\"midnight\")\n    interval: int = 1\n    backupCount: int = 0\n\n    def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n        \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n        handler_dict: dict[str, dict[str, t.Any]] = {\n            self.name: {\n                \"class\": self.get_handler_class(),\n                \"level\": self.level,\n                \"formatter\": self.formatter,\n                \"filename\": self.filename,\n                \"when\": self.when,\n                \"interval\": self.interval,\n                \"backupCount\": self.backupCount,\n            }\n        }\n        return handler_dict\n\n    def get_handler_class(self) -&gt; str:\n        \"\"\"Return the logging handler class this class represents.\n\n        Returns:\n            (str): `logging.handlers.TimedRotatingFileHandler`.\n\n        \"\"\"\n        return \"logging.handlers.TimedRotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.TimedRotatingFileHandlerConfig.get_configdict","title":"<code>get_configdict()</code>","text":"<p>Return a dict representation of the handler described by this class.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_configdict(self) -&gt; dict[str, dict[str, t.Any]]:\n    \"\"\"Return a dict representation of the handler described by this class.\"\"\"\n    handler_dict: dict[str, dict[str, t.Any]] = {\n        self.name: {\n            \"class\": self.get_handler_class(),\n            \"level\": self.level,\n            \"formatter\": self.formatter,\n            \"filename\": self.filename,\n            \"when\": self.when,\n            \"interval\": self.interval,\n            \"backupCount\": self.backupCount,\n        }\n    }\n    return handler_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.TimedRotatingFileHandlerConfig.get_handler_class","title":"<code>get_handler_class()</code>","text":"<p>Return the logging handler class this class represents.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>logging.handlers.TimedRotatingFileHandler</code>.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\config_classes\\handlers\\_handlers.py</code> <pre><code>def get_handler_class(self) -&gt; str:\n    \"\"\"Return the logging handler class this class represents.\n\n    Returns:\n        (str): `logging.handlers.TimedRotatingFileHandler`.\n\n    \"\"\"\n    return \"logging.handlers.TimedRotatingFileHandler\"\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.assemble_configdict","title":"<code>assemble_configdict(disable_existing_loggers=False, propagate=False, root_handlers=['console'], root_level='DEBUG', formatters=None, handlers=None, loggers=None)</code>","text":"<p>Build a logging dictConfig dict.</p> Description Example logging config dict<pre><code>logging_config: dict = {\n    \"version\": 1,\n    \"disable_existing_loggers\": False,\n    \"propagate\": True,\n    \"root\": {},\n    \"formatters\": {},\n    \"handlers\": {},\n    \"loggers\": {},\n}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>disable_existing_loggers</code> <code>bool</code> <p>When <code>True</code>, disables all currently configured loggers to \"start fresh.\"</p> <code>False</code> <code>propagate</code> <code>bool</code> <p>When <code>True</code>, log messages will propagate up/down to the root logger.</p> <code>False</code> <code>root_handlers</code> <code>list[str]</code> <p>List of handlers for the root logger. These handler configs must exist in the logging dictConfig.</p> <code>['console']</code> <code>root_level</code> <code>str</code> <p>The log level for the root logger.</p> <code>'DEBUG'</code> <code>formatters</code> <code>list[FormatterConfig] | list[dict[str, dict[str, Any]]] | None</code> <p>List of logging formatter config objects.</p> <code>None</code> <code>handlers</code> <code>list[BaseHandlerConfig | dict[str, dict[str, Any]]] | None</code> <p>List of logging handler config objects.</p> <code>None</code> <code>loggers</code> <code>list[LoggerConfig | LoggerFactory | dict[str, dict[str, t.Any]]]] | None</code> <p>List of logging logger config objects.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>An initialized logging config dict created from inputs. Used with <code>logging.config.dictConfig()</code></p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def assemble_configdict(\n    disable_existing_loggers: bool = False,\n    propagate: bool = False,\n    root_handlers: list[str] = [\"console\"],\n    root_level: str = \"DEBUG\",\n    formatters: (\n        t.Union[list[FormatterConfig], list[LOGGING_CONFIG_DICT_TYPE_ANNOTATION]] | None\n    ) = None,\n    handlers: (\n        t.Union[HANDLER_CLASSES_TYPE_ANNOTATION, LOGGING_CONFIG_DICT_TYPE_ANNOTATION]\n        | None\n    ) = None,\n    loggers: (\n        t.Union[\n            list[t.Union[LoggerConfig, LoggerFactory]],\n            list[LOGGING_CONFIG_DICT_TYPE_ANNOTATION],\n        ]\n        | None\n    ) = None,\n) -&gt; dict[str, t.Any]:\n    \"\"\"Build a logging dictConfig dict.\n\n    Description:\n        ```python title=\"Example logging config dict\" linenums=\"1\"\n        logging_config: dict = {\n            \"version\": 1,\n            \"disable_existing_loggers\": False,\n            \"propagate\": True,\n            \"root\": {},\n            \"formatters\": {},\n            \"handlers\": {},\n            \"loggers\": {},\n        }\n        ```\n\n    Params:\n        disable_existing_loggers (bool): When `True`, disables all currently configured loggers to \"start fresh.\"\n        propagate (bool): When `True`, log messages will propagate up/down to the root logger.\n        root_handlers (list[str]): List of handlers for the root logger. These handler configs must exist in the logging dictConfig.\n        root_level (str): The log level for the root logger.\n        formatters (list[FormatterConfig] | list[dict[str, dict[str, t.Any]]] | None): List of logging formatter config objects.\n        handlers (list[BaseHandlerConfig | dict[str, dict[str, t.Any]]] | None): List of logging handler config objects.\n        loggers (list[LoggerConfig | LoggerFactory | dict[str, dict[str, t.Any]]]] | None): List of logging logger config objects.\n\n    Returns:\n        (dict[str, Any]): An initialized logging config dict created from inputs. Used with `logging.config.dictConfig()`\n\n    \"\"\"\n    ## Get base logging configDict object, with empty formatters, loggers, etc\n    logging_config: dict[str, t.Any] = BASE_LOGGING_CONFIG_DICT\n\n    ## Set logging config options\n    logging_config[\"disable_existing_loggers\"] = disable_existing_loggers\n    logging_config[\"propagate\"] = propagate\n\n    ## Build root logger\n    config_key_root = {\n        ## Set handlers\n        \"handlers\": root_handlers,\n        ## Set log level string\n        \"level\": root_level.upper(),\n    }\n\n    ## Update config dict's `root` key\n    logging_config[\"root\"] = config_key_root\n\n    ## Initialize formatter, handler, logger config dicts\n    formatter_configdicts: LOGGING_CONFIG_DICT_TYPE = {}\n    handler_configdicts: LOGGING_CONFIG_DICT_TYPE = {}\n    logger_configdicts: LOGGING_CONFIG_DICT_TYPE = {}\n\n    if formatters is not None:\n        ## Formatters passed to function, parse and add to config\n        for formatter_dict in formatters:\n            if isinstance(formatter_dict, dict):\n                pass\n            elif isinstance(formatter_dict, FormatterConfig):\n                try:\n                    formatter_dict: dict = formatter_dict.get_configdict()\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Unhandled exception getting config dict for FormatterConfig object. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n            formatter_configdicts.update(formatter_dict)\n\n    if handlers is not None:\n        ## Handlers passed to function, parse and add to config\n        for handler_dict in handlers:\n            if isinstance(handler_dict, dict):\n                pass\n            elif isinstance(handler_dict, HANDLER_CLASSES_TYPE):\n                try:\n                    handler_dict = handler_dict.get_configdict()\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Unhandled exception getting config dict for *HandlerConfig object. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n            handler_configdicts.update(handler_dict)\n\n    if loggers:\n        ## Loggers passed to function, parse and add to config\n        for logger_dict in loggers:\n            if isinstance(logger_dict, dict):\n                pass\n            elif isinstance(logger_dict, LoggerConfig):\n                try:\n                    logger_dict = logger_dict.get_configdict()\n                except Exception as exc:\n                    msg = Exception(\n                        f\"Unhandled exception getting config dict for LoggerConfig object. Details: {exc}\"\n                    )\n                    log.error(msg)\n\n                    raise exc\n\n            logger_configdicts.update(logger_dict)\n\n    ## Create a copy of the original config\n    try:\n        return_dict = deepcopy(logging_config)\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception copying original logging config. Proceeding with original logging config\"\n        )\n        log.warning(msg)\n\n        return_dict = logging_config\n\n    ## Update formatters, handlers, loggers in logging config copy\n    return_dict[\"formatters\"] = formatter_configdicts\n    return_dict[\"handlers\"] = handler_configdicts\n    return_dict[\"loggers\"] = logger_configdicts\n\n    ## Return initialized logging config\n    return return_dict\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.ensure_logdir","title":"<code>ensure_logdir(p=None)</code>","text":"<p>Ensure a directory exists.</p> <p>Used by logging FileHandlers (RotatingFileHandler, TimedRotatingFileHandler, etc) if a logging file path is nested, like <code>logs/example/test.log</code>.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>str | Path</code> <p>A path to a logging directory, i.e. <code>logs/</code>, <code>logs/app/</code>, <code>logs/app/dev/</code>. This should not be the full path to a logging config, like <code>logs/app/test.log</code>; instead, call this function like <code>ensure_logdir(p=log_filename.parent)</code>.</p> <code>None</code> <p>Raises:</p> Type Description <code>PermissionError</code> <p>When permission to create the path in <code>p</code> is denied.</p> <code>Exception</code> <p>When any unhandled exception occurs.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def ensure_logdir(p: t.Union[str, Path] = None) -&gt; None:\n    \"\"\"Ensure a directory exists.\n\n    Used by logging FileHandlers (RotatingFileHandler, TimedRotatingFileHandler, etc) if\n    a logging file path is nested, like `logs/example/test.log`.\n\n    Params:\n        p (str | Path): A path to a logging directory, i.e. `logs/`, `logs/app/`, `logs/app/dev/`.\n            This should *not* be the full path to a logging config, like `logs/app/test.log`; instead,\n            call this function like `ensure_logdir(p=log_filename.parent)`.\n\n    Raises:\n        PermissionError: When permission to create the path in `p` is denied.\n        Exception: When any unhandled exception occurs.\n\n    \"\"\"\n    p: Path = Path(f\"{p}\")\n    if \"~\" in f\"{p}\":\n        p = p.expanduser()\n\n    if not p.exists():\n        try:\n            p.mkdir(parents=True, exist_ok=True)\n        except PermissionError as perm_err:\n            msg = Exception(f\"Permission denied creating path '{p}'. Details: {exc}\")\n            log.error(msg)\n\n            raise perm_err\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception creating directory '{p}'. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n    else:\n        return\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.get_formatter_config","title":"<code>get_formatter_config(name='default', fmt=MESSAGE_FMT_STANDARD, datefmt=DATE_FMT_STANDARD, style='%', validate=True, as_dict=False)</code>","text":"<p>Return a FormatterConfig, or a dict representing a Formatter.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name for the formatter. Reference this formatter by name in a LoggerConfig.</p> <code>'default'</code> <code>fmt</code> <code>str</code> <p>The string format for log messages. Python docs: Log Record Attributes</p> <code>MESSAGE_FMT_STANDARD</code> <code>datefmt</code> <code>str</code> <p>The format for log message timestamps, if <code>%(asctime)s</code> is used in the logging <code>fmt</code>.</p> <code>DATE_FMT_STANDARD</code> <code>style</code> <code>str</code> <p>The style of string substitution to use for the formatter. Options include <code>%</code> for <code>'%', some_var</code>, <code>{</code> for <code>'{some_var}</code>, etc.</p> <code>'%'</code> <code>validate</code> <code>bool</code> <p>If <code>True</code>, the handler will be validated by the logging module before fully initializing.</p> <code>True</code> <code>as_dict</code> <code>bool</code> <p>If <code>True</code>, return the configuration as a dict that can be joined into <code>dictConfig()</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>If <code>as_dict=True</code>, return a config dict instead of a FormatterConfig object.</p> <code>FormatterConfig</code> <p>If <code>as_dict=False</code>, return a FormatterConfig object.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def get_formatter_config(\n    name: str = \"default\",\n    fmt: str = MESSAGE_FMT_STANDARD,\n    datefmt: str = DATE_FMT_STANDARD,\n    style: str = \"%\",\n    validate: bool = True,\n    as_dict: bool = False,\n) -&gt; dict[str, dict[str, str]] | FormatterConfig:\n    \"\"\"Return a FormatterConfig, or a dict representing a Formatter.\n\n    Params:\n        name (str): The name for the formatter. Reference this formatter by name in a LoggerConfig.\n        fmt (str): The string format for log messages.\n            [Python docs: Log Record Attributes](https://docs.python.org/3/library/logging.html#logrecord-attributes)\n        datefmt (str): The format for log message timestamps, if `%(asctime)s` is used in the logging `fmt`.\n        style (str): The style of string substitution to use for the formatter. Options include `%` for `'%', some_var`,\n            `{` for `'{some_var}`, etc.\n        validate (bool): If `True`, the handler will be validated by the logging module before fully initializing.\n        as_dict (bool): If `True`, return the configuration as a dict that can be joined into `dictConfig()`.\n\n    Returns:\n        (dict[str, dict[str, Any]]): If `as_dict=True`, return a config dict instead of a FormatterConfig object.\n        (FormatterConfig): If `as_dict=False`, return a FormatterConfig object.\n\n    \"\"\"\n    try:\n        ## Initialize formatter object\n        _formatter: FormatterConfig = FormatterConfig(\n            name=name, fmt=fmt, datefmt=datefmt, style=style, validate=validate\n        )\n\n        if as_dict:\n            ## Return formatter representation as a dict\n            return _formatter.get_configdict()\n        else:\n            ## Return FormatterConfig object\n            return _formatter\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception building FormatterConfig. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.get_logger_config","title":"<code>get_logger_config(name='app', handlers=['console'], level='DEBUG', propagate=False, as_dict=False)</code>","text":"<p>Return a LoggerConfig, or a dict representing a Logger.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name for the logger. Reference this logger by name in a LoggerConfig.</p> <code>'app'</code> <code>level</code> <code>str</code> <p>The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'DEBUG'</code> <code>handlers</code> <code>list[str]</code> <p>List of handler names that exist in the logging configDict that this logger should use.</p> <code>['console']</code> <code>propagate</code> <code>bool</code> <p>If <code>True</code>, log messages will be propagated up/down to the root logger.</p> <code>False</code> <code>as_dict</code> <code>bool</code> <p>If <code>True</code>, return the configuration as a dict that can be joined into <code>dictConfig()</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>If <code>as_dict=True</code>, return a config dict instead of a RotatingFileHandlerConfig object.</p> <code>RotatingFileHandlerConfig</code> <p>If <code>as_dict=False</code>, return a RotatingFileHandlerConfig object.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def get_logger_config(\n    name: str = \"app\",\n    handlers: list[str] = [\"console\"],\n    level: str = \"DEBUG\",\n    propagate: bool = False,\n    as_dict: bool = False,\n) -&gt; dict[str, dict[str, str]] | LoggerConfig:\n    \"\"\"Return a LoggerConfig, or a dict representing a Logger.\n\n    Params:\n        name (str): The name for the logger. Reference this logger by name in a LoggerConfig.\n        level (str): The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        handlers (list[str]): List of handler names that exist in the logging configDict that this logger should use.\n        propagate (bool): If `True`, log messages will be propagated up/down to the root logger.\n        as_dict (bool): If `True`, return the configuration as a dict that can be joined into `dictConfig()`.\n\n    Returns:\n        (dict[str, dict[str, Any]]): If `as_dict=True`, return a config dict instead of a RotatingFileHandlerConfig object.\n        (RotatingFileHandlerConfig): If `as_dict=False`, return a RotatingFileHandlerConfig object.\n\n    \"\"\"\n    try:\n        ## Initialize logger object\n        _logger: LoggerConfig = LoggerConfig(\n            name=name, level=level.upper(), handlers=handlers, propagate=propagate\n        )\n\n        if as_dict:\n            ## Return logger representation as a dict\n            return _logger.get_configdict()\n        else:\n            ## Return LoggerConfig object\n            return _logger\n\n    except Exception as exc:\n        msg = Exception(f\"Unhandled exception initializing logger. Details: {exc}\")\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.get_rotatingfilehandler_config","title":"<code>get_rotatingfilehandler_config(name='rotating_app_file', level='DEBUG', formatter='default', filters=None, filename=None, maxBytes=100000, backupCount=3, as_dict=False)</code>","text":"<p>Return a RotatingFileHandlerConfig, or a dict representing a RotatingFileHandler.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name for the rotating file handler. Reference this handler by name in a LoggerConfig.</p> <code>'rotating_app_file'</code> <code>level</code> <code>str</code> <p>The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'DEBUG'</code> <code>formatter</code> <code>str</code> <p>The name of a formatter that exists in the overall logging dictConfig.</p> <code>'default'</code> <code>filters</code> <code>list[str] | None</code> <p>A list of function names for logging filters.</p> <code>None</code> <code>filename</code> <code>str | Path</code> <p>The full path to the log file you want to create. If parent directories do not exist, this method will handle creating them.</p> <code>None</code> <code>maxBytes</code> <code>int</code> <p>The maximum size (in bytes) before a logfile is rotated.</p> <code>100000</code> <code>backupCount</code> <code>int</code> <p>The number of backups to keep as log files rotate.</p> <code>3</code> <code>as_dict</code> <code>bool</code> <p>If <code>True</code>, return the configuration as a dict that can be joined into <code>dictConfig()</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>If <code>as_dict=True</code>, return a config dict instead of a RotatingFileHandlerConfig object.</p> <code>RotatingFileHandlerConfig</code> <p>If <code>as_dict=False</code>, return a RotatingFileHandlerConfig object.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def get_rotatingfilehandler_config(\n    name: str = \"rotating_app_file\",\n    level: str = \"DEBUG\",\n    formatter: str = \"default\",\n    filters: list | None = None,\n    filename: t.Union[str, Path] = None,\n    maxBytes: int = 100000,\n    backupCount: int = 3,\n    as_dict: bool = False,\n) -&gt; dict[str, dict[str, t.Any]] | RotatingFileHandlerConfig:\n    \"\"\"Return a RotatingFileHandlerConfig, or a dict representing a RotatingFileHandler.\n\n    Params:\n        name (str): The name for the rotating file handler. Reference this handler by name in a LoggerConfig.\n        level (str): The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        formatter (str): The name of a formatter that exists in the overall logging dictConfig.\n        filters (list[str] | None): A list of function names for logging filters.\n        filename (str | Path): The full path to the log file you want to create. If parent directories do not exist,\n            this method will handle creating them.\n        maxBytes (int): The maximum size (in bytes) before a logfile is rotated.\n        backupCount (int): The number of backups to keep as log files rotate.\n        as_dict (bool): If `True`, return the configuration as a dict that can be joined into `dictConfig()`.\n\n    Returns:\n        (dict[str, dict[str, Any]]): If `as_dict=True`, return a config dict instead of a RotatingFileHandlerConfig object.\n        (RotatingFileHandlerConfig): If `as_dict=False`, return a RotatingFileHandlerConfig object.\n\n    \"\"\"\n    ## Convert &amp; optionally expand input path\n    filename: Path = Path(f\"{filename}\")\n    if \"~\" in f\"{filename}\":\n        filename = filename.expanduser()\n\n    ## Create parent dirs for logging file, if they don't exist\n    ensure_logdir(p=filename.parent)\n\n    try:\n        ## Initialize handler object\n        _handler: RotatingFileHandlerConfig = RotatingFileHandlerConfig(\n            name=name,\n            level=level,\n            formatter=formatter,\n            filters=filters,\n            filename=filename,\n            maxBytes=maxBytes,\n            backupCount=backupCount,\n        )\n\n        if as_dict:\n            ## Return handler representation as a dict\n            return _handler.get_configdict()\n        else:\n            ## Return RotatingFileHandlerConfig object\n            return _handler\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception building RotatingFileHandlerConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.get_streamhandler_config","title":"<code>get_streamhandler_config(name='console', level='INFO', formatter='default', filters=None, stream='ext://sys.stdout', as_dict=False)</code>","text":"<p>Return a StreamHandlerConfig, or a dict representing a StreamingHandler.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name for the stream handler. Reference this handler by name in a LoggerConfig.</p> <code>'console'</code> <code>level</code> <code>str</code> <p>The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).</p> <code>'INFO'</code> <code>formatter</code> <code>str</code> <p>The name of a formatter that exists in the overall logging dictConfig.</p> <code>'default'</code> <code>filters</code> <code>list[str] | None</code> <p>A list of function names for logging filters.</p> <code>None</code> <code>stream</code> <code>str</code> <p>The stream this handler should use, i.e. <code>ext://sys.stdout</code>, <code>ext://sys.stderr</code>, etc.</p> <code>'ext://sys.stdout'</code> <code>as_dict</code> <code>bool</code> <p>If <code>True</code>, return the configuration as a dict that can be joined into <code>dictConfig()</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>If <code>as_dict=True</code>, return a config dict instead of a StreamHandlerConfig object.</p> <code>StreamHandlerConfig</code> <p>If <code>as_dict=False</code>, return a StreamHandlerConfig object.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def get_streamhandler_config(\n    name: str = \"console\",\n    level: str = \"INFO\",\n    formatter: str = \"default\",\n    filters: list | None = None,\n    stream: str = \"ext://sys.stdout\",\n    as_dict: bool = False,\n) -&gt; dict[str, dict[str, str]] | StreamHandlerConfig:\n    \"\"\"Return a StreamHandlerConfig, or a dict representing a StreamingHandler.\n\n    Params:\n        name (str): The name for the stream handler. Reference this handler by name in a LoggerConfig.\n        level (str): The logging level for this handler (NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        formatter (str): The name of a formatter that exists in the overall logging dictConfig.\n        filters (list[str] | None): A list of function names for logging filters.\n        stream (str): The stream this handler should use, i.e. `ext://sys.stdout`, `ext://sys.stderr`, etc.\n        as_dict (bool): If `True`, return the configuration as a dict that can be joined into `dictConfig()`.\n\n    Returns:\n        (dict[str, dict[str, Any]]): If `as_dict=True`, return a config dict instead of a StreamHandlerConfig object.\n        (StreamHandlerConfig): If `as_dict=False`, return a StreamHandlerConfig object.\n\n    \"\"\"\n    try:\n        ## Initialize handler object\n        _handler: StreamHandlerConfig = StreamHandlerConfig(\n            name=name, level=level, formatter=formatter, filters=filters, stream=stream\n        )\n\n        if as_dict:\n            ## Return handler representation as a dict\n            return _handler.get_configdict()\n        else:\n            ## Return StreamHandlerConfig object\n            return _handler\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception building StreamHandlerConfig. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.print_configdict","title":"<code>print_configdict(logging_config=None)</code>","text":"<p>Print a logging config dict as a JSON string.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def print_configdict(logging_config: dict = None) -&gt; None:\n    \"\"\"Print a logging config dict as a JSON string.\"\"\"\n    assert logging_config, ValueError(\"Missing a logging dictConfig to print.\")\n\n    print_msg: str = json.dumps(logging_config)\n\n    print(f\"Logging config dict:\\n{print_msg}\")\n</code></pre>"},{"location":"reference/red_utils/std/logging_utils/helpers/__methods/#red_utils.std.logging_utils.helpers.__methods.save_configdict","title":"<code>save_configdict(logging_config=None, output_file=Path('logging_config.json'), overwrite=False)</code>","text":"<p>Save a logging dictConfig to a JSON file.</p> Source code in <code>src\\red_utils\\std\\logging_utils\\helpers\\__methods.py</code> <pre><code>def save_configdict(\n    logging_config: dict = None,\n    output_file: t.Union[str, Path] = Path(\"logging_config.json\"),\n    overwrite: bool = False,\n) -&gt; None:\n    \"\"\"Save a logging dictConfig to a JSON file.\"\"\"\n    output_file: Path = Path(f\"{output_file}\")\n    if \"~\" in f\"{output_file}\":\n        output_file = output_file.expanduser()\n\n    ensure_logdir(p=output_file.parent)\n\n    if output_file.exists() and not overwrite:\n        log.warning(\n            f\"Logging dictConfig already saved to file '{output_file}' and overwrite=False. Skipping.\"\n        )\n\n        return\n\n    try:\n        config_json = json.dumps(logging_config, indent=2)\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception converting logging dict to JSON. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n\n    try:\n        with open(output_file, \"w\") as f:\n            f.write(config_json)\n    except PermissionError as perm_err:\n        msg = Exception(\n            f\"Permission denied saving logging dictConfig to file '{output_file}'. Details: {perm_err}\"\n        )\n        log.error(msg)\n\n        raise perm_err\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception saving logging dictConfig to JSON file '{output_file}'. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/path_utils/__init__/","title":"path_utils","text":"<p>Utilities for interacting with the Python <code>pathlib</code> module.</p>"},{"location":"reference/red_utils/std/path_utils/__init__/#red_utils.std.path_utils.crawl_dir","title":"<code>crawl_dir(target=None, filetype_filter=None, return_type='all')</code>","text":"<p>Crawl a directory and return an object with all found files &amp; dirs.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str | Path</code> <p>The target directory to crawl</p> <code>None</code> <code>filetype_filter</code> <code>str</code> <p>An optional filetype filter str; only files matching this filter will be returned</p> <code>None</code> <code>return_type</code> <code>str</code> <p>Return <code>files</code>, <code>dirs</code>, or <code>all</code></p> <code>'all'</code> <p>Returns:</p> Type Description <code>list[Path]</code> <p>A list of <code>Path</code> objects if <code>return_type</code> is <code>dirs</code> or <code>files</code></p> <code>dict[str, list[Path]]</code> <p>If <code>return_type</code> is <code>all</code>, return a dict <code>{\"file\": [], \"dirs\": []}</code></p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When input validation fails</p> <code>FileNotFoundError</code> <p>When a file/directory path cannot be found</p> Source code in <code>src\\red_utils\\std\\path_utils\\operations.py</code> <pre><code>def crawl_dir(\n    target: Union[str, Path] = None,\n    filetype_filter: str | None = None,\n    return_type: str = \"all\",\n) -&gt; Union[dict[str, list[Path]]]:\n    \"\"\"Crawl a directory and return an object with all found files &amp; dirs.\n\n    Params:\n        target (str | Path): The target directory to crawl\n        filetype_filter (str): An optional filetype filter str; only files matching this filter will be returned\n        return_type (str): Return `files`, `dirs`, or `all`\n\n    Returns:\n        (list[Path]): A list of `Path` objects if `return_type` is `dirs` or `files`\n        (dict[str, list[Path]]): If `return_type` is `all`, return a dict `{\"file\": [], \"dirs\": []}`\n\n    Raises:\n        ValueError: When input validation fails\n        FileNotFoundError: When a file/directory path cannot be found\n\n    \"\"\"\n\n    def validate_target(target: Union[str, Path] = target) -&gt; Path:\n        \"\"\"Validate a target path.\n\n        Params:\n            target (str, Path): The path to validate\n\n        Returns:\n            (Path): A Python `Path` object\n\n        Raises:\n            ValueError: When input validation fails\n            FileNotFoundError: When the path to validate does not exist\n\n        \"\"\"\n        if target is None:\n            raise ValueError(\"Missing a target directory to scan\")\n        target: Path = Path(f\"{target}\")\n        if \"~\" in f\"{target}\":\n            target: Path = target.expanduser()\n        if not target.exists():\n            exc = FileNotFoundError(f\"Could not find directory: {target}\")\n            log.error(exc)\n\n            raise exc\n\n        return target\n\n    def validate_return_type(\n        return_type: str = return_type,\n        VALID_RETURN_TYPES: list[str] = VALID_RETURN_TYPES,\n    ) -&gt; str:\n        \"\"\"Validate a return type.\n\n        Params:\n            return_type (str): The `return_type` string to validate\n            VALID_RETURN_TYPES `list[str]`: Valid options for the `return_type` string. Defaults to a predefined list of `[\"all\", \"files\", \"dirs\"]`\n\n        Returns:\n            (str): The validated `return_type` string\n\n        Raises:\n            ValueError: When input validation fails\n            TypeError: When input value is not a `str`\n\n        \"\"\"\n        if return_type is None:\n            raise ValueError(\"Missing return type\")\n        if not isinstance(return_type, str):\n            raise TypeError(\n                f\"Invalid type for return_type: ({type(return_type)}). Must be one of {VALID_RETURN_TYPES}\"\n            )\n        if return_type not in VALID_RETURN_TYPES:\n            exc = ValueError(\n                f\"Invalid return type: {return_type}. Must be one of: {VALID_RETURN_TYPES}\"\n            )\n            log.error(exc)\n\n            raise exc\n\n        return return_type\n\n    def _crawl(\n        target=target, search_str: str = \"**/*\", return_type=return_type\n    ) -&gt; Union[dict[str, list[Path]], list[Path]]:\n        \"\"\"Run Path crawl.\n\n        Inherits `target`, `search_str`, and `return_type` from parent method that calls this function.\n        \"\"\"\n        return_obj: dict[str, list[Path]] = {\"files\": [], \"dirs\": []}\n\n        log.info(f\"Crawling target: {target} ...\")\n\n        for i in target.glob(search_str):\n            if i.is_file():\n                if return_type in [\"all\", \"files\"]:\n                    return_obj[\"files\"].append(i)\n                else:\n                    pass\n            else:\n                if return_type in [\"all\", \"dirs\"]:\n                    return_obj[\"dirs\"].append(i)\n\n        match return_type:\n            case \"all\":\n                return return_obj\n            case \"files\":\n                return return_obj[\"files\"]\n            case \"dirs\":\n                return return_obj[\"dirs\"]\n\n    if filetype_filter:\n        if not isinstance(filetype_filter, str):\n            raise TypeError(\n                f\"Invalid type for filetype_filter: ({type(filetype_filter)}). Must be of type str\"\n            )\n        if not filetype_filter.startswith(\".\"):\n            filetype_filter: str = f\".{filetype_filter}\"\n\n        search_str: str = f\"**/*{filetype_filter}\"\n    else:\n        search_str: str = \"**/*\"\n\n    target: Path = validate_target()\n    return_type: str = validate_return_type()\n\n    return_obj = _crawl(target=target, search_str=search_str, return_type=return_type)\n\n    return return_obj\n</code></pre>"},{"location":"reference/red_utils/std/path_utils/__init__/#red_utils.std.path_utils.delete_path","title":"<code>delete_path(rm_path=None)</code>","text":"<p>Recursively delete a path.</p> <p>Parameters:</p> Name Type Description Default <code>rm_path</code> <code>str | Path</code> <p>The path to delete</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>rm_path</code> deleted successfully</p> <code>bool</code> <p><code>False</code> if <code>rm_path</code> not deleted successfully</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>When path to delete does not exist</p> <code>PermissionError</code> <p>When permission to delete the path is not granted</p> <code>Exception</code> <p>Generic <code>Exception</code> when operation fails and is not caught by another exception</p> Source code in <code>src\\red_utils\\std\\path_utils\\operations.py</code> <pre><code>def delete_path(rm_path: Union[str, Path] = None) -&gt; bool:\n    \"\"\"Recursively delete a path.\n\n    Params:\n        rm_path (str | Path): The path to delete\n\n    Returns:\n        (bool): `True` if `rm_path` deleted successfully\n        (bool): `False` if `rm_path` not deleted successfully\n\n    Raises:\n        FileNotFoundError: When path to delete does not exist\n        PermissionError: When permission to delete the path is not granted\n        Exception: Generic `Exception` when operation fails and is not caught by another exception\n\n    \"\"\"\n    if rm_path is None:\n        raise ValueError(\"Missing a path to remove.\")\n    if isinstance(rm_path, str):\n        rm_path: Path = Path(rm_path)\n\n    try:\n        if rm_path.is_file():\n            rm_path.unlink()\n        elif rm_path.is_dir():\n            shutil.rmtree(rm_path)\n\n        return True\n\n    except FileNotFoundError as fnf:\n        msg = Exception(f\"Could not find file {str(rm_path)}. Details: {fnf}\")\n        log.error(msg)\n\n        return False\n    except PermissionError as perm:\n        msg = Exception(\n            f\"Insufficient permissions to delete file {str(rm_path)}. Details: {perm}\"\n        )\n        log.error(msg)\n\n        return False\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception deleting file {str(rm_path)}. Details: {exc}\"\n        )\n        log.error(msg)\n\n        return False\n</code></pre>"},{"location":"reference/red_utils/std/path_utils/__init__/#red_utils.std.path_utils.ensure_dirs_exist","title":"<code>ensure_dirs_exist(ensure_dirs=None)</code>","text":"<p>Loop over a list of directories and create any paths that do not already exist.</p> <p>Parameters:</p> Name Type Description Default <code>ensure_dirs</code> <code>list[str] | list[Path]</code> <p>A list of directory paths formatted as strings or Path objects. If any list item is of type str, it will be converted to a Path.</p> <code>None</code> Source code in <code>src\\red_utils\\std\\path_utils\\operations.py</code> <pre><code>def ensure_dirs_exist(ensure_dirs: list[Union[str, Path]] = None) -&gt; None:\n    \"\"\"Loop over a list of directories and create any paths that do not already exist.\n\n    Params:\n        ensure_dirs (list[str]|list[Path]): A list of directory paths formatted as strings or Path objects.\n            If any list item is of type str, it will be converted to a Path.\n    \"\"\"\n    if not ensure_dirs:\n        raise ValueError(\"Missing list of directories to ensure existence\")\n\n    validated_list: list[Path] = []\n\n    for i in ensure_dirs:\n        if isinstance(i, str):\n            i = Path(i)\n            validated_list.append(i)\n        elif isinstance(i, Path):\n            validated_list.append(i)\n        else:\n            log.error(\n                ValueError(\n                    f\"Invalid type for list item: ({type(i)}). Must be of type str or Path.\"\n                )\n            )\n            pass\n\n    ensure_dirs = validated_list\n\n    for d in ensure_dirs:\n        if not d.exists():\n            try:\n                d.mkdir(exist_ok=True, parents=True)\n            except Exception as exc:\n                msg = Exception(\n                    f\"Unhandled exception creating directory: {d}. Details: {exc}\"\n                )\n                log.error(msg)\n                pass\n</code></pre>"},{"location":"reference/red_utils/std/path_utils/__init__/#red_utils.std.path_utils.export_json","title":"<code>export_json(input=None, output_dir=JSON_DIR, output_filename=f'{file_ts()}_unnamed_json.json')</code>","text":"<p>Export JSON object to an output file.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str | list[list, dict] | dict[str, Any]</code> <p>The input object to be output to a file.</p> <code>None</code> <code>output_dir</code> <code>str</code> <p>The directory where a .json file will be saved.</p> <code>JSON_DIR</code> <code>output_filename</code> <code>str</code> <p>The name of the file that will be saved in output_dir.</p> <code>f'{file_ts()}_unnamed_json.json'</code> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>When the output path already exists</p> <code>FileNotFoundError</code> <p>When the export path does not exist</p> <code>Exception</code> <p>When other exceptions have not been caught, a generic <code>Exception</code> is raised</p> Source code in <code>src\\red_utils\\std\\path_utils\\operations.py</code> <pre><code>def export_json(\n    input: Union[str, list[list, dict], dict[str, Any]] = None,\n    output_dir: str = JSON_DIR,\n    output_filename: str = f\"{file_ts()}_unnamed_json.json\",\n):\n    \"\"\"Export JSON object to an output file.\n\n    Params:\n        input (str|list[list,dict]|dict[str,Any]): The input object to be output to a file.\n        output_dir (str): The directory where a .json file will be saved.\n        output_filename (str): The name of the file that will be saved in output_dir.\n\n    Raises:\n        FileExistsError: When the output path already exists\n        FileNotFoundError: When the export path does not exist\n        Exception: When other exceptions have not been caught, a generic `Exception` is raised\n\n    \"\"\"\n    if not Path(output_dir).exists():\n        Path(output_dir).mkdir(parents=True, exist_ok=True)\n\n    if isinstance(input, dict):\n        input = json.dumps(input)\n\n    if Path(f\"{output_dir}/{output_filename}\").exists():\n        raise FileExistsError(\n            f\"JSON file already exists: {output_dir}/{output_filename}\"\n        )\n\n    if output_dir.endswith(\"/\"):\n        output_dir = output_dir[:-1]\n\n    if not output_filename.endswith(\".json\"):\n        output_filename = f\"{output_filename}.json\"\n\n    output_path: str = f\"{output_dir}/{output_filename}\"\n\n    log.debug(f\"Output path: {output_path}\")\n\n    if not Path(output_path).exists():\n        try:\n            with open(output_path, \"w+\") as f:\n                f.write(input)\n        except FileExistsError as file_exists_exc:\n            log.error(file_exists_exc)\n\n            raise file_exists_exc\n        except FileNotFoundError as file_not_found_exc:\n            log.error(file_not_found_exc)\n            raise file_not_found_exc\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception writing JSON to file: {output_path}. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/std/path_utils/__init__/#red_utils.std.path_utils.extract_file_ext","title":"<code>extract_file_ext(path=None)</code>","text":"<p>Extract full file extension from a Path.</p> Description <p>Given a file with multiple file extensions, i.e. <code>file.tar.gz</code>, this function will join all suffixes (<code>.tar</code>, <code>.gz</code>) into a single string. A <code>Path.suffix</code> on its own only returns the last suffix (i.e. <code>.gz</code>).</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>A <code>pathlib.Path</code> object to a file. Path is checked with <code>.is_file()</code>, skipping directories passed by mistake.</p> <code>None</code> Source code in <code>src\\red_utils\\std\\path_utils\\operations.py</code> <pre><code>def extract_file_ext(path: Path = None) -&gt; str:\n    \"\"\"Extract full file extension from a Path.\n\n    Description:\n        Given a file with multiple file extensions, i.e. `file.tar.gz`,\n        this function will join all suffixes (`.tar`, `.gz`) into a single string.\n        A `Path.suffix` on its own only returns the last suffix (i.e. `.gz`).\n\n    Params:\n        path (Path): A `pathlib.Path` object to a file. Path is checked with `.is_file()`, skipping directories passed by mistake.\n\n    \"\"\"\n    assert path, ValueError(\"Missing a file path\")\n    assert isinstance(path, Path), TypeError(\n        f\"path must be a pathlib.Path object. Got type: ({type(path)})\"\n    )\n    if not path.is_file():\n        log.error(\n            ValueError(f\"[WARNING] path should be a file, but {path} is a directory.\")\n        )\n\n        return \"\"\n\n    ## Extract all suffixes from file path\n    suffixes: list[str] = path.suffixes\n\n    if len(suffixes) &gt; 1:\n        ## Join suffixes, i.e. [\".tar\", \".gz\"] -&gt; \".tar.gz\"\n        return \"\".join(suffixes)\n\n    elif len(suffixes) == 1:\n        ## Return [\".suffix\"] -&gt; \".suffix\"\n        return suffixes[0]\n\n    else:\n        ## No suffix(es) detected, return empty string\n\n        return \"\"\n</code></pre>"},{"location":"reference/red_utils/std/path_utils/__init__/#red_utils.std.path_utils.file_ts","title":"<code>file_ts(fmt='%Y-%m-%d_%H:%M:%S')</code>","text":"<p>Return a formatted timestamp, useful for prepending to dir/file names.</p> <p>Parameters:</p> Name Type Description Default <code>fmt</code> <code>str</code> <p>String that defines the format of a timestamp</p> <code>'%Y-%m-%d_%H:%M:%S'</code> <p>Returns:</p> Type Description <code>str</code> <p>A formatted datetime string</p> Source code in <code>src\\red_utils\\std\\path_utils\\operations.py</code> <pre><code>def file_ts(fmt: str = \"%Y-%m-%d_%H:%M:%S\") -&gt; str:\n    \"\"\"Return a formatted timestamp, useful for prepending to dir/file names.\n\n    Params:\n        fmt (str): String that defines the format of a timestamp\n\n    Returns:\n        (str): A formatted datetime string\n\n    \"\"\"\n    now: str = datetime.now().strftime(fmt)\n\n    return now\n</code></pre>"},{"location":"reference/red_utils/std/path_utils/__init__/#red_utils.std.path_utils.list_files","title":"<code>list_files(in_dir=None, ext_filter=None, return_files=[])</code>","text":"<p>List all files in a path, optionally filtering by file extension.</p> <p>Parameters:</p> Name Type Description Default <code>in_dir</code> <code>str</code> <p>Directory path to scan</p> <code>None</code> <code>ext_filter</code> <code>str</code> <p>Filetype to search for</p> <code>None</code> <code>return_files</code> <code>list[Path]</code> <p>Used by the function to recurse through subdirectories</p> <code>[]</code> <p>Returns:</p> Type Description <code>list[Path]</code> <p>A list of found files, represented as <code>Path</code> objects</p> Source code in <code>src\\red_utils\\std\\path_utils\\operations.py</code> <pre><code>def list_files(\n    in_dir: str = None, ext_filter: str = None, return_files: list[Path] = []\n) -&gt; list[Path]:\n    \"\"\"List all files in a path, optionally filtering by file extension.\n\n    Params:\n        in_dir (str): Directory path to scan\n        ext_filter (str): Filetype to search for\n        return_files (list[Path]): Used by the function to recurse through subdirectories\n\n    Returns:\n        (list[Path]): A list of found files, represented as `Path` objects\n\n    \"\"\"\n    if not in_dir:\n        raise ValueError(\"Missing input directory to search\")\n    if ext_filter is not None:\n        if not ext_filter.startswith(\".\"):\n            ext_filter = f\".{ext_filter}\"\n\n    if ext_filter:\n        search_str: str = f\"**/*{ext_filter}\"\n    else:\n        search_str: str = \"**/*\"\n\n    return_files: list[Path] = []\n\n    try:\n        for _p in Path(in_dir).glob(search_str):\n            if _p.is_file():\n                return_files.append(_p)\n            elif _p.is_dir():\n                list_files(in_dir=_p, ext_filter=ext_filter, return_files=return_files)\n\n        return return_files\n\n    except FileNotFoundError as fnf:\n        msg = Exception(f\"Could not find input path: {in_dir}. Details: {fnf}\")\n        log.error(msg)\n\n        raise fnf\n    except PermissionError as perm:\n        msg = Exception(f\"Could not open path: {in_dir}. Details: {perm}\")\n        log.error(msg)\n\n        raise perm\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception looping input path: {in_dir}. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/path_utils/__init__/#red_utils.std.path_utils.scan_dir","title":"<code>scan_dir(target=None, as_str=False, as_pathlib=False, return_type='all')</code>","text":"<p>Return a list of path strings found in self.path.</p> <p>Parameters:</p> Name Type Description Default <code>as_str</code> <code>bool</code> <p>If <code>True</code>, returns a list of paths formatted as Python strings.</p> <code>False</code> <code>as_pathlib</code> <code>bool</code> <p>If <code>True</code>, returns a list of paths formatted as Python <code>pathlib.Path</code> objects.</p> <code>False</code> <code>return_type</code> <code>str</code> <p>Control return type. Options:     - <code>all</code>: Return both files &amp; dirs     - <code>files</code>: Return only files     - <code>dirs</code>: Return only dirs</p> <code>'all'</code> <p>Returns:</p> Type Description <code>Union[list[DirEntry, str, Path]]</code> <p>list[os.DirEntry]: (default) If <code>as_str = False</code></p> <code>Union[list[DirEntry, str, Path]]</code> <p>list[str]: If <code>as_str = True</code></p> <code>Union[list[DirEntry, str, Path]]</code> <p>list[pathlib.Path]: If <code>as_str = False</code> and <code>as_pathlib = True</code>.</p> Source code in <code>src\\red_utils\\std\\path_utils\\operations.py</code> <pre><code>def scan_dir(\n    target: Union[str, Path] = None,\n    as_str: bool = False,\n    as_pathlib: bool = False,\n    return_type: str = \"all\",\n) -&gt; Union[list[os.DirEntry, str, Path]]:\n    \"\"\"Return a list of path strings found in self.path.\n\n    Params:\n        as_str (bool): If `True`, returns a list of paths formatted as Python strings.\n        as_pathlib (bool): If `True`, returns a list of paths formatted as Python `pathlib.Path` objects.\n        return_type (str): Control return type.\n            Options:\n                - `all`: Return both files &amp; dirs\n                - `files`: Return only files\n                - `dirs`: Return only dirs\n\n    Returns:\n        list[os.DirEntry]: (default) If `as_str = False`\n        list[str]: If `as_str = True`\n        list[pathlib.Path]: If `as_str = False` and `as_pathlib = True`.\n\n    \"\"\"\n    ## Validate return_type\n    if not return_type:\n        log.warning(\"return_type cannot be None. Defaulting to 'all'.\")\n        return_type = \"all\"\n    else:\n        return_type: str = return_type.lower()\n        assert isinstance(return_type, str), TypeError(\n            f\"return_type must be of type str. Got type: {type(return_type)}\"\n        )\n        assert return_type in VALID_RETURN_TYPES, ValueError(\n            f\"Invalid return type: '{return_type}'. Must be one of {VALID_RETURN_TYPES}\"\n        )\n\n    ## Validate as_str/as_pathlib\n    if as_str and as_pathlib:\n        log.warning(\n            \"as_str and as_pathlib cannot both be true. Defaulting to as_str=True, as_pathlib=False\"\n        )\n        as_pathlib = False\n\n    ## Validate target\n    assert target is not None, ValueError(\"target cannot be None\")\n    assert isinstance(target, str) or isinstance(target, Path), TypeError(\n        f\"target must be of type str or pathlib.Path. Got type: {type(target)}\"\n    )\n    target: Path = Path(f\"{target}\")\n    if \"~\" in f\"{target}\":\n        target: Path = target.expanduser()\n\n    assert target.exists(), FileNotFoundError(\n        f\"Could not find target path: '{target}'.\"\n    )\n\n    ## Initialize empty list to store found paths\n    paths: list[os.DirEntry] = []\n\n    ## Scan target directory\n    for p in os.scandir(target):\n        if return_type == \"all\":\n            ## Append path\n            paths.append(p)\n        elif return_type == \"files\":\n            if Path(p.path).is_file():\n                ## Append file path\n                paths.append(p)\n        elif return_type == \"dirs\":\n            if Path(p.path).is_dir():\n                ## Append dir path\n                paths.append(p)\n\n    if as_str:\n        ## Convert all found paths to str type\n        _paths: list[str] = []\n\n        for p in paths:\n            _path: str = p.path\n\n            _paths.append(_path)\n\n        return _paths\n\n    elif as_pathlib:\n        ## Convert all found paths to pathlib.Path type\n        _paths: list[Path] = []\n\n        for p in paths:\n            _path: Path = Path(p.path)\n            _paths.append(_path)\n\n        return _paths\n\n    else:\n        ## Return list of os.DirEntry types\n        return paths\n</code></pre>"},{"location":"reference/red_utils/std/path_utils/constants/","title":"constants","text":""},{"location":"reference/red_utils/std/path_utils/operations/","title":"operations","text":""},{"location":"reference/red_utils/std/path_utils/operations/#red_utils.std.path_utils.operations.crawl_dir","title":"<code>crawl_dir(target=None, filetype_filter=None, return_type='all')</code>","text":"<p>Crawl a directory and return an object with all found files &amp; dirs.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str | Path</code> <p>The target directory to crawl</p> <code>None</code> <code>filetype_filter</code> <code>str</code> <p>An optional filetype filter str; only files matching this filter will be returned</p> <code>None</code> <code>return_type</code> <code>str</code> <p>Return <code>files</code>, <code>dirs</code>, or <code>all</code></p> <code>'all'</code> <p>Returns:</p> Type Description <code>list[Path]</code> <p>A list of <code>Path</code> objects if <code>return_type</code> is <code>dirs</code> or <code>files</code></p> <code>dict[str, list[Path]]</code> <p>If <code>return_type</code> is <code>all</code>, return a dict <code>{\"file\": [], \"dirs\": []}</code></p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When input validation fails</p> <code>FileNotFoundError</code> <p>When a file/directory path cannot be found</p> Source code in <code>src\\red_utils\\std\\path_utils\\operations.py</code> <pre><code>def crawl_dir(\n    target: Union[str, Path] = None,\n    filetype_filter: str | None = None,\n    return_type: str = \"all\",\n) -&gt; Union[dict[str, list[Path]]]:\n    \"\"\"Crawl a directory and return an object with all found files &amp; dirs.\n\n    Params:\n        target (str | Path): The target directory to crawl\n        filetype_filter (str): An optional filetype filter str; only files matching this filter will be returned\n        return_type (str): Return `files`, `dirs`, or `all`\n\n    Returns:\n        (list[Path]): A list of `Path` objects if `return_type` is `dirs` or `files`\n        (dict[str, list[Path]]): If `return_type` is `all`, return a dict `{\"file\": [], \"dirs\": []}`\n\n    Raises:\n        ValueError: When input validation fails\n        FileNotFoundError: When a file/directory path cannot be found\n\n    \"\"\"\n\n    def validate_target(target: Union[str, Path] = target) -&gt; Path:\n        \"\"\"Validate a target path.\n\n        Params:\n            target (str, Path): The path to validate\n\n        Returns:\n            (Path): A Python `Path` object\n\n        Raises:\n            ValueError: When input validation fails\n            FileNotFoundError: When the path to validate does not exist\n\n        \"\"\"\n        if target is None:\n            raise ValueError(\"Missing a target directory to scan\")\n        target: Path = Path(f\"{target}\")\n        if \"~\" in f\"{target}\":\n            target: Path = target.expanduser()\n        if not target.exists():\n            exc = FileNotFoundError(f\"Could not find directory: {target}\")\n            log.error(exc)\n\n            raise exc\n\n        return target\n\n    def validate_return_type(\n        return_type: str = return_type,\n        VALID_RETURN_TYPES: list[str] = VALID_RETURN_TYPES,\n    ) -&gt; str:\n        \"\"\"Validate a return type.\n\n        Params:\n            return_type (str): The `return_type` string to validate\n            VALID_RETURN_TYPES `list[str]`: Valid options for the `return_type` string. Defaults to a predefined list of `[\"all\", \"files\", \"dirs\"]`\n\n        Returns:\n            (str): The validated `return_type` string\n\n        Raises:\n            ValueError: When input validation fails\n            TypeError: When input value is not a `str`\n\n        \"\"\"\n        if return_type is None:\n            raise ValueError(\"Missing return type\")\n        if not isinstance(return_type, str):\n            raise TypeError(\n                f\"Invalid type for return_type: ({type(return_type)}). Must be one of {VALID_RETURN_TYPES}\"\n            )\n        if return_type not in VALID_RETURN_TYPES:\n            exc = ValueError(\n                f\"Invalid return type: {return_type}. Must be one of: {VALID_RETURN_TYPES}\"\n            )\n            log.error(exc)\n\n            raise exc\n\n        return return_type\n\n    def _crawl(\n        target=target, search_str: str = \"**/*\", return_type=return_type\n    ) -&gt; Union[dict[str, list[Path]], list[Path]]:\n        \"\"\"Run Path crawl.\n\n        Inherits `target`, `search_str`, and `return_type` from parent method that calls this function.\n        \"\"\"\n        return_obj: dict[str, list[Path]] = {\"files\": [], \"dirs\": []}\n\n        log.info(f\"Crawling target: {target} ...\")\n\n        for i in target.glob(search_str):\n            if i.is_file():\n                if return_type in [\"all\", \"files\"]:\n                    return_obj[\"files\"].append(i)\n                else:\n                    pass\n            else:\n                if return_type in [\"all\", \"dirs\"]:\n                    return_obj[\"dirs\"].append(i)\n\n        match return_type:\n            case \"all\":\n                return return_obj\n            case \"files\":\n                return return_obj[\"files\"]\n            case \"dirs\":\n                return return_obj[\"dirs\"]\n\n    if filetype_filter:\n        if not isinstance(filetype_filter, str):\n            raise TypeError(\n                f\"Invalid type for filetype_filter: ({type(filetype_filter)}). Must be of type str\"\n            )\n        if not filetype_filter.startswith(\".\"):\n            filetype_filter: str = f\".{filetype_filter}\"\n\n        search_str: str = f\"**/*{filetype_filter}\"\n    else:\n        search_str: str = \"**/*\"\n\n    target: Path = validate_target()\n    return_type: str = validate_return_type()\n\n    return_obj = _crawl(target=target, search_str=search_str, return_type=return_type)\n\n    return return_obj\n</code></pre>"},{"location":"reference/red_utils/std/path_utils/operations/#red_utils.std.path_utils.operations.delete_path","title":"<code>delete_path(rm_path=None)</code>","text":"<p>Recursively delete a path.</p> <p>Parameters:</p> Name Type Description Default <code>rm_path</code> <code>str | Path</code> <p>The path to delete</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>rm_path</code> deleted successfully</p> <code>bool</code> <p><code>False</code> if <code>rm_path</code> not deleted successfully</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>When path to delete does not exist</p> <code>PermissionError</code> <p>When permission to delete the path is not granted</p> <code>Exception</code> <p>Generic <code>Exception</code> when operation fails and is not caught by another exception</p> Source code in <code>src\\red_utils\\std\\path_utils\\operations.py</code> <pre><code>def delete_path(rm_path: Union[str, Path] = None) -&gt; bool:\n    \"\"\"Recursively delete a path.\n\n    Params:\n        rm_path (str | Path): The path to delete\n\n    Returns:\n        (bool): `True` if `rm_path` deleted successfully\n        (bool): `False` if `rm_path` not deleted successfully\n\n    Raises:\n        FileNotFoundError: When path to delete does not exist\n        PermissionError: When permission to delete the path is not granted\n        Exception: Generic `Exception` when operation fails and is not caught by another exception\n\n    \"\"\"\n    if rm_path is None:\n        raise ValueError(\"Missing a path to remove.\")\n    if isinstance(rm_path, str):\n        rm_path: Path = Path(rm_path)\n\n    try:\n        if rm_path.is_file():\n            rm_path.unlink()\n        elif rm_path.is_dir():\n            shutil.rmtree(rm_path)\n\n        return True\n\n    except FileNotFoundError as fnf:\n        msg = Exception(f\"Could not find file {str(rm_path)}. Details: {fnf}\")\n        log.error(msg)\n\n        return False\n    except PermissionError as perm:\n        msg = Exception(\n            f\"Insufficient permissions to delete file {str(rm_path)}. Details: {perm}\"\n        )\n        log.error(msg)\n\n        return False\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception deleting file {str(rm_path)}. Details: {exc}\"\n        )\n        log.error(msg)\n\n        return False\n</code></pre>"},{"location":"reference/red_utils/std/path_utils/operations/#red_utils.std.path_utils.operations.ensure_dirs_exist","title":"<code>ensure_dirs_exist(ensure_dirs=None)</code>","text":"<p>Loop over a list of directories and create any paths that do not already exist.</p> <p>Parameters:</p> Name Type Description Default <code>ensure_dirs</code> <code>list[str] | list[Path]</code> <p>A list of directory paths formatted as strings or Path objects. If any list item is of type str, it will be converted to a Path.</p> <code>None</code> Source code in <code>src\\red_utils\\std\\path_utils\\operations.py</code> <pre><code>def ensure_dirs_exist(ensure_dirs: list[Union[str, Path]] = None) -&gt; None:\n    \"\"\"Loop over a list of directories and create any paths that do not already exist.\n\n    Params:\n        ensure_dirs (list[str]|list[Path]): A list of directory paths formatted as strings or Path objects.\n            If any list item is of type str, it will be converted to a Path.\n    \"\"\"\n    if not ensure_dirs:\n        raise ValueError(\"Missing list of directories to ensure existence\")\n\n    validated_list: list[Path] = []\n\n    for i in ensure_dirs:\n        if isinstance(i, str):\n            i = Path(i)\n            validated_list.append(i)\n        elif isinstance(i, Path):\n            validated_list.append(i)\n        else:\n            log.error(\n                ValueError(\n                    f\"Invalid type for list item: ({type(i)}). Must be of type str or Path.\"\n                )\n            )\n            pass\n\n    ensure_dirs = validated_list\n\n    for d in ensure_dirs:\n        if not d.exists():\n            try:\n                d.mkdir(exist_ok=True, parents=True)\n            except Exception as exc:\n                msg = Exception(\n                    f\"Unhandled exception creating directory: {d}. Details: {exc}\"\n                )\n                log.error(msg)\n                pass\n</code></pre>"},{"location":"reference/red_utils/std/path_utils/operations/#red_utils.std.path_utils.operations.export_json","title":"<code>export_json(input=None, output_dir=JSON_DIR, output_filename=f'{file_ts()}_unnamed_json.json')</code>","text":"<p>Export JSON object to an output file.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str | list[list, dict] | dict[str, Any]</code> <p>The input object to be output to a file.</p> <code>None</code> <code>output_dir</code> <code>str</code> <p>The directory where a .json file will be saved.</p> <code>JSON_DIR</code> <code>output_filename</code> <code>str</code> <p>The name of the file that will be saved in output_dir.</p> <code>f'{file_ts()}_unnamed_json.json'</code> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>When the output path already exists</p> <code>FileNotFoundError</code> <p>When the export path does not exist</p> <code>Exception</code> <p>When other exceptions have not been caught, a generic <code>Exception</code> is raised</p> Source code in <code>src\\red_utils\\std\\path_utils\\operations.py</code> <pre><code>def export_json(\n    input: Union[str, list[list, dict], dict[str, Any]] = None,\n    output_dir: str = JSON_DIR,\n    output_filename: str = f\"{file_ts()}_unnamed_json.json\",\n):\n    \"\"\"Export JSON object to an output file.\n\n    Params:\n        input (str|list[list,dict]|dict[str,Any]): The input object to be output to a file.\n        output_dir (str): The directory where a .json file will be saved.\n        output_filename (str): The name of the file that will be saved in output_dir.\n\n    Raises:\n        FileExistsError: When the output path already exists\n        FileNotFoundError: When the export path does not exist\n        Exception: When other exceptions have not been caught, a generic `Exception` is raised\n\n    \"\"\"\n    if not Path(output_dir).exists():\n        Path(output_dir).mkdir(parents=True, exist_ok=True)\n\n    if isinstance(input, dict):\n        input = json.dumps(input)\n\n    if Path(f\"{output_dir}/{output_filename}\").exists():\n        raise FileExistsError(\n            f\"JSON file already exists: {output_dir}/{output_filename}\"\n        )\n\n    if output_dir.endswith(\"/\"):\n        output_dir = output_dir[:-1]\n\n    if not output_filename.endswith(\".json\"):\n        output_filename = f\"{output_filename}.json\"\n\n    output_path: str = f\"{output_dir}/{output_filename}\"\n\n    log.debug(f\"Output path: {output_path}\")\n\n    if not Path(output_path).exists():\n        try:\n            with open(output_path, \"w+\") as f:\n                f.write(input)\n        except FileExistsError as file_exists_exc:\n            log.error(file_exists_exc)\n\n            raise file_exists_exc\n        except FileNotFoundError as file_not_found_exc:\n            log.error(file_not_found_exc)\n            raise file_not_found_exc\n        except Exception as exc:\n            msg = Exception(\n                f\"Unhandled exception writing JSON to file: {output_path}. Details: {exc}\"\n            )\n            log.error(msg)\n\n            raise exc\n</code></pre>"},{"location":"reference/red_utils/std/path_utils/operations/#red_utils.std.path_utils.operations.extract_file_ext","title":"<code>extract_file_ext(path=None)</code>","text":"<p>Extract full file extension from a Path.</p> Description <p>Given a file with multiple file extensions, i.e. <code>file.tar.gz</code>, this function will join all suffixes (<code>.tar</code>, <code>.gz</code>) into a single string. A <code>Path.suffix</code> on its own only returns the last suffix (i.e. <code>.gz</code>).</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>A <code>pathlib.Path</code> object to a file. Path is checked with <code>.is_file()</code>, skipping directories passed by mistake.</p> <code>None</code> Source code in <code>src\\red_utils\\std\\path_utils\\operations.py</code> <pre><code>def extract_file_ext(path: Path = None) -&gt; str:\n    \"\"\"Extract full file extension from a Path.\n\n    Description:\n        Given a file with multiple file extensions, i.e. `file.tar.gz`,\n        this function will join all suffixes (`.tar`, `.gz`) into a single string.\n        A `Path.suffix` on its own only returns the last suffix (i.e. `.gz`).\n\n    Params:\n        path (Path): A `pathlib.Path` object to a file. Path is checked with `.is_file()`, skipping directories passed by mistake.\n\n    \"\"\"\n    assert path, ValueError(\"Missing a file path\")\n    assert isinstance(path, Path), TypeError(\n        f\"path must be a pathlib.Path object. Got type: ({type(path)})\"\n    )\n    if not path.is_file():\n        log.error(\n            ValueError(f\"[WARNING] path should be a file, but {path} is a directory.\")\n        )\n\n        return \"\"\n\n    ## Extract all suffixes from file path\n    suffixes: list[str] = path.suffixes\n\n    if len(suffixes) &gt; 1:\n        ## Join suffixes, i.e. [\".tar\", \".gz\"] -&gt; \".tar.gz\"\n        return \"\".join(suffixes)\n\n    elif len(suffixes) == 1:\n        ## Return [\".suffix\"] -&gt; \".suffix\"\n        return suffixes[0]\n\n    else:\n        ## No suffix(es) detected, return empty string\n\n        return \"\"\n</code></pre>"},{"location":"reference/red_utils/std/path_utils/operations/#red_utils.std.path_utils.operations.file_ts","title":"<code>file_ts(fmt='%Y-%m-%d_%H:%M:%S')</code>","text":"<p>Return a formatted timestamp, useful for prepending to dir/file names.</p> <p>Parameters:</p> Name Type Description Default <code>fmt</code> <code>str</code> <p>String that defines the format of a timestamp</p> <code>'%Y-%m-%d_%H:%M:%S'</code> <p>Returns:</p> Type Description <code>str</code> <p>A formatted datetime string</p> Source code in <code>src\\red_utils\\std\\path_utils\\operations.py</code> <pre><code>def file_ts(fmt: str = \"%Y-%m-%d_%H:%M:%S\") -&gt; str:\n    \"\"\"Return a formatted timestamp, useful for prepending to dir/file names.\n\n    Params:\n        fmt (str): String that defines the format of a timestamp\n\n    Returns:\n        (str): A formatted datetime string\n\n    \"\"\"\n    now: str = datetime.now().strftime(fmt)\n\n    return now\n</code></pre>"},{"location":"reference/red_utils/std/path_utils/operations/#red_utils.std.path_utils.operations.list_files","title":"<code>list_files(in_dir=None, ext_filter=None, return_files=[])</code>","text":"<p>List all files in a path, optionally filtering by file extension.</p> <p>Parameters:</p> Name Type Description Default <code>in_dir</code> <code>str</code> <p>Directory path to scan</p> <code>None</code> <code>ext_filter</code> <code>str</code> <p>Filetype to search for</p> <code>None</code> <code>return_files</code> <code>list[Path]</code> <p>Used by the function to recurse through subdirectories</p> <code>[]</code> <p>Returns:</p> Type Description <code>list[Path]</code> <p>A list of found files, represented as <code>Path</code> objects</p> Source code in <code>src\\red_utils\\std\\path_utils\\operations.py</code> <pre><code>def list_files(\n    in_dir: str = None, ext_filter: str = None, return_files: list[Path] = []\n) -&gt; list[Path]:\n    \"\"\"List all files in a path, optionally filtering by file extension.\n\n    Params:\n        in_dir (str): Directory path to scan\n        ext_filter (str): Filetype to search for\n        return_files (list[Path]): Used by the function to recurse through subdirectories\n\n    Returns:\n        (list[Path]): A list of found files, represented as `Path` objects\n\n    \"\"\"\n    if not in_dir:\n        raise ValueError(\"Missing input directory to search\")\n    if ext_filter is not None:\n        if not ext_filter.startswith(\".\"):\n            ext_filter = f\".{ext_filter}\"\n\n    if ext_filter:\n        search_str: str = f\"**/*{ext_filter}\"\n    else:\n        search_str: str = \"**/*\"\n\n    return_files: list[Path] = []\n\n    try:\n        for _p in Path(in_dir).glob(search_str):\n            if _p.is_file():\n                return_files.append(_p)\n            elif _p.is_dir():\n                list_files(in_dir=_p, ext_filter=ext_filter, return_files=return_files)\n\n        return return_files\n\n    except FileNotFoundError as fnf:\n        msg = Exception(f\"Could not find input path: {in_dir}. Details: {fnf}\")\n        log.error(msg)\n\n        raise fnf\n    except PermissionError as perm:\n        msg = Exception(f\"Could not open path: {in_dir}. Details: {perm}\")\n        log.error(msg)\n\n        raise perm\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception looping input path: {in_dir}. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/path_utils/operations/#red_utils.std.path_utils.operations.scan_dir","title":"<code>scan_dir(target=None, as_str=False, as_pathlib=False, return_type='all')</code>","text":"<p>Return a list of path strings found in self.path.</p> <p>Parameters:</p> Name Type Description Default <code>as_str</code> <code>bool</code> <p>If <code>True</code>, returns a list of paths formatted as Python strings.</p> <code>False</code> <code>as_pathlib</code> <code>bool</code> <p>If <code>True</code>, returns a list of paths formatted as Python <code>pathlib.Path</code> objects.</p> <code>False</code> <code>return_type</code> <code>str</code> <p>Control return type. Options:     - <code>all</code>: Return both files &amp; dirs     - <code>files</code>: Return only files     - <code>dirs</code>: Return only dirs</p> <code>'all'</code> <p>Returns:</p> Type Description <code>Union[list[DirEntry, str, Path]]</code> <p>list[os.DirEntry]: (default) If <code>as_str = False</code></p> <code>Union[list[DirEntry, str, Path]]</code> <p>list[str]: If <code>as_str = True</code></p> <code>Union[list[DirEntry, str, Path]]</code> <p>list[pathlib.Path]: If <code>as_str = False</code> and <code>as_pathlib = True</code>.</p> Source code in <code>src\\red_utils\\std\\path_utils\\operations.py</code> <pre><code>def scan_dir(\n    target: Union[str, Path] = None,\n    as_str: bool = False,\n    as_pathlib: bool = False,\n    return_type: str = \"all\",\n) -&gt; Union[list[os.DirEntry, str, Path]]:\n    \"\"\"Return a list of path strings found in self.path.\n\n    Params:\n        as_str (bool): If `True`, returns a list of paths formatted as Python strings.\n        as_pathlib (bool): If `True`, returns a list of paths formatted as Python `pathlib.Path` objects.\n        return_type (str): Control return type.\n            Options:\n                - `all`: Return both files &amp; dirs\n                - `files`: Return only files\n                - `dirs`: Return only dirs\n\n    Returns:\n        list[os.DirEntry]: (default) If `as_str = False`\n        list[str]: If `as_str = True`\n        list[pathlib.Path]: If `as_str = False` and `as_pathlib = True`.\n\n    \"\"\"\n    ## Validate return_type\n    if not return_type:\n        log.warning(\"return_type cannot be None. Defaulting to 'all'.\")\n        return_type = \"all\"\n    else:\n        return_type: str = return_type.lower()\n        assert isinstance(return_type, str), TypeError(\n            f\"return_type must be of type str. Got type: {type(return_type)}\"\n        )\n        assert return_type in VALID_RETURN_TYPES, ValueError(\n            f\"Invalid return type: '{return_type}'. Must be one of {VALID_RETURN_TYPES}\"\n        )\n\n    ## Validate as_str/as_pathlib\n    if as_str and as_pathlib:\n        log.warning(\n            \"as_str and as_pathlib cannot both be true. Defaulting to as_str=True, as_pathlib=False\"\n        )\n        as_pathlib = False\n\n    ## Validate target\n    assert target is not None, ValueError(\"target cannot be None\")\n    assert isinstance(target, str) or isinstance(target, Path), TypeError(\n        f\"target must be of type str or pathlib.Path. Got type: {type(target)}\"\n    )\n    target: Path = Path(f\"{target}\")\n    if \"~\" in f\"{target}\":\n        target: Path = target.expanduser()\n\n    assert target.exists(), FileNotFoundError(\n        f\"Could not find target path: '{target}'.\"\n    )\n\n    ## Initialize empty list to store found paths\n    paths: list[os.DirEntry] = []\n\n    ## Scan target directory\n    for p in os.scandir(target):\n        if return_type == \"all\":\n            ## Append path\n            paths.append(p)\n        elif return_type == \"files\":\n            if Path(p.path).is_file():\n                ## Append file path\n                paths.append(p)\n        elif return_type == \"dirs\":\n            if Path(p.path).is_dir():\n                ## Append dir path\n                paths.append(p)\n\n    if as_str:\n        ## Convert all found paths to str type\n        _paths: list[str] = []\n\n        for p in paths:\n            _path: str = p.path\n\n            _paths.append(_path)\n\n        return _paths\n\n    elif as_pathlib:\n        ## Convert all found paths to pathlib.Path type\n        _paths: list[Path] = []\n\n        for p in paths:\n            _path: Path = Path(p.path)\n            _paths.append(_path)\n\n        return _paths\n\n    else:\n        ## Return list of os.DirEntry types\n        return paths\n</code></pre>"},{"location":"reference/red_utils/std/sqlite_utils/__init__/","title":"sqlite_utils","text":"<p>Utilities &amp; classes for interacting with the builtin <code>sqlite</code> module.</p>"},{"location":"reference/red_utils/std/sqlite_utils/__init__/#red_utils.std.sqlite_utils.SQLiteDB","title":"<code>SQLiteDB</code>  <code>dataclass</code>","text":"<p>Define a simple SQLite database path.</p> <p>Use this object's <code>.create_empty_db()</code> function to attempt to create a database at the object's <code>.db_path</code> property (this is a calculated property, available once the class is initialized).</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the database file</p> <code>'demo'</code> <code>ext</code> <code>str</code> <p>The file extension to use (<code>.db</code>, <code>.sqlite</code>, etc)</p> <code>'.sqlite'</code> <code>location</code> <code>str</code> <p>Path where database file will be created. Database file will be created at <code>self.location</code>/<code>self.name</code> + <code>self.ext</code></p> <code>DB_DIR</code> <p>Returns:</p> Type Description <code>SQLiteDB</code> <p>An initialized <code>SQLiteDB</code> object</p> Source code in <code>src\\red_utils\\std\\sqlite_utils\\schemas.py</code> <pre><code>@dataclass\nclass SQLiteDB:\n    \"\"\"Define a simple SQLite database path.\n\n    Use this object's `.create_empty_db()` function to attempt to create a database at the object's `.db_path` property\n    (this is a calculated property, available once the class is initialized).\n\n    Params:\n        name (str): The name of the database file\n        ext (str): The file extension to use (`.db`, `.sqlite`, etc)\n        location (str): Path where database file will be created. Database file will be created at `self.location`/`self.name` + `self.ext`\n\n    Returns:\n        (SQLiteDB): An initialized `SQLiteDB` object\n\n    \"\"\"\n\n    name: str = field(default=\"demo\")\n    ext: str = field(default=\".sqlite\")\n    location: str = field(default=DB_DIR)\n\n    @property\n    def filename(self) -&gt; str:\n        _filename: str = f\"{self.name}{self.ext}\"\n\n        return _filename\n\n    @property\n    def db_path(self) -&gt; str:\n        _path: str = f\"{self.location}/{self.filename}\"\n\n        return _path\n\n    @property\n    def exists(self) -&gt; bool:\n        if Path(self.db_path).exists():\n            return True\n        else:\n            return False\n\n    @property\n    def stat_str(self) -&gt; str:\n        _str: str = (\n            f\"[{self.filename}] | {'Exists' if self.exists else 'Does not exist'} @ {self.db_path}/\"\n        )\n\n        return _str\n\n    def create_empty_db(self) -&gt; bool:\n        if not self.exists:\n            try:\n                connection = sqlite3.Connection = sqlite3.connect(self.db_path)\n                log.debug(f\"Initializing empty database file at: {self.db_path}\")\n\n                connection.close()\n\n                return True\n            except Exception as exc:\n                msg = Exception(\n                    f\"Unhandled exception initializing an empty SQLite database at {self.db_path}. Details: {exc}\"\n                )\n                log.error(msg)\n\n                return False\n        else:\n            return True\n\n    def __post_init__(self) -&gt; None:  # noqa: D105\n        if not self.ext.startswith(\".\"):\n            self.ext = f\".{self.ext}\"\n\n        if not Path(self.db_path).exists():\n            Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"reference/red_utils/std/sqlite_utils/__init__/#red_utils.std.sqlite_utils.get_demo_db","title":"<code>get_demo_db()</code>","text":"<p>Return an initialized SQLiteDB object with default settings.</p> <p>Returns:</p> Type Description <code>SQLiteDB</code> <p>An initialized <code>SQLiteDB</code> instance. A SQLite database file will also be created at the path: <code>.db/demo.db</code></p> <p>Raises:</p> Type Description <code>Exception</code> <p>When SQLite database initialization is unsuccessful</p> Source code in <code>src\\red_utils\\std\\sqlite_utils\\operations.py</code> <pre><code>def get_demo_db() -&gt; SQLiteDB:\n    \"\"\"Return an initialized SQLiteDB object with default settings.\n\n    Returns:\n        (SQLiteDB): An initialized `SQLiteDB` instance. A SQLite database file will also be created at the path: `.db/demo.db`\n\n    Raises:\n        Exception: When SQLite database initialization is unsuccessful\n\n    \"\"\"\n    try:\n        _db: SQLiteDB = SQLiteDB()\n        return _db\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception initializing default database. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/sqlite_utils/__init__/#red_utils.std.sqlite_utils.get_sqlite_db","title":"<code>get_sqlite_db(name=None, location=None)</code>","text":"<p>Initialize a SQLiteDB object.</p> <p>This is the same as simply instantiating a SQLiteDB object, like:</p> <pre><code>example_db: SQLiteDB = SQLiteDB(name=..., location=...)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the SQLite database. This will be used for the filename. location (str|Path): The directory location to save the database. Note that Path values will be converted to string, then back to Path, so it is best to just pass the location as a string.</p> <code>None</code> <p>Returns:</p> Type Description <code>SQLiteDB</code> <p>An initialized <code>SQLiteDB</code> object</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When input value validation fails</p> <code>Exception</code> <p>When SQLite database initialization fails</p> Source code in <code>src\\red_utils\\std\\sqlite_utils\\operations.py</code> <pre><code>def get_sqlite_db(name: str = None, location: Union[str, Path] = None) -&gt; SQLiteDB:\n    \"\"\"Initialize a SQLiteDB object.\n\n    This is the same as simply instantiating a SQLiteDB object, like:\n\n    ``` py linenums=\"1\"\n    example_db: SQLiteDB = SQLiteDB(name=..., location=...)\n    ```\n\n    Params:\n        name (str): The name of the SQLite database. This will be used for the filename.\n            location (str|Path): The directory location to save the database. Note that Path values will be converted to string, then\n            back to Path, so it is best to just pass the location as a string.\n\n    Returns:\n        (SQLiteDB): An initialized `SQLiteDB` object\n\n    Raises:\n        ValueError: When input value validation fails\n        Exception: When SQLite database initialization fails\n\n    \"\"\"\n    if name is None:\n        raise ValueError(\"Missing database name\")\n    if location is None:\n        raise ValueError(\"Missing output path location for database\")\n    if isinstance(location, Path):\n        location: str = str(location)\n\n    try:\n        _db: SQLiteDB = SQLiteDB(name=name, location=location)\n        return _db\n    except Exception as exc:\n        raise Exception(f\"Unhandled exception creating SQLite database. Details: {exc}\")\n</code></pre>"},{"location":"reference/red_utils/std/sqlite_utils/__init__/#red_utils.std.sqlite_utils.init_sqlite_db","title":"<code>init_sqlite_db(db_definition=None)</code>","text":"<p>Initialize an empty SQLite database.</p> <p>Parameters:</p> Name Type Description Default <code>db_definition</code> <code>SQLiteDB</code> <p>An initialized SQLiteDB object defining the SQLite database to create.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if SQLite database successfully initialized</p> <code>bool</code> <p><code>False</code> if SQLite database initialization unsuccessful</p> <p>Raises:</p> Type Description <code>Exception</code> <p>When initializing empty SQLite database fails</p> Source code in <code>src\\red_utils\\std\\sqlite_utils\\operations.py</code> <pre><code>def init_sqlite_db(db_definition: SQLiteDB = None) -&gt; bool:\n    \"\"\"Initialize an empty SQLite database.\n\n    Params:\n        db_definition (SQLiteDB): An initialized SQLiteDB object defining the SQLite database to create.\n\n    Returns:\n        (bool): `True` if SQLite database successfully initialized\n        (bool): `False` if SQLite database initialization unsuccessful\n\n    Raises:\n        Exception: When initializing empty SQLite database fails\n\n    \"\"\"\n    if db_definition is None:\n        raise ValueError(\"Missing SQLiteDB object.\")\n\n    if db_definition.exists:\n        log.warning(f\"Database already exists at {db_definition.db_path}\")\n        return False\n\n    try:\n        db_definition.create_empty_db()\n\n        return True\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception initializing empty SQLite database. Details: {exc}\"\n        )\n        log.error(msg)\n\n        return False\n</code></pre>"},{"location":"reference/red_utils/std/sqlite_utils/operations/","title":"operations","text":"<p>Methods for interacting with a SQLite database.</p>"},{"location":"reference/red_utils/std/sqlite_utils/operations/#red_utils.std.sqlite_utils.operations.SQLiteDB","title":"<code>SQLiteDB</code>  <code>dataclass</code>","text":"<p>Define a simple SQLite database path.</p> <p>Use this object's <code>.create_empty_db()</code> function to attempt to create a database at the object's <code>.db_path</code> property (this is a calculated property, available once the class is initialized).</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the database file</p> <code>'demo'</code> <code>ext</code> <code>str</code> <p>The file extension to use (<code>.db</code>, <code>.sqlite</code>, etc)</p> <code>'.sqlite'</code> <code>location</code> <code>str</code> <p>Path where database file will be created. Database file will be created at <code>self.location</code>/<code>self.name</code> + <code>self.ext</code></p> <code>DB_DIR</code> <p>Returns:</p> Type Description <code>SQLiteDB</code> <p>An initialized <code>SQLiteDB</code> object</p> Source code in <code>src\\red_utils\\std\\sqlite_utils\\schemas.py</code> <pre><code>@dataclass\nclass SQLiteDB:\n    \"\"\"Define a simple SQLite database path.\n\n    Use this object's `.create_empty_db()` function to attempt to create a database at the object's `.db_path` property\n    (this is a calculated property, available once the class is initialized).\n\n    Params:\n        name (str): The name of the database file\n        ext (str): The file extension to use (`.db`, `.sqlite`, etc)\n        location (str): Path where database file will be created. Database file will be created at `self.location`/`self.name` + `self.ext`\n\n    Returns:\n        (SQLiteDB): An initialized `SQLiteDB` object\n\n    \"\"\"\n\n    name: str = field(default=\"demo\")\n    ext: str = field(default=\".sqlite\")\n    location: str = field(default=DB_DIR)\n\n    @property\n    def filename(self) -&gt; str:\n        _filename: str = f\"{self.name}{self.ext}\"\n\n        return _filename\n\n    @property\n    def db_path(self) -&gt; str:\n        _path: str = f\"{self.location}/{self.filename}\"\n\n        return _path\n\n    @property\n    def exists(self) -&gt; bool:\n        if Path(self.db_path).exists():\n            return True\n        else:\n            return False\n\n    @property\n    def stat_str(self) -&gt; str:\n        _str: str = (\n            f\"[{self.filename}] | {'Exists' if self.exists else 'Does not exist'} @ {self.db_path}/\"\n        )\n\n        return _str\n\n    def create_empty_db(self) -&gt; bool:\n        if not self.exists:\n            try:\n                connection = sqlite3.Connection = sqlite3.connect(self.db_path)\n                log.debug(f\"Initializing empty database file at: {self.db_path}\")\n\n                connection.close()\n\n                return True\n            except Exception as exc:\n                msg = Exception(\n                    f\"Unhandled exception initializing an empty SQLite database at {self.db_path}. Details: {exc}\"\n                )\n                log.error(msg)\n\n                return False\n        else:\n            return True\n\n    def __post_init__(self) -&gt; None:  # noqa: D105\n        if not self.ext.startswith(\".\"):\n            self.ext = f\".{self.ext}\"\n\n        if not Path(self.db_path).exists():\n            Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"reference/red_utils/std/sqlite_utils/operations/#red_utils.std.sqlite_utils.operations.get_demo_db","title":"<code>get_demo_db()</code>","text":"<p>Return an initialized SQLiteDB object with default settings.</p> <p>Returns:</p> Type Description <code>SQLiteDB</code> <p>An initialized <code>SQLiteDB</code> instance. A SQLite database file will also be created at the path: <code>.db/demo.db</code></p> <p>Raises:</p> Type Description <code>Exception</code> <p>When SQLite database initialization is unsuccessful</p> Source code in <code>src\\red_utils\\std\\sqlite_utils\\operations.py</code> <pre><code>def get_demo_db() -&gt; SQLiteDB:\n    \"\"\"Return an initialized SQLiteDB object with default settings.\n\n    Returns:\n        (SQLiteDB): An initialized `SQLiteDB` instance. A SQLite database file will also be created at the path: `.db/demo.db`\n\n    Raises:\n        Exception: When SQLite database initialization is unsuccessful\n\n    \"\"\"\n    try:\n        _db: SQLiteDB = SQLiteDB()\n        return _db\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception initializing default database. Details: {exc}\"\n        )\n        log.error(msg)\n\n        raise exc\n</code></pre>"},{"location":"reference/red_utils/std/sqlite_utils/operations/#red_utils.std.sqlite_utils.operations.get_sqlite_db","title":"<code>get_sqlite_db(name=None, location=None)</code>","text":"<p>Initialize a SQLiteDB object.</p> <p>This is the same as simply instantiating a SQLiteDB object, like:</p> <pre><code>example_db: SQLiteDB = SQLiteDB(name=..., location=...)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the SQLite database. This will be used for the filename. location (str|Path): The directory location to save the database. Note that Path values will be converted to string, then back to Path, so it is best to just pass the location as a string.</p> <code>None</code> <p>Returns:</p> Type Description <code>SQLiteDB</code> <p>An initialized <code>SQLiteDB</code> object</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When input value validation fails</p> <code>Exception</code> <p>When SQLite database initialization fails</p> Source code in <code>src\\red_utils\\std\\sqlite_utils\\operations.py</code> <pre><code>def get_sqlite_db(name: str = None, location: Union[str, Path] = None) -&gt; SQLiteDB:\n    \"\"\"Initialize a SQLiteDB object.\n\n    This is the same as simply instantiating a SQLiteDB object, like:\n\n    ``` py linenums=\"1\"\n    example_db: SQLiteDB = SQLiteDB(name=..., location=...)\n    ```\n\n    Params:\n        name (str): The name of the SQLite database. This will be used for the filename.\n            location (str|Path): The directory location to save the database. Note that Path values will be converted to string, then\n            back to Path, so it is best to just pass the location as a string.\n\n    Returns:\n        (SQLiteDB): An initialized `SQLiteDB` object\n\n    Raises:\n        ValueError: When input value validation fails\n        Exception: When SQLite database initialization fails\n\n    \"\"\"\n    if name is None:\n        raise ValueError(\"Missing database name\")\n    if location is None:\n        raise ValueError(\"Missing output path location for database\")\n    if isinstance(location, Path):\n        location: str = str(location)\n\n    try:\n        _db: SQLiteDB = SQLiteDB(name=name, location=location)\n        return _db\n    except Exception as exc:\n        raise Exception(f\"Unhandled exception creating SQLite database. Details: {exc}\")\n</code></pre>"},{"location":"reference/red_utils/std/sqlite_utils/operations/#red_utils.std.sqlite_utils.operations.init_sqlite_db","title":"<code>init_sqlite_db(db_definition=None)</code>","text":"<p>Initialize an empty SQLite database.</p> <p>Parameters:</p> Name Type Description Default <code>db_definition</code> <code>SQLiteDB</code> <p>An initialized SQLiteDB object defining the SQLite database to create.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if SQLite database successfully initialized</p> <code>bool</code> <p><code>False</code> if SQLite database initialization unsuccessful</p> <p>Raises:</p> Type Description <code>Exception</code> <p>When initializing empty SQLite database fails</p> Source code in <code>src\\red_utils\\std\\sqlite_utils\\operations.py</code> <pre><code>def init_sqlite_db(db_definition: SQLiteDB = None) -&gt; bool:\n    \"\"\"Initialize an empty SQLite database.\n\n    Params:\n        db_definition (SQLiteDB): An initialized SQLiteDB object defining the SQLite database to create.\n\n    Returns:\n        (bool): `True` if SQLite database successfully initialized\n        (bool): `False` if SQLite database initialization unsuccessful\n\n    Raises:\n        Exception: When initializing empty SQLite database fails\n\n    \"\"\"\n    if db_definition is None:\n        raise ValueError(\"Missing SQLiteDB object.\")\n\n    if db_definition.exists:\n        log.warning(f\"Database already exists at {db_definition.db_path}\")\n        return False\n\n    try:\n        db_definition.create_empty_db()\n\n        return True\n\n    except Exception as exc:\n        msg = Exception(\n            f\"Unhandled exception initializing empty SQLite database. Details: {exc}\"\n        )\n        log.error(msg)\n\n        return False\n</code></pre>"},{"location":"reference/red_utils/std/sqlite_utils/schemas/","title":"schemas","text":""},{"location":"reference/red_utils/std/sqlite_utils/schemas/#red_utils.std.sqlite_utils.schemas.SQLiteDB","title":"<code>SQLiteDB</code>  <code>dataclass</code>","text":"<p>Define a simple SQLite database path.</p> <p>Use this object's <code>.create_empty_db()</code> function to attempt to create a database at the object's <code>.db_path</code> property (this is a calculated property, available once the class is initialized).</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the database file</p> <code>'demo'</code> <code>ext</code> <code>str</code> <p>The file extension to use (<code>.db</code>, <code>.sqlite</code>, etc)</p> <code>'.sqlite'</code> <code>location</code> <code>str</code> <p>Path where database file will be created. Database file will be created at <code>self.location</code>/<code>self.name</code> + <code>self.ext</code></p> <code>DB_DIR</code> <p>Returns:</p> Type Description <code>SQLiteDB</code> <p>An initialized <code>SQLiteDB</code> object</p> Source code in <code>src\\red_utils\\std\\sqlite_utils\\schemas.py</code> <pre><code>@dataclass\nclass SQLiteDB:\n    \"\"\"Define a simple SQLite database path.\n\n    Use this object's `.create_empty_db()` function to attempt to create a database at the object's `.db_path` property\n    (this is a calculated property, available once the class is initialized).\n\n    Params:\n        name (str): The name of the database file\n        ext (str): The file extension to use (`.db`, `.sqlite`, etc)\n        location (str): Path where database file will be created. Database file will be created at `self.location`/`self.name` + `self.ext`\n\n    Returns:\n        (SQLiteDB): An initialized `SQLiteDB` object\n\n    \"\"\"\n\n    name: str = field(default=\"demo\")\n    ext: str = field(default=\".sqlite\")\n    location: str = field(default=DB_DIR)\n\n    @property\n    def filename(self) -&gt; str:\n        _filename: str = f\"{self.name}{self.ext}\"\n\n        return _filename\n\n    @property\n    def db_path(self) -&gt; str:\n        _path: str = f\"{self.location}/{self.filename}\"\n\n        return _path\n\n    @property\n    def exists(self) -&gt; bool:\n        if Path(self.db_path).exists():\n            return True\n        else:\n            return False\n\n    @property\n    def stat_str(self) -&gt; str:\n        _str: str = (\n            f\"[{self.filename}] | {'Exists' if self.exists else 'Does not exist'} @ {self.db_path}/\"\n        )\n\n        return _str\n\n    def create_empty_db(self) -&gt; bool:\n        if not self.exists:\n            try:\n                connection = sqlite3.Connection = sqlite3.connect(self.db_path)\n                log.debug(f\"Initializing empty database file at: {self.db_path}\")\n\n                connection.close()\n\n                return True\n            except Exception as exc:\n                msg = Exception(\n                    f\"Unhandled exception initializing an empty SQLite database at {self.db_path}. Details: {exc}\"\n                )\n                log.error(msg)\n\n                return False\n        else:\n            return True\n\n    def __post_init__(self) -&gt; None:  # noqa: D105\n        if not self.ext.startswith(\".\"):\n            self.ext = f\".{self.ext}\"\n\n        if not Path(self.db_path).exists():\n            Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"reference/red_utils/std/time_utils/__init__/","title":"time_utils","text":"<p>Utilities &amp; methods for interacting with Python's <code>datetime</code> library.</p> <p>This is meant to ease some common uses I have for <code>datetime</code>, like generating a timestamp with my preferred format, or converting between <code>str</code> and <code>datetime.datetime</code>.</p>"},{"location":"reference/red_utils/std/time_utils/__init__/#red_utils.std.time_utils.datetime_as_dt","title":"<code>datetime_as_dt(ts=None, format=TIME_FMT_24H)</code>","text":"<p>Convert a datetime string to a <code>datetime.datetime</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>ts</code> <code>str</code> <p>A datetime str to convert to a Python <code>datetime.datetime</code> object</p> <code>None</code> <code>format</code> <code>str</code> <p>The <code>str</code> time string format to use</p> <code>TIME_FMT_24H</code> <p>Returns:</p> Type Description <code>str</code> <p>A formatted <code>datetime.datetime</code> object</p> Source code in <code>src\\red_utils\\std\\time_utils\\operations.py</code> <pre><code>def datetime_as_dt(ts: str = None, format: str = TIME_FMT_24H) -&gt; dt:\n    \"\"\"Convert a datetime string to a `datetime.datetime` object.\n\n    Params:\n        ts (str): A datetime str to convert to a Python `datetime.datetime` object\n        format (str): The `str` time string format to use\n\n    Returns:\n        (str): A formatted `datetime.datetime` object\n\n    \"\"\"\n    _ts: dt = dt.strptime(ts, format)\n\n    return _ts\n</code></pre>"},{"location":"reference/red_utils/std/time_utils/__init__/#red_utils.std.time_utils.datetime_as_str","title":"<code>datetime_as_str(ts=None, format=TIME_FMT_24H)</code>","text":"<p>Convert a <code>datetime.datetime</code> object to a string.</p> <p>Parameters:</p> Name Type Description Default <code>ts</code> <code>datetime</code> <p>A Python <code>datetime.datetime</code> object to convert to a <code>str</code></p> <code>None</code> <code>format</code> <code>str</code> <p>The <code>str</code> time string format to use</p> <code>TIME_FMT_24H</code> <p>Returns:</p> Type Description <code>str</code> <p>A formatted <code>datetime.datetime</code> <code>str</code></p> Source code in <code>src\\red_utils\\std\\time_utils\\operations.py</code> <pre><code>def datetime_as_str(ts: dt = None, format: str = TIME_FMT_24H) -&gt; str:\n    \"\"\"Convert a `datetime.datetime` object to a string.\n\n    Params:\n        ts (datetime.datetime): A Python `datetime.datetime` object to convert to a `str`\n        format (str): The `str` time string format to use\n\n    Returns:\n        (str): A formatted `datetime.datetime` `str`\n\n    \"\"\"\n    _ts: str = ts.strftime(format=format)\n\n    return _ts\n</code></pre>"},{"location":"reference/red_utils/std/time_utils/__init__/#red_utils.std.time_utils.get_ts","title":"<code>get_ts(as_str=False, format=TIME_FMT_24H)</code>","text":"<p>Get a timestamp object.</p> <p>Parameters:</p> Name Type Description Default <code>as_str</code> <code>bool</code> <p>If <code>True</code>, converts <code>datetime</code> to a <code>str</code></p> <code>False</code> <code>format</code> <code>str</code> <p>The <code>str</code> time string format to use</p> <code>TIME_FMT_24H</code> <p>Returns:</p> Type Description <code>datetime</code> <p>a Python <code>datetime.datetime</code> object.</p> <code>str</code> <p>If <code>as_str</code> is <code>True</code>, converts datetime to a string &amp; returns.</p> Source code in <code>src\\red_utils\\std\\time_utils\\operations.py</code> <pre><code>def get_ts(as_str: bool = False, format: str = TIME_FMT_24H) -&gt; Union[dt, str]:\n    \"\"\"Get a timestamp object.\n\n    Params:\n        as_str (bool): If `True`, converts `datetime` to a `str`\n        format (str): The `str` time string format to use\n\n    Returns:\n        (datetime.datetime): a Python `datetime.datetime` object.\n        (str): If `as_str` is `True`, converts datetime to a string &amp; returns.\n\n    \"\"\"\n    now: dt = dt.now()\n\n    if as_str:\n        now: str = datetime_as_str(ts=now, format=format)\n\n    return now\n</code></pre>"},{"location":"reference/red_utils/std/time_utils/constants/","title":"constants","text":"<p>Constant variables for <code>datetime</code> functions.</p> <ul> <li>TIME_FMT_24H (str): \"%Y-%m-%d_%H:%M:%S\"</li> <li>TIME_FMT_12H (str): \"%Y-%m-%d_%I:%M:%S%p\"</li> </ul>"},{"location":"reference/red_utils/std/time_utils/operations/","title":"operations","text":""},{"location":"reference/red_utils/std/time_utils/operations/#red_utils.std.time_utils.operations.datetime_as_dt","title":"<code>datetime_as_dt(ts=None, format=TIME_FMT_24H)</code>","text":"<p>Convert a datetime string to a <code>datetime.datetime</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>ts</code> <code>str</code> <p>A datetime str to convert to a Python <code>datetime.datetime</code> object</p> <code>None</code> <code>format</code> <code>str</code> <p>The <code>str</code> time string format to use</p> <code>TIME_FMT_24H</code> <p>Returns:</p> Type Description <code>str</code> <p>A formatted <code>datetime.datetime</code> object</p> Source code in <code>src\\red_utils\\std\\time_utils\\operations.py</code> <pre><code>def datetime_as_dt(ts: str = None, format: str = TIME_FMT_24H) -&gt; dt:\n    \"\"\"Convert a datetime string to a `datetime.datetime` object.\n\n    Params:\n        ts (str): A datetime str to convert to a Python `datetime.datetime` object\n        format (str): The `str` time string format to use\n\n    Returns:\n        (str): A formatted `datetime.datetime` object\n\n    \"\"\"\n    _ts: dt = dt.strptime(ts, format)\n\n    return _ts\n</code></pre>"},{"location":"reference/red_utils/std/time_utils/operations/#red_utils.std.time_utils.operations.datetime_as_str","title":"<code>datetime_as_str(ts=None, format=TIME_FMT_24H)</code>","text":"<p>Convert a <code>datetime.datetime</code> object to a string.</p> <p>Parameters:</p> Name Type Description Default <code>ts</code> <code>datetime</code> <p>A Python <code>datetime.datetime</code> object to convert to a <code>str</code></p> <code>None</code> <code>format</code> <code>str</code> <p>The <code>str</code> time string format to use</p> <code>TIME_FMT_24H</code> <p>Returns:</p> Type Description <code>str</code> <p>A formatted <code>datetime.datetime</code> <code>str</code></p> Source code in <code>src\\red_utils\\std\\time_utils\\operations.py</code> <pre><code>def datetime_as_str(ts: dt = None, format: str = TIME_FMT_24H) -&gt; str:\n    \"\"\"Convert a `datetime.datetime` object to a string.\n\n    Params:\n        ts (datetime.datetime): A Python `datetime.datetime` object to convert to a `str`\n        format (str): The `str` time string format to use\n\n    Returns:\n        (str): A formatted `datetime.datetime` `str`\n\n    \"\"\"\n    _ts: str = ts.strftime(format=format)\n\n    return _ts\n</code></pre>"},{"location":"reference/red_utils/std/time_utils/operations/#red_utils.std.time_utils.operations.get_ts","title":"<code>get_ts(as_str=False, format=TIME_FMT_24H)</code>","text":"<p>Get a timestamp object.</p> <p>Parameters:</p> Name Type Description Default <code>as_str</code> <code>bool</code> <p>If <code>True</code>, converts <code>datetime</code> to a <code>str</code></p> <code>False</code> <code>format</code> <code>str</code> <p>The <code>str</code> time string format to use</p> <code>TIME_FMT_24H</code> <p>Returns:</p> Type Description <code>datetime</code> <p>a Python <code>datetime.datetime</code> object.</p> <code>str</code> <p>If <code>as_str</code> is <code>True</code>, converts datetime to a string &amp; returns.</p> Source code in <code>src\\red_utils\\std\\time_utils\\operations.py</code> <pre><code>def get_ts(as_str: bool = False, format: str = TIME_FMT_24H) -&gt; Union[dt, str]:\n    \"\"\"Get a timestamp object.\n\n    Params:\n        as_str (bool): If `True`, converts `datetime` to a `str`\n        format (str): The `str` time string format to use\n\n    Returns:\n        (datetime.datetime): a Python `datetime.datetime` object.\n        (str): If `as_str` is `True`, converts datetime to a string &amp; returns.\n\n    \"\"\"\n    now: dt = dt.now()\n\n    if as_str:\n        now: str = datetime_as_str(ts=now, format=format)\n\n    return now\n</code></pre>"},{"location":"reference/red_utils/std/time_utils/operations/#red_utils.std.time_utils.operations.wait","title":"<code>wait(s=1, msg='Waiting {} seconds...')</code>","text":"<p>Sleep for a number of seconds, with optional custom message.</p> <p>Parameters:</p> Name Type Description Default <code>s</code> <code>int</code> <p>Amount of time (in seconds) to sleep/pause.</p> <code>1</code> <code>msg</code> <code>str</code> <p>[default: 'Wating {} seconds...'] A custom message to print. Use {} in the message to print the value of s.</p> <pre><code>Example: 'I will now wait for {} second(s)' =&gt; 'I will now wait for 15 seconds...'\n</code></pre> <code>'Waiting {} seconds...'</code> Source code in <code>src\\red_utils\\std\\time_utils\\operations.py</code> <pre><code>def wait(s: int = 1, msg: str | None = \"Waiting {} seconds...\") -&gt; None:\n    \"\"\"Sleep for a number of seconds, with optional custom message.\n\n    Params:\n        s (int): Amount of time (in seconds) to sleep/pause.\n        msg (str): [default: 'Wating {} seconds...'] A custom message to print. Use {} in the\n            message to print the value of s.\n\n                Example: 'I will now wait for {} second(s)' =&gt; 'I will now wait for 15 seconds...'\n    \"\"\"\n    assert s, ValueError(\"Missing amount of time to sleep\")\n    assert isinstance(s, int) and s &gt; 0, ValueError(\n        f\"Value of s must be a positive, non-zero integer. Input value ({type(s)}): {s} is invalid.\"\n    )\n\n    ## If msg != None, validate &amp; print before pausing\n    if msg:\n        try:\n            ## Validate &amp; print pause message\n            assert isinstance(msg, str), TypeError(\n                f\"msg must be a string or None. Got type: ({type(msg)})\"\n            )\n\n            try:\n                log.info(msg.format(s))\n            except Exception as exc:\n                ## Error compiling message text. Print an error, then wait\n                msg = Exception(\n                    f\"Unhandled exception composing wait message. Details: {exc}.\\nWaiting [{s}] seconds...\"\n                )\n                log.error(msg)\n\n        except Exception as exc:\n            ## Error compiling message text. Print an error, then wait\n            msg = Exception(\n                f\"Unhandled exception composing wait message. Details: {exc}\\nWaiting [{s}] seconds...\"\n            )\n            log.error(msg)\n\n    ## Pause\n    time.sleep(s)\n</code></pre>"},{"location":"reference/red_utils/std/uuid_utils/__init__/","title":"uuid_utils","text":"<p>Utilities for generating/splicing a UUID string using Python's <code>uuid.UUID</code> module.</p>"},{"location":"reference/red_utils/std/uuid_utils/__init__/#red_utils.std.uuid_utils.UUIDLength","title":"<code>UUIDLength</code>  <code>dataclass</code>","text":"<p>Simple dataclass to store UUID string lengths.</p> <p>When setting the length of a string, you can use something like UUID().standard to pass these pre-defined values.</p> <p>Parameters:</p> Name Type Description Default <code>standard</code> <code>int</code> <p>The number of characters expected in a standard UUID string</p> <code>36</code> <code>hex</code> <code>int</code> <p>The number of characters expeceted in a UUID hex string</p> <code>32</code> Source code in <code>src\\red_utils\\std\\uuid_utils\\classes.py</code> <pre><code>@dataclass\nclass UUIDLength:\n    \"\"\"Simple dataclass to store UUID string lengths.\n\n    When setting the length of a string, you can use something like UUID().standard to pass these pre-defined values.\n\n    Args:\n        standard (int): The number of characters expected in a standard UUID string\n        hex (int): The number of characters expeceted in a UUID hex string\n\n    \"\"\"\n\n    standard: int = 36\n    hex: int = 32\n</code></pre>"},{"location":"reference/red_utils/std/uuid_utils/__init__/#red_utils.std.uuid_utils.first_n_chars","title":"<code>first_n_chars(first_n=36, in_uuid=uuid.uuid4(), as_hex=False)</code>","text":"<p>Return first n characters of UUID string (where n is first_n).</p> <p>Parameters:</p> Name Type Description Default <code>first_n</code> <code>int</code> <p>trim (int): Number of characters to remove from beginning of UUID string.</p> <code>36</code> <code>in_uuid</code> <code>str</code> <p>in_uuid (str): An existing UUID <code>str</code> to be trimmed/converted to hex.</p> <code>uuid4()</code> <code>as_hex</code> <code>bool</code> <p>as_hex (bool): If <code>True</code>, returns a UUID hex (UUID <code>str</code> without the <code>-</code> characters).</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>A 36 character UUID string</p> <code>str</code> <p>A 32 character UUID hex string (a UUID minus the <code>-</code> characters)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If input <code>first_n</code> is an invalid number of characters to return, less than 0 or greater than predefined max value (32 for hex, 36 for standard).</p> Source code in <code>src\\red_utils\\std\\uuid_utils\\operations.py</code> <pre><code>def first_n_chars(first_n: int = 36, in_uuid: str = uuid.uuid4(), as_hex: bool = False):\n    \"\"\"Return first n characters of UUID string (where n is first_n).\n\n    Params:\n        first_n (int): trim (int): Number of characters to remove from beginning of UUID string.\n        in_uuid (str): in_uuid (str): An existing UUID `str` to be trimmed/converted to hex.\n        as_hex (bool): as_hex (bool): If `True`, returns a UUID hex (UUID `str` without the `-` characters).\n\n    Returns:\n        (str): A 36 character UUID string\n        (str): A 32 character UUID hex string (a UUID minus the `-` characters)\n\n    Raises:\n        ValueError: If input `first_n` is an invalid number of characters to return, less than 0 or greater than predefined max value (32 for hex, 36 for standard).\n\n    \"\"\"\n    if not isinstance(first_n, int):\n        first_n = int(first_n)\n\n    if as_hex:\n        _max = glob_uuid_lens.hex - 1\n    else:\n        _max = glob_uuid_lens.standard - 1\n\n    if first_n &lt; 0 or first_n &gt; _max:\n        raise ValueError(\n            f\"Invalid number of UUID characters requested: {first_n}. Must be greater than 0 and less than or equal to {_max}.\"\n        )\n\n    ## Return first n characters from beginning of string\n    _uuid: str = str(in_uuid)[0:first_n]\n\n    return _uuid\n</code></pre>"},{"location":"reference/red_utils/std/uuid_utils/__init__/#red_utils.std.uuid_utils.gen_uuid","title":"<code>gen_uuid(as_hex=False)</code>","text":"<p>Return a UUID.</p> <p>Nested function to simply return a UUID object.</p> <p>Parameters:</p> Name Type Description Default <code>as_hex</code> <code>bool</code> <p>If True, returns a UUID hex (a UUID without the '-' characters, which is 32 characters instead of 36).</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>A 36 character UUID string</p> <code>str</code> <p>A 32 character UUID hex string (a UUID minus the <code>-</code> characters)</p> Source code in <code>src\\red_utils\\std\\uuid_utils\\operations.py</code> <pre><code>def gen_uuid(as_hex: bool = False) -&gt; Union[str, uuid.UUID]:\n    \"\"\"Return a UUID.\n\n    Nested function to simply return a UUID object.\n\n    Params:\n        as_hex (bool): If True, returns a UUID hex (a UUID without the '-' characters, which is 32 characters instead of 36).\n\n    Returns:\n        (str): A 36 character UUID string\n        (str): A 32 character UUID hex string (a UUID minus the `-` characters)\n\n    \"\"\"\n    if as_hex:\n        hex_uuid = uuid.uuid4().hex\n\n        ## Returns a str\n        return hex_uuid\n\n    _uuid: uuid.UUID = uuid.uuid4()\n\n    ## Returns a UUID\n    return _uuid\n</code></pre>"},{"location":"reference/red_utils/std/uuid_utils/__init__/#red_utils.std.uuid_utils.get_rand_uuid","title":"<code>get_rand_uuid(trim=0, characters=0, as_str=True, as_hex=False)</code>","text":"<p>Return a UUID.</p> <p>Parameters:</p> Name Type Description Default <code>trim</code> <code>int</code> <p>Remove <code>n</code> characters from end of string.</p> <code>0</code> <code>characters</code> <code>int</code> <p>Return first <code>n</code> characters from beginning of string.</p> <code>0</code> <code>as_str</code> <code>bool</code> <code>True</code> <code>as_hex</code> <code>bool</code> <p>Return UUID as a hexadecimal (32 chars, UUID without <code>-</code> characters).</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>A 36 character UUID string</p> <code>str</code> <p>A 32 character UUID hex string (a UUID minus the <code>-</code> characters)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If inputs <code>trim</code> or <code>characters</code> are invalid. TODO: Add <code>TypeErrors</code> too</p> Source code in <code>src\\red_utils\\std\\uuid_utils\\operations.py</code> <pre><code>def get_rand_uuid(\n    trim: int = 0, characters: int = 0, as_str: bool = True, as_hex: bool = False\n) -&gt; Union[str, uuid.UUID]:\n    \"\"\"Return a UUID.\n\n    Params:\n        trim (int): Remove `n` characters from end of string.\n        characters (int): Return first `n` characters from beginning of string.\n        as_str (bool):\n        as_hex (bool): Return UUID as a hexadecimal (32 chars, UUID without `-` characters).\n\n    Returns:\n        (str): A 36 character UUID string\n        (str): A 32 character UUID hex string (a UUID minus the `-` characters)\n\n    Raises:\n        ValueError: If inputs `trim` or `characters` are invalid. TODO: Add `TypeErrors` too\n\n    \"\"\"\n    if isinstance(trim, int) and isinstance(characters, int):\n        if trim &gt; 0 and characters &gt; 0:\n            raise ValueError(\n                \"Cannot pass both a trim value and a characters value, please use one or the other.\"\n            )\n    elif not isinstance(trim, int) and isinstance(characters, int):\n        raise ValueError(\"Trim value must be an int\")\n    elif isinstance(trim, int) and not isinstance(characters, int):\n        raise ValueError(\"Characters value must be an int\")\n    else:\n        raise ValueError(\"Trim and Characters values must be int\")\n\n    ## Generate a UUID. Returns a 36 char string, or 32 char if as_hex is set\n    _uuid: uuid.UUID = gen_uuid(as_hex=as_hex)\n\n    # if as_hex:\n    trim = validate_trim(trim_in=trim, as_hex=as_hex)\n\n    if characters &gt; 0:\n        characters = validate_characters(characters_in=characters, as_hex=as_hex)\n\n    if trim:\n        _uuid: str = trim_uuid(trim=trim, in_uuid=_uuid, as_hex=as_hex)\n\n    if characters:\n        _uuid: str = first_n_chars(first_n=characters, in_uuid=_uuid, as_hex=as_hex)\n\n    ## If as_str was passed, convert UUID to string\n    if as_str:\n        _uuid: str = str(_uuid)\n\n    return _uuid\n</code></pre>"},{"location":"reference/red_utils/std/uuid_utils/__init__/#red_utils.std.uuid_utils.trim_uuid","title":"<code>trim_uuid(trim=0, in_uuid=uuid.uuid4(), as_hex=False)</code>","text":"<p>Trim UUID string, removing n characters from end of string (where n is value of trim).</p> <p>Parameters:</p> Name Type Description Default <code>trim</code> <code>int</code> <p>Number of characters to remove from end of UUID string.</p> <code>0</code> <code>in_uuid</code> <code>str</code> <p>An existing UUID <code>str</code> to be trimmed/converted to hex.</p> <code>uuid4()</code> <code>as_hex</code> <code>bool</code> <p>If <code>True</code>, returns a UUID hex (UUID <code>str</code> without the <code>-</code> characters).</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>A 36 character UUID string</p> <code>str</code> <p>A 32 character UUID hex string (a UUID minus the <code>-</code> characters)</p> Source code in <code>src\\red_utils\\std\\uuid_utils\\operations.py</code> <pre><code>def trim_uuid(trim: int = 0, in_uuid: str = uuid.uuid4(), as_hex: bool = False) -&gt; str:\n    \"\"\"Trim UUID string, removing n characters from end of string (where n is value of trim).\n\n    Params:\n        trim (int): Number of characters to remove from end of UUID string.\n        in_uuid (str): An existing UUID `str` to be trimmed/converted to hex.\n        as_hex (bool): If `True`, returns a UUID hex (UUID `str` without the `-` characters).\n\n    Returns:\n        (str): A 36 character UUID string\n        (str): A 32 character UUID hex string (a UUID minus the `-` characters)\n\n    \"\"\"\n    ## Set max character count\n    ## Attempt to convert inputs value to integer\n    if not isinstance(trim, int):\n        trim = int(trim)\n\n    if as_hex:\n        _max = glob_uuid_lens.hex - 1\n    else:\n        _max = glob_uuid_lens.standard - 1\n\n    ## Validate trim/characters\n    if trim &lt; 0 or trim &gt; _max:\n        raise ValueError(\n            f\"Invalid trim length: {trim}. Must be greater than 0 and less than {_max} ({_max -1}).\"\n        )\n\n    ## Trim n characters from end of string\n    _uuid: str = str(in_uuid)[:-trim]\n\n    return _uuid\n</code></pre>"},{"location":"reference/red_utils/std/uuid_utils/classes/","title":"classes","text":""},{"location":"reference/red_utils/std/uuid_utils/classes/#red_utils.std.uuid_utils.classes.UUIDLength","title":"<code>UUIDLength</code>  <code>dataclass</code>","text":"<p>Simple dataclass to store UUID string lengths.</p> <p>When setting the length of a string, you can use something like UUID().standard to pass these pre-defined values.</p> <p>Parameters:</p> Name Type Description Default <code>standard</code> <code>int</code> <p>The number of characters expected in a standard UUID string</p> <code>36</code> <code>hex</code> <code>int</code> <p>The number of characters expeceted in a UUID hex string</p> <code>32</code> Source code in <code>src\\red_utils\\std\\uuid_utils\\classes.py</code> <pre><code>@dataclass\nclass UUIDLength:\n    \"\"\"Simple dataclass to store UUID string lengths.\n\n    When setting the length of a string, you can use something like UUID().standard to pass these pre-defined values.\n\n    Args:\n        standard (int): The number of characters expected in a standard UUID string\n        hex (int): The number of characters expeceted in a UUID hex string\n\n    \"\"\"\n\n    standard: int = 36\n    hex: int = 32\n</code></pre>"},{"location":"reference/red_utils/std/uuid_utils/constants/","title":"constants","text":""},{"location":"reference/red_utils/std/uuid_utils/constants/#red_utils.std.uuid_utils.constants.UUIDLength","title":"<code>UUIDLength</code>  <code>dataclass</code>","text":"<p>Simple dataclass to store UUID string lengths.</p> <p>When setting the length of a string, you can use something like UUID().standard to pass these pre-defined values.</p> <p>Parameters:</p> Name Type Description Default <code>standard</code> <code>int</code> <p>The number of characters expected in a standard UUID string</p> <code>36</code> <code>hex</code> <code>int</code> <p>The number of characters expeceted in a UUID hex string</p> <code>32</code> Source code in <code>src\\red_utils\\std\\uuid_utils\\classes.py</code> <pre><code>@dataclass\nclass UUIDLength:\n    \"\"\"Simple dataclass to store UUID string lengths.\n\n    When setting the length of a string, you can use something like UUID().standard to pass these pre-defined values.\n\n    Args:\n        standard (int): The number of characters expected in a standard UUID string\n        hex (int): The number of characters expeceted in a UUID hex string\n\n    \"\"\"\n\n    standard: int = 36\n    hex: int = 32\n</code></pre>"},{"location":"reference/red_utils/std/uuid_utils/operations/","title":"operations","text":"<p>Utility functions for generating a UUID.</p> <p>Can generate a UUID as a uuid.UUID, str, or hex (UUID without '-' characters).</p> <p>Allows trimming a number of characters from the end of a UUID string, as well as returning the first n number of characters.</p> <p>Note</p> <p>A UUID string is 36 characters (32 characters as hex).</p>"},{"location":"reference/red_utils/std/uuid_utils/operations/#red_utils.std.uuid_utils.operations.UUIDLength","title":"<code>UUIDLength</code>  <code>dataclass</code>","text":"<p>Simple dataclass to store UUID string lengths.</p> <p>When setting the length of a string, you can use something like UUID().standard to pass these pre-defined values.</p> <p>Parameters:</p> Name Type Description Default <code>standard</code> <code>int</code> <p>The number of characters expected in a standard UUID string</p> <code>36</code> <code>hex</code> <code>int</code> <p>The number of characters expeceted in a UUID hex string</p> <code>32</code> Source code in <code>src\\red_utils\\std\\uuid_utils\\classes.py</code> <pre><code>@dataclass\nclass UUIDLength:\n    \"\"\"Simple dataclass to store UUID string lengths.\n\n    When setting the length of a string, you can use something like UUID().standard to pass these pre-defined values.\n\n    Args:\n        standard (int): The number of characters expected in a standard UUID string\n        hex (int): The number of characters expeceted in a UUID hex string\n\n    \"\"\"\n\n    standard: int = 36\n    hex: int = 32\n</code></pre>"},{"location":"reference/red_utils/std/uuid_utils/operations/#red_utils.std.uuid_utils.operations.first_n_chars","title":"<code>first_n_chars(first_n=36, in_uuid=uuid.uuid4(), as_hex=False)</code>","text":"<p>Return first n characters of UUID string (where n is first_n).</p> <p>Parameters:</p> Name Type Description Default <code>first_n</code> <code>int</code> <p>trim (int): Number of characters to remove from beginning of UUID string.</p> <code>36</code> <code>in_uuid</code> <code>str</code> <p>in_uuid (str): An existing UUID <code>str</code> to be trimmed/converted to hex.</p> <code>uuid4()</code> <code>as_hex</code> <code>bool</code> <p>as_hex (bool): If <code>True</code>, returns a UUID hex (UUID <code>str</code> without the <code>-</code> characters).</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>A 36 character UUID string</p> <code>str</code> <p>A 32 character UUID hex string (a UUID minus the <code>-</code> characters)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If input <code>first_n</code> is an invalid number of characters to return, less than 0 or greater than predefined max value (32 for hex, 36 for standard).</p> Source code in <code>src\\red_utils\\std\\uuid_utils\\operations.py</code> <pre><code>def first_n_chars(first_n: int = 36, in_uuid: str = uuid.uuid4(), as_hex: bool = False):\n    \"\"\"Return first n characters of UUID string (where n is first_n).\n\n    Params:\n        first_n (int): trim (int): Number of characters to remove from beginning of UUID string.\n        in_uuid (str): in_uuid (str): An existing UUID `str` to be trimmed/converted to hex.\n        as_hex (bool): as_hex (bool): If `True`, returns a UUID hex (UUID `str` without the `-` characters).\n\n    Returns:\n        (str): A 36 character UUID string\n        (str): A 32 character UUID hex string (a UUID minus the `-` characters)\n\n    Raises:\n        ValueError: If input `first_n` is an invalid number of characters to return, less than 0 or greater than predefined max value (32 for hex, 36 for standard).\n\n    \"\"\"\n    if not isinstance(first_n, int):\n        first_n = int(first_n)\n\n    if as_hex:\n        _max = glob_uuid_lens.hex - 1\n    else:\n        _max = glob_uuid_lens.standard - 1\n\n    if first_n &lt; 0 or first_n &gt; _max:\n        raise ValueError(\n            f\"Invalid number of UUID characters requested: {first_n}. Must be greater than 0 and less than or equal to {_max}.\"\n        )\n\n    ## Return first n characters from beginning of string\n    _uuid: str = str(in_uuid)[0:first_n]\n\n    return _uuid\n</code></pre>"},{"location":"reference/red_utils/std/uuid_utils/operations/#red_utils.std.uuid_utils.operations.gen_uuid","title":"<code>gen_uuid(as_hex=False)</code>","text":"<p>Return a UUID.</p> <p>Nested function to simply return a UUID object.</p> <p>Parameters:</p> Name Type Description Default <code>as_hex</code> <code>bool</code> <p>If True, returns a UUID hex (a UUID without the '-' characters, which is 32 characters instead of 36).</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>A 36 character UUID string</p> <code>str</code> <p>A 32 character UUID hex string (a UUID minus the <code>-</code> characters)</p> Source code in <code>src\\red_utils\\std\\uuid_utils\\operations.py</code> <pre><code>def gen_uuid(as_hex: bool = False) -&gt; Union[str, uuid.UUID]:\n    \"\"\"Return a UUID.\n\n    Nested function to simply return a UUID object.\n\n    Params:\n        as_hex (bool): If True, returns a UUID hex (a UUID without the '-' characters, which is 32 characters instead of 36).\n\n    Returns:\n        (str): A 36 character UUID string\n        (str): A 32 character UUID hex string (a UUID minus the `-` characters)\n\n    \"\"\"\n    if as_hex:\n        hex_uuid = uuid.uuid4().hex\n\n        ## Returns a str\n        return hex_uuid\n\n    _uuid: uuid.UUID = uuid.uuid4()\n\n    ## Returns a UUID\n    return _uuid\n</code></pre>"},{"location":"reference/red_utils/std/uuid_utils/operations/#red_utils.std.uuid_utils.operations.get_rand_uuid","title":"<code>get_rand_uuid(trim=0, characters=0, as_str=True, as_hex=False)</code>","text":"<p>Return a UUID.</p> <p>Parameters:</p> Name Type Description Default <code>trim</code> <code>int</code> <p>Remove <code>n</code> characters from end of string.</p> <code>0</code> <code>characters</code> <code>int</code> <p>Return first <code>n</code> characters from beginning of string.</p> <code>0</code> <code>as_str</code> <code>bool</code> <code>True</code> <code>as_hex</code> <code>bool</code> <p>Return UUID as a hexadecimal (32 chars, UUID without <code>-</code> characters).</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>A 36 character UUID string</p> <code>str</code> <p>A 32 character UUID hex string (a UUID minus the <code>-</code> characters)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If inputs <code>trim</code> or <code>characters</code> are invalid. TODO: Add <code>TypeErrors</code> too</p> Source code in <code>src\\red_utils\\std\\uuid_utils\\operations.py</code> <pre><code>def get_rand_uuid(\n    trim: int = 0, characters: int = 0, as_str: bool = True, as_hex: bool = False\n) -&gt; Union[str, uuid.UUID]:\n    \"\"\"Return a UUID.\n\n    Params:\n        trim (int): Remove `n` characters from end of string.\n        characters (int): Return first `n` characters from beginning of string.\n        as_str (bool):\n        as_hex (bool): Return UUID as a hexadecimal (32 chars, UUID without `-` characters).\n\n    Returns:\n        (str): A 36 character UUID string\n        (str): A 32 character UUID hex string (a UUID minus the `-` characters)\n\n    Raises:\n        ValueError: If inputs `trim` or `characters` are invalid. TODO: Add `TypeErrors` too\n\n    \"\"\"\n    if isinstance(trim, int) and isinstance(characters, int):\n        if trim &gt; 0 and characters &gt; 0:\n            raise ValueError(\n                \"Cannot pass both a trim value and a characters value, please use one or the other.\"\n            )\n    elif not isinstance(trim, int) and isinstance(characters, int):\n        raise ValueError(\"Trim value must be an int\")\n    elif isinstance(trim, int) and not isinstance(characters, int):\n        raise ValueError(\"Characters value must be an int\")\n    else:\n        raise ValueError(\"Trim and Characters values must be int\")\n\n    ## Generate a UUID. Returns a 36 char string, or 32 char if as_hex is set\n    _uuid: uuid.UUID = gen_uuid(as_hex=as_hex)\n\n    # if as_hex:\n    trim = validate_trim(trim_in=trim, as_hex=as_hex)\n\n    if characters &gt; 0:\n        characters = validate_characters(characters_in=characters, as_hex=as_hex)\n\n    if trim:\n        _uuid: str = trim_uuid(trim=trim, in_uuid=_uuid, as_hex=as_hex)\n\n    if characters:\n        _uuid: str = first_n_chars(first_n=characters, in_uuid=_uuid, as_hex=as_hex)\n\n    ## If as_str was passed, convert UUID to string\n    if as_str:\n        _uuid: str = str(_uuid)\n\n    return _uuid\n</code></pre>"},{"location":"reference/red_utils/std/uuid_utils/operations/#red_utils.std.uuid_utils.operations.trim_uuid","title":"<code>trim_uuid(trim=0, in_uuid=uuid.uuid4(), as_hex=False)</code>","text":"<p>Trim UUID string, removing n characters from end of string (where n is value of trim).</p> <p>Parameters:</p> Name Type Description Default <code>trim</code> <code>int</code> <p>Number of characters to remove from end of UUID string.</p> <code>0</code> <code>in_uuid</code> <code>str</code> <p>An existing UUID <code>str</code> to be trimmed/converted to hex.</p> <code>uuid4()</code> <code>as_hex</code> <code>bool</code> <p>If <code>True</code>, returns a UUID hex (UUID <code>str</code> without the <code>-</code> characters).</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>A 36 character UUID string</p> <code>str</code> <p>A 32 character UUID hex string (a UUID minus the <code>-</code> characters)</p> Source code in <code>src\\red_utils\\std\\uuid_utils\\operations.py</code> <pre><code>def trim_uuid(trim: int = 0, in_uuid: str = uuid.uuid4(), as_hex: bool = False) -&gt; str:\n    \"\"\"Trim UUID string, removing n characters from end of string (where n is value of trim).\n\n    Params:\n        trim (int): Number of characters to remove from end of UUID string.\n        in_uuid (str): An existing UUID `str` to be trimmed/converted to hex.\n        as_hex (bool): If `True`, returns a UUID hex (UUID `str` without the `-` characters).\n\n    Returns:\n        (str): A 36 character UUID string\n        (str): A 32 character UUID hex string (a UUID minus the `-` characters)\n\n    \"\"\"\n    ## Set max character count\n    ## Attempt to convert inputs value to integer\n    if not isinstance(trim, int):\n        trim = int(trim)\n\n    if as_hex:\n        _max = glob_uuid_lens.hex - 1\n    else:\n        _max = glob_uuid_lens.standard - 1\n\n    ## Validate trim/characters\n    if trim &lt; 0 or trim &gt; _max:\n        raise ValueError(\n            f\"Invalid trim length: {trim}. Must be greater than 0 and less than {_max} ({_max -1}).\"\n        )\n\n    ## Trim n characters from end of string\n    _uuid: str = str(in_uuid)[:-trim]\n\n    return _uuid\n</code></pre>"},{"location":"reference/red_utils/std/uuid_utils/operations/#red_utils.std.uuid_utils.operations.validate_characters","title":"<code>validate_characters(characters_in=0, as_hex=False)</code>","text":"<p>Validate a characters value.</p> <p>Parameters:</p> Name Type Description Default <code>characters_in</code> <code>int</code> <p>Integer value passed from another function</p> <code>0</code> <code>as_hex</code> <code>int</code> <p>Bool value passed from another function</p> <code>False</code> <p>Raises:</p> Type Description <code>Exception</code> <p>When attempting to convert <code>characters_in</code> value to an <code>int</code> fails.</p> <code>ValueError</code> <p>When <code>trim_in</code> is less than 0, or greater than the length of a UUID string/hex (36/32 characters).</p> Source code in <code>src\\red_utils\\std\\uuid_utils\\validators.py</code> <pre><code>def validate_characters(characters_in: int = 0, as_hex: bool = False) -&gt; int:\n    \"\"\"Validate a characters value.\n\n    Params:\n        characters_in (int): Integer value passed from another function\n        as_hex (int): Bool value passed from another function\n\n    Raises:\n        Exception: When attempting to convert `characters_in` value to an `int` fails.\n        ValueError: When `trim_in` is less than 0, or greater than the length of a UUID string/hex (36/32 characters).\n\n    \"\"\"\n    if not isinstance(characters_in, str):\n        try:\n            characters_in = int(characters_in)\n        except Exception as exc:\n            raise Exception(\n                f\"Unhandled exception converting characters value to int. Errored on converting int (type: {type(characters_in)}): {characters_in}. Details: {exc}\"\n            )\n\n    if as_hex:\n        ## Set length of UUID hex string (without '-' characters)\n        uuid_len: int = glob_uuid_lens.hex\n\n        ## If characters_in is greater than uuid_len, set trim to max number of characters\n        if characters_in &gt; uuid_len:\n            characters_in = uuid_len\n\n    else:\n        uuid_len: int = glob_uuid_lens.standard\n\n        if characters_in &gt; uuid_len:\n            raise ValueError(\n                f\"Character count must be less than UUID string length ({uuid_len})\"\n            )\n\n    if not characters_in &gt;= 0:\n        raise ValueError(f\"Trim value must be 0 or greater.\")\n\n    if characters_in &gt;= uuid_len:\n        exc_msg: str = (\n            f\"Trim value must be less than {uuid_len}. At least 1 character must be returned.\"\n        )\n\n        if as_hex:\n            exc_msg: str = (\n                f\"{exc_msg} Note that a hexadecimal UUID string is only {glob_uuid_lens.hex} characters because of the missing '-' characters.\"\n            )\n\n        raise ValueError(exc_msg)\n\n    return characters_in\n</code></pre>"},{"location":"reference/red_utils/std/uuid_utils/operations/#red_utils.std.uuid_utils.operations.validate_trim","title":"<code>validate_trim(trim_in=0, as_hex=False)</code>","text":"<p>Validate a trim value.</p> <p>Parameters:</p> Name Type Description Default <code>trim_in</code> <code>int</code> <p>Value of <code>trim</code> passed from another function.</p> <code>0</code> <code>as_hex</code> <code>bool</code> <p>Value of <code>as_hex</code> passed from another function.</p> <code>False</code> <p>Returns:</p> Type Description <code>int</code> <p>A validated <code>int</code></p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When <code>trim_in</code> is less than 0, or greater than the length of a UUID string/hex (36/32 characters).</p> Source code in <code>src\\red_utils\\std\\uuid_utils\\validators.py</code> <pre><code>def validate_trim(trim_in: int = 0, as_hex: bool = False) -&gt; int:\n    \"\"\"Validate a trim value.\n\n    Params:\n        trim_in (int): Value of `trim` passed from another function.\n        as_hex (bool): Value of `as_hex` passed from another function.\n\n    Returns:\n        (int): A validated `int`\n\n    Raises:\n        ValueError: When `trim_in` is less than 0, or greater than the length of a UUID string/hex (36/32 characters).\n\n    \"\"\"\n    if not isinstance(trim_in, int):\n        ## If trim_in is not an int, try converting to one\n        try:\n            trim_in = int(trim_in)\n        except Exception as exc:\n            raise Exception(\n                f\"Unhandled exception converting trim value to int. Errored on converting input (type: {type(trim_in)}): {trim_in}. Details: {exc}\"\n            )\n\n    if as_hex:\n        ## Set length of UUID hex string (without '-' characters)\n        uuid_len: int = glob_uuid_lens.hex\n    else:\n        ## Set length of UUID to standard 36 characters\n        uuid_len: int = glob_uuid_lens.standard\n\n    if not trim_in &gt;= 0:\n        raise ValueError(f\"Trim value must be 0 or greater.\")\n\n    ## Check that trim_in does not exceed length of UUID string\n    if trim_in &gt;= uuid_len:\n        exc_msg: str = (\n            f\"Trim value must be less than {uuid_len}. At least 1 character must be returned.\"\n        )\n\n        if as_hex:\n            exc_msg: str = (\n                f\"{exc_msg} Note that a hexadecimal UUID string is only 32 characters because of the missing '-' characters.\"\n            )\n\n        raise ValueError(exc_msg)\n\n    return trim_in\n</code></pre>"},{"location":"reference/red_utils/std/uuid_utils/validators/","title":"validators","text":""},{"location":"reference/red_utils/std/uuid_utils/validators/#red_utils.std.uuid_utils.validators.UUIDLength","title":"<code>UUIDLength</code>  <code>dataclass</code>","text":"<p>Simple dataclass to store UUID string lengths.</p> <p>When setting the length of a string, you can use something like UUID().standard to pass these pre-defined values.</p> <p>Parameters:</p> Name Type Description Default <code>standard</code> <code>int</code> <p>The number of characters expected in a standard UUID string</p> <code>36</code> <code>hex</code> <code>int</code> <p>The number of characters expeceted in a UUID hex string</p> <code>32</code> Source code in <code>src\\red_utils\\std\\uuid_utils\\classes.py</code> <pre><code>@dataclass\nclass UUIDLength:\n    \"\"\"Simple dataclass to store UUID string lengths.\n\n    When setting the length of a string, you can use something like UUID().standard to pass these pre-defined values.\n\n    Args:\n        standard (int): The number of characters expected in a standard UUID string\n        hex (int): The number of characters expeceted in a UUID hex string\n\n    \"\"\"\n\n    standard: int = 36\n    hex: int = 32\n</code></pre>"},{"location":"reference/red_utils/std/uuid_utils/validators/#red_utils.std.uuid_utils.validators.validate_characters","title":"<code>validate_characters(characters_in=0, as_hex=False)</code>","text":"<p>Validate a characters value.</p> <p>Parameters:</p> Name Type Description Default <code>characters_in</code> <code>int</code> <p>Integer value passed from another function</p> <code>0</code> <code>as_hex</code> <code>int</code> <p>Bool value passed from another function</p> <code>False</code> <p>Raises:</p> Type Description <code>Exception</code> <p>When attempting to convert <code>characters_in</code> value to an <code>int</code> fails.</p> <code>ValueError</code> <p>When <code>trim_in</code> is less than 0, or greater than the length of a UUID string/hex (36/32 characters).</p> Source code in <code>src\\red_utils\\std\\uuid_utils\\validators.py</code> <pre><code>def validate_characters(characters_in: int = 0, as_hex: bool = False) -&gt; int:\n    \"\"\"Validate a characters value.\n\n    Params:\n        characters_in (int): Integer value passed from another function\n        as_hex (int): Bool value passed from another function\n\n    Raises:\n        Exception: When attempting to convert `characters_in` value to an `int` fails.\n        ValueError: When `trim_in` is less than 0, or greater than the length of a UUID string/hex (36/32 characters).\n\n    \"\"\"\n    if not isinstance(characters_in, str):\n        try:\n            characters_in = int(characters_in)\n        except Exception as exc:\n            raise Exception(\n                f\"Unhandled exception converting characters value to int. Errored on converting int (type: {type(characters_in)}): {characters_in}. Details: {exc}\"\n            )\n\n    if as_hex:\n        ## Set length of UUID hex string (without '-' characters)\n        uuid_len: int = glob_uuid_lens.hex\n\n        ## If characters_in is greater than uuid_len, set trim to max number of characters\n        if characters_in &gt; uuid_len:\n            characters_in = uuid_len\n\n    else:\n        uuid_len: int = glob_uuid_lens.standard\n\n        if characters_in &gt; uuid_len:\n            raise ValueError(\n                f\"Character count must be less than UUID string length ({uuid_len})\"\n            )\n\n    if not characters_in &gt;= 0:\n        raise ValueError(f\"Trim value must be 0 or greater.\")\n\n    if characters_in &gt;= uuid_len:\n        exc_msg: str = (\n            f\"Trim value must be less than {uuid_len}. At least 1 character must be returned.\"\n        )\n\n        if as_hex:\n            exc_msg: str = (\n                f\"{exc_msg} Note that a hexadecimal UUID string is only {glob_uuid_lens.hex} characters because of the missing '-' characters.\"\n            )\n\n        raise ValueError(exc_msg)\n\n    return characters_in\n</code></pre>"},{"location":"reference/red_utils/std/uuid_utils/validators/#red_utils.std.uuid_utils.validators.validate_trim","title":"<code>validate_trim(trim_in=0, as_hex=False)</code>","text":"<p>Validate a trim value.</p> <p>Parameters:</p> Name Type Description Default <code>trim_in</code> <code>int</code> <p>Value of <code>trim</code> passed from another function.</p> <code>0</code> <code>as_hex</code> <code>bool</code> <p>Value of <code>as_hex</code> passed from another function.</p> <code>False</code> <p>Returns:</p> Type Description <code>int</code> <p>A validated <code>int</code></p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When <code>trim_in</code> is less than 0, or greater than the length of a UUID string/hex (36/32 characters).</p> Source code in <code>src\\red_utils\\std\\uuid_utils\\validators.py</code> <pre><code>def validate_trim(trim_in: int = 0, as_hex: bool = False) -&gt; int:\n    \"\"\"Validate a trim value.\n\n    Params:\n        trim_in (int): Value of `trim` passed from another function.\n        as_hex (bool): Value of `as_hex` passed from another function.\n\n    Returns:\n        (int): A validated `int`\n\n    Raises:\n        ValueError: When `trim_in` is less than 0, or greater than the length of a UUID string/hex (36/32 characters).\n\n    \"\"\"\n    if not isinstance(trim_in, int):\n        ## If trim_in is not an int, try converting to one\n        try:\n            trim_in = int(trim_in)\n        except Exception as exc:\n            raise Exception(\n                f\"Unhandled exception converting trim value to int. Errored on converting input (type: {type(trim_in)}): {trim_in}. Details: {exc}\"\n            )\n\n    if as_hex:\n        ## Set length of UUID hex string (without '-' characters)\n        uuid_len: int = glob_uuid_lens.hex\n    else:\n        ## Set length of UUID to standard 36 characters\n        uuid_len: int = glob_uuid_lens.standard\n\n    if not trim_in &gt;= 0:\n        raise ValueError(f\"Trim value must be 0 or greater.\")\n\n    ## Check that trim_in does not exceed length of UUID string\n    if trim_in &gt;= uuid_len:\n        exc_msg: str = (\n            f\"Trim value must be less than {uuid_len}. At least 1 character must be returned.\"\n        )\n\n        if as_hex:\n            exc_msg: str = (\n                f\"{exc_msg} Note that a hexadecimal UUID string is only 32 characters because of the missing '-' characters.\"\n            )\n\n        raise ValueError(exc_msg)\n\n    return trim_in\n</code></pre>"}]}